[[["index.html","Ch1.html","Ch1.S1.html"],"1.1 Espa√ßos mensur√°veis ‚Ä£ Cap√≠tulo 1 Fundamentos ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Espa√ßos mensur√°veis 1.1 Espa√ßos mensur√°veis Denotaremos sempre por \\Omega o nosso espa√ßo amostral (a princ√≠pio qualquer conjunto). Um ponto nesse espa√ßo corresponde por exemplo a um poss√≠vel resultado do nosso experimento aleat√≥rio. {example} Poss√≠veis exemplos de espa√ßo amostral ‚ÄÉa)‚Äã \\Omega_{1}=\\{1,2,\\dots,6\\} , ‚ÄÉb)‚Äã \\Omega_{2}=\\mathbb{R}_{+} , ‚ÄÉc)‚Äã \\Omega_{3}=\\{f:[0,1]\\to\\mathbb{R};\\text{$f$ \\'{e} cont\\'{\\i}nua}\\} . Os exemplos acima poderiam ser usados em modelar por exemplo: o resultado de um dado, o volume anual de chuva em uma cidade e o comportamento ao longo do dia do pre√ßo de uma a√ß√£o na bolsa de valores. Consideraremos sempre \\Omega ‚Äôs equipados com uma \\sigma -√°lgebra denotada por \\mathcal{F} . Mais precisamente {definition} Dizemos que \\mathcal{F}\\subseteq\\mathcal{P}(\\Omega) √© uma \\sigma -√°lgebra se ‚ÄÉa)‚Äã \\Omega\\in\\mathcal{F} , ‚ÄÉb)‚Äã A\\in\\mathcal{F} implica que A^{c}\\in\\mathcal{F} e ‚ÄÉc)‚Äãse A_{1},A_{2},\\dots\\in\\mathcal{F} , ent√£o \\cup_{i}A_{i}\\in\\mathcal{F} . Nesse caso, dizemos que (\\Omega,\\mathcal{F}) √© um espa√ßo mensur√°vel e os elementos A\\in\\mathcal{F} s√£o chamados de eventos. Se \\mathcal{G}\\subseteq\\mathcal{P}(\\Omega) (que chamamos de uma classe ou fam√≠lia), denotamos por \\sigma(\\mathcal{G}) a \\sigma -√°lgebra gerada por \\mathcal{G} , que √© a menor \\sigma -√°lgebra contendo \\mathcal{G} (ou em outras palavras, a interse√ß√£o de todas \\sigma -√°lgebras que cont√©m \\mathcal{G} ). Um exemplo importante √© dado pela \\sigma -√°lgebra de Borel , gerada pelos abertos de uma topologia em \\Omega . {example} T√≠picos exemplos de \\sigma -√°lgebra correspondentes aos espa√ßos amostrais do Exemplo¬†1.1 ‚ÄÉa)‚Äã \\mathcal{F}_{1}=\\mathcal{P}(\\Omega_{1}) , ‚ÄÉb)‚Äã \\mathcal{F}_{2}=\\mathcal{B}([0,1]) e ‚ÄÉc)‚Äã \\mathcal{F}_{3}=\\mathcal{B}(C[0,1]) . {example} Alguns eventos de \\mathcal{F}_{1},\\mathcal{F}_{2} e \\mathcal{F}_{3} acima ‚ÄÉa)‚Äã \\{\\text{$x$ \\'{e} \\'{\\i}mpar}\\},\\{1\\}\\subset\\Omega_{1} , ‚ÄÉb)‚Äã [0,1/2],\\{0\\},(\\mathbb{Q}\\cap[0,1])\\subset\\Omega_{2} e ‚ÄÉc)‚Äã \\{f:[0,1]\\to\\mathbb{R};f(1)>0\\}\\subset\\Omega_{3} . {exercise} Mostre que \\{f:[0,1]\\to\\mathbb{R};f(t)\\geq 0\\text{ para todo $t\\in[0,1]$}\\}\\subset\\Omega_% {3} √© um evento (ou seja, pertence a \\mathcal{F}_{3} ). {notation} Se Q for uma condi√ß√£o qualquer sobre candidatos \\omega\\in\\Omega , escreveremos [\\text{$\\omega$ satisfaz $Q$}] para denotar \\{\\omega\\in\\Omega;\\text{ $\\omega$ satisfaz $Q$}\\} . Por exemplo, \\{f:[0,1]\\to\\mathbb{R};f(1)>0\\} pode ser escrita simplesmente como [f(1)>0] . Previous page Next page"],[["index.html","Ch1.html","Ch1.S2.html"],"1.2 Espa√ßos de probabilidade ‚Ä£ Cap√≠tulo 1 Fundamentos ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Espa√ßos de probabilidade 1.2 Espa√ßos de probabilidade Agora estamos prontos para introduzir o conceito moderno do que √© uma probabilidade. {definition} Dado (\\Omega,\\mathcal{F}) espa√ßo mensur√°vel, dizemos que P:\\mathcal{F}\\to[0,1] √© uma probabilidade se ‚ÄÉa)‚Äã P(\\Omega)=1 e ‚ÄÉb)‚ÄãSeja uma seq√º√™ncia (A_{i})_{i\\in I} finita ou enumer√°vel de eventos disjuntos ( A_{i}\\cap A_{j}=\\varnothing se i\\neq j ), ent√£o P\\big{(}{\\mcup\\nolimits_{i\\in I}}A_{i}\\big{)}=\\sum_{i\\in I}P(A_{i}). (1.1) Obviamente, isso nada mais √© que uma medida que associa massa um ao espa√ßo todo. {example} Probabilidades nos espa√ßos do Exemplo¬†1.1 ‚ÄÉa)‚Äã P_{1}(A)=(\\#A)/6 em (\\Omega_{1},\\mathcal{F}_{1}) . Ou mais geralmente P_{1}^{\\prime}(A)=\\sum_{i\\in A}p_{i} , onde p_{i}\\geq 0 e \\sum_{i}p_{i}=1 . ‚ÄÉb)‚Äã P_{2} pode ser a medida de Lebesgue em ([0,1],\\mathcal{B}([0,1])) . Mais geralmente tamb√©m podemos ter P_{2}^{\\prime}(A)=\\int_{A}\\rho(x)\\d{x} , onde \\rho:[0,1]\\to\\mathbb{R}_{+} √© uma fun√ß√£o mensur√°vel, chamada densidade, tal que \\int_{[0,1]}\\rho(x)\\d{x}=1 . ‚ÄÉc)‚Äã P_{3}=\\delta_{0} , que atribui o valor um se o evento cont√©m a fun√ß√£o identicamente nula ( f\\equiv 0 ) e zero caso contr√°rio. Obviamente o terceiro exemplo √© bastante artificial (e in√∫til). Mas, futuramente, estaremos prontos para introduzir medidas bem interessantes no espa√ßo (\\Omega_{3},\\mathcal{F}_{3}) . {proposition} Valem as afirmativas seguintes ‚ÄÉa)‚ÄãSe A\\subseteq B ent√£o P(A)\\leq P(B) . ‚ÄÉb)‚ÄãA cota da uni√£o: para I finito ou enumer√°vel P\\big{(}\\mcup\\nolimits_{i\\in I}A_{i}\\big{)}\\leq\\smash{\\sum\\limits_{i\\in I}}P(A% _{i}). (1.2) ‚ÄÉc)‚ÄãO que chamamos de princ√≠pio da inclus√£o e exclus√£o P\\big{(}\\mcup\\nolimits_{i=1}^{n}A_{i}\\big{)}=\\smash{\\sum\\limits_{k=1}^{n}}(-1)% ^{k-1}\\sum\\limits_{1\\leq i_{1}<\\dots<i_{k}\\leq n}P(A_{i_{1}}\\cap\\dots\\cap A_{i% _{k}}). (1.3) Demonstra√ß√£o. a) Como A\\cap(B\\setminus A)=\\varnothing , ent√£o P(B)=P(A\\cup(B\\setminus A))=P(A)+P(B\\setminus A)\\geq P(A). (1.4) b) P(A\\cup B)=P(A\\cup(B\\setminus A))=P(A)+P(B\\setminus A)\\leq P(A)+P(B) . Deixamos o caso enumer√°vel como exerc√≠cio abaixo. c) Chamamos de A a uni√£o dos A_{i} . Basta mostrar a validade da equa√ß√£o abaixo e depois integrar com respeito a P . \\1_{A}(\\omega)=\\sum_{k=1}^{n}(-1)^{k-1}\\sum_{\\begin{subarray}{c}I\\subseteq\\{1,% \\dots,n\\}\\\\ |I|=k\\end{subarray}}\\prod_{i\\in I}\\1_{A_{i}}(\\omega). (1.5) Para tanto, observe que para todo \\omega\\in\\Omega , (\\1_{A}-\\1_{A_{1}})\\cdot\\dots\\cdot(\\1_{A}-\\1_{A_{n}})(\\omega)=0. (1.6) Logo, expandindo o produto acima obtemos \\1_{A}+\\sum_{k=1}^{n}\\sum_{\\begin{subarray}{c}I\\subseteq\\{1,\\dots,n\\}\\\\ |I|=k\\end{subarray}}(-1)^{k}\\prod_{i\\in I}\\1_{A_{i}}(\\omega)=0, (1.7) que equivale a (1.5). ‚àé {exercise} Mostre que P\\big{(}\\mcup\\nolimits_{i}A_{i}\\big{)}\\leq\\sum_{i}P(A_{i}) no caso enumer√°vel. {exercise} Mostre que \\begin{split}P\\big{(}\\mcup\\nolimits_{i=1}^{n}A_{i}\\big{)}&\\leq\\sum\\limits_{k=1% }^{m}(-1)^{k-1}\\sum\\limits_{1\\leq i_{1}<\\dots<i_{k}\\leq n}P(A_{i_{1}}\\cap\\dots% \\cap A_{i_{k}})\\text{ se $m$ \\'{e} \\'{\\i}mpar e}\\\\ P\\big{(}\\mcup\\nolimits_{i=1}^{n}A_{i}\\big{)}&\\geq\\sum\\limits_{k=1}^{m}(-1)^{k-% 1}\\sum\\limits_{1\\leq i_{1}<\\dots<i_{k}\\leq n}P(A_{i_{1}}\\cap\\dots\\cap A_{i_{k}% })\\text{ se $m$ \\'{e} par.}\\end{split} {exercise} Seja n\\geq 1 um n√∫mero inteiro e considere \\Omega=\\{0,1\\}^{n} , o hipercubo de dimens√£o n (cada \\omega\\in\\Omega pode ser visto como uma fun√ß√£o \\omega:\\{1,\\dots,n\\}\\to\\{0,1\\} ). Para cada i\\in\\{1,\\dots,n\\} , definimos o evento A_{i}=\\{\\omega\\in\\Omega;\\omega(i)=1\\} . Dadas duas probabilidades P e P^{\\prime} em (\\Omega,\\mathcal{P}(\\Omega)) , mostre que se P(B)=P^{\\prime}(B) para todos conjuntos B dados por interse√ß√µes de A_{i} ‚Äôs, ent√£o P=P^{\\prime} . {proposition} Toda probabilidade P √© cont√≠nua, isto √©: ‚ÄÉa)‚ÄãSe A_{1}\\subseteq A_{2}\\subseteq\\dots\\in\\mathcal{F} for uma sequ√™ncia crescente de eventos, ent√£o \\lim_{n\\to\\infty}P(A_{n})=P(\\mcup\\nolimits_{n=1}^{\\infty}A_{n}) . ‚ÄÉb)‚ÄãTamb√©m, se A_{1}\\supseteq A_{2}\\supseteq\\dots\\in\\mathcal{F} , temos \\lim\\limits_{n\\to\\infty}P(A_{n})=P(\\mcap\\nolimits_{n=1}^{\\infty}A_{n}) . Demonstra√ß√£o. a) Observe que \\mcup_{n=1}^{\\infty}A_{n}=\\mcup_{n=1}^{\\infty}\\Big{(}A_{n}\\setminus\\big{(}% \\mcup_{i=1}^{n-1}A_{i}\\big{)}\\Big{)}, (1.8) que s√£o disjuntos. Logo \\begin{split}P\\big{(}\\mcup\\nolimits_{n=1}^{\\infty}A_{n}\\big{)}&=\\sum_{n=1}^{% \\infty}P\\Big{(}A_{n}\\setminus\\big{(}\\mcup\\nolimits_{i=1}^{n-1}A_{i}\\big{)}\\Big% {)}\\\\ &=\\lim_{n\\to\\infty}P({\\mcup\\nolimits_{i=1}^{n}}A_{i})=\\lim_{n\\to\\infty}P(A_{n}% ).\\end{split} (1.9) b) A prova √© an√°loga √† de (a) . ‚àé {lemma} [Borel-Cantelli - primeira parte] Sejam A_{1},A_{2},\\dots\\in\\mathcal{F} satisfazendo \\sum_{i=1}^{\\infty}P(A_{i})<\\infty . Ent√£o P[\\text{$A_{i}$ para infinitos $i$}]:=P\\big{(}{\\mcap\\nolimits_{n=1}^{\\infty}}(% {\\mcup\\nolimits_{i\\geq n}}A_{i})\\big{)}=0. (1.10) Demonstra√ß√£o. Estimamos P\\Big{(}{\\mcap_{n=1}^{\\infty}}\\big{(}{\\mcup\\nolimits_{i\\geq n}}A_{i}\\big{)}% \\Big{)}=\\lim_{n\\to\\infty}P\\big{(}{\\mcup\\nolimits_{i\\geq n}}A_{i}\\big{)}\\leq% \\lim_{n\\to\\infty}{\\textstyle\\sum\\limits_{i\\geq n}}P(A_{i})=0. (1.11) O que termina a prova do lemma. ‚àé Demonstra√ß√£o. Sejam A_{1},A_{2},\\dots\\in\\mathcal{F} satisfazendo \\sum_{i=1}^{\\infty}P(A_{i})<\\infty , e defina, para n\\geq 1 , f_{n}=\\sum_{k=1}^{n}\\textbf{1}_{A_{k}}, (1.12) de modo que \\big{[}\\text{$A_{i}$ para infinitos $i$}\\big{]}=\\big{[}\\lim_{n}f_{n}=\\infty% \\big{]}. (1.13) Note agora que (f_{n})_{n\\geq 1} forma uma sequ√™ncia mon√≥tona de fun√ß√µes com \\lim_{n}f_{n}=\\sum_{k=1}^{\\infty}\\textbf{1}_{A_{k}} . Em particular, o Teorema da converg√™ncia mon√≥tona implica que \\int\\sum_{k=1}^{\\infty}\\textbf{1}_{A_{k}}=\\lim_{n}\\int f_{n}\\d{P}=\\lim_{n}\\sum% _{k=1}^{n}P(A_{i})=\\sum_{i=1}^{\\infty}P(A_{i})<\\infty. (1.14) Isto nos d√° que P\\big{(}\\lim_{n}f_{n}=\\infty)=0, (1.15) e completa a demonstra√ß√£o. ‚àé Imagine que jogamos todos os dias em uma loteria e que nossa probabilidade de ganhar no dia i √© p_{i} . Ent√£o se \\sum_{i}p_{i}<\\infty , sabemos que certamente n√£o ganharemos infinitas vezes. Previous page Next page"],[["index.html","Ch1.html","Ch1.S3.html"],"1.3 Sistemas ùúÜ-ùúã ‚Ä£ Cap√≠tulo 1 Fundamentos ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Sistemas 1.3 Sistemas \\lambda - \\pi Uma importante ferramenta para provar fatos te√≥ricos sobre probabilidades √© o Teorema de Dynkin que apresentaremos nessa se√ß√£o. Ele trata de classes de eventos que n√£o s√£o necessariamente \\sigma -√°lgebras, mas sistemas \\lambda ou \\pi como definidos abaixo. {definition} Dizemos que uma classe \\mathcal{A}\\subseteq\\mathcal{P}(\\Omega) √© um \\pi -sistema se for fechado por interse√ß√µes finitas, isto √©: para todos A,B\\in\\mathcal{A} temos A\\cap B\\in\\mathcal{A} . {definition} Dizemos que \\mathcal{A}\\subseteq\\mathcal{P}(\\Omega) √© um \\lambda -sistema, se ‚ÄÉa)‚Äã \\Omega\\in\\mathcal{A} , ‚ÄÉb)‚ÄãSempre que A\\in\\mathcal{A} temos A^{c}\\in\\mathcal{A} . ‚ÄÉc)‚ÄãPara A_{1},A_{2},\\dots\\in\\mathcal{A} disjuntos dois a dois, temos \\cup_{i}A_{i}\\in\\mathcal{A} . {exercise} D√™ um exemplo de \\lambda -sistema que n√£o seja uma \\sigma -√°lgebra. Definimos para \\mathcal{A}\\subseteq\\mathcal{P}(\\Omega) , o menor \\lambda -sistema contendo \\mathcal{A} , ou seja, \\lambda(\\mathcal{A})=\\bigcap_{\\begin{subarray}{c}\\text{$\\mathcal{B}$ $\\lambda$% -sistema}\\\\ \\mathcal{A}\\subseteq\\mathcal{B}\\end{subarray}}\\mathcal{B}. (1.16) √â f√°cil ver que \\lambda(\\mathcal{A}) √© sempre um \\lambda -sistema. {theorem} [Dynkin] Se \\mathcal{A} √© um \\pi -sistema, ent√£o \\lambda(\\mathcal{A})=\\sigma(\\mathcal{A}) . Note pelo Exerc√≠cio¬†1.3 que a hip√≥tese de que \\mathcal{A} √© um \\pi -sistema √© necess√°ria em geral. Demonstra√ß√£o. Obviamente, basta mostrar √© que \\lambda(\\mathcal{A}) √© fechado por uni√µes n√£o necessariamente disjuntas. Na verdade, vamos ver que √© suficiente provar que \\lambda(\\mathcal{A})\\text{ \\'{e} um $\\pi$-sistema}. (1.17) De fato, caso isso seja provado teremos que \\lambda(\\mathcal{A}) √© fechado por diferen√ßas (pois A\\setminus B=A\\cap B^{c} ). Assim, podemos mostrar que \\lambda(\\mathcal{A}) √© fechado por uni√µes enumer√°veis, pois se A_{1},A_{2},\\dots\\in\\lambda(\\mathcal{A}) , definimos B_{n}=\\cup_{i=1}^{n}A_{i}=(\\cap_{i=1}^{n}A_{i}^{c})^{c}\\in\\lambda(\\mathcal{A}) e escrevemos \\mcup_{n=1}^{\\infty}A_{n}=\\mcup_{n=1}^{\\infty}\\big{(}A_{n}\\setminus B_{n-1}% \\big{)}, (1.18) que √© uma uni√£o disjunta de termos em \\lambda(\\mathcal{A}) , logo est√° em \\lambda(\\mathcal{A}) . Isso mostra que \\lambda(\\mathcal{A}) √© uma \\sigma -√°lgebra e que de fato √© suficiente demonstrar (1.17). Vamos primeiramente mostrar que \\lambda(\\mathcal{A}) √© fechado por interse√ß√µes com \\mathcal{A} . Para tanto, definimos \\mathcal{B}=\\big{\\{}B\\in\\lambda(\\mathcal{A});\\text{$B\\cap A\\in\\lambda(\\mathcal% {A})$ para todo $A\\in\\mathcal{A}$})\\big{\\}} e veremos que B=\\lambda(\\mathcal{A}). (1.19) Obviamente, \\mathcal{A}\\subseteq\\mathcal{B} , pois \\mathcal{A} √© um \\pi -sistema. Ent√£o basta mostrar que \\mathcal{B} √© um \\lambda -sistema. ‚ÄÉa)‚Äã \\Omega obviamente pertence a \\mathcal{B} . ‚ÄÉb)‚ÄãSe B\\in\\mathcal{B} e A\\in\\mathcal{A} , ent√£o B^{c}\\cap A=A\\setminus(B\\cap A)=(A^{c}\\cup(B\\cap A))^{c} . Mas como B\\in\\mathcal{B} , (B\\cap A)\\in\\lambda(\\mathcal{A}) e usando o fato que \\lambda -sistemas s√£o fechados por complementos e uni√µes disjuntas, B^{c}\\cap A\\in\\lambda(\\mathcal{A}) . Como isso vale para todo A\\in\\mathcal{A} , temos B^{c}\\in\\mathcal{B} por defini√ß√£o. ‚ÄÉc)‚ÄãSe B_{1},B_{2},\\dots\\in\\mathcal{B} s√£o disjuntos e A\\in\\mathcal{A} , ent√£o \\big{(}\\mcup\\nolimits_{n=1}^{\\infty}B_{n}\\big{)}\\cap A=\\mcup_{n=1}^{\\infty}% \\big{(}B_{n}\\cup A\\big{)}\\in\\lambda(\\mathcal{A}), (1.20) pois a uni√£o acima √© disjunta. Logo \\mcup_{n=1}^{\\infty}B_{n}\\in\\mathcal{B} . Isso mostra que \\mathcal{B} √© um \\lambda -sistema com \\mathcal{A}\\subseteq\\mathcal{B}\\subseteq\\lambda(\\mathcal{A}) , mostrando (1.19). No pr√≥ximo passo, definimos \\bar{\\mathcal{B}}=\\{A\\in\\lambda(A);\\text{$B\\cap A\\in\\lambda(A),\\;\\forall B\\in% \\lambda(A)$}\\} e mostraremos que \\bar{\\mathcal{B}}=\\lambda(\\mathcal{A}), (1.21) que vai na dire√ß√£o de provar (1.17). Primeiramente, observe que \\mathcal{A}\\subseteq\\bar{\\mathcal{B}} pois \\mathcal{B}=\\lambda(\\mathcal{A}) (veja a defini√ß√£o de \\mathcal{B} ). Mostraremos agora que \\text{$\\bar{\\mathcal{B}}$ \\'{e} um $\\lambda$-sistema}. (1.22) Para tanto, verificaremos ‚ÄÉa)‚Äã \\Omega\\in\\bar{\\mathcal{B}} , que √© claro. ‚ÄÉb)‚ÄãTomando A\\in\\bar{\\mathcal{B}} e B\\in\\lambda(\\mathcal{A}) , A^{c}\\cap B=B\\setminus(A\\cap B)=\\big{(}B^{c}\\cup(A\\cap B)\\big{)}^{c}\\in\\lambda% (\\mathcal{A}) , por um argumento an√°logo ao apresentado para \\mathcal{B} . Logo A^{c}\\in\\bar{\\mathcal{B}} . ‚ÄÉc)‚ÄãTamb√©m o caso de uni√µes disjuntas √© bastante an√°logo ao feito para \\mathcal{B} . Isso mostra que \\bar{\\mathcal{B}} √© um \\lambda -sistema com \\mathcal{A}\\subseteq\\bar{\\mathcal{B}}\\subseteq\\lambda(\\mathcal{A}) , estabelecendo (1.22). Finalmente mostraremos que \\lambda(\\mathcal{A}) √© um \\pi -sistema. De fato, dado A\\in\\lambda(\\mathcal{A}) , segue da igualdade \\bar{\\mathcal{B}}=\\lambda(\\mathcal{A}) que A\\cap B\\in\\lambda(\\mathcal{A}) , para todo B\\in\\lambda(\\mathcal{A}) . Logo estabelecemos (1.17), terminando a prova do teorema. ‚àé 1.3.1 Igualdade de probabilidades {proposition} Se P_{1} e P_{2} s√£o probabilidades em (\\Omega,\\mathcal{F}) , tais que P_{1}(A)=P_{2}(A) para todo A\\in\\mathcal{A} e \\mathcal{A} √© um \\pi -sistema, ent√£o P_{1}(B)=P_{2}(B) para todo B\\in\\sigma(\\mathcal{A}) . Demonstra√ß√£o. Seja \\mathcal{B}=\\{A\\in\\mathcal{F};P_{1}(A)=P_{2}(A)\\} . √â f√°cil ver que \\mathcal{B} √© um \\lambda -sistema. Logo \\mathcal{B} cont√©m \\lambda(\\mathcal{A}) que √© igual a \\sigma(\\mathcal{A}) por Dynkin. ‚àé {corollary} Se P_{1} e P_{2} s√£o probabilidades em (\\Omega_{1}\\times\\Omega_{2},\\mathcal{F}_{1}\\otimes\\mathcal{F}_{2}) , tais que P_{1}(A_{1}\\times A_{2})=P_{2}(A_{1}\\times A_{2}),\\text{ para todos $A_{1}\\in% \\mathcal{F}_{1}$, $A_{2}\\in\\mathcal{F}_{2}$,} (1.23) ent√£o P_{1}=P_{2} . Demonstra√ß√£o. Obviamente as caixas do tipo A_{1}\\times A_{2} formam um \\pi -sistema que gera \\mathcal{F}_{1}\\otimes\\mathcal{F}_{2} (por defini√ß√£o). ‚àé {example} Observe portanto que √© importante que \\mathcal{A} seja um \\pi -sistema na Proposi√ß√£o¬†1.3.1. Imagine por exemplo que \\Omega=\\{0,1\\}^{2} e P_{1}=\\tfrac{1}{4}\\sum_{x\\in\\Omega}\\delta_{x} e P_{2}=\\tfrac{1}{2}(\\delta_{(0,0)}+\\delta_{(1,1)}) . Nesse caso P_{1}(A)=P_{2}(A)=1/2=P_{1}(B)=P_{2}(B), (1.24) com A=\\{(0,0),(0,1)\\} e B=\\{(0,0),(1,0)\\} . Contudo, P_{1}\\neq P_{2} , mesmo tendo \\mathcal{P}(\\Omega)=\\sigma(\\{A,B\\}) . Previous page Next page"],[["index.html","Ch1.html","Ch1.S4.html"],"1.4 Elementos aleat√≥rios ‚Ä£ Cap√≠tulo 1 Fundamentos ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Elementos aleat√≥rios 1.4 Elementos aleat√≥rios Muitas vezes n√£o estamos interessados no resultado exato do nosso experimento aleat√≥rio, mas sim em uma determinada medi√ß√£o ou fun√ß√£o de \\omega\\in\\Omega . Por exemplo, no caso do Exemplo¬†1.1 c) , talvez n√£o nos interesse toda a fun√ß√£o f , mas apenas o seu valor no fim do dia f(1) . Essas medi√ß√µes s√£o ditas elementos aleat√≥rios que definimos √† seguir. Seja (E,\\mathcal{A}) um espa√ßo mensur√°vel. Nesse caso, se X:\\Omega\\to E √© uma fun√ß√£o (\\mathcal{F},\\mathcal{A}) -mensur√°vel, dizemos que X √© um elemento aleat√≥rio em (\\Omega,\\mathcal{F}) tomando valores em E , ou um E -elemento aleat√≥rio. {example} Consideramos os casos ‚ÄÉa)‚Äã X:\\Omega\\to\\mathbb{R} mensur√°vel √© dita vari√°vel aleat√≥ria. ‚ÄÉb)‚Äã X:\\Omega\\to\\mathbb{R}^{d} mensur√°vel √© dito vetor aleat√≥rio ( d -dimensional). ‚ÄÉc)‚Äã X:\\Omega\\to C[0,1] mensur√°vel √© dita fun√ß√£o aleat√≥ria. Seguindo a motiva√ß√£o do Exemplo¬†1.1 c) , poderia ser que, por exemplo, estiv√©ssemos interessados apenas na vari√°vel aleat√≥ria X:\\Omega_{3}\\to\\mathbb{R} dada por X(f)=f(1) . {exercise} Mostre que X:\\Omega_{3}\\to\\mathbb{R} dada por X(f)=f(1) √© uma vari√°vel aleat√≥ria. Citando Kingman em seu livro Poisson Processes: ‚Äúa random elephant is a function from \\Omega into a suitable space of elephants.‚Äù Relembrando a nossa nota√ß√£o: P[X\\in A]=P(\\{\\omega\\in\\Omega;X(\\omega)\\in A\\}) . {proposition} Seja X:\\Omega\\to E onde (E,\\mathcal{A}) √© um espa√ßo mensur√°vel com \\mathcal{A}=\\sigma(\\mathcal{G}) . Ent√£o para verificar que X √© um elemento aleat√≥rio, basta provar que X^{-1}(G)\\in\\mathcal{F} para todo G\\in\\mathcal{G} . Demonstra√ß√£o. Teoria da Medida. ‚àé {example} Se \\Omega e E s√£o espa√ßos topol√≥gicos dotados das correspondentes \\sigma -√°lgebras de Borel, ent√£o toda fun√ß√£o cont√≠nua √© um E -elemento aleat√≥rio. 1.4.1 Distribui√ß√£o de elementos aleat√≥rios {definition} Se X:\\Omega\\to E √© um elemento aleat√≥rio e \\Omega √© dotado de uma probabilidade P , ent√£o denotamos por X_{*}P , a chamada distribui√ß√£o de X , a medida de probabilidade X_{*}P(A):=P\\big{(}\\{\\omega\\in\\Omega;X(\\omega)\\in A\\}\\big{)}=P[X\\in A]. (1.25) no espa√ßo mensur√°vel (E,\\mathcal{A}) . {remark} Essa defini√ß√£o corresponde com a de medida imagem vista no curso de integra√ß√£o que tem um papel ainda mais importante em probabilidade. Fica como exerc√≠cio verificar que X_{*}P √© de fato uma probabilidade em E . {exercise} Seja X:[0,1]\\to\\{0,1\\} dada por X(\\omega)=\\1_{A}(\\omega) . Nesse caso, mostre que X_{*}P=\\Ber(p) para algum p\\in[0,1] . Calcule o valor de p . Duas nota√ß√µes importantes nesse contexto s√£o: ‚ÄÉa)‚ÄãSejam (\\Omega,\\mathcal{F},P) e (\\Omega^{\\prime},\\mathcal{F}^{\\prime},P^{\\prime}) dois espa√ßos de probabilidade e X e Y dois elementos aleat√≥rios. Dizemos que X\\stackrel{{\\scriptstyle d}}{{=}}Y , quando X_{*}P=Y_{*}P^{\\prime} . Note que X e Y nem ao menos precisam pertencer ao mesmo espa√ßo de probabilidade para dizermos que s√£o igualmente distribu√≠dos, mas precisam ser elementos aleat√≥rios de mesmo tipo (ou seja, possuir o mesmo contradom√≠nio). ‚ÄÉb)‚ÄãEscrevemos X\\distr\\mu , que l√™-se X √© distribu√≠da como \\mu , onde \\mu √© uma probabilidade em E , caso X_{*}P=\\mu . {exercise} Sejam X e Y vari√°veis aleat√≥rias tais que X √© nula quase certamente. Mostre que X+Y tem a mesma distribui√ß√£o de Y . O exerc√≠cio acima √© bastante simples, mas o usaremos para fazer uma importante observa√ß√£o sobre como s√£o enunciados tipicamente os resultados de probabilidade. Raramente encontramos teoremas que explicitam qual √© o espa√ßo de probabilidades \\Omega em quest√£o. Como no exerc√≠cio acima, o contexto de um teorema frequentemente √© dado apenas em termos de elementos aleat√≥rios em \\Omega e de suas distribui√ß√µes. Dessa forma, podemos utilizar o resultado em v√°rios contextos diferentes, desde que possamos encontrar elementos aleat√≥rios que satisfa√ßam as hip√≥teses. Com o tempo, passamos at√© mesmo a considerar menos relevante a escolha espec√≠fica do espa√ßo amostral, focando cada vez mais na distribui√ß√£o de seus elementos aleat√≥rios. Previous page Next page"],[["index.html","Ch1.html","Ch1.Sx1.html"],"T√≥pico: O paradoxo de Bertrand ‚Ä£ Cap√≠tulo 1 Fundamentos ‚Ä£ Notas de aula: Probabilidade I","Skip to content. T√≥pico: O paradoxo de Bertrand T√≥pico: O paradoxo de Bertrand Vamos estudar um problema que real√ßa a import√¢ncia do jeito em que escolhemos o espa√ßo amostral. Queremos calcular a probabilidade que uma corda ‚Äúuniformemente distribuida‚Äù em um c√≠rculo seja maior do que o lado do tri√¢ngulo equil√°tero inscrito nesse c√≠rculo (no caso do c√≠rculo unit√°rio, o comprimento desse lado vale \\sqrt{3} ). Bertrand prop√¥s dois m√©todos para realizar esse c√°lculo. 11 1 Somos gratos a Hubert Lacoin por sugerir e redigir esse t√≥pico. ‚ÄÉa)‚ÄãEscolher as duas extremidades da corda uniformemente no c√≠rculo. ‚ÄÉb)‚ÄãEscolher o centro da corda uniformemente no interior do disco. No caso a) , uma vez que uma extremidade √© fixada, o comprimento da corda fica maior do que \\sqrt{3} somente se o segundo ponto ficar num setor angular de comprimento 2\\pi/3 . Logo, essa probabilidade vale (2\\pi/3)/(2\\pi)=1/3 . No caso b) , pra que a corda fique maior do que \\sqrt{3} , o centro dela deve ficar no circulo inscrito dentro do tri√¢ngulo equil√°tero, cujo raio √© 1/2 . Ent√£o a probabilidade vale a raz√£o dessas √°reas, que √© 1/4 . Obtemos ent√£o duas respostas diferentes para essa pergunta simples, o que n√£o √© nada surpreendente: a) e b) correspondem a dois experimentos diferentes com espa√ßos amostrais diferentes. {exercise} ‚ÄÉa)‚ÄãDescreva o espa√ßo amostral e as lei de probabilidade associadas aos experimentos a) e b) ‚ÄÉb)‚ÄãCalcule a lei de probabilidade do comprimento da corda em cada caso. ‚ÄÉc)‚ÄãRepita os √≠tens anteriores para o seguinte caso: Escolhemos uniformemente um raio do disco. Depois escolhemos o centro da corda uniformemente ao longo desse raio. Previous page Next page"],[["index.html","Ch1.html"],"Cap√≠tulo 1 Fundamentos ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Fundamentos Cap√≠tulo 1 Fundamentos A probabilidade moderna se baseia fortemente na Teoria da Medida e supomos durante esse curso que o leitor esteja bem familiarizado com conceitos tais como: Medida de Lebesgue, extens√µes de medida e teoremas de converg√™ncia. Iremos agora justificar brevemente a escolha da Teoria da Medida para o estudo de probabilidade. No in√≠cio da Teoria da Probabilidade, a maioria dos fen√¥menos estudados apresentava apenas um n√∫mero finito de resultados poss√≠veis, como por exemplo ao se jogar um dado de seis lados ou sortear uma carta em um baralho. Em tais casos √© desnecess√°rio o uso de ferramentas sofisticadas pra modelar tais situa√ß√µes. Por exemplo, podemos simplesmente dizer que a probabilidade de se obter cada um dos lados do dado √© igual a 1/6 . Mas digamos por exemplo que queremos um modelo para estudar o volume de chuva em uma cidade durante um ano. Obviamente, esse volume poderia ser qualquer n√∫mero real positivo e n√£o podemos simplesmente atribuir valores positivos de probabilidade a cada n√∫mero real (lembramos que somas n√£o enumer√°veis de termos positivos s√£o sempre infinitas). Mas como podemos continuar nossa modelagem se nem ao menos podemos dizer qual √© a probabilidade de chover um determinado volume esse ano, por exemplo (\\pi/19)mm ? A solu√ß√£o para tal dilema, se baseia no fato de que na verdade nunca estamos interessados no exato resultado do nosso experimento. Gostar√≠amos sim de responder perguntas do tipo: qual √© a probabilidade de que chova entre zero e 37mm ? Estamos portanto interessados em atribuir probabilidades n√£o a valores exatos do experimento, mas a certos conjuntos de poss√≠veis valores. Chamamos tais conjuntos de eventos. Voltando ao caso do dado de seis lados, poder√≠amos nos interessar por exemplo pela probabilidade dos seguintes eventos: o lado sorteado foi √≠mpar ( P(\\{1,3,5\\})=1/2 ) ou o lado serteado foi dois ( P(\\{2\\})=1/6 ). E percebemos rapidamente que para eventos disjuntos a probabilidade de sua uni√£o √© a soma de suas probabilidades (no caso acima, P(\\{1,2,3,5\\})=1/2+1/6=2/3 ). Esse car√°ter aditivo da probabilidade certamente nos remete aos conceitos b√°sicos de Teoria da Medida. Vamos agora formalizar a discuss√£o acima com mais calma, sob a √≥tica dessa teoria. Previous page Next page"],[["index.html","Ch2.html","Ch2.S1.html"],"2.1 Caso enumer√°vel ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Caso enumer√°vel 2.1 Caso enumer√°vel Quando \\Omega √© finito ou enumer√°vel, tipicamente definimos sobre \\Omega a \\sigma -√°lgebra das partes, ou seja \\mathcal{F}=\\mathcal{P}(\\Omega)=\\sigma(\\{\\omega\\}_{\\omega\\in\\Omega}) . Al√©m disso podemos definir probabilidades sobre (\\Omega,\\mathcal{F}) de maneira simples tomando (p_{\\omega})_{\\omega\\in\\Omega} tais que ‚ÄÉa)‚Äã p_{\\omega}\\geq 0 para todo \\omega\\in\\Omega e ‚ÄÉb)‚Äã \\sum_{\\omega\\in\\Omega}p_{\\omega}=1 . De fato, nesse caso definimos P(A)=\\sum_{\\omega\\in A}p_{\\omega} que claramente define uma probabilidade. {exercise} Mostre que se \\Omega √© finito ou enumer√°vel, toda probabilidade sobre (\\Omega,\\mathcal{P}(\\Omega)) √© dada como na descri√ß√£o acima. {example} ‚ÄÉa)‚ÄãDado p\\in[0,1] , definimos a medida \\Ber(p) (em homenagem a Bernoulli) em \\{0,1\\} com p_{1}=p,p_{0}=1-p . ‚ÄÉb)‚ÄãDados n\\geq 1 e p\\in[0,1] , definimos a medida \\Bin(n,p) (binomial) em \\Omega=\\{0,1,\\dots,n\\} com p_{i}=\\binom{n}{i}p^{i}(1-p)^{n-i},\\text{ para $i\\in\\Omega$.} (2.1) ‚ÄÉc)‚ÄãDado p\\in(0,1] , em \\Omega=\\{0,1,\\dots\\} definimos a medida \\Geo(p) (geom√©trica) em \\Omega induzida pelos pesos p_{i}=(1-p)^{i}p,\\text{ para $i\\geq 1$.} (2.2) {exercise} Seja \\Omega=\\{0,1\\}^{n} e p_{\\omega}=\\tfrac{1}{2^{n}} para todo \\omega\\in\\Omega (ou seja a probabilidade uniforme). Considere X:\\Omega\\to\\{0,1,\\dots,n\\} dada por X(\\omega_{1},\\dots,\\omega_{n})=\\sum_{i=1}^{n}\\omega_{i} . Obtenha a distribui√ß√£o P_{X} . D√™ um exemplo de medida em \\omega para a qual a distribui√ß√£o de X seja \\Bin(n,p) . Previous page Next page"],[["index.html","Ch2.html","Ch2.S10.html"],"2.10 Espa√ßos can√¥nicos ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Espa√ßos can√¥nicos 2.10 Espa√ßos can√¥nicos Em v√°rias √°reas da matem√°tica, existe um importante conceito de equival√™ncia entre duas estruturas, como por exemplo: homeomorfismos, isometrias e isomorfismos. Nessa se√ß√£o estudaremos o caso an√°logo para espa√ßos mensur√°veis, que nos trar√° uma grande surpresa. {definition} Uma fun√ß√£o \\phi:E\\to E^{\\prime} entre dois espa√ßos mensur√°veis √© dita bi-mensur√°vel quando \\phi √© uma bije√ß√£o mensur√°vel, com inversa mensur√°vel. Vamos agora tentar classificar os espa√ßos a menos de bi-mensurabilidade. Descobriremos que na verdade os borelianos da reta incluem praticamente tudo em que podemos estar interessados. Come√ßamos com a seguinte defini√ß√£o. {definition} Dizemos que o espa√ßo mensur√°vel (E,\\mathcal{A}) √© can√¥nico se existe uma fun√ß√£o \\phi:E\\to B bi-mensur√°vel para algum B\\in\\mathcal{B}(\\mathbb{R}) . Antes de mostrar que essa classe de espa√ßos can√¥nicos inclui muit√≠ssimos exemplos, vamos motivar a defini√ß√£o acima exemplificando como esse conceito pode ser utilizado. {theorem} [Extens√£o de Kolmogorov Extendida] Se (E_{1},\\mathcal{F}_{1}),(E_{2},\\mathcal{F}_{2}),\\dots s√£o espa√ßos mensur√°veis can√¥nicos, ent√£o o Teorema¬†2.6.2 (da extens√£o de Kolmogorov) tamb√©m √© v√°lido no espa√ßo produto \\Omega=E_{1}\\times E_{2}\\times\\dots : Se a seguinte condi√ß√£o de consist√™ncia for v√°lida \\forall n\\geq 0,\\forall A\\in\\bigotimes_{i=1}^{n}\\mathcal{F}_{i},\\quad P_{n+1}(% A\\times E_{n+1})=P_{n}(A). (2.103) ent√£o existe uma probabilidade P em \\Omega tal que \\forall n\\geq 0,\\forall A\\in\\bigotimes_{i=1}^{n}\\mathcal{F}_{i},\\quad P(A% \\times E_{n+1}\\times E_{n+2}\\times\\dots)=P_{n}(A). (2.104) Demonstra√ß√£o. Sejam \\phi_{i}:E_{i}\\to B_{i}\\in\\mathcal{B}(\\mathbb{R}) bije√ß√µes bi-mensur√°veis e defina \\widebar{\\phi}_{n}:E_{1}\\times\\dots\\times E_{n}\\to\\mathbb{R}^{n} por \\widebar{\\phi}_{n}(\\omega_{1},\\dots,\\omega_{n})=\\big{(}\\phi_{1}(\\omega_{1}),% \\dots,\\phi_{n}(\\omega_{n})\\big{)} . Assim podemos introduzir as medidas de probabilidade \\widebar{P}_{n}=(\\widebar{\\phi}_{n})_{*}P_{n},\\text{ em $\\mathbb{R}^{n}$}. (2.105) √â f√°cil verificar que as \\widebar{P}_{n} s√£o consistentes como em (2.58). Logo, existe \\widebar{P} em (\\mathbb{R}^{\\mathbb{N}},\\mathcal{F}) extendendo \\widebar{P}_{n} . Vamos agora definir uma medida em \\prod_{i=1}^{\\infty}E_{i} . Para tanto, primeiramente fixamos para cada i\\geq 1 um elemento arbitr√°rio w_{i} de E_{i} e definimos \\psi_{i}:\\mathbb{R}\\to E_{i} por \\psi_{i}(x)=\\begin{cases}\\phi_{i}^{-1}(x),\\quad&\\text{se $x\\in B_{i}$,}\\\\ w_{i}&\\text{no caso contr\\'{a}rio}.\\end{cases} Como B_{i}\\in\\mathcal{B}(\\mathbb{R}) , concluimos que \\psi_{i} √© mensur√°vel. Finalmente, consideramos o mapa \\Psi:\\mathbb{R}^{\\mathbb{N}}\\to\\Omega dado por \\Psi(x_{1},x_{2},\\dots)=(\\psi_{1}(x_{1}),\\psi_{2}(x_{2}),\\dots). (2.106) Resta mostrar que a medida P=\\Psi_{*}\\widebar{P} estende as probabilidades P_{n} . Observe que \\begin{split}P\\big{(}A_{1}\\times\\dots\\times A_{n}\\times&E_{n+1}\\times\\dots\\big% {)}=\\widebar{P}\\big{(}\\Psi^{-1}(A_{1}\\times\\dots\\times A_{n}\\times E_{n+1}% \\times\\dots)\\big{)}\\\\ &=\\widebar{P}\\big{(}\\psi^{-1}_{1}(A_{1})\\times\\dots\\times\\psi^{-1}_{n}(A_{n})% \\times\\mathbb{R}\\times\\dots\\big{)}\\\\ &=\\widebar{P}_{n}(\\psi^{-1}_{1}(A_{1})\\times\\dots\\times\\psi^{-1}_{n}(A_{n}))\\\\ &=P_{n}\\big{(}\\phi^{-1}_{1}\\big{(}\\psi^{-1}_{1}(A_{1}))\\times\\dots\\times\\phi^{% -1}_{n}\\big{(}\\psi_{n}^{-1}(A_{n})\\big{)}\\big{)}\\\\ &=P_{n}(A_{1}\\times\\dots\\times A_{n}),\\end{split} concluindo a prova do teorema. ‚àé Uma ferramenta importante para construirmos espa√ßos can√¥nicos √© a seguinte. {lemma} Seja (E,\\mathcal{A}) √© um espa√ßo can√¥nico e A\\in\\mathcal{A} , ent√£o A tamb√©m √© can√¥nico quando dotado da \\sigma -√°lgebra \\{A\\cap C\\,:\\,C\\in\\mathcal{A}\\} induzida por \\mathcal{A} em A . Demonstra√ß√£o. Seja \\phi:E\\to B\\in\\mathcal{B}(\\mathbb{R}) uma fun√ß√£o bi-mensur√°vel que mostra que E √© can√¥nico. Consideramos \\phi^{\\prime}:A\\to\\mathbb{R} dada pela restri√ß√£o de \\phi a A e precisamos mostrar as seguintes afirmativas: ‚ÄÉa)‚Äã \\phi^{\\prime} √© injetiva. ‚ÄÉb)‚Äã \\phi^{\\prime} √© mensur√°vel. ‚ÄÉc)‚Äã \\phi(A)\\in\\mathcal{B}(\\mathbb{R}) . ‚ÄÉd)‚ÄãA inversa de \\phi^{\\prime} (chamada \\psi^{\\prime} ) de \\phi^{\\prime}(A) em A √© mensur√°vel. Vejamos, ‚ÄÉa)‚Äã \\phi ser injetiva implica que \\phi^{\\prime} tamb√©m o √©. ‚ÄÉb)‚ÄãDado D\\in\\mathcal{B}(\\mathbb{R}) , (\\phi^{\\prime})^{-1}(D)=A\\cap\\phi^{-1}(D) which is of the form A\\cap C with C\\in\\mathcal{B}(\\mathbb{R}^{d}) . ‚ÄÉc)‚ÄãDenotando por \\psi:B\\to E a inversa de \\phi , temos que \\phi(A)=\\psi^{-1}(A)\\in\\mathcal{B}(B) pois \\psi √© mensur√°vel. ‚ÄÉd)‚ÄãFinalmente, se D\\in\\mathcal{B}(A) , ent√£o (\\psi^{\\prime})^{-1}(D)=\\psi^{-1}(D)\\in\\mathcal{B}(B) , novamente pela mensurabilidade de \\psi . Concluindo portanto a bi-mensurabilidade de \\phi^{\\prime} quando o seu contra-dom√≠nio √© restrito a sua imagem. ‚àé A seguir daremos um exemplo de espa√ßo can√¥nico que ser√° importante na se√ß√£o seguinte. {lemma} O espa√ßo produto E=\\mathbb{N}\\times\\mathbb{N}\\times\\dots , dotado da \\sigma -√°lgebra produto √© can√¥nico. Demonstra√ß√£o. Primeiramente definimos em E a M√©trica de Hamming: d_{H}(x,y)=\\sum_{i\\geq 1}\\frac{1}{2^{i+1}}\\1_{\\{x_{i}\\neq y_{i}\\}}. (2.107) Fica como exerc√≠cio mostrar que a \\sigma -√°lgebra dos borelianos induzida por essa m√©trica coincide com a \\sigma -√°lgebra produto em E . Definimos agora o mapa \\phi:E\\to\\mathbb{R} dado por \\phi(n_{1},n_{2},\\dots)=2^{-n_{1}}+2^{-1-n_{1}-n_{2}}+\\dots+2^{-k-\\sum_{i=1}^{% k}n_{i}}+\\dots (2.108) Tamb√©m deixamos a cargo do leitor mostrar que \\phi define um homeomorfismo entre (E,d_{H}) e um boreliano de \\mathbb{R} . ‚àé 2.10.1 Espa√ßos poloneses Nessa se√ß√£o mostraremos que todos espa√ßos chamados poloneses s√£o can√¥nicos. {definition} Um espa√ßo m√©trico (E,d) √© dito polon√™s se √© separ√°vel e completo. {example} ‚ÄÉa)‚ÄãTodo espa√ßo enumer√°vel \\Omega pode ser feito em um espa√ßo m√©trico polon√™s de forma que a \\sigma -√°lgebra de Borel seja \\mathcal{P}(\\Omega) . ‚ÄÉb)‚Äã \\mathbb{R}^{n} e C([0,1]) s√£o notoriamente poloneses. {exercise} Se (E_{i},d_{i})_{i=1}^{\\infty} √© uma sequencia de espa√ßos m√©tricos poloneses, mostre que E=\\prod_{i=1}^{\\infty}E_{i} com a m√©trica d(x,y)=\\sum_{i=1}^{\\infty}\\frac{1}{2^{i+1}}\\frac{d_{i}(x_{i},y_{i})}{1+d_{i}(x% _{i},y_{i})} (2.109) tamb√©m √© polon√™s. Mostre tamb√©m que a topologia induzida por essa m√©trica √© equivalente √† topologia produto em E . Outros exemplos de espa√ßos poloneses s√£o dados pelo seguinte lema, que tamb√©m ser√° √∫til para provar o resultado principal desta se√ß√£o. {lemma} Seja (E,d) um espa√ßo polon√™s e G,F\\subseteq E um aberto e um fechado de E respectivamente. Ent√£o, existe uma m√©trica d^{\\prime} em F\\cap G tal que ‚ÄÉa)‚Äã d e d^{\\prime} s√£o equivalentes em F\\cap G (induzem a mesma no√ß√£o de converg√™ncia), ‚ÄÉb)‚Äã d(x,y)\\leq d^{\\prime}(x,y) para todo x,y\\in F\\cap G e ‚ÄÉc)‚Äã (F\\cap G,d^{\\prime}) √© polon√™s. Demonstra√ß√£o. A primeira observa√ß√£o que faremos √© que F\\cap G √© separ√°vel com respeito a d . Isso segue do fato de separabilidade ser equivalente √† exist√™ncia de uma base enumer√°vel. Vamos definir para x,y em G , d^{\\prime}(x,y)=d(x,y)+\\Big{|}\\frac{1}{d(x,G^{c})}-\\frac{1}{d(y,G^{c})}\\Big{|}, (2.110) onde d(x,A)=\\inf\\{d(x,x^{\\prime})\\,:\\,x^{\\prime}\\in A\\} . N√£o √© dif√≠cil ver que com a defini√ß√£o acima (e deixamos como exerc√≠cio) que: ‚ÄÉa)‚ÄãAs m√©tricas d e d^{\\prime} s√£o equivalentes em G . ‚ÄÉb)‚Äã F\\cap G √© separ√°vel quando dotado da m√©trica d^{\\prime} . ‚ÄÉc)‚Äã (F\\cap G,d^{\\prime}) √© completo. Isso termina a prova do lema. ‚àé {example} Um importante exemplo √© dado por espa√ßos produto. Seja (E_{i},d_{i})_{i=1}^{\\infty} uma sequ√™ncia de espa√ßos poloneses e introduza em E=\\prod_{i=1}^{\\infty}E_{i} a m√©trica d definida em (2.109). Ent√£o, se A_{1}\\subseteq E_{1} , \\dots , A_{k}\\subseteq E_{k} forem abertos, o ret√¢ngulo R=A_{1}\\times\\dots\\times A_{k}\\times E_{k+1}\\times\\dots √© aberto. Dessa forma vemos que tanto R como R^{c} podem ser dotados de m√©tricas com as quais se tornam espa√ßos poloneses. Al√©m disso tais m√©tricas podem ser escolhidas satisfazendo as hip√≥teses do Lema¬†2.10.1 O pr√≥ximo lema √© o ingrediente chave para provarmos o resultado principal dessa se√ß√£o. Ele nos d√° uma maneira de fatiar um espa√ßo polon√™s em uma parti√ß√£o de espa√ßos poloneses pequenos. {lemma} Seja (E,d) um espa√ßo polon√™s e r>0 . Ent√£o existe uma parti√ß√£o finita ou enumer√°vel (A_{i})_{i\\in I} de A e m√©tricas (d_{i})_{i\\in I} nesses respectivos subconjuntos de forma que para todo i\\in I , ‚ÄÉa)‚Äã (A_{i},d_{i}) s√£o espa√ßos poloneses disjuntos. ‚ÄÉb)‚Äã d_{i} e d s√£o equivalentes em A_{i} e d_{i}\\geq d . ‚ÄÉc)‚ÄãO di√¢metro de A_{i} (com respeito a d ) √© menor ou igual a r . Observe que podemos sempre escolher I=\\mathbb{N} mas nesse caso os A_{i} podem ser vazios. Demonstra√ß√£o. Obtemos atrav√©s da separabilidade de E , uma cole√ß√£o de bolas (B_{i})_{i\\geq 1} com di√¢metros limitados por r e cobrindo E . Ent√£o definimos A_{1}=B_{1},\\quad\\text{e}\\quad A_{n}=B_{n}\\setminus\\mcup_{i=0}^{n-1}B_{i}\\quad% \\text{para $n\\geq 1$.} (2.111) Agora podemos dotar cada um dos A_{i} com a m√©trica d_{i} obtida atrav√©s do Lema¬†2.10.1 (observe para tanto que os A_{i} s√£o dados por interse√ß√µes de um aberto com um fechado). As propriedades enunciadas no lema s√£o trivialmente satisfeitas. ‚àé Terminamos essa se√ß√£o com esse importante resultado, que confirma nossa afirma√ß√£o de que quase todos os espa√ßos mensur√°veis que podemos nos interessar s√£o can√¥nicos. {theorem} Todo sub-conjunto boreliano de espa√ßo polon√™s (E,d) √© can√¥nico. Demonstra√ß√£o. Primeiramente, pelo Lema¬†2.10, basta mostrar que todo espa√ßo E polon√™s √© can√¥nico. Pelo Lema¬†2.10 e novamente o Lema¬†2.10, {display} basta construir uma fun√ß√£o bi-mensur√°vel \\phi:E\\to B\\in\\mathcal{B}(\\mathbb{N}^{\\mathbb{N}}) e depois comp√¥-la com uma fun√ß√£o bi-mensur√°vel \\phi^{\\prime}:B\\to C\\in\\mathcal{B}(\\mathbb{R}) . Para come√ßar, construiremos uma parti√ß√£o encaixada de E . Mais precisamente, defina os conjuntos M_{n} que ser√£o utilizados como √≠ndices M_{n}=\\mathbb{N}^{n}\\quad\\text{para $n\\geq 1$ e}\\quad M=\\cup_{n}M_{n}. (2.112) Vamos definir borelianos A_{m} de E e m√©tricas d_{m} em A_{m} para cada m\\in M . Faremos isso da seguinte forma: ‚ÄÉa)‚Äãse m=i\\in M_{1} , ent√£o definimos A_{1},A_{2},A_{3},\\dots e d_{1},d_{2},d_{3},\\dots como no Lema¬†2.10.1 com r=1 , ‚ÄÉb)‚Äãse (A_{m},d_{m}) j√° foi definido para algum m\\in M_{n} , ent√£o utilizamos tamb√©m o Lema¬†2.10.1 com r=1/n para particionar o conjunto A_{m} (com a m√©trica d_{m} ) em A_{(m,1)},A_{(m,2)},\\dots com suas respectivas m√©tricas d_{(m,1)},d_{(m,2)},\\dots Obviamente suporemos que s√£o v√°lidas as propriedades de tais m√©tricas garantidas pelo Lema¬†2.10.1. Podemos desde j√° definir \\phi:E\\to\\mathbb{N}^{\\mathbb{N}} e para tanto, considere x\\in E . Indutivamente ‚ÄÉa)‚Äãcomo \\{A_{m}\\}_{m\\in M_{1}} formam uma parti√ß√£o de E , definimos \\phi_{1}(x) como o √∫nico √≠ndice tal que x\\in A_{\\phi_{1}(x)} , ‚ÄÉb)‚Äãse j√° encontramos \\phi_{1}(x),\\dots,\\phi_{n}(x) tal que x\\in A_{(\\phi_{1}(x),\\dots,\\phi_{n}(x))} , ent√£o o fato que particionamos o √∫ltimo conjunto na defini√ß√£o de A_{m} , m\\in M_{n+1} nos garante que podemos definir unicamente \\phi_{n+1}(x) de forma a continuar a indu√ß√£o. Da maneira acima j√° obtivemos \\phi(x)=(\\phi_{1}(x),\\phi_{2}(x),\\dots) . Para terminar, devemos mostrar que \\phi √© bi-mensur√°vel quando seu contra-dom√≠nio √© restrito √† sua imagem. Isso come√ßa com a prova de que \\phi √© injetiva. Se \\phi(x)=\\phi(y) , ent√£o existe uma sequ√™ncia m_{n}\\in M_{n} tal que x,y\\in A_{m_{n}} para todo n . Mas isso n√£o √© poss√≠vel dado que o di√¢metro de A_{m_{n+1}} √© menor ou igual a 1/n na m√©trica d_{m_{n}}\\geq d . Isso mostra que x=y . Vejamos agora que \\phi √© mensur√°vel. Seja w\\in\\mathbb{N}^{\\mathbb{N}} tal que \\phi(x)=w e tome G\\subseteq\\mathbb{N}^{\\mathbb{N}} com G=\\{(w_{1},\\dots,w_{l})\\}\\times\\mathbb{N}^{\\mathbb{N}} (esses conjuntos geram a \\sigma -√°lgebra can√¥nica em \\mathbb{N}^{\\mathbb{N}} ). Claramente, \\phi^{-1}(G)=A_{(\\phi_{1}(x),\\dots,\\phi_{l}(x))} , de forma que mostramos que \\phi √© mensur√°vel. Para mostrar que sua inversa \\psi:\\phi(E)\\to E √© mensur√°vel, veremos que ela √© de fato cont√≠nua com respeito √† M√©trica de Hamming definida em (2.107). Dado n\\geq 1 , tomamos \\delta<2^{-n} . Se w,w^{\\prime}\\in\\phi(E) s√£o tais que d_{H}(w,w^{\\prime})<\\delta em \\mathbb{N}^{\\mathbb{N}} , ent√£o w_{i}=w^{\\prime}_{i} para todo i\\leq n , de forma que \\phi^{-1}(w) e \\phi^{-1}(w^{\\prime}) pertencem a A_{(w_{1},\\dots,w_{n})} . A continuidade de \\phi^{-1} segue do fato que o di√¢metro de A_{(w_{1},\\dots,w_{n})} √© no m√°ximo 1/n (com respeito a d_{(w_{1},\\dots,w_{n-1})} e portanto com respeito a d ). Mas aten√ß√£o, apesar de que parece que provamos o teorema, ainda falta mostrar que \\phi(E) √© mensur√°vel. Para tanto, afirmamos que \\phi(E)=\\mathbb{N}^{\\mathbb{N}}\\setminus\\Big{(}\\bigcup_{(w_{1},\\dots,w_{k})\\in% \\mathcal{E}}\\{w_{1}\\}\\times\\{w_{k}\\}\\times\\mathbb{N}\\times\\dots\\Big{)}, (2.113) onde \\mathcal{E}:=\\{(w_{1},\\dots,w_{k})\\in\\bigcup_{n\\geq 1}\\mathbb{N}^{n}\\,:\\,A_{% \\omega_{1},\\dots,\\omega_{k}}=\\emptyset\\}. A igualdade acima ser√° mostrada no que segue. Dado w\\in\\phi(E) existe x\\in E tal que \\phi(x)=w . Como x\\in A_{w_{1},\\dots,w_{n}} para todo n\\geq 1 , esses conjuntos n√£o s√£o vazios. Logo w n√£o pertence √† uni√£o em (2.113), mostrando o lado ( \\subseteq ) da equalidade. Finalmente, suponha que w=(w_{1},w_{2},\\dots) √© tal que para todo k\\geq 1 , A_{w_{1},\\dots,w_{k}}\\neq\\varnothing . Tomamos portanto para todo k\\geq 1 um ponto x_{k}\\in A_{w_{1},\\dots,w_{k}} . Afirmamos que para todo n , (x_{k})_{k\\geq n} √© Cauchy em (A_{w_{1},\\dots,w_{n}},d_{w_{1},\\dots,w_{n}}) , (2.114) o que segue logo do fato que por k\\geq n+1 , x_{k}\\in A_{w_{1},\\dots,w_{k}} cujo d_{w_{1},\\dots,w_{n}} -di√¢metro √© menor que 1/k . Consideramos x^{n} o limite de (x_{k})_{k\\geq n} em (A_{w_{1},\\dots,w_{n}},d_{w_{1},\\dots,w_{n}}) . √â f√°cil de mostrar que x^{n}=x^{0}:=x (o limite da sequ√™ncia em (E,d) ) para todo valor de n . √â suficiente ver que d(x^{n},x_{k})\\leq d_{w_{1},\\dots,w_{n}}(x^{n},x_{k}) , para todo k\\geq n , o que implica que x^{n} √© o limite em (E,d) . Como consequ√™ncia podemos concluir que x\\in A_{w_{1},\\dots,w_{n}} para todo n e ent√£o que \\phi(x)=\\omega , o que conclui a prova do teorema. ‚àé Previous page Next page"],[["index.html","Ch2.html","Ch2.S2.html"],"2.2 Caso absolutamente cont√≠nuo ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Caso absolutamente cont√≠nuo 2.2 Caso absolutamente cont√≠nuo Uma outra maneira simples de definir um espa√ßo de probabilidade √© partindo de um espa√ßo de medida. Seja (\\Omega,\\mathcal{F},\\mu) um espa√ßo de medida e \\rho:\\Omega\\to\\mathbb{R}_{+} uma fun√ß√£o mensur√°vel com \\int\\rho(x)\\mu(\\d{x})=1 . Ent√£o podemos definir a probabilidade induzida P(A)=\\int_{A}\\rho(x)\\mu(\\d{x}). (2.8) Nesse caso, chamamos \\rho de a densidade de P com respeito a \\mu . Uma outra poss√≠vel nota√ß√£o para a equa√ß√£o acima √© \\d{P}=\\rho(x)\\d{\\mu} (lembrando a derivada de Radon-Nikodym). Observe que o caso discreto pode ser definido em termos de uma densidade, onde \\rho(\\omega)=p_{\\omega} e \\mu √© a medida da contagem em \\Omega . {example} V√°rios exemplos podem ser obtidos via (2.8) se tomamos \\Omega\\subseteq\\mathbb{R} e \\mu a medida de Lebesgue restrita a \\Omega . Nesses casos, escrevemos P=\\rho(x)\\d{x} em \\Omega . Alguns exemplos importantes s√£o: ‚ÄÉa)‚ÄãPara a<b\\in\\mathbb{R} , definimos a medida U[a,b] usando \\rho(x)=\\tfrac{1}{b-a}\\1_{[a,b]}(x) . ‚ÄÉb)‚ÄãPara \\lambda>0 , definimos a medida \\Exp(\\lambda) (chamada exponencial de par√¢metro \\lambda ) por meio da densidade \\rho(x)=\\lambda\\exp\\{-\\lambda x\\} em [0,\\infty) . Podemos tamb√©m usar a distribui√ß√£o de um elemento aleat√≥rio para construir outras probabilidades, como mostra o seguinte exemplo. {example} Considere por exemplo X:[0,2\\pi]\\to\\mathbb{C} dada por X(t)=\\exp\\{-it\\} . A distribui√ß√£o imagem X_{*}U_{[0,2\\pi]} √© o que chamamos de distribui√ß√£o uniforme em \\mathbb{S}^{1} , tamb√©m denotada por U_{S^{1}} . {exercise} Mostre que U_{\\mathbb{S}^{1}} n√£o √© absolutamente cont√≠nua com respeito √† medida de Lebesgue em \\mathbb{C}\\sim\\mathbb{R}^{2} . {exercise} Mostre que U_{\\mathbb{S}^{1}} √© invariante por rota√ß√µes r√≠gidas de \\mathbb{C} , isto √©, se T:\\mathbb{C}\\to\\mathbb{C} √© uma isometria linear, T_{*}U_{\\mathbb{S}^{1}}=U_{\\mathbb{S}^{1}} . {exercise} Construa uma probabilidade em S^{2} invariante por rota√ß√µes. Previous page Next page"],[["index.html","Ch2.html","Ch2.S3.html"],"2.3 Fun√ß√µes acumuladas de distribui√ß√£o ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Fun√ß√µes acumuladas de distribui√ß√£o 2.3 Fun√ß√µes acumuladas de distribui√ß√£o Um caso muito importante de espa√ßo amostral √© \\Omega=\\mathbb{R} , principalmente por nos ajudar a entender distribui√ß√µes de vari√°veis aleat√≥rias. Para tanto, precisaremos de uma boa ferramenta para descrever probabilidades em \\mathbb{R} . {definition} Dada P em \\mathbb{R} , definimos F_{P}:\\mathbb{R}\\to[0,1] por F_{P}(x)=P\\big{(}(-\\infty,x]\\big{)} . Essa fun√ß√£o √© chamada a fun√ß√£o de distribui√ß√£o acumulada de P . {notation} Se X:\\Omega\\to\\mathbb{R} √© uma vari√°vel aleat√≥ria num espa√ßo (\\Omega,\\mathcal{F},P) , denotamos por F_{X} a fun√ß√£o de distribui√ß√£o acumulada correspondente √† distribui√ß√£o X_{*}P . Lembramos que uma probabilidade em \\mathbb{R} √© uma fun√ß√£o P:\\mathcal{B}(\\mathbb{R})\\to[0,1] e o dom√≠nio dessa fun√ß√£o √© bastante complicado. Por exemplo se quisermos representar uma distribui√ß√£o de uma vari√°vel aleat√≥ria no computador atrav√©s dessa fun√ß√£o P , ter√≠amos problemas. Contudo, a fun√ß√£o F_{P} (ou F_{X} ) √© muito mais simples de ser compreendida ou representada, por seu dom√≠nio ser \\mathbb{R} . {example} N√£o √© dif√≠cil verificar que F_{\\delta_{x_{0}}}=\\begin{cases}0&\\text{ se $x<x_{0}$,}\\\\ 1&\\text{ se $x\\geq x_{0}$}\\end{cases} (2.9) e que F_{U_{[0,1]}}=\\begin{cases}0&\\text{ se $x\\leq 0$,}\\\\ x&\\text{ se $x\\in[0,1]$ e}\\\\ 1&\\text{ se $x\\geq 1$.}\\end{cases} (2.10) {exercise} Calcule F_{\\Exp(\\lambda)} . {proposition} F_{P} (e obviamente F_{X} ) satisfazem: ‚ÄÉa)‚Äã \\smash{\\lim\\limits_{x\\to-\\infty}}F(x)=0 , \\smash{\\lim\\limits_{x\\to\\infty}}F(x)=1 , ‚ÄÉb)‚Äã F √© mon√≥tona n√£o-decrescente e ‚ÄÉc)‚Äã F √© cont√≠nua √† direita e possui limite √† esquerda (c√†dl√†g, do franc√™s). Demonstra√ß√£o. ‚ÄÉa)‚ÄãSe x_{n}\\to-\\infty monotonamente, ent√£o A_{n}=(-\\infty,x_{n}] s√£o encaixados e de interse√ß√£o vazia. Logo, pela Proposi√ß√£o¬†1.2, temos P(A_{n})\\to 0 . O outro caso √© an√°logo. ‚ÄÉb)‚ÄãSe x\\leq x^{\\prime} ent√£o (-\\infty,x]\\subseteq(-\\infty,x^{\\prime}] , donde F(x)\\leq F(x^{\\prime}) . ‚ÄÉc)‚ÄãContinuidade √† direita (c√†d) - Se x_{n}\\downarrow x monotonamente, ent√£o A_{n}=(-\\infty,x_{n}]\\downarrow(-\\infty,x] (eles s√£o encaixados). Logo F(x_{n})\\to F(x) . Limite √† esquerda (l√†g) - Segue do fato de F ser mon√≥tona e limitada. ‚àé {theorem} Se F satisfaz as tr√™s propriedades listadas na Proposi√ß√£o¬†2.3, ent√£o existe uma √∫nica P em (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) tal que F=F_{P} . Poder√≠amos usar o Teorema da Extens√£o de Caratheodory para provar tal resultado, de maneira similar ao que foi feito no caso da Medida de Lebesgue. Mas escolhemos abaixo um m√©todo mais simples, que parte da exist√™ncia de U_{[0,1]} . Demonstra√ß√£o. A unicidade de tal P segue da Proposi√ß√£o¬†1.3.1 (consequ√™cia do Teorema de Dynkin), pois se P e P^{\\prime} s√£o tais que F_{P}=F_{P^{\\prime}} , ent√£o temos que P\\big{(}(-\\infty,x]\\big{)}=P^{\\prime}\\big{(}(-\\infty,x]\\big{)} . Mas a classe de intervalos semi-infinitos da forma (-\\infty,x] forma um \\pi -sistema que gera a \\sigma -√°lgebra dos borelianos, logo P=P^{\\prime} . Para construir uma P tal que F_{P}=F , definiremos S:(0,1)\\to\\mathbb{R} , a inversa generalizada de F , por S(u)=\\sup\\{x\\in\\mathbb{R}\\,:\\,F(x)<u\\}. (2.11) u u S(u) S(u) Figura 2.1: Ilustra√ß√£o da defini√ß√£o de S(u) . Seja P=S_{*}U_{[0,1]} , isto √© P(A)=U_{[0,1]}(S^{-1}(A)) e mostraremos que F_{P}=F . Para tanto, basta ver que \\{u\\in[0,1]\\,:\\,S(u)\\leq x\\}=\\{u\\in[0,1]\\,:\\,u\\leq F(x)\\},\\text{ para todo $x% \\in\\mathbb{R}$}. (2.12) Pois isso implicaria que F_{P}(x)=U_{[0,1]}[S(u)\\leq x]=U_{[0,1]}[u\\leq F(x)]=F(x) . Vamos agora checar (2.12) observando que: ‚ÄÉa)‚ÄãSe u\\leq F(x) ent√£o todo x^{\\prime} tal que F(x^{\\prime})<u √© menor que x . Logo S(u)\\leq x . ‚ÄÉb)‚ÄãPor outro lado, se x\\geq S(u) ent√£o todo x^{\\prime}>x satisfaz F(x^{\\prime})>u . Pois por continuidade a direita F(x)\\geq u . Isso prova (2.12), terminando a prova da proposi√ß√£o. ‚àé {exercise} Mostre o resultado acima usando o Teorema de Extens√£o de Caratheodory. Previous page Next page"],[["index.html","Ch2.html","Ch2.S4.html"],"2.4 Espa√ßos produto finito ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Espa√ßos produto finito 2.4 Espa√ßos produto finito Dados espa√ßos \\Omega_{1},\\dots,\\Omega_{n} com suas respectivas \\sigma -√°lgebras \\mathcal{F}_{1},\\dots,\\mathcal{F}_{n} , podemos definir o espa√ßo mensur√°vel produto (\\widebar{\\Omega},\\widebar{\\mathcal{F}}) da seguinte forma \\widebar{\\Omega}=\\prod_{i=1}^{n}\\Omega_{i}\\quad\\text{e}\\quad\\widebar{\\mathcal{% F}}=\\sigma\\Big{(}\\{A_{1}\\times\\cdots\\times A_{n}\\,:\\,\\forall i\\in\\{1,\\dots,n\\}% ,\\ A_{i}\\in\\mathcal{F}_{i}\\}\\Big{)}. (2.13) Essa \\sigma -√°lgebra √© chamada de \\sigma -√°lgebra produto e denotaremos ela por \\bigotimes_{i=1}^{n}\\mathcal{F}_{i} , ou \\mathcal{F}_{1}\\otimes\\mathcal{F}_{2} quando n=2 . {proposition} Se (\\Omega_{1},\\mathcal{F}_{1},P_{1}),\\dots,(\\Omega_{n},\\mathcal{F}_{n},P_{n}) s√£o espa√ßos de probabilidade, ent√£o existe uma √∫nica probabilidade \\widebar{P} no espa√ßo mensur√°vel (\\widebar{\\Omega},\\widebar{\\mathcal{F}}) tal que \\widebar{P}(A_{1}\\times\\cdots\\times A_{n})=\\prod_{i=1}^{n}P_{i}(A_{i}),\\text{ % para todos $A_{i}\\in\\mathcal{F}_{i}$, $i\\leq n$.} (2.14) Essa probabilidade √© chamada probabilidade produto. Usaremos a nota√ß√£o \\bigotimes_{i=1}^{n}P_{i} o P_{1}\\otimes P_{2}\\otimes\\dots\\otimes P_{n} . Demonstra√ß√£o. Teoria da Medida. ‚àé Note que a unicidade do produto pode ser conclu√≠da por exemplo usando o Corol√°rio¬†1.3.1. {exercise} Mostre que o produto de n c√≥pias de (\\{0,1\\},\\mathcal{P}(\\{0,1\\}),\\Ber(1/2)) √© a distribui√ß√£o uniforme em \\{0,1\\}^{n} . Previous page Next page"],[["index.html","Ch2.html","Ch2.S5.html"],"2.5 Independ√™ncia ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Independ√™ncia 2.5 Independ√™ncia Nossa intui√ß√£o nos diz que quando jogamos duas moedas, o resultado de cada uma delas n√£o deve depender um do outro. Dessa forma, a probabilidade de obtermos um determinado resultado (como por exemplo duas caras) deve ser um quarto, ou seja, meio vezes meio. Em geral, definimos dois eventos como independentes da seguinte forma. {definition} Dizemos que dois eventos A,B\\in\\mathcal{F} s√£o independentes se P(A\\cap B)=P(A)P(B). (2.15) {example} Se \\Omega=\\{1,\\dots,6\\} √© dotada da \\sigma -√°lgebra das partes e P(A)=\\#A/6 , ent√£o os eventos A=[\\omega\\text{ \\'{e} impar}] e B=[\\omega\\geq 5] satisfazem P(A\\cap B)=P(\\{5\\})=1/6=(1/2)(1/3)=P(A)P(B). (2.16) Logo tais eventos s√£o independentes. {exercise} Seja \\Omega=\\{0,1\\}^{n} com P(A)=\\#A/2^{n} e X_{i}(\\omega_{1},\\dots,\\omega_{n})=\\omega_{i} para i=1,\\dots,n . Mostre que P[X_{i}=a,X_{j}=b]=P[X_{i}=a]P[X_{j}=b], (2.17) onde [A,B] denota a interse√ß√£o A\\cap B . 2.5.1 Cole√ß√µes de eventos 22todo: 2 discutir a alternativa I=\\{1,\\dots,k\\} que √© ruim (basta adicionar \\varnothing que qq coisa fica indep). {definition} Sejam A_{1},A_{2},\\dots,A_{k} eventos. Dizemos que eles formam uma cole√ß√£o independente se para todo I\\subseteq\\{1,\\dots,k\\} n√£o vazio P\\big{(}\\mcap\\nolimits_{i\\in I}A_{i}\\big{)}=\\prod\\limits_{i\\in I}P(A_{i}). (2.18) Vale observar que independ√™ncia dois a dois n√£o implica independ√™ncia. Mais precisamente {example} Seja \\Omega=\\{1,2,3,4\\} com P(A)=\\#A/4 e sejam os seguintes eventos: A_{1}=\\{1,2\\} , A_{2}=\\{2,3\\} e A_{3}=\\{1,3\\} . Nesse caso, ‚ÄÉa)‚Äã P(A_{i})=1/2 para i=1,2,3 , ‚ÄÉb)‚Äã P(A_{i}\\cap A_{j})=1/4 para todo i\\neq j mas ‚ÄÉc)‚Äã P(A_{1}\\cap A_{2}\\cap A_{3})=0\\neq 1/8=P(A_{1})P(A_{2})P(A_{3}) . {definition} Dizemos que uma cole√ß√£o infinita de eventos (A_{n})_{n\\geq 1} √© independente se toda sub-cole√ß√£o finita de tais eventos forem independentes. {lemma} Se (A_{n})_{n\\geq 1} forma uma sequencia de eventos independentes, ent√£o P\\Big{(}\\mcap_{i=1}^{\\infty}A_{i}\\Big{)}=\\prod\\limits_{i=1}^{\\infty}P(A_{i}). (2.19) Demonstra√ß√£o. De fato, P\\Big{(}\\mcap_{i=1}^{\\infty}A_{i}\\Big{)}=\\lim_{n\\to\\infty}P\\Big{(}\\mcap_{i=1}^% {n}A_{i}\\Big{)}=\\lim_{n\\to\\infty}\\prod\\limits_{i=1}^{n}P(A_{i})=\\prod\\limits_{% i=1}^{\\infty}P(A_{i}).\\qed {exercise} Mostre que se A\\in\\mathcal{F} , ent√£o \\{B\\in\\mathcal{F}\\,:\\,B\\text{ \\'{e} independente de }A\\} √© um \\lambda -sistema. {exercise} Mostre que se B √© independente de A para todo B\\in\\mathcal{B} , com \\mathcal{B} um \\pi -sistema, ent√£o B √© independente de A para todo B\\in\\sigma(\\mathcal{B}) . 2.5.2 Independ√™ncia de \\sigma -√°lgebras {definition} Dado um espa√ßo de probabilidade (\\Omega,P,\\mathcal{F}) Dizemos que as \\sigma -√°lgebra \\mathcal{F}_{1},\\dots,\\mathcal{F}_{n}\\subset\\mathcal{F} s√£o independentes se \\forall\\mathcal{A}_{1}\\in\\mathcal{F}_{1},\\dots,\\mathcal{A}_{n}\\in\\mathcal{F}_{% n},\\ P(\\cap_{i=1}^{n}A_{i})=\\prod_{i=1}^{n}P(A_{i}). (2.20) Nessa defini√ß√£o podemos tomar uma cole√ß√£o infinita. {exercise} Em um espa√ßo produto (\\Omega_{1}\\times\\Omega_{2},\\mathcal{F}_{1}\\otimes\\mathcal{F}_{2},P_{1}\\otimes P% _{2}) , podemos definir \\begin{split}\\widebar{\\mathcal{F}}_{1}&=\\{A\\times\\Omega_{2}\\,:\\,A\\in\\mathcal{F% }_{1}\\},\\\\ \\widebar{\\mathcal{F}}_{2}&=\\{\\Omega_{1}\\times B\\,:\\,B\\in\\mathcal{F}_{2}\\}.\\end% {split} (2.21) Mostre que essas \\sigma -√°lgebras s√£o independentes. Podemos extender esse conceito a elementos aleat√≥rios, ou seja: {definition} Dizemos que X_{1},\\dots,X_{k} s√£o elementos aleat√≥rios independentes se as respectivas \\sigma -√°lgebras \\sigma(X_{1}),\\dots,\\sigma(X_{k}) o forem. Quando X_{1},\\dots,X_{k} s√£o elementos aleat√≥rios independentes e com a mesma distribui√ß√£o, escrevemos que X_{i} s√£o \\iid(independentes e identicamente distribu√≠dos). {exercise} Com a nota√ß√£o do exerc√≠cio anterior, mostre que as fun√ß√µes X_{i}:\\Omega_{1}\\times\\Omega_{2}\\to\\Omega_{i} dadas por X_{1}(x,y)=x\\text{ e }X_{2}(x,y)=y, (2.22) s√£o elementos aleat√≥rios e s√£o independentes. {exercise} Mostre que as coordenadas can√¥nicas do exerc√≠cio anterior no caso X_{i}:\\mathbb{R}^{2}\\to\\mathbb{R} n√£o s√£o independentes segundo a medida U_{\\mathbb{S}^{1}} . Mas o s√£o segundo U_{[0,1]^{2}} (que √© a medida de Lebesgue em \\mathbb{R}^{2} restrita a [0,1]^{2} ). {exercise} Seja \\Omega=\\{0,1\\}^{n} com P(A)=\\#A/2^{n} e X_{i}(\\omega_{1},\\dots,\\omega_{n})=\\omega_{i} para i=1,\\dots,n . Mostre que os X_{i} s√£o independentes. {exercise} Sejam (X_{i})_{i\\geq 1} elementos aleat√≥rios independentes tomando valores em espa√ßos (E_{i})_{i\\geq 1} , respectivamente. Mostre que para fun√ß√µes mensur√°veis (f_{i})_{i\\geq 1} temos que (f_{i}(X_{i}))_{i\\geq 1} s√£o independentes. {exercise} Mostre que se X,Y s√£o elementos aleat√≥rios e se X √© constante quase certamente ent√£o X e Y s√£o independentes. {exercise} Sejam X e Y vari√°veis aleat√≥rias independentes com distribui√ß√£o \\Exp(1) , calcule a distribui√ß√£o de ‚ÄÉa)‚Äã \\min\\{X,Y\\} e ‚ÄÉb)‚Äã X+Y . {exercise} Seja um espa√ßo produto de medidas (\\Omega_{1}\\times\\Omega_{2},\\mathcal{F}_{1}\\otimes\\mathcal{F}_{2},\\mu_{1}% \\otimes\\mu_{2}) e defina a probabilidade P atrav√©s de \\d{P}=\\rho(x,y)\\d{(}\\mu_{1}\\otimes\\mu_{2}). (2.23) Mostre nesse caso que as coordenadas can√¥nicas X_{1} e X_{2} s√£o independentes se e somente se existem \\rho_{1} e \\rho_{2} em \\Omega_{1} e \\Omega_{2} respectivamente, tais que \\rho(x,y)=\\rho_{1}(x)\\rho_{2}(y) quase certamente com respeito a \\mu_{1}\\otimes\\mu_{2} . {exercise} Sejam X,Y vari√°veis aleat√≥rias tais que P[X\\leq x,Y\\leq y]=\\begin{cases}0&\\quad\\text{if $x<0$,}\\\\ (1-e^{-x})\\Big{(}\\frac{1}{2}+\\frac{1}{\\pi}\\tan^{-1}y\\Big{)},&\\quad\\text{if $x% \\geq 0$}.\\end{cases} (2.24) ‚ÄÉa)‚ÄãMostre que a distribui√ß√£o conjunta \\mu_{(X,Y)} √© absolutamente cont√≠nua com rela√ß√£o √† medida de Lebesgue em \\mathbb{R}^{2} . ‚ÄÉb)‚ÄãMostre que X e Y s√£o independentes. {exercise} Mostre que se X,Y s√£o vari√°veis aleat√≥rias independentes com distribui√ß√µes X\\distr f_{X}(x)\\d{x} e Y\\distr f_{Y}(y)\\d{y} , ent√£o X+Y tem distribui√ß√£o absolutamente cont√≠nua com respeito a Lebesgue e f_{X+Y}(z)=\\int_{-\\infty}^{\\infty}f_{Y}(z-x)f_{X}(x)\\d{x}. (2.25) 33todo: 3 mandar para depois de produtos infinitos? {lemma} [Borel-Cantelli - segunda parte] Se A_{1},A_{2},\\dots\\in\\mathcal{F} s√£o independentes e p_{i}=P(A_{i}) satisfazem \\sum_{i}p_{i}=\\infty , ent√£o P[A_{i}\\text{ infinitas vezes}]=1. (2.26) Demonstra√ß√£o. Queremos mostrar que P\\Big{(}\\big{(}\\mcap_{n}\\mcup_{i=n}^{\\infty}A_{i}\\big{)}^{c}\\Big{)}=0, (2.27) mas P\\Big{(}\\big{(}\\mcap_{n}\\mcup_{i=n}^{\\infty}A_{i}\\big{)}^{c}\\Big{)}=P\\Big{(}% \\mcup_{n}\\mcap_{i=n}^{\\infty}A_{i}^{c}\\Big{)}\\leq\\sum\\limits_{n}P\\Big{(}\\mcap_% {i=n}^{\\infty}A_{i}^{c}\\Big{)}. (2.28) Logo basta mostrar que a probabilidade √† direita √© zero para todo n . Mas \\begin{split}P\\Big{(}\\mcap_{i=n}^{\\infty}A_{i}^{c}\\Big{)}&=\\prod\\limits_{i=n}^% {\\infty}P(A_{i}^{c})=\\prod\\limits_{i=n}^{\\infty}(1-p_{i})\\\\ &\\leq\\prod\\limits_{i=n}^{\\infty}\\exp\\{-p_{i}\\}=\\exp\\big{\\{}-\\sum_{i=n}^{\\infty% }p_{i}\\big{\\}}=0.\\end{split} (2.29) Terminando a prova do lema. ‚àé \\todosec T√≥pico: Uma din√¢mica em [0,1] fazer din√¢mica 2x mod 1 e rela√ß√µes Lebesgue[0,1] com produtos de bernoulli Previous page Next page"],[["index.html","Ch2.html","Ch2.S6.html"],"2.6 Espa√ßos produto infinito ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Espa√ßos produto infinito 2.6 Espa√ßos produto infinito Nessa se√ß√£o estudaremos \\Omega que s√£o dados por produtos enumer√°veis de outros espa√ßos de probabilidade. Mas antes iremos recordar o Teorema da Extens√£o de Caratheodory. 2.6.1 Recordar √© viver‚Ä¶ Vamos lembrar o enunciado do Teorema da Extens√£o de Caratheodory . Antes, vamos relembrar uma defini√ß√£o defini√ß√£o importante. Uma fam√≠lia \\mathcal{G}\\subseteq\\mathcal{P}(\\Omega) √© dita uma √°lgebra de conjuntos se valem: ‚ÄÉa)‚Äã \\Omega\\in\\mathcal{G} . ‚ÄÉb)‚ÄãSe A\\in\\mathcal{G} , ent√£o A^{c}\\in\\mathcal{G} . ‚ÄÉc)‚ÄãPara todo n\\geq 1 , se A_{1},\\dots,A_{n}\\in\\mathcal{G} , ent√£o \\bigcup_{i=1}^{n}A_{i}\\in\\mathcal{G} . {theorem} [Teorema da Extens√£o de Caratheodory] Seja \\mathcal{G}\\subseteq\\mathcal{P}(\\Omega) uma √°lgebra de conjuntos em \\Omega e suponha que \\mu:\\mathcal{G}\\to\\mathbb{R}_{+} satisfa√ßa a seguinte propriedade: {display} Se (A_{i})_{i\\in I} e uma familia finita ou enumer√°vel de elementos disjuntos de \\mathcal{G} tal que \\cup_{i\\in I}A_{i}\\in\\mathcal{G} , temos \\mu(\\cup_{i\\in I}A_{i})=\\sum_{i\\in I}\\mu(A_{i}) . Ent√£o existe uma medida \\widebar{\\mu}:\\sigma(\\mathcal{G})\\to\\mathbb{R}_{+} tal que \\widebar{\\mu}(A)=\\mu(A) para todo A\\in\\mathcal{G} . Mostraremos agora uma consequ√™ncia simples do teorema acima, que √© muito utilizada em probabilidade. {lemma} [Extens√£o por continuidade no vazio] Seja \\mathcal{G}\\subseteq\\mathcal{P}(\\Omega) uma √°lgebra de conjuntos em \\Omega e suponha que P:\\mathcal{G}\\to\\mathbb{R}_{+} satisfa√ßa as seguintes propriedades: ‚ÄÉa)‚Äã P(\\Omega)=1 , ‚ÄÉb)‚Äã P √© finitamente aditiva e ‚ÄÉc)‚Äãsempre que B_{1}\\supseteq B_{2}\\supseteq\\dots\\in\\mathcal{G} forem tais que \\cap_{i}B_{i}=\\varnothing (denotamos isso por B_{i}\\downarrow\\varnothing ), temos que \\lim_{i}\\mu(B_{i})=0 . Ent√£o existe uma √∫nica medida \\widebar{P}:\\sigma(\\mathcal{G})\\to\\mathbb{R}_{+} tal que \\widebar{P}(A)=P(A) para A\\in\\mathcal{G} . Observe que P(\\Omega)=1 somente √© necess√°rio para provar a unicidade de \\widebar{P} , ent√£o poder√≠amos tentar mostrar uma vers√£o mais geral desse lema. Mas no contexto de medidas infinitas, n√£o √© de se esperar que B_{i}\\downarrow\\varnothing implique \\lim_{i}\\mu(B_{i})=0 , como foi assumido acima (veja tamb√©m a Proposi√ß√£o¬†1.2). Portanto resolvemos escrever o enunciado com probabilidades. {exercise} D√™ um exemplo de medida que n√£o satisfaz a terceira hip√≥tese do Lema¬†2.6.1. Demonstra√ß√£o. Primeiro observe que a unicidade segue da Proposi√ß√£o¬†1.3.1, j√° que \\mathcal{G} √© um \\pi -sistema. Iremos agora mostrar que a propriedade (2.6.1) √© v√°lida para P , logo tome A_{1},A_{2},\\dots\\in\\mathcal{G} disjuntos e tais que A=\\cup_{i\\in\\mathbb{N}}A_{i}\\in\\mathcal{G} . Definimos o ‚Äúresto da uni√£o‚Äù por B_{n}=A\\setminus\\mcup_{i=1}^{n}A_{i}. (2.52) Claramente ‚ÄÉa)‚Äã B_{n}\\downarrow\\varnothing e ‚ÄÉb)‚Äã B_{n}\\in\\mathcal{G} , pois \\mathcal{G} √© uma √°lgebra. Logo podemos escrever A como a uni√£o disjunta A=\\bigcup_{i=1}^{n}A_{i}\\cup B_{n} e j√° que P √© finitamente aditiva, P(A)=\\sum_{i=1}^{n}P(A_{i})+P(B_{n}), (2.53) mas como \\lim_{n\\to\\infty}P(B_{n})=0 , temos P(\\cup_{i=1}^{\\infty}A_{i})=\\sum_{i=1}^{\\infty}P(A_{i}), (2.54) mostrando a propriedade (2.6.1) e concluindo o teorema. ‚àé 2.6.2 Teorema da Extens√£o de Kolmogorov O objetivo desta se√ß√£o √© provar um resultado que nos permitir√° construir probabilidades em espa√ßos produtos infinitos. Antes precisaremos de introduzir algumas nota√ß√µes. Dada uma cole√ß√£o de espa√ßos (E_{i})_{i\\in\\mathbb{N}} , definimos o espa√ßo produto \\Omega=\\prod_{i=1}^{\\infty}E_{i}=\\big{\\{}(\\omega_{i})_{i\\in\\mathbb{N}}\\,:\\,% \\omega_{i}\\in E_{i}\\text{ para todo $i\\geq 1$}\\big{\\}} (2.55) e os mapas X_{i}:\\Omega\\to E_{i} , definidos para i=1,2,\\dots por X_{i}(\\omega_{1},\\omega_{2},\\dots)=\\omega_{i}, (2.56) que chamamos de coordenadas can√¥nicas associadas ao produto \\Omega . Se cada E_{i} √© dotado de uma \\sigma -√°lgebra \\mathcal{A}_{i} , ent√£o definimos \\mathcal{F}=\\sigma((X_{i})_{i\\geq 1}), (2.57) que √© claramente uma \\sigma -√°lgebra em \\Omega . Chamamos \\mathcal{F} de \\sigma -√°lbegra can√¥nica. {exercise} Mostre que em (\\mathbb{R}^{\\mathbb{N}},\\mathcal{F}) temos que os conjuntos ‚ÄÉa)‚Äã A=\\{\\liminf_{n\\to\\infty}X_{n}\\notin\\{\\infty,-\\infty\\}\\} , ‚ÄÉb)‚Äã B=\\{\\lim_{n\\to\\infty}X_{n}=4\\} e ‚ÄÉc)‚Äã C=\\{\\lim_{n\\to\\infty}\\tfrac{1}{n}X_{n}\\text{ existe}\\} s√£o todos mensur√°veis (eventos) com respeito a \\mathcal{F} . Al√©m disso Y=\\1_{A}\\liminf_{n\\to\\infty}X_{n} √© uma vari√°vel aleat√≥ria em (\\Omega,\\mathcal{F}) . {exercise} Verifique as seguinte afirma√ß√µes ‚ÄÉa)‚Äã \\mathcal{F}=\\sigma\\big{(}A_{1}\\times\\dots\\times A_{k}\\times E_{k+1}\\times E_{k% +2}\\times\\dots\\,:\\,k\\geq 1,A_{i}\\in\\mathcal{A}_{i},i\\leq k\\big{)} , os chamados eventos retangulares. ‚ÄÉb)‚Äã \\mathcal{F}=\\sigma\\big{(}A\\times E_{k+1}\\times E_{k+2}\\times\\dots\\,:\\,k\\geq 1,% A\\in\\mathcal{A}_{i}\\otimes\\dots\\otimes\\mathcal{A}_{k}\\big{)} , conhecidos como eventos cil√≠ndricos. {definition} Seja \\Omega=\\prod_{i\\in I}E_{i} um espa√ßo produto (infinito ou finito) dotado de uma probabilidade P . Se X_{i} √© uma coordenada can√¥nica, ent√£o chamamos a probabilidade (X_{i})_{*}P de distribui√ß√£o marginal de P na coordenada i . {theorem} [Extens√£o de Kolmogorov] Seja para cada n\\geq 1 uma medida de probabilidade P_{n} em \\mathbb{R}^{n} tal que seja satisfeita a seguinte condi√ß√£o de compatibilidade P_{n+1}(A\\times\\mathbb{R})=P_{n}(A),\\text{ para todo $A\\in\\mathcal{B}(\\mathbb{% R}^{n})$}. (2.58) Ent√£o existe uma √∫nica probabilidade P no espa√ßo produto infinito (\\Omega,\\mathcal{F}) tal que P(A\\times\\mathbb{R}\\times\\dots)=P_{n}(A) para todo n e todo boreliano A de \\mathbb{R}^{n} . Demonstra√ß√£o. Considere a classe de conjuntos \\mathcal{S}_{l}=\\Big{\\{}\\mcup_{j=1}^{k}[a_{1,j},b_{1,j})\\times\\dots\\times[a_{l% ,j},b_{l,j})\\subseteq\\mathbb{R}^{l}\\,:\\,a_{i,j}\\in\\mathbb{R}\\cup\\{-\\infty\\},\\ % b_{i,j}\\in\\mathbb{R}\\cup\\{\\infty\\}\\Big{\\}}. Que √© obviamente uma √°lgebra em \\mathbb{R}^{l} e seja tamb√©m \\mathcal{S}=\\big{\\{}A\\times\\mathbb{R}\\times\\dots\\,:\\,\\text{ onde }l\\geq 1\\text% { e }A\\in\\mathcal{S}_{l}\\big{\\}}. (2.59) Claramente, \\mathcal{S} tamb√©m √© uma √°lgebra. Se B=A\\times\\mathbb{R}\\times\\dots\\in\\mathcal{S} com A\\in\\mathcal{S}_{l} como acima, definimos P(B)=P_{l}(A). (2.60) Note que por (2.58) essa defini√ß√£o independe da escolha de l que usamos na defini√ß√£o de B . Gostar√≠amos agora de utilizar o Lemma¬†2.6.1. Para tanto, tome uma sequ√™ncia encaixada B_{1}\\supseteq B_{2}\\supseteq\\dots\\in\\mathcal{S} e, supondo que P(B_{n})\\geq\\delta>0 para todo n\\geq 1 , temos de mostrar que sua interse√ß√£o n√£o pode ser vazia. Como B_{n}\\in\\mathcal{S} , podemos escrever B_{n}=A_{n}\\times\\mathbb{R}\\times\\dots,\\text{ onde $A_{n}\\in\\mathcal{S}_{l_{n}% }$ e $n\\geq 1$.} (2.61) Podemos obviamente supor que l_{n} s√£o estritamente crescentes. (2.62) A fim de obter um ponto na interse√ß√£o de B_{n} , gostar√≠amos de aproxim√°-lo usando conjuntos compactos encaixados. Para tanto definimos os conjuntos C_{n}=C_{n}^{*}\\times\\mathbb{R}\\times\\dots,\\text{ com $C_{n}^{*}\\in\\mathcal{S}% _{l_{n}}$} (2.63) de forma que C_{n}^{*} seja compacto, C_{n}^{*}\\subseteq A_{n} e P(B_{n}\\setminus C_{n})\\leq\\frac{\\delta}{2^{l_{n}+1}}, (2.64) o que pode ser feito gra√ßas √† continuidade de P_{l_{n}} , que √© uma probabilidade. Temos ainda um problema, pois os conjuntos C_{n} n√£o s√£o encaixados, e isso nos impede de utilizar resultados sobre interse√ß√µes de compactos. Introduzimos pois D_{n}=\\bigcap_{i=1}^{n}C_{i} , que obviamente pertence √† √°lgebra \\mathcal{S} , e estimamos P(B_{n}\\setminus D_{n})=P\\big{(}\\mcup\\nolimits_{i=1}^{n}(B_{n}\\setminus C_{i})% \\big{)}\\leq\\sum_{i=1}^{n}P(B_{n}\\setminus C_{i})\\leq\\frac{\\delta}{2}, (2.65) donde P(D_{n})=P(B_{n})-P(B_{n}\\setminus D_{n})\\geq\\delta/2 . De forma que os D_{n} s√£o encaixados e n√£o vazios. Nosso pr√≥ximo obst√°culo vem do fato de que os conjuntos D_{n} est√£o definidos em \\mathbb{R}^{\\mathbb{N}} , e gostar√≠amos de ter conjuntos em espa√ßos de dimens√£o finita. Isso pode ser feito observando que podemos escrever D_{n}=D_{n}^{*}\\times\\mathbb{R}\\times\\mathbb{R}\\times\\dots , onde D_{n}^{*}\\in\\mathcal{S}_{l_{n}} e D_{n}^{*}=\\underbrace{C_{n}^{*}}_{\\mathclap{\\text{compacto}}}\\mcap\\underbrace{% \\Big{(}\\mcap_{i=1}^{n-1}C_{i}^{*}\\times\\mathbb{R}^{l_{n}-l_{i}}\\Big{)}}_{\\text% {fechado}}, (2.66) de forma que os D_{n}^{*}\\subseteq\\mathbb{R}^{l_{n}} s√£o compactos e n√£o vazios. Para cada n\\geq 1 considere um \\omega^{n}\\in D_{n} . Usando um argumento de diagonal de Cantor, podemos obter um \\omega\\in\\Omega e uma sub-sequ√™ncia de \\omega^{n_{j}} que convirja para \\omega\\in\\Omega coordenada a coordenada (observe que \\omega^{n_{j}}\\in\\mathbb{R}^{\\smash{l_{n_{j}}}} ). Para concluir a prova mostramos que \\omega\\in\\bigcap_{n\\geq 1}B_{n} . Para isso e suficiente mostrar (lembramos que por defini√ß√£o C_{n}\\subseteq B_{n} ) que para todo n\\in\\mathbb{N} \\omega=(\\omega_{1},\\omega_{2},\\dots)\\in C_{n}. O que e equivalente a (\\omega_{1},\\omega_{2},\\dots,\\omega_{n})\\in C^{*}_{n} , que vale por compacidade. ‚àé Observe que usamos muito poucos atributos de \\mathbb{R} na prova. Poder√≠amos na verdade substituir \\mathbb{R} por um espa√ßo m√©trico que satisfa√ßa certas propriedades, como por exemplo a exist√™ncia de uma √°lgebra cujos conjuntos possam ser aproximados por compactos. Contudo, decidimos n√£o apresentar essa vers√£o mais geral aqui porque muito em breve obteremos uma vers√£o bem mais geral do Teorema de Kolmogorov usando apenas o resultado para \\mathbb{R} . {exercise} Mostre que a hip√≥tese (2.58) pode ser substituida por P_{n+1}(I_{1}\\times\\dots,\\times I_{n}\\times\\mathbb{R})=P_{n}(I_{1}\\times\\dots% \\times I_{n}), (2.67) para todo n\\geq 1 e I_{i}=(-\\infty,b_{i}] , onde b_{i}\\in\\mathbb{R} , i\\leq n . Um importante exemplo do uso deste teorema √© o seguinte. {example} Se P_{i} s√£o probabilidades em (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) , podemos definir \\mathbb{P}_{n}=\\bigotimes_{i=1}^{n}P_{i} (relembrando, \\mathbb{P}_{n} √© a √∫nica distribui√ß√£o em \\mathbb{R}^{n} tal que \\mathbb{P}_{n}(A_{1}\\times\\dots\\times A_{n})=\\prod_{i=1}^{n}P_{i}(A_{i}) ). N√£o √© dif√≠cil verificar que essa lei satisfaz as equa√ß√µes de consist√™ncia (2.58). Desta forma, podemos construir uma √∫nica \\mathbb{P} em \\mathbb{R}^{\\mathbb{N}} para os quais as coordenadas can√¥nicas X_{i} s√£o independentes e possuem distribui√ß√µes marginais P_{i} . Denotamos nesse caso \\mathbb{P}=\\bigotimes_{i\\geq 1}P_{i} . Mais adiante no texto daremos outros exemplos bastante interessantes do uso do Teorema¬†2.6.2. {exercise} Mostre que se p>0 e \\mathbb{P}=\\bigotimes_{i\\geq 1}\\Ber(p) em \\mathbb{R}^{\\mathbb{N}} , ent√£o \\limsup_{n\\to\\infty}X_{n}=1 quase certamente. (2.68) {exercise} Mostre que se \\mathbb{P}=\\bigotimes_{i\\geq 1}U_{[0,1]} em \\mathbb{R}^{\\mathbb{N}} , ent√£o \\limsup_{n\\to\\infty}X_{n}=1 quase certamente. (2.69) {exercise} Mostre que se \\mathbb{P}=\\bigotimes_{i\\geq 1}\\Exp(i) em \\mathbb{R}^{\\mathbb{N}} , ent√£o \\limsup_{n\\to\\infty}X_{n}<\\infty quase certamente. (2.70) Previous page Next page"],[["index.html","Ch2.html","Ch2.S7.html"],"2.7 Distribui√ß√µes conjuntas ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Distribui√ß√µes conjuntas 2.7 Distribui√ß√µes conjuntas Um caso bastante importante de distribui√ß√£o de um elemento aleat√≥rio √© o caso de vetores. Digamos por exemplo que temos dois elementos aleat√≥rios X:\\Omega\\to E e Y:\\Omega\\to E^{\\prime} . J√° sabemos a defini√ß√£o de X_{*}P e Y_{*}P (vamos tamb√©m usar a nota√ß√£o P_{X} e P_{Y} ) que nada mais s√£o que as distribui√ß√µes de X e Y , respectivamente. Mas podemos considerar o vetor (X,Y) que ser√° um elemento aleat√≥rio tomando valores em E\\times E^{\\prime} e possui tamb√©m sua pr√≥pria distribui√ß√£o dada por (X,Y)_{*}P (tamb√©m denotada por P_{(X,Y)} ). A essa probabilidade em E\\times E^{\\prime} damos o nome de distribu√ß√£o conjunta deste par. . Vejamos as rela√ß√µes que existem entre P_{X} , P_{Y} e P_{(X,Y)} . Primeiramente, √© f√°cil ver que a distribu√ß√£o conjunta nos fornece as demais, pois para todo A\\subseteq E mensur√°vel P_{(X,Y)}(A\\times E^{\\prime})=P[(X,Y)\\in A\\times E^{\\prime}]=P[X\\in A]=P_{X}(A) (2.77) e analogamente para P_{Y} . De acordo com a Defini√ß√£o¬†2.6.2, as distribui√ß√µes P_{X} e P_{Y} nada mais s√£o do que as marginais da distribui√ß√£o conjunta. Apesar de podermos extrair as marginais P_{X} e P_{Y} de P_{(X,Y)} , o contr√°rio n√£o √© sempre poss√≠vel como mostra o seguinte exemplo. {example} Sejam X,Y \\iidcom distribui√ß√£o \\Ber(1/2) . Ent√£o (X,Y) n√£o tem a mesma distribui√ß√£o de (X,X) , apesar de que esses vetores possuem as mesmas marginais. {exercise} Mostre que se X e Y s√£o independentes, ent√£o P_{(X,Y)}=P_{X}\\otimes P_{Y} . {exercise} Sejam X,Y \\iidcom distribui√ß√£o U_{[0,1]} e calcule P_{(X,X+Y)} . Note que a discuss√£o acima se extende naturalmente para cole√ß√µes maiores de elementos aleat√≥rios. Mais precisamente, considere um conjunto I qualquer (finito, enumer√°vel ou n√£o enumer√°vel) de √≠ndices e seja (X_{i})_{i\\in I} uma cole√ß√£o de elementos aleat√≥rios tomando valores em (E_{i})_{i\\in I} . Ent√£o a distribui√ß√£o conjunta destes elementos aleat√≥rios √© P_{(X_{i})_{i\\in I}} . {exercise} Mostre que no caso acima, se P_{(X_{i})_{i\\in J}}=P_{(X^{\\prime}_{i})_{i\\in J}} para todo J\\subseteq I finito, ent√£o P_{(X_{i})_{i\\in I}}=P_{(X^{\\prime}_{i})_{i\\in I}} . Previous page Next page"],[["index.html","Ch2.html","Ch2.S8.html"],"2.8 Probabilidades condicionais ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Probabilidades condicionais 2.8 Probabilidades condicionais Uma outra maneira de se construir espa√ßos de probabilidade √© atrav√©s de condicionamento, como mostra a seguinte defini√ß√£o. {definition} Se (\\Omega,\\mathcal{F},P) √© espa√ßo de probabilidade e B\\in\\mathcal{F} √© tal que P(B)>0 , ent√£o definimos a probabilidade P(\\cdot|B):\\mathcal{F}\\to[0,1] por P(A|B)=\\frac{P(A\\cap B)}{P(B)}, (2.78) chamada probabilidade condicional dado o evento B . Obviamente P(\\cdot|B) √© uma probabilidade em (\\Omega,\\mathcal{F}) e podemos entend√™-la de duas formas: como uma normaliza√ß√£o ou como uma tentativa de sucesso. Explicaremos abaixo cada uma dessas interpreta√ß√µes. Quando restringimos o espa√ßo amostral \\Omega ao conjunto B (e associamos a A\\in\\mathcal{F} o valor P(A\\cap B) ), temos uma sub-probabilidade, isto √©, possivelmente P(\\Omega\\cap B)<1 . Logo podemos entender o denominador de (2.78) como uma normaliza√ß√£o para obtermos novamente uma probabilidade. Mas a interpreta√ß√£o mais natural de (2.78) √© dada pela seguinte proposi√ß√£o. Para enunci√°-la, considere (\\Omega,\\mathcal{F},P) um espa√ßo de probabilidade e defina o produto infinito \\widebar{\\Omega}=\\Omega^{\\mathbb{N}},\\qquad\\widebar{\\mathcal{F}}=\\mathcal{F}^{% \\otimes\\mathbb{N}}\\quad\\text{e}\\quad\\widebar P=P^{\\otimes\\mathbb{N}}. (2.79) Na verdade somente definimos esse produto para \\Omega=\\mathbb{R} , mas como mencionamos abaixo do Teorema da Extens√£o de Kolmogorov, isso pode ser facilmente generalizado e o faremos posteriormente. {proposition} Na situa√ß√£o acima, seja B\\in\\mathcal{F} com P(B)>0 e defina T:\\widebar{\\Omega}\\to\\mathbb{N} por T(\\omega)=\\inf\\{n\\geq 1\\,:\\,X_{n}(\\omega)\\in B\\} , onde os X_{n} s√£o as coordenadas can√¥nicas. Ent√£o T<\\infty quase certamente e X_{T(\\omega)}(\\omega) √© um elemento aleat√≥rio em \\Omega com distribui√ß√£o P(\\cdot|B) . (2.80) A intui√ß√£o desta proposi√ß√£o √© que se repetimos o experimento (\\Omega,\\mathcal{F},P) independentemente at√© obter uma amostra em B , essa ter√° a distribui√ß√£o condicional. Demonstra√ß√£o. Sejam os eventos A_{n}=[X_{n}\\in B] , n\\geq 1 que s√£o claramente independentes segundo \\widebar{P} . Logo, como \\sum_{n}\\widebar{P}(A_{n})=\\sum_{n}P(B)=\\infty , temos pelo Lema de Borel-Cantelli (segunda parte) que \\widebar{P}(\\text{$A_{n}$ infinitas vezes})=1 , logo T<\\infty quase certamente. Para ver que X_{T(\\omega)}(\\omega) √© um elemento alet√≥rio, basta escrever [X_{T}\\in A]=\\mcup_{t=1}^{\\infty}[X_{t}\\in A,T=t], (2.81) e observar que tanto [X_{t}\\in A] quanto [T=t]=[X_{1}\\not\\in B,\\dots,X_{t-1}\\not\\in B,X_{t}\\in B] s√£o mensur√°veis. Finalmente podemos usar a decomposi√ß√£o (disjunta) acima para calcular \\begin{split}\\widebar{P}[X_{T}\\in A]&=\\sum_{t=1}^{\\infty}\\widebar{P}[X_{t}\\in A% ,T=t]\\\\ &=\\sum_{t=1}^{\\infty}\\widebar{P}[X_{t}\\in A,X_{t}\\in B,X_{s}\\not\\in B\\text{ % for $s<t$}]\\\\ &=\\sum_{t=1}^{\\infty}P(A\\cap B)P(B^{c})^{t-1}=\\frac{P(A\\cap B)}{1-P(B^{c})}=P(% A|B),\\end{split} (2.82) terminando a prova da proposi√ß√£o. ‚àé {exercise} Sejam \\lambda>0 e X\\distr\\Exp(\\lambda) (lembrando a defini√ß√£o da distribui√ß√£o exponencial: \\Exp(\\lambda)(\\d{x})=\\lambda\\exp\\{-\\lambda x\\}\\d{x} ). Mostre que as vari√°veis com distribui√ß√£o exponencial n√£o possuem mem√≥ria, ou seja: P[X>t+s\\,|\\,X>t]=P[X>s],\\text{ para todo $s,t>0$}. (2.83) Ou em outras palavras, sabendo que X √© maior que t , a distribui√ß√£o condicional de X-t ainda √© \\Exp(\\lambda) . Definimos a distribui√ß√£o geom√©trica de par√¢metro p\\in(0,1] por \\Geo(p)=\\sum_{i=1}^{\\infty}(1-p)^{i-1}p\\delta_{i}. (2.84) {exercise} Inspirado no exerc√≠cio anterior, mostre que a distribui√ß√£o geom√©trica \\Geo(p) tamb√©m satisfaz (2.83) para todos t,s\\in\\mathbb{N} . Mostre que essas s√£o as √∫nicas distribui√ß√µes com suporte em \\mathbb{N} satisfazendo tal propriedade {exercise} Sejam Y_{i} , para i\\geq 1 , \\iidcom distribui√ß√£o \\Ber(p) e defina T=\\inf\\{i\\,:\\,Y_{i}=1\\}. (2.85) Mostre que T\\overset{d}{\\sim}\\Geo(p) . {exercise} Barry James: Cap. 2-5, Ex: 5, 10, 21, 22 (a) e (b). {exercise} [Porta dos desesperados] Nas tardes da d√©cada de 80, as crian√ßas tinham poucas op√ß√µes de entretenimento al√©m de assistir S√©rgio Malandro, que todos os dias apresentava o seguinte jogo. O participante era apresentado a tr√™s portas ( \\Omega=\\{1,2,3\\} ) e apenas uma delas (chamada de X ) continha um pr√™mio X\\distr U_{\\Omega} e o jogo seguia tr√™s fases: ‚ÄÉa)‚ÄãO participante escolhia uma porta arbitrariamente (digamos y\\in\\Omega ), ‚ÄÉb)‚Äão S√©rgio Malandro abria uma porta X^{\\prime} que n√£o fosse a escolhida nem a premiada ( X^{\\prime}\\distr U_{\\Omega\\setminus\\{y,X\\}} ) ‚ÄÉc)‚Äãao participante era dada a oportunidade de trocar sua porta X pela porta restante em \\Omega\\setminus\\{X,X^{\\prime}\\} . Mostre que o participante sempre aumenta suas chances ao trocar sua escolha. Tente interpretar esse aparente paradoxo tomando o n√∫mero de portas para infinito. {exercise} Em√≠lio e Cristina tiveram dois filhos cujos sexos X,X^{\\prime} s√£o \\iide distribuidos como U_{\\{\\male,\\female\\}} . Enunciando hip√≥teses adequadas se for necessario, calcule ‚ÄÉa)‚Äã P[X,X^{\\prime}=\\male|\\text{ pelo menos um \\'{e} $\\male$}] e ‚ÄÉb)‚Äã P[X,X^{\\prime}=\\male|\\text{ pelo menos um \\'{e} $\\male$ e nasceu em uma % segunda-feira}] . Interprete esses resultados trocando ‚Äúsegunda-feira‚Äù por ‚Äúprimeiro de abril‚Äù. 22 2 Gratos ao Ricardo Misturini por sugerir esse problema {exercise} Supondo que P(A\\cap B)>0 , mostre que ‚Äú P(\\cdot|A|B)=P(\\cdot|B|A) ‚Äù. Mais precisamente, podemos condicionar P em B e depois a probabilidade resultante em A ou vice-versa. {exercise} Sejam X,Y vari√°veis aleat√≥rias em um espa√ßo (\\Omega,\\mathcal{F},P) , independentes e com distribui√ß√£o U_{[0,1]} . ‚ÄÉa)‚ÄãCalcule P_{X+Y} . ‚ÄÉb)‚ÄãConsidere P^{\\prime}(\\cdot)=P\\big{(}\\cdot\\,|\\,X+Y\\leq 1\\big{)} e calcule X_{*}P^{\\prime} . 44todo: 4 Falar de Lei da Probabilidade Total, com exemplos. 2.8.1 Regra de Bayes Frequentemente definimos um espa√ßo de probabilidade atrav√©s de probabilidades condicionais. Consideramos por exemplo um exame m√©dico para detectar uma doen√ßa, caso em que temos \\Omega=\\{(\\text{doente},+),(\\text{doente},-),(\\text{saud\\'{a}vel},+),(\\text{% saud\\'{a}vel},-)\\}, (2.86) com obviamente a \\sigma -√°lgebra das partes. Contudo, ao contr√°rio do que fizemos anteriormente, n√£o daremos probabilidades p_{\\omega}\\in[0,1] para cada \\omega\\in\\Omega . Poder√≠amos por exemplo fornecer P(\\text{doente})=0.005,\\quad P(+|\\text{saud\\'{a}vel})=0.01,\\quad P(-|\\text{% doente})=0.05. (2.87) Obviamente podemos obter as probabilidades dos complementos dos eventos acima. As probabilidades acima podem ser facilmente estimadas num laborat√≥rio e as duas √∫ltimas s√£o chamadas respectivamente de probabilidades de falso positivo e falso negativo. Outra vantagem da representa√ß√£o em (2.87) √© que as probabilidades descritas s√£o mais ‚Äúcompartimentadas‚Äù no seguinte sentido. Note que P(\\text{doente}) somente depende da popula√ß√£o em quest√£o, enquanto as outras duas dependem apenas do exame e n√£o da popula√ß√£o. Isso n√£o pode ser dito das probabilidades de pontos individuais em \\Omega . Agora fica f√°cil construir nosso espa√ßo de probabilidade escrevendo, para r\\in\\{+,-\\} e e\\in\\{\\text{saud\\'{a}vel},\\text{doente}\\} , P(r\\cap e)=P(r|e)P(e). (2.88) E as probabilidades do lado direito da equa√ß√£o acima est√£o todas determinadas em (2.87) (possivelmente tomando complementos). Contudo, o que estamos interessado muitas vezes √© em como interpretar resultados de um exame. Por exemplo, quanto vele P(\\text{doente}|+) ? Isso nos √© fornecido em geral pela regra de Bayes enunciada na seguinte proposi√ß√£o. {proposition} Se (A_{j})_{j\\in I} formam uma parti√ß√£o (finita o enume√°vel) de \\Omega e B\\in\\mathcal{F} tem probabilidade positiva, ent√£o P(A_{i}|B)=\\frac{P(A_{i})P(B|A_{i})}{\\sum_{j\\in I}P(A_{j})P(B|A_{j})}. (2.89) Demonstra√ß√£o. Basta notar que P(A_{i}|B)=\\frac{P(A_{i})P(B|A_{i})}{P(B)}=\\frac{P(A_{i})P(B|A_{i})}{\\sum_{j% \\in I}P(B\\cap A_{j})}=\\frac{P(A_{i})P(B|A_{i})}{\\sum_{j\\in I}P(A_{j})P(B|A_{j}% )}. (2.90) ‚àé {exercise} Utilize a f√≥rmula acima para calcular P(\\text{doente}|+) com os dados em (2.87). Comente o resultado. {exercise} Barry James: Cap. 1, Ex: 18 e 19. \\todosec T√≥pico: Distribui√ß√µes de Extremosfazer‚Ä¶ \\todosec AcoplamentosTalvez valha a pena escrever sobre acoplamentos de maneira geral. Talvez pegando algo do Pascal Massart. Vale a pena tentar escrever algo sobre: composi√ßao de acoplamentos, quando um acoplamento ‚Äúd√° errado‚Äù‚Ä¶ Previous page Next page"],[["index.html","Ch2.html","Ch2.S9.html"],"2.9 N√∫cleos de transi√ß√£o ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. N√∫cleos de transi√ß√£o 2.9 N√∫cleos de transi√ß√£o J√° focamos bastante energia em vari√°veis aleat√≥rias independentes. Por exemplo, estudamos em detalhes o que acontece com a soma de tais vari√°veis. Agora passaremos a estudar elementos aleat√≥rios dependentes e o primeiro passo para isso √© obter um m√©todo geral de constru√≠-los. Definiremos agora um n√∫cleo de transi√ß√£o. Intuitivamente, ele nos d√° uma maneira de usar um elemento aleat√≥rio em um espa√ßo para induzir uma probabilidade em outro espa√ßo. Um exemplo em que poder√≠amos utilizar essa constru√ß√£o seria o seguinte. Digamos que estamos preocupados com a possibilidade de um deslizamento de terra em uma determinada regi√£o. A ocorr√™ncia desse deslizamento √© algo aleat√≥rio, mas que certamente depende da quantidade de chuva no per√≠odo, que tamb√©m podemos modelar como sendo aleat√≥ria. Ap√≥s estudarmos alguns trabalhos anteriores, descobrimos uma fun√ß√£o F:\\mathbb{R}_{+}\\to[0,1] que nos d√° a probabilidade de um deslizamento ocorrer, como fun√ß√£o da quantidade de chuva em mil√≠metros. Lendo o hist√≥rico pluvial da regi√£o, podemos estimar a distribui√ß√£o Q em \\mathbb{R}_{+} correspondente √† quantidade de chuva naquele per√≠odo. A lei F_{*}Q (tamb√©m chamada de Q_{F} ) √© uma lei em [0,1] que nos d√° a distribui√ß√£o da probabilidade de deslizamento, mas como seguimos em frente para obter a probabilidade de deslizamento (um n√∫mero entre zero e um)? Saberemos como fazer isso ao terminar essa se√ß√£o. Sejam (E_{1},\\mathcal{A}_{1}) e (E_{2},\\mathcal{A}_{2}) espa√ßos mensur√°veis. {definition} Um n√∫cleo de transi√ß√£o entre E_{1} e E_{2} √© uma fun√ß√£o K:E_{1}\\times\\mathcal{A}_{2}\\to[0,1], (2.91) tal que ‚ÄÉa)‚Äãpara todo y\\in E_{1} , K(y,\\cdot) √© uma probabilidade em (E_{2},\\mathcal{A}_{2}) e ‚ÄÉb)‚Äãpara todo A\\in\\mathcal{A}_{2} , a fun√ß√£o K(\\cdot,A):E_{1}\\to[0,1] √© \\mathcal{A}_{1} -mensur√°vel. {example} Daremos agora o exemplo da probabilidade de deslizamento como fun√ß√£o de F (que ser√° possivelmente uma vari√°vel aleat√≥ria). Nesse caso, seja E_{1}=[0,1] e E_{2}=\\{0,1\\} com as \\sigma -√°lgebras naturais e defina K(p,A)=\\big{(}(1-p)\\delta_{0}+p\\delta_{1}\\big{)}(A). (2.92) Vamos verificar que K definido acima √© um n√∫cleo de transi√ß√£o. De fato, ‚ÄÉi)‚Äã K(p,\\cdot) √© a distribui√ß√£o Bernoulli com par√¢metro p , que obviamente √© uma probabilidade, ‚ÄÉii)‚Äãal√©m disso, K(\\cdot,\\Omega)=1 , K(\\cdot,\\varnothing)=1 e K(\\cdot,\\{0\\})=1-p=1-K(\\cdot,\\{1\\}) , que obviamente s√£o mensur√°veis. Isso prova que esse K espec√≠fico √© um n√∫cleo de transi√ß√£o {example} [Caso discreto] Sejam E_{1} e E_{2} espa√ßos finitos ou enumer√°veis. Se p:E_{1}\\times E_{2}\\to[0,1] √© tal que para todo y\\in E_{1} temos \\sum_{z\\in E_{2}}p(y,z)=1 , ent√£o K(y,A):=\\sum_{z\\in A}p(y,z)\\text{ \\'{e} um n\\'{u}cleo de transi\\c{c}\\~{a}o % entre $E_{1}$ e $E_{2}$.} (2.93) Nesse caso p(y,z) representa a probabilidade que a segunda coordenada seja z , se a primeira √© y . {exercise} Mostre que se E_{1} e E_{2} s√£o enumer√°veis ent√£o todo n√∫cleo entre E_{1} e E_{2} pode ser escrito na forma do exemplo acima. {example} [Caso absolutamente cont√≠nuo] Digamos que E_{1} e E_{2} sejam dotados de medidas \\mu_{1} e \\mu_{2} \\sigma -finitas. Seja \\rho:E_{1}\\times E_{2}\\to\\mathbb{R}_{+} mensur√°vel e tal que para \\mu_{1} -quase todo y\\in E_{1} , tenhamos \\int_{E_{2}}\\rho(y,z)\\mu_{2}(\\d{z})=1 . Ent√£o K(y,A):=\\int_{A}\\rho(y,z)\\mu_{2}(\\d{z})\\text{ \\'{e} um n\\'{u}cleo de transi\\c{% c}\\~{a}o entre $E_{1}$ e $E_{2}$.} (2.94) Note que K(\\cdot,A) est√° bem definido para \\mu_{2} -quase todo ponto pelo Teorema de Fubini. {exercise} Prove que os dois exemplos acima de fato definem um n√∫cleo. Tipicamente, definimos os n√∫cleos de transi√ß√£o introduzindo K(y,\\cdot) como sendo uma medida que depende de y . Nesse caso, uma das condi√ß√µes para que K seja um n√∫cleo est√° automaticamente satisfeita, restando apenas mostrar que K(\\cdot,A) √© mensur√°vel para quaisquer A\\in\\mathcal{A}_{2} . Mas obviamente o conjunto \\mathcal{A}_{2} pode ser muito complexo, ent√£o gostar√≠amos de apenas verificar que K(\\cdot,A) √© mensur√°vel para os conjuntos A em uma classe rica o suficiente. {proposition} Seja K:E_{1}\\times\\mathcal{A}_{2}\\to[0,1] , tal que K(y,\\cdot) √© uma medida para todo y\\in E_{1} . Se K(\\cdot,A) √© mensur√°vel para todo A\\in\\mathcal{G} , onde \\mathcal{G} √© um \\pi -sistema que gera \\mathcal{A}_{2} , ent√£o K √© um n√∫cleo de transi√ß√£o. Demonstra√ß√£o. Como de costume, vamos definir \\mathcal{B}=\\{B\\in\\mathcal{A}_{2}\\,:\\,K(\\cdot,B)\\text{ \\'{e} $\\mathcal{A}_{1}$% -mensur\\'{a}vel}\\}. (2.95) Obviamente, como K(y,\\cdot) √© uma probabilidade, vale que ‚ÄÉa)‚Äã \\Omega\\in\\mathcal{B} , pois a fun√ß√£o constante igual a um √© mensur√°vel. ‚ÄÉb)‚ÄãSe B\\in\\mathcal{B} , ent√£o B^{c}\\in\\mathcal{B} , pois 1-f √© mensur√°vel se f o √©. ‚ÄÉc)‚ÄãE se B_{1},B_{2},\\dots,B_{n}\\in\\mathcal{B} s√£o disjuntos, ent√£o \\mcup_{i=1}^{n}B_{i}\\in\\mathcal{B} , pois a soma de fun√ß√µes mensur√°veis tamb√©m √© mensur√°vel. A discuss√£o acima mostra que \\mathcal{B} √© um \\lambda -sistema que cont√©m o \\pi -sistema \\mathcal{G} . Da√≠, vemos pelo Teorema¬†1.3 que \\mathcal{A}_{2}=\\sigma(\\mathcal{G})\\subseteq\\mathcal{B} , provando a proposi√ß√£o. ‚àé {exercise} Seja K:\\mathbb{R}\\times\\mathcal{B}(\\mathbb{R})\\to[0,1] dada por K(y,\\cdot)=U_{[y-1,y+1]} . Mostre que K define um n√∫cleo de transi√ß√£o. Apesar de interessante, a defini√ß√£o acima ainda n√£o nos permitiu definir espa√ßos de probabilidade novos. Isso ser√° possibilitado pelo pr√≥ximo resultado, que pode ser visto como uma generaliza√ß√£o do Teorema de Fubini. \\chooseoptpar{theorem} [Fubini para N√∫cleos de Transi√ß√£o] Dado um n√∫cleo \\optde transi√ß√£o K de (E_{1},\\mathcal{A}_{1}) para (E_{2},\\mathcal{A}_{2}) e uma probabilidade P_{1} em E_{1} , existe uma √∫nica probabilidade P em (E_{1}\\times E_{2},\\mathcal{A}_{1}\\otimes\\mathcal{A}_{2}) tal que \\int_{E_{1}\\times E_{2}}fdP=\\int_{E_{1}}\\int_{E_{2}}f(y,z)K(y,\\d{z})P_{1}(\\d{y% }), (2.96) para toda f:E_{1}\\times E_{2}\\to\\mathbb{R}_{+} . Em particular, P(A_{1}\\times A_{2})=\\int_{A_{1}}K(y,A_{2})P_{1}(\\d{y}) . Nesse caso escrevemos P=P_{1}\\star K . Antes de iniciar a prova do teorema, vamos ver que as integrais do lado direito de (2.96) est√£o bem definidas. Para isso, definimos para y\\in E_{1} a fun√ß√£o fatiadora \\phi_{y}:E_{2}\\to E_{1}\\times E_{2} dada por \\phi_{y}(z)=(y,z) . Obviamente essa fun√ß√£o √© mensur√°vel, pois \\phi_{y}^{-1}(A_{1}\\times A_{2})=\\begin{cases}\\varnothing,\\quad&\\text{ se $y% \\not\\in A_{1}$ e}\\\\ A_{2},&\\text{ se $y\\in A_{1}$}.\\end{cases} (2.97) Dessa forma, para definirmos \\int f(y,z)K(y,\\d{z}) , introduzimos f_{y}:A_{2}\\to\\mathbb{R}_{+} dada por f_{y}(z)=f(y,z) , que √© mensur√°vel pois f_{y}=f\\circ\\phi_{y} . Assim, gostar√≠amos de integrar a fun√ß√£o y\\mapsto\\int f_{y}(z)K(y,\\d{z}) , que est√° obviamente bem definida. Por√©m resta a pergunta, ser√° que essa express√£o define uma fun√ß√£o mensur√°vel de y ? {lemma} Se K √© um n√∫cleo de transi√ß√£o, ent√£o para toda f:E_{1}\\times E_{2}\\to\\mathbb{R}_{+} que seja \\mathcal{A}_{1}\\otimes\\mathcal{A}_{2} mensur√°vel, temos que g^{f}:A_{1}\\to\\mathbb{R}_{+} dada por g^{f}(y)=\\int f_{y}(z)K(y,\\d{z}) (2.98) √© \\mathcal{A}_{1} -mensur√°vel. Demonstra√ß√£o. Se f=\\1_{A_{1}\\times A_{2}} para A_{i}\\in\\mathcal{A}_{i} , i=1,2 , ent√£o temos que g^{f}(y)=K(y,A_{2})\\1_{A_{1}} , que obviamente √© mensur√°vel pois K √© um n√∫cleo. Definimos \\mathcal{D}=\\{B\\in\\mathcal{A}_{1}\\otimes\\mathcal{A}_{2}\\,:\\,g^{\\1_{B}}\\text{ % \\'{e} $\\mathcal{A}_{1}$-mensur\\'{a}vel}\\} . √â f√°cil ver que \\mathcal{D} √© um \\lambda -sistema que cont√©m o \\pi -sistema dos ret√¢ngulos, logo \\mathcal{D}=\\mathcal{A}_{1}\\otimes\\mathcal{A}_{2} . Acabamos de ver que g^{f} √© mensur√°vel para toda f indicadora, donde o mesmo vale para f simples por linearidade e para toda f positiva pelo Teorema da Converg√™ncia Mon√≥tona (lembre que limite de fun√ß√µes mensur√°veis √© mensur√°vel). ‚àé Estamos prontos agora para fornecer a Demonstra√ß√£o do Teorema¬†2.9. J√° sabemos que a integral do lado direito de (2.96) est√° bem definida (assumindo possivelmente o valor infinito). A unicidade vale obviamente pois (2.96) aplicado a fun√ß√µes indicadoras temos necessariamente para todos B P(B)=\\int_{E_{1}}\\int_{E_{2}}\\1_{B}K(y,\\d{z})P_{1}(\\d{y}). (2.99) S√≥ temos que verificar a f√≥rmula acima nos define uma probabilidade em (E_{1}\\times E_{2},\\mathcal{A}_{1}\\otimes\\mathcal{A}_{2}) . De fato, ‚ÄÉa)‚Äãobviamente P(\\Omega)=\\int_{E_{1}}\\int_{E_{2}}K(y,\\d{z})P_{1}(\\d{y})=1 e ‚ÄÉb)‚Äãse (B_{i})_{i\\in I} e uma fam√≠lia finita ou enumer√°vel de eventos disjuntos (em \\mathcal{A}_{1}\\otimes\\mathcal{A}_{2} ) ent√£o \\1_{\\bigcup_{i\\in I}B_{i}}=\\sum_{i\\in I}\\1_{B_{i}} a \\sigma -aditividade de P segue das propriedades b√°sicas (linearidade e Teorema de converg√™ncia mon√≥tona) da integra√ß√£o. Isto demonstra o teorema. ‚àé {exercise} Considere duas probabilidades P_{i} em (E_{i},\\mathcal{A}_{i}) para i=1,2 e K:E_{1}\\times\\mathcal{A}_{2}\\to[0,1] dado por K(y,A)=P_{2}(A) . Mostre que K √© n√∫cleo e que P_{1}\\star K=P_{1}\\otimes P_{2} . Relacione esse resultado ao Teorema de Fubini cl√°ssico para produtos de medidas. {exercise} Considere o n√∫cleo do Exemplo¬†2.9 e calcule: ‚ÄÉa)‚Äã U_{[0,1]}\\star K[X_{2}=1] , ‚ÄÉb)‚Äã P_{1}\\star K[X_{2}=1] , onde \\d{P}_{1}=2x\\d{x} e ‚ÄÉc)‚Äãencontre a distribui√ß√£o de (X_{1})_{*}\\big{(}U_{[0,1]}\\star K[\\;\\cdot\\;|X_{2}=1]\\big{)} . Interprete o resultado. {exercise} Seja P=P_{1}\\star K como acima e Q(\\cdot)=P[\\cdot|X_{2}=1] . Calcule \\int_{[0,1]\\times\\{0,1\\}}X_{1}\\d{Q} (2.100) {exercise} Para 0\\leq a<b\\leq 1 , definimos a probabilidade U_{[a,b]} em ([0,1],\\mathcal{B}([0,1])) atrav√©s da seguinte f√≥rmula U_{[a,b]}(B)=\\mathcal{L}(B\\cap[a,b])/(b-a) . Consideramos tamb√©m a fun√ß√£o K:[0,1]\\times\\mathcal{B}([0,1])\\to[0,1] dada por K(x,\\cdot)=U_{[0,x]}(\\cdot) , se x>0 e K(0,\\cdot)=\\delta_{0}(\\cdot) . ‚ÄÉa)‚ÄãMostre que K √© um n√∫cleo de transi√ß√£o. ‚ÄÉb)‚ÄãCalcule U_{[0,1]}\\star K[X_{1}<1/2] e U_{[0,1]}\\star K[X_{2}<1/2] , onde X_{1} e X_{2} s√£o as proje√ß√µes can√¥nicas em [0,1]^{2} . ‚ÄÉc)‚ÄãMostre que U_{[0,1]}\\star K √© absolutamente cont√≠nua com respeito √† medida de Lebesgue em [0,1]^{2} e calcule sua densidade. {exercise} Considere K:E_{1}\\times\\mathcal{A}_{2}\\to[0,1] dada por K(p,\\cdot)=\\Exp(p) . Mostre que K √© n√∫cleo de transi√ß√£o e calcule U_{[0,1]}\\star K[X_{2}>1] . {exercise} Se K √© um n√∫cleo de transi√ß√£o entre E_{1} e E_{2} e \\{y\\}\\in\\mathcal{A}_{1} satisfaz P_{1}(\\{y\\})>0 , mostre que P_{1}\\star K[X_{2}\\in\\cdot|X_{1}=y]=K(y,\\cdot). (2.101) Ou em outras palavras, K nos d√° a distribui√ß√£o condicional de X_{2} dado X_{1}=y . Posteriormente extenderemos o resultado acima para o caso P_{1}(\\{y\\})=0 , mas isso demandar√° algum esfor√ßo. Vamos introduzir uma √∫ltima nota√ß√£o com respeito a n√∫cleos de transi√ß√£o. Muitas vezes, n√£o estamos interessados na distribui√ß√£o conjunta de P_{1}\\star K em E_{1}\\times E_{2} , mas apenas na distribui√ß√£o marginal da segunda coordenada. No nosso problema da chuva por exemplo, talvez poder√≠amos estar interessados apenas na probabilidade final de ocorrer um deslizamento. Nesse caso, √© conveniente escrever P_{1}K:=(X_{2})_{*}(P_{1}\\star K)=(P_{1}\\star K)_{X_{2}}. (2.102) {exercise} Seja K:\\mathbb{R}_{+}\\times\\mathcal{B}(\\mathbb{R}_{+})\\to[0,1] dada pela equa√ß√£o K(x,A)=\\int_{A}x\\exp\\{-xt\\}\\d{t} . ‚ÄÉa)‚ÄãProve que K √© um n√∫cleo de transi√ß√£o. ‚ÄÉb)‚ÄãSeja P dada por P=\\textnormal{Exp}(1)\\star K . Obtenha P[X_{2}>x_{2}] para todo x_{2}\\geq 0 (lembrando que X_{2} denota a segunda coordenada no espa√ßo produto onde est√° definida P ). Compare a probabilidade acima com K(1,[x_{2},\\infty)) . ‚ÄÉc)‚ÄãMostre que P[X_{1}+X_{2}\\geq z]=\\int_{0}^{z}\\exp\\{-x(z-x+1)\\}\\d{x}+\\exp\\{-z\\} . Previous page Next page"],[["index.html","Ch2.html","Ch2.Sx1.html"],"T√≥pico: M√©todo Probabil√≠stico ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. T√≥pico: M√©todo Probabil√≠stico T√≥pico: M√©todo Probabil√≠stico Uma importante ferramenta em v√°rias √°reas da matem√°tica, tais como Teoria dos N√∫meros, Combinat√≥ria e Teoria da Computa√ß√£o √© o que chamamos de M√©todo Probabil√≠stico. Em v√°rias situa√ß√µes, n√≥s precisamos de mostrar a exist√™ncia de objetos satisfazendo determinadas propriedades, mas n√£o temos informa√ß√£o suficiente ou capacidade para constru√≠-los explicitamente. Nesse caso, podemos recorrer ao M√©todo Probabil√≠stico, que simplesmente nos sugere tomar um objeto aleat√≥rio de uma maneira esperta e mostrar que com probabilidade positiva as propriedades desejadas ser√£o satisfeitas. Esse m√©todo, apesar de muito ing√™nuo, √© muito eficiente e em diversos casos prov√™ os melhores exemplos conhecidos de certos objetos (para embara√ßo da comunidade cient√≠fica). Nessa se√ß√£o daremos um exemplo em Teoria dos N√∫meros provido primeiramente por Erd√µs11 1 Somos gratos a Robert Morris por sugerir esse teorema como exemplo do M√©todo Probabil√≠stico.. {theorem} [Erd√∂s] Para todo conjunto finito A\\subset\\mathbb{N} , existe um sub-conjunto B\\subseteq A satisfazendo ‚ÄÉa)‚Äã \\#B\\geq\\frac{\\#A}{3} e tal que ‚ÄÉb)‚Äãn√£o existem x,y e z\\in B com x+y=z . A propriedade b) acima √© o que chamamos de um conjunto ser livre de somas. Certamente n√£o temos muita informa√ß√£o sobre A , ent√£o vamos usar o m√©todo probabil√≠stico para a prova desse teorema. Demonstra√ß√£o. Fixamos p um n√∫mero primo maior que tr√™s vezes o maior elemento de A e considere o espa√ßo \\mathbb{Z}_{p} dos inteiros m√≥dulo p . Seja X um elemento aleat√≥rio de \\mathbb{Z}_{p} com distribui√ß√£o uniforma, isto √© U_{\\{0,\\dots,p-1\\}} . {exercise} Mostre que para todo a\\in A , a multiplica√ß√£o por a √© uma bije√ß√£o em \\mathbb{Z}_{p} , ou seja \\mathbb{Z}_{p}\\cdot a=\\mathbb{Z}_{p}. (2.3) onde o produto \\mathbb{Z}_{p}\\cdot a √© entendido elemento a elemento. Conclua que P\\Big{[}X\\cdot a\\in\\big{[}\\tfrac{p}{3},\\tfrac{2p}{3}\\big{)}\\Big{]}\\geq\\frac{1}% {3}-\\frac{1}{p}. (2.4) Definimos o conjunto aleat√≥rio \\mathcal{B}=\\{a\\in A\\ |X\\cdot a\\in[\\tfrac{p}{3},\\tfrac{2p}{3})\\}. (2.5) Esse conjunto √© livre de soma: se X=0 o conjunto √© vazio e, nos outros casos, se a,b\\in\\mathcal{B} ent√£o X(a+b)\\in[\\tfrac{2p}{3},\\tfrac{4p}{3}) (2.6) que √© o complemento de [\\tfrac{p}{3},\\tfrac{2p}{3}) em \\mathbb{Z}_{p} . Basta portanto mostrar que com probabilidade positiva \\#\\mathcal{B}\\geq\\tfrac{\\#A}{3} , que segue do seguinte argumento. Note inicialmente que \\int\\#\\mathcal{B}\\d{P}=\\int\\sum_{a\\in A}\\1_{\\big{[}X\\cdot a\\in[p/3,2p/3)\\big{]% }}\\d{P}\\\\ =\\sum_{a\\in A}P\\Big{[}X\\cdot a\\in\\big{[}\\tfrac{p}{3},\\tfrac{2p}{3}\\big{)}\\Big{% ]}\\geq\\frac{\\#A}{3}-\\frac{\\#A}{p}>\\frac{\\#A-1}{3}, mas, para qualquer vari√°vel aleat√≥ria, P[Y\\geq\\int Y\\d{P}]>0 . Nesse caso, isso implica P[\\#\\mathcal{B}\\geq\\tfrac{\\#A}{3}]=P[\\#\\mathcal{B}>\\tfrac{\\#A-1}{3}]\\geq P\\Big% {[}\\#\\mathcal{B}>\\int\\#\\mathcal{B}\\d{P}\\Big{]}>0. (2.7) ‚àé 11todo: 1 Adicionar contexto hist√≥rico: citar artigo Erdos e o Annals of Math que mostra que n√£o √© poss√≠vel com \\#A(1/3+\\varepsilon) . Previous page Next page"],[["index.html","Ch2.html","Ch2.Sx2.html"],"T√≥pico: Lei dos pequenos n√∫meros ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. T√≥pico: Lei dos pequenos n√∫meros T√≥pico: Lei dos pequenos n√∫meros Nessa se√ß√£o estudaremos como se comportam limites de algumas vari√°veis aleat√≥rias bastante importantes, mas primeiramente, uma breve intui√ß√£o. Apesar de que descreveremos a nossa motiva√ß√£o a partir desse exemplo do estudo de um material radioativo, podemos encontrar aplica√ß√µes com justificativas bastante semelhantes para outros problemas, como: chegada de carros em um sinal de tr√¢nsito, n√∫mero de muta√ß√µes em um gene, n√∫mero de mortes por ano em uma faixa et√°ria‚Ä¶ Digamos que estamos observando um material radioativo que esporadicamente emite f√≥tons que podemos detectar atrav√©s de um aparelho. A raz√£o dessas emiss√µes pode ser aproximada pelo seguinte modelo. Na amostra temos um n√∫mero n grande de √°tomos inst√°veis ( n\\sim 10^{23} ) e em um determinado tempo de observa√ß√£o, cada um deles tem probabilidade muito baixa de decair emitindo um f√≥ton (digamos p\\sim 10^{-23} ). Nesse caso, supondo que todos decidam emitir de maneira independente, temos para p\\in[0,1] , \\Omega_{n}=\\{0,1\\}^{n},\\quad\\mathcal{F}_{n}=\\mathcal{P}(\\Omega)\\quad\\text{e}% \\quad P_{p}=\\otimes_{i=1}^{n}Ber(p). (2.30) Dessa forma, o n√∫mero total de emiss√µes observadas para \\omega=(\\omega_{1},\\dots,\\omega_{n})\\in\\Omega √© X_{n}(\\omega)=\\sum_{i=1}^{n}\\omega_{i}. (2.31) E gostar√≠amos de entender como se comporta essa distribui√ß√£o, que nada mais √© que \\Bin(n,p) . Uma primeira tentativa seria modelar esse processo dizendo que o n√∫mero de √°tomos n √© t√£o grande, que somente estamos interessados no comportamento assint√≥tico quando n vai para infinito. Mas para manter o n√∫mero de emiss√µes sob controle, tamb√©m gostar√≠amos que p=p_{n} , que converge a zero. Poder√≠amos por exemplo escolher p_{n}=\\frac{\\lambda}{n}. (2.32) Mas a discuss√£o que se segue √© muito mais geral que essa escolha espec√≠fica. Como estaremos interessados em um regime assint√≥tico da distribui√ß√£o de X_{p} (lembre que apesar do espa√ßo amostral de X_{n} variar com n , sua distribui√ß√£o √© sempre uma probabilidade em \\mathbb{N} ), precisamos de definir uma no√ß√£o de dist√¢ncia entre duas distribui√ß√µes em \\mathbb{N} . {definition} Dadas duas distribui√ß√µes \\mu_{1} e \\mu_{2} em (\\Omega,\\mathcal{A}) , definimos \\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}=\\sup_{A\\in\\mathcal{A}}|\\mu_{1}(A)-\\mu_{2}(A)|, (2.33) chamada de dist√¢ncia em varia√ß√£o total entre \\mu_{1} e \\mu_{2} . No nosso caso, \\Omega √© enumer√°vel. Vamos ver que nesse caso √© poss√≠vel reescrever a defini√ß√£o acima de modo a ver mais facilmente que se trata de uma dist√¢ncia no espa√ßo de probabilidades em \\Omega . {lemma} Se \\Omega for finito ou enumer√°vel, ent√£o podemos escrever \\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}=\\frac{1}{2}\\sum_{x\\in\\Omega}|\\mu_{1}(x)-\\mu_% {2}(x)|. (2.34) Demonstra√ß√£o. Para mostrar que o lado esquerdo √© maior ou igual ao direito, escolhemos A=\\{x\\in\\Omega\\,:\\,\\mu_{2}(x)\\leq\\mu_{1}(x)\\} . Assim \\begin{split}\\sum_{x\\in A}\\mu_{1}(x)-\\mu_{2}(x)&=|\\mu_{1}(A)-\\mu_{2}(A)|\\\\ &=|\\mu_{1}(A^{c})-\\mu_{2}(A^{c})|=\\sum_{x\\in A^{c}}\\mu_{2}(x)-\\mu_{1}(x),\\end{split} (2.35) donde \\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}\\geq|\\mu_{1}(A)-\\mu_{2}(A)|=\\frac{1}{2}\\sum_{% i}|\\mu_{1}(x_{i})-\\mu_{2}(x_{i})|. (2.36) Na outra dire√ß√£o, observe que para todo B\\subseteq\\Omega , \\begin{split}\\sum_{i}|\\mu_{1}(x_{i})-\\mu_{2}(x_{i})|&\\geq\\sum_{x\\in B}\\mu_{1}(% x)-\\mu_{2}(x)+\\sum_{x\\in B^{c}}\\mu_{2}(x)-\\mu_{1}(x)\\\\ &=\\mu_{1}(B)-\\mu_{2}(B)+(1-\\mu_{2}(B))-(1-\\mu_{1}(B))\\\\ &=2(\\mu_{1}(B)-\\mu_{2}(B)).\\end{split} (2.37) O que termina a prova do lema. ‚àé Fica agora claro que \\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT} determina uma dist√¢ncia. {exercise} Mostre um lema an√°logo ao anterior para (\\Omega,\\mathcal{A}) qualquer, desde que \\mu_{1} e \\mu_{2} sejam absolutamente cont√≠nuas com rela√ß√£o √† uma medida fixa nesse espa√ßo mensur√°vel. Nesse caso utilizaremos as derivadas de Radon‚ÄìNikodym. Como estaremos interessados em vari√°veis independentes, precisamos de um resultado que relacione a dist√¢ncia em varia√ß√£o total com produtos de medida. Isso √© parte do seguinte {lemma} Sejam \\mu_{1},\\mu_{2} distribui√ß√µes em \\Omega e \\nu_{1},\\nu_{2} distribui√ß√µes em \\Omega^{\\prime} ambos enumer√°veis. Ent√£o \\lVert\\mu_{1}\\otimes\\nu_{1}-\\mu_{2}\\otimes\\nu_{2}\\rVert_{\\VT}\\leq\\lVert\\mu_{1}% -\\mu_{2}\\rVert_{\\VT}+\\lVert\\nu_{1}-\\nu_{2}\\rVert_{\\VT}. (2.38) Demonstra√ß√£o. Basta expandir \\begin{split}2\\lVert\\mu_{1}&\\otimes\\nu_{1}-\\mu_{2}\\otimes\\nu_{2}\\rVert_{\\VT}=% \\sum_{x\\in\\Omega,y\\in\\Omega^{\\prime}}|\\mu_{1}(x)\\nu_{1}(y)-\\mu_{2}(x)\\nu_{2}(y% )|\\\\ &\\leq\\sum_{x\\in\\Omega,y\\in\\Omega^{\\prime}}|\\mu_{1}(x)\\nu_{1}(y)-\\mu_{1}(x)\\nu_% {2}(y)|+|\\mu_{1}(x)\\nu_{2}(y)-\\mu_{2}(x)\\nu_{2}(y)|\\\\ &\\leq 2\\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}+2\\lVert\\nu_{1}-\\nu_{2}\\rVert_{\\VT},% \\end{split} (2.39) onde acima usamos que \\mu_{1} e \\nu_{2} s√£o probabilidades. Isso termina a prova do lema. ‚àé Finalmente, gostar√≠amos de entender como a dist√¢ncia de varia√ß√£o total se comporta com respeito √† soma de vari√°veis independentes. Isso estar√° ligado √† convolu√ß√£o de distribui√ß√µes: {definition} Dadas, \\mu e \\nu distribui√ß√µes em \\mathbb{Z} , definimos a distribui√ß√£o (\\mu\\star\\nu)(x):=\\sum_{y\\in\\mathbb{Z}}\\mu(x-y)\\nu(y). (2.40) Essa defini√ß√£o se relaciona com a soma de vari√°veis independentes gra√ßas ao seguinte {exercise} Se X\\overset{d}{\\sim}\\mu e Y\\overset{d}{\\sim}\\nu s√£o vari√°veis aleat√≥rias inteiras e independentes, ent√£o X+Y\\overset{d}{\\sim}\\mu\\star\\nu . Dica: particione o espa√ßo amostral nos eventos [X=j] , para j\\in\\mathbb{Z} , como na prova do Lema¬†2 abaixo. {corollary} Se \\mu e \\nu s√£o distribui√ß√µes em \\mathbb{Z} , ent√£o \\mu\\star\\nu=\\nu\\star\\mu . Como prometido, obtemos a seguinte rela√ß√£o entre a convolu√ß√£o e a dist√¢ncia de varia√ß√£o total. {lemma} Sejam \\mu , \\nu duas medidas em \\Omega enumer√°vel e X:\\ (\\Omega,\\mathcal{P}(\\Omega))\\to(E,\\mathcal{A}) um elemento aleatorio \\lVert X_{*}\\mu-X_{*}\\nu\\rVert_{\\VT}\\leq\\lVert\\mu-\\nu\\rVert_{\\VT}. (2.41) Em particular se \\mu_{1},\\mu_{2},\\nu_{1},\\nu_{2} s√£o distribui√ß√µes em \\mathbb{Z} , ent√£o \\lVert\\mu_{1}\\star\\nu_{1}-\\mu_{2}\\star\\nu_{2}\\rVert_{\\VT}\\leq\\lVert\\mu_{1}% \\otimes\\nu_{1}-\\mu_{2}\\otimes\\nu_{2}\\rVert_{\\VT} (2.42) Demonstra√ß√£o. O segundo ponto segue do primeiro aplicado ao caso \\Omega=\\mathbb{Z}^{2} , E=\\mathbb{Z} e X:\\ (x,y)\\mapsto(x+y) . Para o primeiro, observamos \\begin{split}2\\lVert X_{*}\\mu-X_{*}\\nu\\rVert_{\\VT}&=\\sum_{x\\in X(\\Omega)}\\Big{% |}\\mu(X(\\omega)=x)-\\nu(X(\\omega)=x)\\Big{|}\\\\ &=\\sum_{x\\in X(\\Omega)}\\Big{|}\\sum_{\\omega\\in\\Omega\\ :\\ X(\\omega)=x}\\mu(\\omega% )-\\nu(\\omega)\\Big{|}\\\\ &\\leq\\sum_{\\omega\\in\\Omega}\\big{|}\\mu(\\omega)-\\nu(\\omega)\\big{|}\\\\ &=2\\lVert\\mu-\\nu\\rVert_{\\VT},\\end{split} (2.43) provando o lema. ‚àé Para enunciar o resultado principal dessa se√ß√£o, vamos apresentar uma distribui√ß√£o em \\mathbb{N} bastane importante, que em particular se comporta muito bem com respeito a somas de vari√°veis independentes, como veremos. {definition} Uma vari√°vel aleat√≥ria X √© dita ter distribui√ß√£o de Poisson com par√¢metro \\lambda , se P[X=k]=\\frac{\\lambda^{k}e^{-\\lambda}}{k!},\\text{ para $k\\geq 0$ inteiro.} (2.44) Denotamos isso por X\\overset{d}{\\sim}\\Poisson(\\lambda) . A distribui√ß√£o de Poisson se comporta bem com respeito a somas independentes, como mostra o seguinte {lemma} Sejam X\\overset{d}{\\sim}\\Poisson(\\lambda_{1}) e Y\\overset{d}{\\sim}\\Poisson(\\lambda_{2}) independentes, ent√£o X+Y\\overset{d}{\\sim}\\Poisson(\\lambda_{1}+\\lambda_{2}) . Demonstra√ß√£o. Basta calcular \\begin{split}P[X+Y=k]&=\\sum_{j=0}^{k}P[X=j,Y=k-j]=\\sum_{j=0}^{k}\\frac{\\lambda_% {1}^{j}e^{-\\lambda_{1}}\\lambda_{2}^{k-j}e^{-\\lambda_{2}}}{j!(k-j)!}\\\\ &=e^{-(\\lambda_{1}+\\lambda_{2})}\\frac{1}{k!}\\sum_{j=0}^{k}\\frac{k!}{j!(k-j)!}% \\lambda_{1}^{j}\\lambda_{2}^{k-j}=\\frac{e^{(\\lambda_{1}+\\lambda_{2})}(\\lambda_{% 1}+\\lambda_{2})^{k}}{k!},\\end{split} (2.45) mostrando o resultado. ‚àé Nossa pr√≥xima tarefa √© estimar a dist√¢ncia entre uma vari√°vel aleat√≥ria com distribui√ß√£o \\Ber(p) e uma \\Poisson(p) , como segue. {lemma} Para p\\in[0,1] , seja \\mu_{1}=\\Ber(p) e \\mu_{2}=\\Poisson(p) , ent√£o, \\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}\\leq p^{2}. (2.46) Demonstra√ß√£o. Sabemos que \\begin{split}\\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}&=\\frac{1}{2}\\sum_{x}|\\mu_{1}(x)% -\\mu_{2}(x)|\\\\ &=\\frac{1}{2}\\Big{(}|\\mu_{1}(0)-\\mu_{2}(0)|+|\\mu_{1}(1)-\\mu_{2}(1)|+\\sum_{x% \\geq 2}\\mu_{2}(x)\\Big{)}\\\\ &=\\frac{1}{2}\\Big{(}e^{-p}-(1-p)+p(1-e^{-p})+(1-e^{-p}-pe^{-p})\\Big{)}\\\\ &=\\frac{2}{2}p(1-e^{-p})\\leq p^{2},\\end{split} (2.47) terminando a prova. ‚àé O teorema principal de converg√™ncia dessa se√ß√£o concerne a soma de vari√°veis Bernoulli. {theorem} [Lei dos Pequenos N√∫meros] Dado, n\\geq 1 e p\\in[0,1] , suponha que \\Omega_{n} , \\mathcal{F}_{n} e P_{p} sejam dados como em (2.30). Ent√£o, \\lVert\\Bin(n,p)-\\Poisson(pn)\\rVert_{\\VT}\\leq np^{2}. (2.48) Demonstra√ß√£o. Basta observar que \\begin{split}\\lVert X_{n}\\circ P_{p}-\\Poisson(pn)\\rVert_{\\VT}&\\overset{\\text{% Lema\\leavevmode\\nobreak\\ \\ref{l:soma_poisson}}}{=}\\lVert\\Ber(p)^{\\star n}-% \\Poisson(p)^{\\star n}\\rVert_{\\VT}\\\\ \\overset{\\text{Lema\\leavevmode\\nobreak\\ \\ref{l:vt_conv}}}{\\leq}&\\lVert\\Ber(p)^% {\\otimes n}-\\Poisson(p)^{\\otimes n}\\rVert_{\\VT}\\\\ \\overset{\\text{Lema\\leavevmode\\nobreak\\ \\ref{l:vt_produto}}}{\\leq}&n\\lVert\\Ber% (p)-\\Poisson(p)\\rVert_{\\VT}\\overset{\\text{Lema\\leavevmode\\nobreak\\ \\ref{l:vt_% ber_poiss}}}{\\leq}np^{2},\\end{split} (2.49) provando o teorema. ‚àé {corollary} No mesmo contexto do teorema acima, se p=\\lambda/n , ent√£o temos \\lVert\\Bin(n,p)-\\Poisson(pn)\\rVert_{\\VT}\\leq\\lambda^{2}/n, (2.50) que converge a zero com n . Veremos mais tarde que existem outros tipos de converg√™ncia. {exercise} Fixado \\lambda>0 , seja N uma vari√°vel aleat√≥ria com distribui√ß√£o Poisson( \\lambda ), isto √© P[N=k]=\\frac{\\lambda^{k}e^{-\\lambda}}{k!}\\text{ para $k=0,1,\\dots$} (2.51) Considere no mesmo espa√ßo de probabilidade uma sequ√™ncia de vari√°veis aleat√≥rias X_{1},X_{2},\\dots que sejam \\iid, com distribui√ß√£o \\Ber(1/2) e independentes de N . ‚ÄÉa)‚ÄãCalcule a distribui√ß√£o de Z=\\sum_{i=1}^{N}X_{i} . ‚ÄÉb)‚ÄãMostre que Z e N-Z s√£o independentes. Previous page Next page"],[["index.html","Ch2.html","Ch2.Sx3.html"],"T√≥pico: Percola√ß√£o ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. T√≥pico: Percola√ß√£o T√≥pico: Percola√ß√£o Imagine que gostar√≠amos de modelar o movimento de um l√≠quido em um meio poroso, como uma rocha ou uma esponja. A primeira tarefa nesse estudo seria modelar esse meio poroso de maneira matematicamente rigorosa, que √© o que faremos a seguir. Fixamos uma dimens√£o d\\geq 1 e consideramos o seguinte grafo (\\mathbb{Z}^{d},E) , onde a rede quadrada \\mathbb{Z}^{d} √© o conjunto de v√©rtices e o conjunto de elos √© dado por E=\\big{\\{}\\{x,y\\}\\subset\\mathbb{Z}^{d}\\,:\\,|x-y|=1\\}, onde |\\cdot| representa a dist√¢ncia euclideana em \\mathbb{R}^{d} . No nosso modelo, esse grafo pode ser entendido como um cristal peri√≥dico onde cada v√©rtice representa uma cavidade do material poroso e os elos s√£o potenciais conex√µes entre poros vizinhos. At√© agora nosso grafo √© apenas uma rede peri√≥dica, mas as coisas come√ßam a ficar interessantes √† partir de agora. Imaginamos que nosso material poroso est√° sujeito a varia√ß√µes durante sua forma√ß√£o. Isso se reflete no fato que alguns elos de E podem estar abertos ou n√£o aleatoriamente. Para o nosso modelo, o espa√ßo amostral vai ser \\Omega:=\\{0,1\\}^{E} considerado com a \\sigma -algebra produto. Fixamos um p\\in[0,1] e definimos uma cole√ß√£o de vari√°veis aleat√≥rias \\omega_{e} , para e\\in E , que sejam \\iide com distribui√ß√£o \\Ber(p) . Chamamos P_{p} a probabilidade correspondente. Essas vari√°veis aleat√≥rias induzem um grafo aleat√≥rio G(\\omega)=(\\mathbb{Z}^{d},\\mathcal{E}(\\omega)) , subgrafo do grafo original, que corresponde a incluir apenas os elos e com \\omega_{e}=1 . Mais precisamente \\mathcal{E}(\\omega)=\\big{\\{}e\\in E\\,:\\,\\omega_{e}=1\\big{\\}}. (2.71) Podemos ver na Figura¬†2.2 algumas simula√ß√µes desse grafo aleat√≥rio. Figura 2.2: Tr√™s simula√ß√µes do grafo aleat√≥rio (\\mathbb{Z}^{d},\\mathcal{E}) , para valores de p=0,4 (esquerda), p=0,5 (centro) e p=0,6 (direita). Tente imaginar como seria caminhar nesse grafo como se ele fosse um labirinto. Agora que temos um modelo de meio poroso bem definido, precisamos pensar em quais perguntas nos interessam sobre \\mathcal{G}=(\\mathbb{Z}^{d},\\mathcal{E}) . Sendo esse um modelo para passagem de fluidos, as primeiras perguntas que faremos concerne a conectividade de \\mathcal{G} . {exercise} Mostre que quase certamente G(\\omega) √© desconexo. Mais precisamente, mostre que existem quase certamente infinitos v√©rtices isolados em G(\\omega) . Como n√£o podemos esperar que G(\\omega) seja conexo, podemos nos perguntar algo mais fraco, como por exemplo se a componente conexa da origem 0\\in\\mathbb{Z}^{d} em G(\\omega) √© infinita. Voltando √† Figura¬†2.2 vemos que, dependendo do valor de p\\in[0,1] , pode ser bem dif√≠cil ou bem f√°cil encontrar um caminho longo √† partir da origem. Isso √© o que estudaremos em mais detalhes no que segue. Mais precisamente estamos interessados em: A=\\big{\\{}\\omega\\in\\Omega\\,:\\,\\text{ a componente conexa de $0\\in\\mathbb{Z}^{d% }$ em $G(\\omega)$ \\'{e} infinita}\\big{\\}}. (2.72) Para estudar A , vamos fazer uma aproxima√ß√£o de A por eventos mais simples A_{n}=\\big{\\{}\\omega\\in\\Omega\\,:\\,\\text{ a componente conexa de $0$ sai da % caixa $[-n,n]^{d}$}\\}, (2.73) para n\\geq 1 . {exercise} Mostre que A=\\cap_{n=1}^{n}A_{n} e consequentemente que A √© de fato mensur√°vel e P(A)=\\lim_{n\\to\\infty}P(A_{n}) . Definimos portanto a fun√ß√£o \\theta:[0,1]\\to[0,1] por \\theta(p)=P_{p}(A), (2.74) onde P_{p} denota a probabilidade correspondente ao valor escolhido de p\\in[0,1] . {exercise} Mostre que \\theta(p)\\leq 1-(1-p)^{2d} . Nosso objetivo √© entender algumas das propriedades de \\theta . A nossa intui√ß√£o diz que quanto maior o valor de p , mais elos ser√£o abertos em \\mathcal{G} e portanto maior ser√° o valor de \\theta , ou em outras palavras, \\theta deve ser mon√≥tona n√£o decrescente. {exercise} Construiremos nosso modelo de uma maneira alternativa num espa√ßo de probabilidade maior. Definimos \\Omega_{0}:=[0,1]^{E} (com a \\sigma -√°lgebra produto correspondente), e (U_{e})_{e\\in E} uma cole√ß√£o de vari√°veis aleat√≥rias \\iidcom distribui√ß√£o U[0,1] , e \\mathbb{P} a probabilidade corespondente. Definimos para cada p\\in[0,1] , X^{p}:\\Omega_{0}\\to\\Omega do jeito seguinte X^{p}_{e}=\\1_{[\\omega_{e}\\leq p]}. (2.75) Mostre que para todo p\\in[0,1] (X^{p})_{*}\\mathbb{P}=P_{p} . Use isso para concluir que \\theta √© mon√≥tona n√£o decrescente. Iremos agora mostrar a exist√™ncia de um regime para o qual a componente conexa da origem n√£o √© infinita. {theorem} Para p<1/(2d) , temos que \\theta(p)=0 . Antes da prova, alguns exerc√≠cios. {exercise} Definimos um caminho como sendo uma sequ√™ncia x_{1} , \\dots , x_{k} ( k\\in\\mathbb{N} ), tal que \\{x_{i},x_{i+1}\\}\\in E para todo i=1,\\dots,k-1 . Tal caminho √© dito aberto se \\omega_{\\{x_{i},x_{i+1}\\}}=1 para todo i\\leq k-1 . E dizemos que ele √© auto-evitante se x_{i}\\neq x_{j} para todo 1\\leq i<j<k . Mostre que \\begin{split}&A_{n}=\\Big{\\{}\\omega\\in\\Omega\\,:\\,\\text{ existe um caminho % aberto $(x_{i})_{i=1}^{k}$ com $x_{1}=0$ e $x_{k}\\not\\in[-n,n]^{d}$}\\Big{\\}}\\\\ &A_{n}=\\big{\\{}\\omega\\in\\Omega\\,:\\,\\text{ existe um caminho auto-evitante como% acima}\\big{\\}}.\\end{split} Demonstra√ß√£o. Dado p<1/(2d) e n\\in\\mathbb{N} , lembramos que \\begin{split}\\theta(p)&\\leq P_{p}(A_{n})=P_{p}\\Big{[}\\begin{array}[]{c}\\text{% existe $k\\in\\mathbb{N}$ e um caminho auto-evitante $(x_{i})_{i=1}^{k}$ }\\\\ \\text{aberto e com $x_{1}=0$ e $x_{k}\\not\\in[-n,n]^{d}$}\\end{array}\\Big{]}\\\\[5% .69054pt] &\\leq\\sum_{k\\geq n}\\;\\;\\sum_{(x_{i})_{i=1}^{k}\\text{ auto-evit.}}P_{p}[(x_{i})% _{i=1}^{k}\\text{ aberto}]=\\sum_{k\\geq n}\\;\\;\\sum_{(x_{i})_{i=1}^{k}\\text{ auto% -evit.}}p^{k}\\\\ &\\leq\\sum_{k\\geq n}\\;\\;\\sum_{(x_{i})_{i=1}^{k}\\text{ caminho}}P_{p}[(x_{i})_{i% =1}^{k}\\text{ aberto}]=\\sum_{k\\geq n}(2d)^{k}p^{k}.\\end{split} Como p<1/(2d) , a soma acima √© finita e converge a zero quando n diverge, provando o teorema. ‚àé Notas - O teorema acima ajuda a compreender o comportamento que observamos no lado esquerdo da Figura¬†2.2. Mais precisamente, ele nos diz que para valores de p baixos (na verdade 0,4 n√£o √© baixo o suficiente para podermos aplicar esse teorema) √© dif√≠cil encontrar um caminho aberto do centro √† borda da caixa. Na verdade, √© poss√≠vel mostrar que para d=2 , \\begin{split}&\\text{$\\theta(p)=0$ para todo $p\\leq 1/2$ e}\\\\ &\\text{$\\theta(p)>0$ para todo $p>1/2$,}\\end{split} (2.76) como foi mostrado por Harris e Kesten, veja por exemplo [2] e [1]. De fato, algo bastante interessante est√° acontecendo nesse modelo para p=1/2 , como nos mostrou o trabalho de grandes matem√°ticos, como: Oded Schramm, Wendelin Werner, Stanislav Smirnov, entre outros. \\todosec T√≥pico: Teorema de Uma S√©riefazer‚Ä¶ Previous page Next page"],[["index.html","Ch2.html","Ch2.Sx4.html"],"T√≥pico: Cadeias de Markov ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. T√≥pico: Cadeias de Markov T√≥pico: Cadeias de Markov Um exemplo de como usar n√∫cleos de transi√ß√£o √© a constru√ß√£o de Cadeias de Markov. Esse tipo de processo √© bastante √∫til em diversas aplica√ß√µes, desde a biologia at√© a computa√ß√£o. Considere um espa√ßo mensur√°vel can√¥nico fixo (E,\\mathcal{A}) e seja K um n√∫cleo de E nele mesmo. Seria bastante intuitivo agora iterar K (j√° que ele est√° no mesmo espa√ßo) e obter uma medida em \\Omega=E^{\\mathbb{N}} com a \\sigma -√°lgebra can√¥nica. Para come√ßar esse procedimento, seja \\mu_{0} uma medida inicial em (E,\\mathcal{A}) . Podemos ent√£o definir \\mu_{1}=\\mu_{0}\\star K o que √© o primeiro passo da nossa constru√ß√£o, por√©m observe que n√£o podemos escrever ‚Äú \\mu_{2}=\\mu_{1}\\star K ‚Äù, pois \\mu_{1}\\star K √© uma medida em (E^{2},\\mathcal{A}^{\\otimes 2}) . Vamos com calma ent√£o. Observe que \\mu_{1}(A_{0}\\times A_{1})=\\int_{A_{0}}\\int_{A_{1}}K(x_{0},\\d{x}_{1})\\mu_{0}(% \\d{x}_{0}), (2.115) ou em outras palavras o valor de x_{0} determina a distribui√ß√£o de x_{1} . Gostar√≠amos agora que x_{1} determinasse a distribui√ß√£o de x_{2} via K , como por exemplo assim \\mu_{2}(A_{0}\\times A_{1}\\times A_{2})=\\int_{A_{0}}\\int_{A_{1}}\\int_{A_{2}}K(x% _{1},\\d{x}_{2})K(x_{0},\\d{x}_{1})\\mu_{0}(\\d{x}_{0}). (2.116) Mas essa nota√ß√£o fica bastante carregada √† medida que iteramos. Para tornar essa nota√ß√£o mais simples, definimos a proje√ß√£o \\phi_{n}:E^{n}\\to E por \\phi_{n}(x_{0},\\dots,x_{n-1})=x_{n-1} . Tamb√©m precisamos de K_{n}:E^{n}\\times\\mathcal{A}\\to[0,1] dado por K_{n}(\\vec{x},A)=K\\big{(}\\phi_{n}(\\vec{x}),A\\big{)}\\quad\\big{(}=K(x_{n-1},A)% \\big{)}. (2.117) O fato de K_{n} ser um n√∫cleo de transi√ß√£o segue imediatamente dessa propriedade para K . Note que, nessa nota√ß√£o, estamos dizendo que para irmos de E^{n} para E^{n+1} iremos olhar apenas para a √∫ltima coordenada, na qual aplicaremos o n√∫cleo K . Isso √© o ponto mais importante que caracteriza uma Cadeia de Markov: a distribui√ß√£o do estado futuro da cadeia depende apenas do estado atual e n√£o do passado. Em alguns contextos essa propriedade √© chamada de aus√™ncia de mem√≥ria. Podemos finalmente definir \\mu_{n+1}=\\mu_{n}\\star K_{n},\\text{ para todo $n\\geq 1$}. (2.118) Mas resta a quest√£o sobre a exist√™ncia de uma \\mu^{\\infty} que ser√° respondida com ajuda do pr√≥ximo resultado. {lemma} As probabilidades \\mu_{n} definidas em (2.118) s√£o compat√≠veis, mais precisamente \\mu_{n+1}(A\\times E)=\\mu_{n}(A) para todo A\\in\\mathcal{A}^{\\otimes n} . Demonstra√ß√£o. Basta observar que \\mu_{n+1}(A\\times E)=\\mu_{n}\\star K(A\\times E)=\\int_{A}\\underbrace{K_{n}(\\vec{% x},E)}_{1}\\mu_{n}(\\d{\\vec{}}{x})=\\mu_{n}(A), (2.119) provando o lema. ‚àé Logo, o Teorema da Extens√£o de Kolmogorov (lembre que (E,\\mathcal{A}) foi suposto can√¥nico) nos fornece uma √∫nica P em (\\Omega,\\mathcal{F}) tal que P_{(X_{0},\\dots,X_{n})}=\\mu_{n},\\text{ para todo $n\\geq 0$}. (2.120) Lembramos que X_{i} denotam as proje√ß√µes can√¥nicas em \\Omega=\\prod_{i=1}^{\\infty}E . Chamamos o processo X_{1},X_{2},\\dots sob a lei P da Cadeia de Markov com distribui√ß√£o inicial \\mu_{0} e n√∫cleo de transi√ß√£o K . {example} Suponha que E seja enumer√°vel. Nesse caso recordamos do Exemplo¬†2.9 que o n√∫cleo pode ser representado por uma matriz \\big{(}p(x,y)\\big{)}_{x,y\\in E} que nos retorna a probabilidade de saltar de x a y . Al√©m disso, a distribui√ß√£o inicial \\mu_{0} √© determinada por P(\\{x\\})=p_{0}(x) , para alguma sequ√™ncia \\big{(}p_{0}(x)\\big{)}_{x\\in E} . {exercise} Mostre que no exemplo acima temos P(X_{0}=x_{0},\\dots,X_{n}=x_{n})=p_{0}(x_{0})p(x_{0},x_{1})\\dots p(x_{n-1},x_{% n}). (2.121) {exercise} Defina K:\\mathbb{R}^{2}\\times\\mathcal{B}(\\mathbb{R}^{2})\\to[0,1] dada por K(x,A)=U_{S^{1}}(A-x). (2.122) Nesse contexto, ‚ÄÉa)‚Äãmostre que K √© um n√∫cleo de transi√ß√£o e, ‚ÄÉb)‚Äãconsiderando a cadeia com distribui√ß√£o inicial \\mu_{0}=\\delta_{0} em \\mathbb{R}^{2} e n√∫cleo K , mostre que X_{2} tem distribui√ß√£o absolutamente cont√≠nua com respeito a Lebesgue e calcule sua densidade. {exercise} Mostre que para qualquer n√∫cleo de transi√ß√£o K entre E e E , existe um n√∫cleo de transi√ß√£o \\widebar{K} entre E e \\Omega=E^{\\mathbb{N}} , tal que para toda medida inicial \\mu_{0} , temos que \\mu_{0}\\star K √© a distribui√ß√£o de uma Cadeia de Markov come√ßando de \\mu_{0} e com transi√ß√£o dada por K . Esse n√∫cleo √© √∫til se quisermos mudar a distribui√ß√£o inicial \\mu_{0} e uma nota√ß√£o bastante comum para esse n√∫cleo √© P_{x}(\\cdot)=\\widebar{K}(x,\\cdot) . Vamos terminar essa se√ß√£o dando uma interpreta√ß√£o bastante interessante para os n√∫cleos de transi√ß√£o em analogia √† √°lgebra linear. Fixe um n√∫cleo de transi√ß√£o K entre E e E , uma medida inicial \\mu e uma fun√ß√£o limitada f:E\\to\\mathbb{R} . Relembre a nota√ß√£o em (2.102) e defina Kf:E\\to\\mathbb{R} dada por Kf(x):=\\int f(y)K(x,\\d{y}), (2.123) que √© obviamente limitada e j√° vimos ser mensur√°vel no Teorema de Fubini. Ent√£o temos dois operadores definidos para n√∫cleos, a multiplica√ß√£o √† esquerda por uma medida em E ( \\mu K que tamb√©m √© uma medida em E ) e a multiplica√ß√£o √† direita por uma fun√ß√£o limitada e mensur√°vel ( Kf que tamb√©m √© uma fun√ß√£o limitada e mensur√°vel). Podemos pensar em f como um vetor coluna e \\mu como um vetor linha, nesse caso K faria o papel de uma matriz. Essa analogia √© real se E for um espa√ßo enumer√°vel. {exercise} No contexto de cadeias de Markov, ‚ÄÉa)‚Äãmostre a rela√ß√£o de associatividade \\mu(Kf)=(\\mu K)f , ‚ÄÉb)‚Äãdefina para todo n o n√∫cleo K^{(n)} iterado (de E em E ), de forma que \\mu K^{(n)}f ainda seja associativa. ‚ÄÉc)‚ÄãMostre que a medida \\mu K^{(n)} √© a distribui√ß√£o de X_{n} se come√ßamos de \\mu , ‚ÄÉd)‚Äãque a fun√ß√£o K^{(n)}f(\\cdot) √© o valor esperado de f no tempo n se come√ßamos no zero do ponto \\cdot e finalmente que ‚ÄÉe)‚Äão n√∫mero real \\mu K^{(n)}f √© a esperan√ßa de f no tempo n se come√ßamos de \\mu . Vamos agora dar um exemplo simples de Cadeia de Markov que poderemos analisar em detalhes. Seja E=\\mathbb{Z} e considere K:\\mathbb{Z}\\times\\mathcal{P}(\\mathbb{Z})\\to[0,1] dado por K(x,\\cdot)=\\frac{\\delta_{x-1}+\\delta_{x+1}}{2}, (2.124) que obviamente define um n√∫cleo pois toda fun√ß√£o em \\mathbb{Z} √© mensur√°vel na \\sigma -√°lgebra das partes. Podemos portanto construir P em \\mathbb{Z}^{\\mathbb{N}} que nos fornece a lei de uma Cadeia de Markov em \\mathbb{Z} com distribui√ß√£o inicial \\delta_{0} e n√∫cleo de transi√ß√£o K . Chamamos esse processo de passeio aleat√≥rio simples sim√©trico. Poder√≠amos estar interessados em v√°rias perguntas sobre esse processo, como por exemplo qu√£o longe esperamos que o passeio aleat√≥rio pode ir depois de um determinado tempo? Para responder essa e v√°rias outras quest√µes, iremos mostrar outra constru√ß√£o do passeio simples sim√©trico atrav√©s de uma soma de vari√°veis aleat√≥rias. Introduzimos um espa√ßo de probabilidade \\tilde{P} , vari√°veis Y_{1},Y_{2},\\dots \\iidcom distribui√ß√£o (\\delta_{-1}+\\delta_{1})/2 e definimos S_{0}=0 e S_{n}=Y_{1}+\\dots+Y_{n} . {lemma} A distribui√ß√£o da sequ√™ncia infinita (X_{0},X_{1},\\dots) sob a lei P do passeio aleat√≥rio simples e sim√©trico √© igual √† distribui√ß√£o de (S_{0},S_{1},\\dots) sob \\tilde{P} . Demonstra√ß√£o. Observamos primeiramente que basta mostrar a igualdade de distribui√ß√µes para cilindros do tipo \\{x_{1}\\}\\times\\dots\\times\\{x_{n}\\}\\times\\mathbb{Z}^{\\mathbb{N}} , pois tais eventos comp√µem um \\pi -sistema que gera a \\sigma -√°lgebra produto em \\mathbb{Z}^{\\mathbb{N}} . Calculamos portanto \\begin{split}\\qquad P&[X_{1}=x_{1},\\dots,X_{n}=x_{n}]\\intertext{pela defini\\c{% c}\\~{a}o de Cadeia de Markov (via extens\\~{a}o de Kolmogorov),}&=\\mu_{n}[X_{1}% =x_{1},\\dots,X_{n}=x_{n}]\\\\ &=\\mu_{n-1}\\star K_{n}[X_{1}=x_{1},\\dots,X_{n}=x_{n}]\\intertext{por Fubini % para n\\'{u}cleos (Teorema\\leavevmode\\nobreak\\ \\ref{t:fubini}),}&=\\mu_{n-1}[X_{% 1}=x_{1},\\dots,X_{n-1}=x_{n-1}]K_{n}\\big{(}(x_{1},\\dots,x_{n-1}),\\{x_{n}\\}\\big% {)}\\\\ &=\\mu_{n-1}[X_{1}=x_{1},\\dots,X_{n-1}=x_{n-1}]K\\big{(}x_{n-1},\\{x_{n}\\}\\big{)}% \\\\ &=\\frac{1}{2}\\mu_{n-1}[X_{1}=x_{1},\\dots,X_{n-1}=x_{n-1}]\\1_{\\{|x_{n-1}-x_{n}|% =1\\}}\\\\ &=\\dots=2^{-n}\\prod_{i=1}^{n}\\1_{\\{|x_{i-1}-x_{i}|=1\\}}.\\end{split} Faremos agora esse c√°lculo para a distribui√ß√£o de S_{i} ‚Äôs: \\begin{split}\\qquad\\tilde{P}&[S_{1}=x_{1},\\dots,S_{n}=x_{n}]\\\\ &=\\mu_{n}[Y_{1}=x_{1}-x_{0},Y_{2}=x_{2}-x_{1}\\dots,Y_{n}=x_{n}-x_{n-1}]\\\\ &=\\prod_{i=1}^{n}\\tilde{P}[Y_{i}=x_{i}-x_{i-1}]=2^{-n}\\prod_{i=1}^{n}\\1_{\\{|x_% {i-1}-x_{i}|=1\\}}.\\end{split} Isso mostra o enunciado do lemma. ‚àé Podemos agora por exemplo estimar P[|X_{n}|\\geq\\varepsilon n]=\\tilde{P}[|S_{n}|\\geq\\varepsilon n]\\leq 2\\exp\\{-% \\psi_{(\\delta_{-1}+\\delta_{1})/2}(\\varepsilon)n\\}, (2.125) que responde nossa pergunta sobre a probabilidade de um passeio aleat√≥rio se distanciar muito da origem. Previous page Next page"],[["index.html","Ch2.html","Ch2.Sx5.html"],"T√≥pico: Urna de P√≥lya ‚Ä£ Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. T√≥pico: Urna de P√≥lya T√≥pico: Urna de P√≥lya Um excelente exemplo de como Cadeias de Markov podem gerar interessantes modelos de situa√ß√µes reais s√£o as chamadas Urnas de P√≥lya. Esse processo modela sistemas de f√≠sica, biologia, computa√ß√£o e economia que apresentam o que chamamos de refor√ßo. Tome por exemplo duas empresas que competem pelo mercado de avi√µes. Inicialmente, n√£o temos nenhuma raz√£o para escolher uma em detrimento da outra, portanto compramos nosso primeiro avi√£o de cada empresa com probabilidade meio. Por√©m, depois que j√° compramos diversos avi√µes de uma determinada empresa, ela j√° recebeu bastante dinheiro que pode ser reinvestido para gerar melhor tecnologia e aumentar as chances que ela seja escolhida novamente no futuro. Isso √© o que chamamos de refor√ßo. Vamos agora apresentar rigorosamente um modelo para situa√ß√µes desse tipo. O nosso modelo come√ßa com uma urna contendo duas bolas, uma vermelha e uma azul. No cada passo do processo, escolheremos uma bola da urna ao acaso, olharemos sua cor e retornaremos essa bola para dentro urna junto com mais uma bola da mesma cor. Isso pode ser√° formalizado √† seguir. Vamos construir uma medida em \\{0,1\\}^{\\mathbb{N}} , dotado da \\sigma -√°lgebra produto. Fixada uma sequ√™ncia finita w_{1},\\dots,w_{n} em \\{0,1\\} , definimos N_{x}(w_{1},\\dots,w_{n})=\\#\\big{\\{}j\\in\\{1,\\dots,n\\}\\,:\\,w_{j}=x\\big{\\}}+1, (2.126) que nada mais √© que o n√∫mero de bolas do tipo x que se encontram na urna no tempo n . Quando tivermos uma sequ√™ncia infinita de w_{i} ‚Äôs, escreveremos N^{n}_{x} para denotar N_{x}(w_{1},\\dots,w_{n}) . Para cada n\\geq 1 , definimos K_{n}:\\{0,1\\}^{n}\\to\\mathcal{P}(\\{0,1\\}) por K_{n}(w_{1},\\dots,w_{n})=\\Ber\\big{(}\\tfrac{N_{1}}{n}\\big{)}. (2.127) Ou seja, dadas cores w_{1},\\dots,w_{n} , escolheremos uma bola de cor 1 proporcionalmente ao n√∫mero N_{1} de bolas de cor 1 que j√° foram sorteadas. {exercise} Mostre que todos K_{n} acima definem n√∫cleos de transi√ß√£o. Al√©m disso a seguinte sequ√™ncia de medidas √© compat√≠vel no sentido de Kolmogorov: ‚Ä¢‚Äã P_{1}=\\Ber(1/2) , ‚Ä¢‚Äã P_{2}=P_{1}\\star K_{1} , ‚Ä¢‚Äã P_{3}=P_{2}\\star K_{2},\\dots Conclua que existe a medida P em \\{0,1\\}^{\\mathbb{N}} que define o modelo de P√≥lya. Podemos agora fazer perguntas como por exemplo: ser√° que escolheremos bolas de ambas as cores para sempre, ou a partir de um certo momento escolheremos bolas de apenas uma cor com certa probabilidade. Mais precisamente, qual √© a probabilidade de [X_{i}=1,\\text{ infinitas vezes}] ? Para responder perguntas desse tipo, iremos mostrar algo muito curioso, que pode ser entendido como uma outra maneira de representar o modelo descrito acima. Mas antes, vamos colecionar alguns fatos sobre o modelo da Urna de P√≥lya. Primeiramente vamos olhar para os seguintes eventos. Fixamos n\\geq 1 e uma sequ√™ncia w_{1},\\dots,w_{n}\\in\\{0,1\\} e seja A o evento \\{w_{1}\\}\\times\\dots\\times\\{w_{n}\\}\\times\\{0,1\\}\\times\\dots Note que os eventos desse tipo (junto com o evento \\varnothing ) formam um \\pi -sistema que gera a \\sigma -√°lgebra can√¥nica de \\{0,1\\}^{\\mathbb{N}} , portanto essa cole√ß√£o √© bastante completa para identificar a distribui√ß√£o da Urna de P√≥lya. Podemos calcular a probabilidade do evento A acima \\begin{split}P(A)&=\\frac{N^{1}_{w_{1}}}{2}\\frac{N^{2}_{w_{1}}}{3}\\dots\\frac{N^% {n}_{w_{n}}}{n+1}=\\frac{1}{(n+1)!}\\prod_{i=1}^{n}N^{i}_{w_{i}}\\\\ &=\\frac{N^{n}_{1}!(n-N^{n}_{1})!}{(n+1)!}=\\frac{1}{(n+1)}\\binom{n}{N^{n}_{1}}^% {-1}.\\end{split} (2.128) O que √© muito interessante sobre a equa√ß√£o acima √© que ela nos remete a problemas combinat√≥rios ao notarmos o fator binomial acima. Vamos portanto construir um processo completamente diferente que apresenta as mesmas probabilidades que o anterior. Seja \\mathcal{S}_{N} o conjunto de todas as permuta√ß√µes \\sigma de \\{1,\\dots,N\\} . √â f√°cil ver que \\frac{1}{(n+1)}\\binom{n}{j}^{-1}=U_{\\mathcal{S}_{n+1}}\\Big{[}\\sigma(n+1)=j+1,% \\sigma(i)\\leq j\\text{ se e s\\'{o} se }\\;i\\leq j\\Big{]}. Um m√©todo muito interessante de se produzir uma permuta√ß√£o uniforme √© dado pelos seguintes exerc√≠cios. {exercise} Seja n\\geq 1 um inteiro, P uma probabilidade em (E,\\mathcal{A}) , \\sigma uma permuta√ß√£o fixa em \\mathcal{S}_{n} . Ent√£o (X_{1},\\dots,X_{n})\\distr(X_{\\sigma(1)},\\dots,X_{\\sigma(n)}), (2.129) onde X_{i} como sempre representam as coordenadas can√¥nicas em (E^{n},\\mathcal{A}^{\\otimes n},P^{\\otimes n}) . Ou em outras palavras, aplicar uma permuta√ß√£o fixa a uma sequ√™ncia \\iidn√£o altera sua distribui√ß√£o. Sequ√™ncias de elementos aleat√≥rios (n√£o necessariamente \\iid‚Äôs) que satisfazem (2.129) s√£o ditas intercambi√°veis. Um outro exerc√≠cio interessante nesse t√≥pico √© o seguinte {exercise} Seja n\\geq 1 e F:[0,1]^{n}\\to\\mathcal{S}_{n} dada por F(x_{1},\\dots,x_{n})=\\begin{cases}(1,2,\\dots,n),\\qquad\\text{se existe $i\\neq j% $ com $x_{i}=x_{j}$, }\\\\ \\text{o \\'{u}nico $\\sigma$ tal que $x_{\\sigma(1)}<\\dots<x_{\\sigma(n)}$,}\\qquad% \\text{caso contr\\'{a}rio.}\\end{cases} Mostre que F_{*}(U_{[0,1]}^{\\otimes n})=U_{\\mathcal{S}_{n}} . Ou seja, ordenar uma sequ√™ncia de uniformes independentes nos fornece uma permuta√ß√£o uniforme. Como prometido, isso nos d√° uma maneira de construir uma permuta√ß√£o uniforme de \\{1,\\dots,n\\} √† partir de uma sequ√™ncia \\iid(que √© algo que j√° estamos come√ßando a entender melhor). Podemos agora escrever nossa probabilidade de observar uma sequ√™ncia no modelo da Urna de P√≥lya em termos de uma sequ√™ncia \\iidde vari√°veis aleat√≥rias. \\begin{split}\\frac{1}{(n+1)}&\\binom{n}{N^{n}_{1}}^{\\mathclap{\\;-1}}=F_{*}U_{[0% ,1]}^{\\otimes n+1}\\Big{[}\\sigma(n+1)=N^{n}_{1}+1,\\sigma(i)\\leq N^{n}_{1}\\text{% se e s\\'{o} se }i\\leq N^{n}_{1}\\Big{]}\\\\ &=U^{\\otimes n+1}_{[0,1]}\\Big{[}\\text{$X_{i}<X_{n+1}$, para $i\\leq N^{n}_{1}$ % e $X_{i}>X_{n+1}$, para $i\\geq N^{n}_{1}+1$}\\Big{]}.\\end{split} Agora estamos prontos para provar o resultado principal que nos ajudar√° a calcular probabilidades no modelo da Urna de P√≥lya. Dado u\\in[0,1] , seja P_{u}=\\Ber(u)^{\\otimes\\mathbb{N}} , ou seja a probabilidade que nos d√° uma sequ√™ncia infinita de moedas independentes com probabilidade u de sucesso. Definimos agora \\widebar{K}:[0,1]\\times(\\mathcal{P}(\\{0,1\\})^{\\otimes\\mathbb{N}})\\to[0,1] dada por \\widebar{K}(u,A)=P_{u}(A). (2.130) {lemma} A fun√ß√£o \\widebar{K} definida acima √© um n√∫cleo entre [0,1] e \\{0,1\\}^{\\mathbb{N}} . Demonstra√ß√£o. Usando a Proposi√ß√£o¬†2.9, basta ver que {display} para todo k\\geq 1 e w_{1},\\dots,w_{k}\\in\\{0,1\\} , temos que P_{u}(X_{1}=w_{1},\\dots,X_{k}=w_{k}) √© uma fun√ß√£o mensur√°vel de u\\in[0,1] . Mas √© f√°cil ver que P_{u}(X_{1}=w_{1},\\dots,X_{k}=w_{k})=u^{N_{1}(w_{1},\\dots,w_{k})}(1-u)^{N_{0}(% w_{1},\\dots,w_{k})}, (2.131) que obviamente √© mensur√°vel, provando assim o lema. ‚àé O resultado muito curioso a qual nos referimos √© o seguinte. {lemma} A lei P definida no Exerc√≠cio¬†2 √© igual a U_{[0,1]}\\widebar{K} . Em outras palavras, digamos que realizamos os seguintes experimentos. Primeiramente Jo√£o realiza o processo da Urna de P√≥lya e anota a sequ√™ncia das cores obtidas. Depois Maria sorteia uma vari√°vel aleat√≥ria X de distribui√ß√£o uniforme em [0,1] e depois joga infinitas vezes uma moeda com probabilidade X de obter vermelho e (1-X) de obter azul, anotando tamb√©m quais cores foram obtidas. Finalmente, n√£o ser√≠amos capazes de distinguir essas duas sequ√™ncias (mesmo que pud√©ssemos repetir v√°rias vezes esse experimento) pois elas tem a mesma distribui√ß√£o em \\{0,1\\}^{\\mathbb{N}} . Demonstra√ß√£o. J√° sabemos que basta mostrar a igualdade para eventos do tipo A=\\{w_{1}\\}\\times\\dots\\times\\{w_{n}\\}\\times\\{0,1\\}^{\\mathbb{N}} . Sabemos pelo Teorema de Fubini para N√∫cleos que U_{[0,1]}\\widebar{K}(A)=\\int_{0}^{1}K(u,A)\\d{u}\\overset{\\eqref{e:Polya_% binomial}}{=}\\int_{0}^{1}u^{N_{1}(w_{1},\\dots,w_{k})}(1-u)^{N_{0}(w_{1},\\dots,% w_{k})}\\d{u}. (2.132) Por outro lado , sabemos (usando simetria entre 0 e 1 ) que P(A)=U^{\\otimes n+1}_{[0,1]}\\Big{[}\\text{$X_{i}<X_{n+1}$, para $i\\leq N^{n}_{0% }$ e $X_{i}>X_{0}$, para $i\\geq N^{n}_{0}+1$}\\Big{]} (2.133) Se definirmos \\tilde{K}:[0,1]\\times\\mathcal{B}([0,1]^{n}) , dado por \\tilde{K}(u,B)=U^{\\otimes n}_{[0,1]} , sabemos que isso define um n√∫cleo pelo Exerc√≠cio¬†2.9. Mais ainda, esse mesmo exerc√≠cio nos diz que U_{[0,1]}\\star\\tilde{K}=U^{\\otimes}_{[0,1]} , de forma que \\begin{split}P(A)&=U_{[0,1]}\\star\\tilde{K}\\Big{[}\\text{$X_{i}<X_{0}$, para $i% \\leq N^{n}_{0}$ e $X_{i}>X_{0}$, para $i\\geq N^{n}_{0}+1$}\\Big{]}\\\\ &=\\int_{0}^{1}U^{\\otimes n}_{[0,1]}\\Big{[}\\text{$X_{i}<u$, para $i\\leq N^{n}_{% 0}$ e $X_{i}>u$, para $i\\geq N^{n}_{0}+1$}\\Big{]}\\d{u}\\\\ &=\\int_{0}^{1}u^{N^{n}_{0}}(1-u)^{n-N^{n}_{0}}\\d{u},\\end{split} que coincide com U_{[0,1]}\\widebar{K}(A) , provando o lema. ‚àé {exercise} Mostre que a probabilidade, segundo o modelo da Urna de P√≥lya, de que observemos infinitas bolas de ambas as cores √© um. Previous page Next page"],[["index.html","Ch2.html"],"Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Constru√ß√£o de espa√ßos de probabilidade Cap√≠tulo 2 Constru√ß√£o de espa√ßos de probabilidade Nessa se√ß√£o descreveremos diversas maneiras diferentes de construir um espa√ßo de probabilidade, dando diversos exemplos de como elas podem ser usadas na modelagem de diferentes processos reais. Previous page Next page"],[["index.html","Ch3.html","Ch3.S1.html"],"3.1 Esperan√ßa ‚Ä£ Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Esperan√ßa 3.1 Esperan√ßa {definition} Se X √© uma vari√°vel aleat√≥ria com \\int_{\\Omega}|X|\\d{\\omega}<\\infty , dizemos que X √© integr√°vel e definimos E(X)=\\int_{\\Omega}X(\\omega)P(\\d{\\omega}), (3.1) a chamada esperan√ßa de X . Nesse caso tamb√©m dizemos que X\\in\\mathcal{L}^{1} . Quando X\\geq 0 , tamb√©m podemos supor que E(X) est√° bem definida, mesmo que possivelmente tomando valor infinito. N√£o demonstraremos algumas propriedades conhecidas da integra√ß√£o de Lebesgue, tais como ‚ÄÉa)‚Äã E(X+\\alpha Y)=E(X)+\\alpha E(Y) (se estiverem bem definidas), ‚ÄÉb)‚ÄãValem os Teoremas de Converg√™ncia (Mon√≥tona e Limitada). {exercise} Mostre que se X\\in\\mathcal{L}^{1} e P[X>x]=0 , ent√£o E(X)\\leq x . {lemma} A esperan√ßa de uma vari√°vel aleat√≥ria X\\in\\mathcal{L}^{1} depende somente de sua distribui√ß√£o. Mais precisamente E(X)=\\int x\\;P_{X}(\\d{x}). (3.2) Demonstra√ß√£o. Vamos mostrar que E\\big{(}f(X)\\big{)}=\\int f(x)(X\\circ P)(\\d{x}), (3.3) para toda f:\\mathbb{R}\\to\\mathbb{R} mensur√°vel tal que f(X)\\in\\mathcal{L}^{1} . Para f=\\1_{A} , temos E\\big{(}f(X)\\big{)}=P[X\\in A]=(X\\circ P)(A), (3.4) por defini√ß√£o de X\\circ P . Agora podemos extender o teorema para fun√ß√µes f simples por linearidade, depois para fun√ß√µes positivas usando o Teorema da Converg√™ncia Mon√≥tona e finalmente escrevemos x=x\\1_{[0,\\infty)}-(-x)\\1_{(-\\infty,0)} . ‚àé Vamos mostrar uma f√≥rmula bastante simples de integra√ß√£o de vari√°veis tomando valores em um conjunto enumer√°vel. Se X\\in\\{x_{1},x_{2},\\dots\\} P -quase certamente, ent√£o \\begin{split}E(X)&=\\int_{\\Omega}XP(\\d{\\omega})=\\int\\sum_{i}\\1_{[X=x_{i}]}XP(\\d% {\\omega})+\\int_{\\{x_{1},x_{2},\\dots\\}^{c}}XP(\\d{\\omega})\\\\ &=\\sum_{i}\\int_{[X=x_{i}]}x_{i}P(\\d{\\omega})+0=\\sum_{i}x_{i}P[X=x_{i}].\\end{split} (3.5) Para nos acostumar √† nota√ß√£o de probabilidade, vamos agora mostrar o mesmo resultado da seguinte forma \\begin{split}E(X)&=E\\Big{(}\\sum_{i}X\\1_{[X=x_{i}]}\\Big{)}+E(X\\1_{\\{x_{1},x_{2}% ,\\dots\\}^{c}})\\\\ &=\\sum_{i}E[X;X=x_{i}]+0=\\sum_{i}x_{i}P[X=x_{i}].\\end{split} (3.6) Que √© certamente muito √∫til quando nos habituamos a ela. Observe que acima usamos a nota√ß√£o E[X;\\mathcal{Q}]=E(X\\1_{[\\mathcal{Q}]}) . Tamb√©m utilizaremos E[X;\\mathcal{Q}_{1},\\mathcal{Q}_{2},\\dots]=E(X\\1_{[\\mathcal{Q}_{1},\\mathcal{Q}% _{2},\\dots]}) {example} Se X\\overset{d}{\\sim}\\Ber(p) , ent√£o E(X)=0\\cdot P[X=0]+1P[X=1]=0+p=p . {example} Seja X\\overset{d}{\\sim}\\Bin(n,p) , ent√£o, para calcular E(X) , basta calcular E(Y) onde X\\overset{d}{\\sim}Y . Como vimos anteriormente, se Z_{1},Z_{2},\\dots,Z_{n} s√£o vari√°veis \\iid(relembrando: independentes e identicamente distribu√≠dos) com Z_{1}\\overset{d}{\\sim}\\Ber(p) , ent√£o Y=\\sum_{i}Z_{i}\\overset{d}{\\sim}\\Bin(n,p) . Logo E(X)=E(Y)=\\sum_{i}E(Z_{i})=np. (3.7) Se d(X\\circ P)=\\rho(x)\\d{x} (com \\rho\\geq 0 e \\int\\rho(x)\\d{x}=1 ), ent√£o E(X)=\\int x(X\\circ P)(\\d{x})=\\int x\\rho(x)\\d{x}. (3.8) {example} Se X\\overset{d}{\\sim}U_{[0,1]} , ent√£o sua densidade com respeito a Lebesgue √© dada por d(X\\circ P)=\\1_{[0,1]}\\d{x} , donde E(X)=\\int_{0}^{1}x\\d{x}=1/2 . {proposition} Se X\\geq 0 P -q.c., ent√£o E(X)=\\int_{0}^{\\infty}P[X>x]\\d{x})=\\int_{0}^{\\infty}1-F(x)\\d{x}. (3.9) Demonstra√ß√£o. \\begin{split}E(X)&=E\\Big{(}\\int_{0}^{X}1\\d{x}\\Big{)}=E\\Big{(}\\int_{0}^{\\infty}% \\1_{[x<X]}\\d{x}\\Big{)}\\\\ &\\overset{\\text{Fubini}}{=}\\int_{0}^{\\infty}E(\\1_{[x<X]})\\d{x}=\\int_{0}^{% \\infty}P[x<X]\\d{x}.\\end{split} (3.10) ‚àé {example} Se X\\overset{d}{\\sim}\\Exp(\\lambda) , ent√£o P[X\\geq x]=\\int_{x}^{\\infty}\\lambda e^{-\\lambda t}\\d{t}=e^{-\\lambda x}, (3.11) donde E(X)=\\int_{0}^{\\infty}e^{-\\lambda x}\\d{x}=\\frac{1}{\\lambda}. (3.12) {exercise} Se X\\in\\mathcal{L}^{1} e P[X\\geq x]=P[X\\leq-x] para todo x\\geq 0 , ent√£o E(X)=0 . {exercise} Marcelo coleciona figurinhas de futebol. O √°lbum completo conter√° N figurinhas. No i -√©simo dia, ele compra uma nova carta X_{i}\\in\\{1,\\dots,N\\} . A cole√ß√£o (X_{i})_{i\\geq 0} √© distribuida de maneira \\iide uniforme nas figurinhas. ‚ÄÉa)‚ÄãPara j=1,\\dots,N , seja T_{j} o tempo passado at√© a aquisi√ß√£o da j -√©sima nova figurinha, i.e. T_{1}=1\\quad\\text{ e }\\quad T_{j}=\\inf\\{i,X_{i}\\not\\in\\{X_{T_{j^{\\prime}}};j^{% \\prime}<j\\}\\}. (3.13) Mostre que T_{j} √© finito quase certamente, para todo j\\leq N . ‚ÄÉb)‚ÄãCalcule a distribui√ß√£o conjunta de (T_{1},T_{2}-T_{1},\\dots,T_{N}-T_{N-1}) . ‚ÄÉc)‚ÄãCalcule a esperan√ßa de T_{N} (o dia em que Marcelo completa seu √°lbum). {exercise} Sejam X_{1},X_{2},\\dots vari√°veis aleat√≥rias \\iide defina o primeiro tempo de r√©corde como R=\\inf\\{i\\geq 2;X_{i}\\geq X_{1}\\}. (3.14) Supondo que X_{1} √© absolutamente cont√≠nua com respeito √† medida de Lebesgue, encontre E(R) . 3.1.1 Desigualdade de Markov {theorem} Se X\\geq 0 P -q.c., ent√£o para todo x>0 , P[X\\geq x]\\leq\\frac{E(X)}{x}. (3.15) Demonstra√ß√£o. Sabemos que X\\geq x\\1_{[X\\geq x]} , logo E(X)\\geq xE(\\1_{[X\\geq x]})=xP[X\\geq x], (3.16) que termina a prova. ‚àé O pr√≥ximo exemplo serve muito bem para mostrar porque estamos interessados em desigualdades como a do Teorema¬†3.1.1 acima. Em v√°rios exemplos importantes, podemos ter dificuldade de calcular probabilidades explicitamente. Nesses casos, poder√≠amos gastar nossas energias tentando calcul√°-las a qualquer custo, ou podemos nos contentar em obter cotas superiores e inferiores para as probabilidades nas quais estamos interessados. Em v√°rios casos, a segunda estrat√©gia tem uma grande vantagem sobre a primeira, por possibilitar que estudemos problemas mais complexos (e consequentemente mais importantes/interessantes) e muitas vezes sem nos afastarmos da realidade (em v√°rios exemplos as cotas superiores e inferiores s√£o pr√≥ximas o suficiente para que n√£o nos preocupemos). {example} Sejam n patos e m ca√ßadores. Cada ca√ßador escolhe um pato aleatorea e uniformemente e atira (abatendo-o com probabilidade p ). Seja X=\\#\\{\\text{patos vivos}\\} , que pode ter uma distribui√ß√£o complicada de calcular, mas \\begin{split}E(X)&=E\\Big{(}\\sum_{i=1}^{n}\\1_{[\\text{pato $i$ vive}]}\\Big{)}=% \\sum_{i=1}^{n}P[\\text{pato $i$ vive}]\\\\ &=nP[\\text{pato $1$ vive}]=P\\Big{(}\\mcap_{j=1}^{m}[\\text{ca\\c{c}ador $j$ n\\~{a% }o mata pato $1$}]\\Big{)}\\\\ &=nP[\\text{ca\\c{c}ador $j$ n\\~{a}o mata pato $1$}]^{m}=n\\Big{(}1-\\frac{p}{n}% \\Big{)}.\\end{split} (3.17) Observe que ‚ÄÉa)‚Äãacima obtivemos uma igualdade e ‚ÄÉb)‚Äã [\\text{pato $i$ vive}] , i=1,\\dots,n n√£o s√£o independentes. Finalmente estimamos (digamos para n par) \\begin{split}&P[\\text{patos para o jantar}\\leq n/2]=P[X\\geq n/2]\\leq\\frac{E(X)% }{n/2}\\\\ &\\qquad=2\\frac{n}{n}\\Big{(}1-\\frac{p}{n}\\Big{)}^{m}\\leq 2\\exp\\{-\\frac{pm}{n}\\}% .\\end{split} (3.18) \\todosec T√≥pico: Grafos Aleat√≥riosfazer erdos renyi‚Ä¶ \\todosec T√≥pico: Currie Weissfazer‚Ä¶ 3.1.2 Esperan√ßa e independ√™ncia {proposition} Sejam X e Y vari√°veis aleat√≥rias independentes e em \\mathcal{L}^{2} , ent√£o E(XY)=E(X)E(Y). (3.19) Demonstra√ß√£o. Obviamente o resultado acima √© v√°lido para fun√ß√µes indicadoras, pois \\1_{A}\\1_{B}=\\1_{A\\cap B} . Por linearidade, o resultado tamb√©m vale para fun√ß√µes simples e usando o Teorema da Converg√™ncia Mon√≥tona podemos extend√™-lo para fun√ß√µes positivas. Finalmente, decompomos X=X_{+}-X_{-} e Y=Y_{+}-Y_{-} e lembramos que ambas est√£o em \\mathcal{L}^{2} para concluir a prova. ‚àé {exercise} Mostre que E(XY) , E(X/Y) , E(X+Y) ‚Ä¶ dependem apenas da distribui√ß√£o de (X,Y)\\in\\mathbb{R}^{2} . {exercise} Mostre que se X,Y\\in\\mathcal{L}^{1} , ent√£o tamb√©m vale E(XY)=E(X)E(Y) . Previous page Next page"],[["index.html","Ch3.html","Ch3.S2.html"],"3.2 Vari√¢ncia ‚Ä£ Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Vari√¢ncia 3.2 Vari√¢ncia Na se√ß√£o anterior, limitamos P[X>a] usando E(X) (se X\\geq 0 ). Esse m√©todo √© chamado de m√©todo do primeiro momento, de acordo com a seguinte {definition} Dada uma vari√°vel aleat√≥ria X , definimos o seu k -√©simo momento como E(X^{k}) , para k=1,2,\\dots Ent√£o, por exemplo, se X\\in\\mathcal{L}^{k} e X\\geq 0 , podemos estimar P[X\\geq x]=P[X^{k}\\geq x^{k}]\\leq\\frac{E(X^{k})}{x^{k}},\\text{ para quaisquer % $k\\geq 1$.} (3.20) Observe que quando o k -√©simo momento de X √© finito, a raz√£o acima decai mais r√°pido quando x diverge. {exercise} Mostre uma f√≥rmula an√°loga √† da Proposi√ß√£o¬†3.1. {exercise} Mostre que se a distribui√ß√£o de X tem densidade \\rho e E(|f(X)|)<\\infty , ent√£o E(f(X))=\\int f(x)\\rho(x)\\d{x}. (3.21) Um caso bastante importante ocorre quando k=2 , por v√°rias raz√µes que descreveremos abaixo. Digamos que estamos interessados em aproximar uma vari√°vel aleat√≥ria por uma constante de forma a minimizar o erro da aproxima√ß√£o. Uma poss√≠vel formula√ß√£o desse problema √© encontrar a de forma a minimizar E\\Big{(}(X-a)^{2}\\Big{)}=E(X^{2})-2aE(X)+a^{2}. (3.22) Essa equa√ß√£o obviamente possui um √∫nico m√≠nimo em a=E(X) . Ao erro da aproxima√ß√£o acima damos o nome de vari√¢ncia {definition} Dada uma vari√°vel aleat√≥ria X\\in\\mathcal{L}^{2} , definimos sua vari√¢ncia como \\Var(X)=E\\Big{(}\\big{(}X-E(X)\\big{)}^{2}\\Big{)}=E(X^{2})-E(X)^{2}. (3.23) Observe pelas defini√ß√µes alternativas dadas acima que ‚ÄÉa)‚Äã \\Var(X)\\geq 0 e ‚ÄÉb)‚Äã E(X^{2})\\geq E(X)^{2} . {exercise} Mostre que se X\\in\\mathcal{L}^{2} , ent√£o \\Var(X)=0 se e somente se X=a quase certamente. Obviamente \\Var(aX)=E(a^{2}X^{2})-E(aX)^{2}=a^{2}\\Var(X). (3.24) Podemos alternativamente entender a vari√¢ncia da seguinte meneira. Sejam X e Y vari√°veis aleat√≥rias independentes em \\mathcal{L}^{2} de mesma distribui√ß√£o. Ent√£o, E\\big{(}(X-Y)^{2}\\big{)}=E(X^{2})-2E(XY)+E(X^{2})=E(X^{2})-E(X)^{2}=\\Var(X). (3.25) {exercise} Mostre que se X\\in\\mathcal{L}^{2} , ent√£o \\Var(X+b)=\\Var(X) . {exercise} Calcule Var(X) quando X tem distribui√ß√µes \\Ber(p) , U[0,1] ou \\Exp(\\lambda) . A seguinte proposi√ß√£o mostra que a vari√¢ncia √© uma maneira de estimar o quanto uma vari√°vel aleat√≥ria se desvia de sua m√©dia. {proposition} Se X\\in\\mathcal{L}^{2} e a>0 , ent√£o P[|X-E(X)|>a]\\leq\\frac{\\Var(X)}{a^{2}}. (3.26) Demonstra√ß√£o. A desigualdade segue trivialmente da cota de Markov, ao observarmos que ‚ÄÉa)‚Äã |X-E(X)|\\geq 0 , ‚ÄÉb)‚Äã |X-E(X)|>a se e somente se |X-E(X)|^{2}>a^{2} e ‚ÄÉc)‚Äã E\\big{(}|X-E(X)|^{2}\\big{)}=E\\big{(}(X-E(X))^{2}\\big{)}=\\Var(X) , mostrando a proposi√ß√£o. ‚àé Para vari√°veis aleat√≥rias de m√©dia zero, a vari√¢ncia nada mais √© que E(X^{2}) , ou em outras palavras \\lVert X\\rVert^{2}_{2} , o quadrado de sua norma em \\mathcal{L}^{2} . Isso nos motiva a olhar mais de perto para o produto interno em \\mathcal{L}^{2} , que se traduz a E(XY) . Mas para n√£o nos restringirmos a vari√°veis de m√©dia zero, introduzimos a seguinte {definition} Se X,Y s√£o vari√°veis em \\mathcal{L}^{2} , definimos \\Cov(X,Y)=E\\Big{(}\\big{(}X-E(X)\\big{)}\\big{(}Y-E(Y)\\big{)}\\Big{)}=E(XY)-E(X)E(% Y). (3.27) Uma observa√ß√£o importante √© que se X e Y em \\mathcal{L}^{2} s√£o independentes, ent√£o \\Cov(X,Y)=0 . (3.28) {exercise} Sejam X_{1} e X_{2} as coordenadas can√¥nicas em \\mathbb{R}^{2} . J√° vimos que elas n√£o s√£o independentes sob a distribui√ß√£o U_{S^{1}} . Mostre que mesmo assim temos \\Cov(X_{1},X_{2})=0 . Uma outra propriedade bastante importante da vari√¢ncia √© que ela se comporta bem com somas, no seguinte sentido {proposition} Se X_{1},\\dots,X_{n} s√£o vari√°veis em \\mathcal{L}^{2} , ent√£o \\Var(X_{1}+\\dots+X_{n})=\\sum_{i=1}^{n}\\Var(X_{i})+\\sum_{i\\neq j}\\Cov(X_{i},X_{% j}). (3.29) Em particular, se as vari√°veis X_{i} forem independentes duas a duas, ent√£o \\Var(X_{1}+\\dots+X_{n})=\\sum_{i=1}^{n}\\Var(X_{i}). (3.30) Demonstra√ß√£o. Basta fazer o tedioso desenvolvimento \\begin{split}\\Var\\Big{(}\\sum_{i}X_{i}\\Big{)}&=E\\Big{(}\\Big{(}\\sum_{i}X_{i}-E% \\Big{(}\\sum_{i}X_{i}\\Big{)}\\Big{)}^{2}\\Big{)}\\\\ &=E\\Big{(}\\Big{(}\\sum_{i}X_{i}-E(X_{i})\\Big{)}^{2}\\Big{)}\\\\ &=\\sum_{i,j=1}^{n}E\\big{(}X_{i}-E(X_{i})\\big{)}E\\big{(}X_{j}-E(X_{j})\\big{)},% \\end{split} (3.31) o que termina a prova ao separarmos i=j de i\\neq j . ‚àé {exercise} Calcule \\Var(X) quando X\\overset{d}{\\sim}\\Bin(n,p) . {exercise} Calcule E(X) quando X\\overset{d}{\\sim}\\Geo(p) . Um dito popular muito comum no Brasil √© que n√£o devemos deixar todos os ‚Äúovos no mesmo cesto‚Äù, o que nos remete √† possibilidade de perdermos todos eles caso o cesto caia. Uma outra maneira de pensar nas vantagens de se dividir nossos riscos entre v√°rias fontes independentes de incerteza, vem da equa√ß√£o (3.30), melhor explicada no exerc√≠cio abaixo. {exercise} Imagine que X_{1},\\dots,X_{n} s√£o vari√°veis \\iid, tomando valores em [0,1] e que temos um certo valor s\\in\\mathbb{R}_{+} que temos que guardar em n caixas (dividindo como quisermos em s_{1},\\dots,s_{n} ). Ao fim da semana, obteremos S=\\sum_{i}s_{i}X_{i} . Calcule E(S) e \\Var(S) , ‚ÄÉa)‚Äãse s_{1}=s e s_{i}=0 para todo i\\geq 2 e ‚ÄÉb)‚Äãse s_{i}=s/n para todo i . Compare os resultados. {exercise} Calcule \\lim_{p\\to 0}F_{p}(x) onde F_{p} √© a fun√ß√£o de distribui√ß√£o acumulada de pX_{p} com X_{p}\\overset{d}{\\sim}\\Geo(p) . Voc√™ reconhece esse limite? Previous page Next page"],[["index.html","Ch3.html","Ch3.S3.html"],"3.3 Lei fraca dos grandes n√∫meros ‚Ä£ Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Lei fraca dos grandes n√∫meros 3.3 Lei fraca dos grandes n√∫meros Nessa se√ß√£o iremos mostrar um dos resultados mais importantes da Teoria da Probabilidade. O que nossa intui√ß√£o tem a nos dizer sobre a probabilidade de obtermos um resultado em um dado √© 1/6 ? Uma poss√≠vel explica√ß√£o seria por simetria, mas e o que podemos dizer no caso de um dado viciado? Se dizemos a algu√©m que a probabilidade de obter 6 em um certo dado √© 1/10 , naturalmente a pessoa pode se perguntar como descobrimos isso. Um bom jeito de obter tal medida seria jogar o dado v√°rias vezes independentemente e calcular em qual propor√ß√£o dos ensaios ele retornou um seis. O objetivo desta se√ß√£o √© confirmar a validade desse experimento de maneira quantitativa. {theorem} Se X_{1},X_{2},\\dots s√£o i.i.d.s em \\mathcal{L}^{2} e definimos S_{n}=\\sum_{i=1}^{n}X_{i}, (3.32) ent√£o para todo \\varepsilon>0 \\lim_{n\\to\\infty}P\\Big{[}\\Big{|}\\frac{S_{n}}{n}-E(X_{1})\\Big{|}>\\varepsilon% \\Big{]}=0. (3.33) Ou seja, \\tfrac{S_{n}}{n}\\to E(X_{1}) em medida (que tamb√©m chamamos de ‚Äúem probabilidade‚Äù). Demonstra√ß√£o. Sabemos que P\\Big{[}\\Big{|}\\frac{S_{n}}{n}-E(X_{1})\\Big{|}>\\varepsilon\\Big{]}\\leq\\frac{% \\Var(\\tfrac{S_{n}}{n})}{\\varepsilon^{2}}, (3.34) pois E(S_{n}/n)=1/nE(X_{1}+\\dots+X_{n})=E(X_{1}) . Mas como \\Var(S_{n}/n)=1/n^{2}\\Var(X_{1}+\\dots+X_{n})=(n/n^{2})\\Var(X_{1}) , temos o resultado. ‚àé Observe que n√≥s apenas utilizamos que as vari√°veis X_{i} eram independentes duas a duas. Al√©m disso, obtivemos o seguinte resultado quantitativo que vale mesmo para valores finitos de n : {scholia} Se X_{1},X_{2},\\dots s√£o i.i.d.s em \\mathcal{L}^{2} e definimos S_{n}=\\sum_{i=1}^{n}X_{i} como acima, ent√£o, para todo \\varepsilon>0 e n\\geq 1 , temos P\\Big{[}\\Big{|}\\frac{S_{n}}{n}-E(X_{1})\\Big{|}>\\varepsilon\\Big{]}\\leq\\frac{% \\Var(X_{1})}{\\varepsilon^{2}n}. (3.35) {corollary} Se A_{1},A_{2},\\dots s√£o eventos independentes dois a dois com P(A_{i})=p\\in[0,1] para todo i , ent√£o \\lim_{n\\to\\infty}P\\Big{[}\\Big{|}\\frac{\\#\\{i\\leq n;\\omega\\in A_{i}\\}}{n}-p\\Big{% |}>\\varepsilon\\Big{]}=0, (3.36) ou em outras palavras a propor√ß√£o de ensaios onde o evento A_{i} ocorre converge em probabilidade para p . Demonstra√ß√£o. Basta tomar X_{i}=\\1_{A_{i}} no Teorema¬†3.3. ‚àé {exercise} Sejam (X_{i})_{i\\geq 1} vari√°veis \\iidcom distribui√ß√£o Ber (p) , p\\in[0,1] . Mostre que \\lim_{N\\to\\infty}\\frac{1}{N}\\sum_{i=1}^{N}X_{i}X_{i+1}=p^{2},\\text{ em % probabilidade.} (3.37) {exercise} Sejam X_{1},\\dots,X_{n} e Y_{1},\\dots,Y_{n} vari√°veis independentes com distribui√ß√£o \\Ber(p) . Defina agora Z_{i,j}=X_{i}Y_{j} , para i,j\\in\\{1,\\dots,n\\} e ‚ÄÉa)‚Äãcalcule a esperan√ßa de S_{n}=\\tfrac{1}{n^{2}}\\sum_{i=1}^{n}\\sum_{j=1}^{n}Z_{i,j} e ‚ÄÉb)‚Äãestime P[|S_{n}-E(S_{n})|>a] usando o m√©todo do segundo momento. Como esse resultado se compara com o caso em que os Z_{i,j} s√£o i.i.d.? {exercise} Considere uma rua infinita com casas i\\in\\mathbb{Z} . Para todo i\\in\\mathbb{Z} , existia uma rua entre as casas i e i+1 , mas ap√≥s uma grande tempestade essas ruas foram danificadas. Mais precisamente, para cada i\\in\\mathbb{Z} , temos vari√°veis aleat√≥rias X_{i} que s√£o i.i.d. com distribui√ß√£o \\text{Ber}(p) , onde X_{i}=1 indica que o trecho da rua entre as casas i e i+1 foi danificado e n√£o pode ser utilizado. Defina, para i\\in\\mathbb{Z} , R_{i} como sendo o n√∫mero de casas que continuaram acess√≠veis √† casa i ap√≥s a tempestade. Por exemplo, se X_{-2} e X_{0}=1 e X_{-1}=0 , temos que a casa 0 somente pode acessar a casa -1 , logo R_{0}=1 . Nesse contexto, ‚ÄÉa)‚ÄãCalcule a distribui√ß√£o e a esperan√ßa de R_{0} , ‚ÄÉb)‚ÄãUse o m√©todo do segundo momento para estimar a probabilidade P\\Big{[}\\Big{|}\\frac{1}{n}\\sum_{i=1}^{n}R_{i}-E(R_{0})\\Big{|}>a\\Big{]}. (3.38) Previous page Next page"],[["index.html","Ch3.html","Ch3.S4.html"],"3.4 Lei forte dos grandes n√∫meros ‚Ä£ Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Lei forte dos grandes n√∫meros 3.4 Lei forte dos grandes n√∫meros {theorem} [Lei Forte dos Grandes N√∫meros] Sejam X_{1},X_{2},\\dots \\iidem \\mathcal{L}^{1} , com m=E(X_{1}) . Ent√£o, \\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{i=1}^{n}X_{n}=m,\\text{ $P$-quase certamente.} (3.47) Antes de come√ßar a prova, buscando inspira√ß√£o no Teorema das Tr√™s S√©ries, mostraremos que basta considerar vers√µes truncadas das vari√°veis X_{i} . Isso √© feito no pr√≥ximo {lemma} Sejam Y_{i}=X_{i}\\1_{[|X_{i}|\\leq i]} . Ent√£o, para demonstrar o Teorema¬†3.4, basta provar que \\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{i=1}^{n}Y_{i}=m,\\text{ $P$-quase certamente.} (3.48) Prova do Lema¬†3.4. Consideramos os eventos A_{i}=[X_{i}\\neq Y_{i}] . Obviamente, \\sum_{i}P(A_{i})=\\sum_{i}P[|X_{i}|\\geq i]\\leq\\int_{0}^{\\infty}P[|X_{i}|\\geq t]% \\d{t}=E\\big{(}|X_{i}|)<\\infty. (3.49) Logo, pelo Lema de Borel-Cantelli, temos que P -quase certamente A_{i} acontece apenas finitas vezes. Digamos que A_{i} n√£o acontece para i>N(\\omega) . Dessa forma, para qualquer n\\geq 1 , \\Big{|}\\frac{1}{n}\\sum_{i=1}^{n}(X_{i}-Y_{i})\\Big{|}\\leq\\frac{1}{n}\\sum_{i=1}^% {n}|X_{i}-Y_{i}|\\leq\\frac{1}{n}\\sum_{i\\leq N(\\omega)}|X_{i}|, (3.50) que converge para zero P -quase certamente, mostrando o resultado. ‚àé O pr√≥ximo passo para a prova da Lei Forte dos Grandes N√∫meros √© cuidar da esperan√ßa das novas vari√°veis Y_{i} . {lemma} Sejam Z_{i}=Y_{i}-E(Y_{i}) , para i\\geq 1 como acima. Ent√£o, para demosntrar o Teorema¬†3.4, basta mostrar que \\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{i=1}^{n}Z_{i}=0,\\text{ $P$-quase certamente.} (3.51) Demonstra√ß√£o. Supondo a converg√™ncia em (3.51), sabemos que \\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{i=1}^{n}Y_{i}-E(Y_{i})=0,\\text{ $P$-quase % certamente.} (3.52) Mas E(Y_{i})=E(X_{i}\\1_{[|X_{i}|\\leq i]}) que converge a E(X_{i})=m , pelo Teorema da Converg√™ncia Dominada, donde conclu√≠mos que \\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{i=1}^{n}E(Y_{i})=m. (3.53) Dessa forma, obtemos que \\tfrac{1}{n}\\sum_{i=1}^{n}Y_{i} converge quase certamente a m , donde conclu√≠mos a prova do Teorema¬†3.4 por meio do Lema¬†3.4. ‚àé Gostar√≠amos de utilizar os teoremas das s√©ries para mostrar a converg√™ncia de \\tfrac{1}{n}\\sum_{n}Z_{n} , mas obviamente, o fator \\tfrac{1}{n} que precede a soma nos impede de faz√™-lo. O pr√≥ximo resultado √© um simples exerc√≠cio de an√°lise real, que nos permite reduzir a prova de (3.51) para uma simples converg√™ncia de uma s√©rie sem pr√©-fatores. {lemma} [Lema de Kronecker] Suponha que x_{n}\\in\\mathbb{R} e b_{n}>0 sejam tais que b_{n}\\uparrow\\infty e \\sum_{i=1}^{\\infty}\\frac{x_{i}}{b_{i}} convirja a s\\in\\mathbb{R} . Ent√£o \\lim_{n\\to\\infty}\\frac{1}{b_{n}}\\sum_{i=1}^{n}x_{i}=0. (3.54) Demonstra√ß√£o. Definindo s_{0}=0 e s_{n}=\\tfrac{x_{1}}{b_{1}}+\\dots+\\tfrac{x_{n}}{b_{n}} , temos, por integra√ß√£o por partes, \\sum_{i=1}^{n}x_{i}=\\sum_{i=1}^{n}b_{i}\\frac{x_{i}}{b_{i}}=\\sum_{i=1}^{n}b_{i}% s_{i}-\\sum_{i=1}^{n}b_{i}s_{i-1}=b_{n}s_{n}+\\sum_{i=1}^{n-1}(b_{i}-b_{i+1})s_{% i}. (3.55) Escolhemos agora, para qualquer \\varepsilon>0 , um n_{0}\\geq 1 tal que |s_{n}-s|<\\varepsilon para todo n\\geq n_{0} . Dessa forma, \\begin{split}\\frac{1}{b_{n}}\\sum_{i=1}^{n}x_{i}&=s_{n}-\\frac{1}{b_{n}}\\sum_{i=% 1}^{n-1}(b_{i+1}-b_{i})s_{i}\\\\ &=s_{n}-\\frac{1}{b_{n}}\\underbrace{\\sum_{i=1}^{n_{0}-1}(b_{i+1}-b_{i})}_{% \\Delta_{n_{0}}}s_{i}-\\frac{1}{b_{n}}\\sum_{i=n_{0}}^{n-1}(b_{i+1}-b_{i})s_{i}\\\\ &=\\underbrace{s_{n}}_{\\to s}-\\underbrace{\\frac{1}{b_{n}}\\Delta_{n_{0}}}_{\\to 0% }-\\underbrace{\\frac{1}{b_{n}}\\sum_{i=n_{0}}^{n-1}(b_{i+1}-b_{i})s}_{=\\tfrac{(b% _{n}-b_{n_{0}})s}{b_{n}}\\to s}-\\underbrace{\\frac{1}{b_{n}}\\sum_{i=n_{0}}^{n-1}% (b_{i+1}-b_{i})(s_{i}-s)}_{\\leq\\varepsilon\\tfrac{(b_{n}-b_{n_{0}})}{b_{n}}\\leq% \\varepsilon},\\end{split} onde os limites indicados acima representam o que acontece quando n\\to\\infty . A prova segue do fato de \\varepsilon ter sido escolhido arbitrariamente. ‚àé Estamos agora em posi√ß√£o de finalizar a Prova do Teorema¬†3.4. De acordo com o Lema de Kronecker e o Lema¬†3.4, √© suficiente mostrar que \\sum_{i=1}^{n}\\frac{Z_{i}}{i},\\text{ converge quase certamente}. (3.56) Por outro lado, como os Z_{i} ‚Äôs tem m√©dia zero, o Teorema de Uma S√©rie diz que √© suficiente mostrar que \\sum_{i=1}^{n}\\Var\\Big{(}\\frac{Z_{i}}{i}\\Big{)}=\\sum_{i=1}^{n}\\frac{1}{i^{2}}% \\Var(Z_{i})<\\infty. (3.57) Isso segue da seguinte estimativa \\begin{split}\\sum_{i=1}^{n}\\frac{1}{i^{2}}\\Var(Z_{i})&=\\sum_{i=1}^{n}\\frac{1}{% i^{2}}\\Var(Y_{i})\\leq\\sum_{i=1}^{n}\\frac{1}{i^{2}}E\\big{(}X_{i}^{2}\\1_{[|X_{i}% |\\leq i]}\\big{)}\\\\ &=\\sum_{i=1}^{n}\\frac{1}{i^{2}}\\sum_{k=1}^{i}E\\big{(}X_{i}^{2}\\1_{[k-1<|X_{i}|% \\leq k]}\\big{)}\\\\ &=\\sum_{k=1}^{n}E\\big{(}X_{1}^{2}\\1_{[k-1<|X_{i}|\\leq k]}\\big{)}\\sum_{i=k}^{n}% \\frac{1}{i^{2}}\\\\ &\\leq 2\\sum_{k=1}^{n}\\frac{1}{k}E\\big{(}X_{1}^{2}\\1_{[k-1<|X_{i}|\\leq k]}\\big{% )}\\\\ &\\leq 2\\sum_{k=1}^{n}E\\big{(}X_{1}\\1_{[k-1<|X_{i}|\\leq k]}\\big{)}\\leq 2E(X_{1}% )<\\infty.\\end{split} (3.58) Isso nos permite concluir a prova de (3.51) via o Lema de Kronecker. Consequentemente, obtemos o Teorema¬†3.4 via o Lema¬†3.4. ‚àé {exercise} Sejam Y_{k} vari√°veis aleat√≥rias independentes e com a seguinte distribui√ß√£o: P[Y_{k}=i]=\\begin{cases}\\frac{1}{2}-\\frac{1}{k^{2}}\\quad&\\text{se $i=1$ or $i=% -1$},\\\\ \\frac{2}{k^{2}}&\\text{se $i=3$.}\\end{cases} (3.59) Mostre que P\\Big{[}\\frac{1}{n}\\sum_{k=1}^{n}Y_{k}\\text{ converge a zero}\\Big{]}=1. (3.60) {exercise} [Depende de T√≥pico: Urna de P√≥lya] Mostre que segundo a lei P construida no Exerc√≠cio¬†2, vale que P\\big{[}\\tfrac{1}{n}\\sum_{i-1}^{n}X_{i}\\text{ converge}]=1. (3.61) Al√©m disso calcule a distribui√ß√£o do limite acima. \\todosec T√≥pico: Teorema de Weierstrassprovar o teorema de Weierstrass de aproxima√ß√£o de fun√ß√µes cont√≠nuas por polin√¥mios (prova probabil√≠stica). Ele √© usado em converg√™ncia fraca em \\mathbb{R} \\todosec T√≥pico: Entropia de Shannonfazer‚Ä¶ \\todosec T√≥pico: Processos de renova√ß√£ofazer‚Ä¶ Previous page Next page"],[["index.html","Ch3.html","Ch3.S5.html"],"3.5 Lei {0,1} de Kolmogorov ‚Ä£ Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Lei 3.5 Lei \\{0,1\\} de Kolmogorov Ao estudarmos o Lema de Borel-Cantelli, vimos que se os eventos (A_{i})_{i\\geq 1} s√£o independentes ent√£o a probabilidade de [A_{i}\\text{ infinitas vezes}] somente pode assumir os valores zero ou um (dependendo da somabilidade de P(A_{i}) ). Nessa se√ß√£o iremos estudar outros tipos de evento que assumem apenas esses dois valores. Esperamos que esse fen√¥meno se torne intuitivo ao final dessa discuss√£o. No que se segue, consideraremos um espa√ßo mensur√°vel \\Omega=\\times_{i=1}^{\\infty}E , com a \\sigma -√°lgebra can√¥nica \\mathcal{F} , isto √© a \\sigma -√°lgebra gerada pelas coordenadas can√µnicas (X_{i})_{i=1}^{\\infty} . {definition} Dizemos que um evento A\\in\\mathcal{F} √© caudal se A\\in\\sigma\\big{(}X_{i};i\\geq n\\big{)},\\text{ para todo $n\\geq 1$}. (3.62) Tamb√©m introduzimos a classe \\mathcal{F}_{\\infty} de tais eventos, que claramente √© uma \\sigma -√°lgebra, pois pode ser escrita como \\mathcal{F}_{\\infty}=\\mcap_{n\\geq 1}\\sigma\\big{(}X_{i};i\\geq n\\big{)}. (3.63) Chamamos \\mathcal{F}_{\\infty} de \\sigma -√°lgebra caudal. Vejamos que, dados A_{i}\\in\\sigma(X_{i}) , i\\geq 1 , temos que [A_{i}\\text{ infinitas vezes}] √© caudal. Para tanto, basta observar que para todo n\\geq 1 , temos que [A_{i}\\text{ infinitas vezes}]=\\big{[}\\#\\{i\\geq 1;\\omega\\in A_{i}\\}=\\infty\\big% {]}=\\big{[}\\#\\{i\\geq n;\\omega\\in A_{i}\\}=\\infty\\big{]}, que obviamente pertence a \\sigma(X_{i};i\\geq n) para todo n\\geq 1 . {exercise} Mostre que em \\Omega=\\mathbb{R}^{\\infty} , s√£o caudais os seguintes eventos ‚ÄÉa)‚Äã [X_{i}\\text{ converge}] , ‚ÄÉb)‚Äã \\big{[}\\tfrac{1}{n}\\sum_{i=1}^{n}X_{i}\\text{ converge}\\big{]} e ‚ÄÉc)‚Äã [\\#\\{i\\geq 1;X_{i}>0\\}<\\infty] . Podemos agora enunciar o pricipal teorema dessa se√ß√£o {theorem} [Lei \\{0,1\\} de Kolmogorov] Se \\Omega=E^{\\infty} , onde E √© um espa√ßo can√¥nico, for provido de uma lei produto P=\\otimes_{i=1}^{\\infty}P_{i} , ent√£o todo evento caudal tem probabilidade 0 ou 1 sob P . Quando uma \\sigma -√°lgebra \\mathcal{F} satisfaz P(A)\\in\\{0,1\\} para todo A\\in\\mathcal{F} , dizemos que \\mathcal{F} √© trivial. Uma outra maneira de enunciar a conclus√£o do teorema acima √© dizer que a \\sigma -√°lgebra caudal \\mathcal{F}_{\\infty} √© trivial. Demonstra√ß√£o. A id√©ia da prova, apesar de soar um pouco estranha, √© mostrar que se A\\in\\mathcal{F}_{\\infty} , ent√£o A √© independente de si mesmo. Em outras palavras, P(A)=P(A\\cap A)=P(A)^{2} , donde P(A)\\in\\{0,1\\} . Mas vamos com calma. Fixe k\\geq 1 , A\\in\\mathcal{F}_{\\infty} e B\\in\\sigma(X_{1},\\dots,X_{k}) . Nesse caso, como o evento A pertence a \\sigma(X_{k+1},X_{k+2},\\dots) , temos que A e B s√£o independentes. Fixe agora A\\in\\mathcal{F}_{\\infty} e considere a classe \\mathcal{B}_{A}=\\{B\\in\\mathcal{F};\\text{ $B$ \\'{e} independente de $A$}\\}. (3.64) J√° sabemos que \\sigma(X_{1},\\dots,X_{k})\\subseteq\\mathcal{B}_{A} para todo k\\geq 1 . Obviamente \\Omega √© independente de A , assim como B^{c}\\in\\mathcal{B}_{A} sempre que B\\in\\mathcal{B}_{A} . Al√©m disso, suponha que B_{1},B_{2},\\dots in \\mathcal{B}_{A} s√£o disjuntos, ent√£o, P\\big{(}(\\mcup_{i}B_{i})\\cap A\\big{)}=P\\big{(}\\mcup_{i}(B_{i}\\mcap A)\\big{)}% \\overset{\\text{disj.}}{=}\\sum_{i}P(B_{i}\\mcap A)\\overset{\\text{indep.}}{=}P(A)% P(\\mcup_{i}B_{i}). Logo \\mathcal{B}_{A} √© um \\lambda -sistema. Lembrando que \\mathcal{B}_{A} cont√©m o \\pi -sistema \\bigcup_{k}\\sigma(X_{1},\\dots,X_{k}) , isto √© dos eventos cil√≠ndricos, temos que todos eventos s√£o indepentes de A , inclusive o pr√≥prio A . Isso termina a prova do teorema. ‚àé {exercise} Dizemos que uma probabilidade P no espa√ßo produto \\Omega=\\times_{n\\geq 1}E (com a \\sigma -√°lgebra can√¥nica) √© fortemente misturadora se, para todo k\\geq 1 , temos \\lim_{n\\to\\infty}\\sup\\big{|}P(A\\cap B)-P(A)P(B)\\big{|}=0, (3.65) onde o supremo acima √© tomado sobre A\\in\\sigma(X_{1},\\dots,X_{k}) e B\\in\\sigma(X_{n},X_{n+1},\\dots) . Mostre que nesse caso, a \\sigma -√°lgebra dos eventos caudais √© trivial. {exercise} [Depende de T√≥pico: Percola√ß√£o] Considere o grafo G=(\\mathbb{Z}^{2},E) , onde E=\\big{\\{}\\{x,y\\};|x-y|_{2}=1\\big{\\}} . Dotamos agora o espa√ßo \\{0,1\\}^{E} com a \\sigma -√°lgebra \\mathcal{A} gerada pelas proje√ß√µes can√¥nicas Y_{e}(\\omega)=\\omega(e) , onde \\omega\\in\\{0,1\\}^{E} e e\\in E . Definimos o conjunto A\\subseteq\\{0,1\\}^{E} por A=\\Big{[}\\begin{array}[]{c}\\text{existe uma sequ\\^{e}ncia de distintos $x_{0},% x_{1},\\dots\\in\\mathbb{Z}^{2}$,}\\\\ \\text{tais que $e_{i}=\\{x_{i},x_{i+1}\\}\\in E$ e $Y_{e_{i}}=1$ para cada $i\\geq 0% $}\\end{array}\\Big{]}. (3.66) ‚ÄÉa)‚ÄãMostre que A √© mensur√°vel com respeito a \\mathcal{A} . ‚ÄÉb)‚ÄãMostre que A √© um evento caudal, ou seja A\\in\\bigcap_{K\\subseteq E;\\text{ finito}}\\sigma\\big{(}Y_{e};e\\not\\in K\\big{)}. (3.67) ‚ÄÉc)‚ÄãConclua que P(A)\\in\\{0,1\\} . {exercise} Seja \\Omega=E^{\\mathbb{Z}} um espa√ßo produto infinito, dotado da \\sigma -√°lgebra \\mathcal{A} gerada pelas proje√ß√µes can√¥nicas (X_{i})_{i\\in\\mathbb{Z}} . Consideramos agora em (\\Omega,\\mathcal{A}) a medida produto \\mathbb{P}=P^{\\otimes\\mathbb{Z}} , onde P √© uma probabilidade fixada no espa√ßo polon√™ns (E,\\mathcal{B}(E)) . ‚ÄÉa)‚ÄãMostre que para qualquer evento A\\in\\mathcal{A} e qualquer \\varepsilon>0 , existe um k\\in\\mathbb{Z}_{+} e um evento A_{k}\\in\\sigma(X_{i},|i|\\leq k) tais que \\mathbb{P}[(A\\setminus A_{k})\\cup(A_{k}\\setminus A)]<\\varepsilon . ‚ÄÉb)‚ÄãConsidere o shift \\theta:\\Omega\\to\\Omega dado por \\theta(\\omega)(i)=\\omega(i-1) e mostre que se A=\\theta(A) , ent√£o P(A)\\in\\{0,1\\} . Previous page Next page"],[["index.html","Ch3.html","Ch3.S6.html"],"3.6 Momentos exponenciais ‚Ä£ Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Momentos exponenciais 3.6 Momentos exponenciais Nessa se√ß√£o desenvolveremos uma outra t√©cnica para estimar a probabilidade de uma vari√°vel aleat√≥ria se desviar de sua esperan√ßa. J√° vimos o m√©todo do primeiro, segundo e quarto momento para controlar uma soma de vari√°veis independentes. Um exemplo disso foi visto na estimativa P\\Big{[}\\sum_{i=1}^{n}(X_{i}-E(X_{i}))\\geq a\\Big{]}\\leq\\frac{\\sum_{i}\\Var(X_{i% })}{a^{2}}. (3.68) Em geral, quanto maior o momento, melhor a estimativa do decaimento para a probabilidade de que uma vari√°vel se desvie de sua esperan√ßa. Nessa se√ß√£o iremos para momentos exponenciais, que em um certo sentido produzem estimativas √≥timas para o comportamento assint√≥tico da probabilidade de desvio. Note que se quisermos uma pequena probabilidade de erro (como por exemplo \\sim 0.01 ), o m√©todo do segundo momento √© muito bom, como veremos posteriormente. Mas se quisermos uma probabilidade de erro min√∫scula (em situa√ß√µes concretas, algo como 10^{-12} por exemplo), certamente teremos que aumentar bastante o valor de n , mas quanto? As cotas de segundo momento s√£o muito ruins para esse tipo de estimativa, nos levando a escolher um n maior que o necess√°rio. Abaixo, desenvolveremos um m√©todo mais eficiente para responder a essa pergunta, obviamente sob certas hip√≥teses na distribui√ß√£o das vari√°veis aleat√≥rias. {definition} Dada uma vari√°vel aleat√≥ria X , definimos sua transformada de Laplace como \\phi_{X}(s)=E(\\ex{sX})\\in(0,\\infty], (3.69) para todos s\\in\\mathbb{R} . Essa transformada tamb√©m √© chamada fun√ß√£o geradora de momentos de X . {exercise} Calcule a fun√ß√£o geradora de momentos das distribui√ß√µes \\Ber(p) , \\Exp(\\lambda) e U_{[0,1]} . {proposition} Se E(\\ex{\\delta|X|})<\\infty , ent√£o ‚ÄÉa)‚Äã X\\in\\mathcal{L}^{p} para todo 1\\leq p<\\infty , ‚ÄÉb)‚Äã \\phi_{X}(s)<\\infty para todo s\\in(-\\delta,\\delta) , ‚ÄÉc)‚Äã \\phi_{X}(s) √© C^{\\infty} em (-\\delta,\\delta) e ‚ÄÉd)‚Äã \\phi_{X}^{(n)}(s)=E(X^{n}\\ex{sX}) . A √∫ltima conclus√£o da proposi√ß√£o acima justifica a nomenclatura fun√ß√£o geradora de momentos pois \\phi_{X}^{(n)}(0)=E(X^{n}) . Demonstra√ß√£o. Obviamente, para todo p\\geq 1 existe c>0 tal que \\ex{\\delta|x|}\\geq c|x|^{p} , donde X\\in\\mathcal{L}^{p} . Al√©m disso, para todo s\\in(-\\delta,\\delta) , temos \\phi_{X}(s)=E(\\ex{sX})\\leq E(\\ex{\\delta|X|})<\\infty , donde 2. segue imediatamente. Fixando s\\in\\mathbb{R} , vamos agora calcular \\frac{\\phi_{X}(s+h)-\\phi_{X}(s)}{h}=\\frac{E\\big{(}\\ex{(s+h)X}-\\ex{sX}\\big{)}}{% h}=E\\Big{(}\\ex{sX}\\frac{\\ex{hX}-1}{h}\\Big{)}. (3.70) Lembrando que |\\tfrac{1}{y}(e^{y}-1)|\\leq e^{|y|} , para todo y\\in\\mathbb{R} , temos que para todos os h<(\\delta-|s|)/2 , o integrando acima √© dominado por |X|\\ex{(|s|+h)|X|}\\leq|X|\\ex{\\smash{\\tfrac{\\delta+|s|}{2}|X|}} que pertence a \\mathcal{L}^{1} . Logo podemos usar o Teorema da Converg√™ncia Dominada para trocar o limite h\\to 0 com a esperan√ßa, obtendo \\phi_{X}^{\\prime}(s)=E(X\\ex{sX}). (3.71) Note que para todo \\varepsilon>0 e k\\geq 1 , |x|^{k}\\leq c(k)\\ex{\\varepsilon|x|} , isso nos permite repetir o argumento acima indutivamente para obter c) e d). ‚àé Lembramos que ao usar o m√©todo do segundo momento, nos foi bastante √∫til o fato que a vari√¢ncia se comporta bem com rela√ß√£o a somas independentes. Mais precisamente, \\Var(X_{1}+\\dots+X_{k})=\\Var(X_{1})+\\dots+\\Var(X_{k}) . Uma outra propriedade importante da fun√ß√£o geradora de momentos √© que ela tamb√©m se comporta bem com respeito √† somas independentes. {proposition} Se X_{1},\\dots,X_{n} s√£o vari√°veis independentes com \\phi_{X_{i}}(s)<\\infty para todo i\\leq k e |s|<\\delta , ent√£o \\phi_{X_{1}+\\dots+X_{k}}(s)=\\phi_{X_{1}}(s)\\dotsm\\phi_{X_{k}}(s),\\text{ para % todos $|s|<\\delta$.} (3.72) Demonstra√ß√£o. Basta observar que \\begin{split}E(\\exp&\\{s(X_{1}+\\dots+X_{k})\\})=E(\\ex{sX_{1}}\\dotsm\\ex{sX_{k}}))% \\\\ &=E\\big{(}\\ex{sX_{1}})\\dotsm E(\\ex{sX_{k}}\\big{)}=\\phi_{X_{1}}(s)\\dotsm\\phi_{X% _{k}}(s),\\end{split} (3.73) usando Fubini. ‚àé Consideraremos agora uma sequ√™ncia X_{1},X_{2},\\dots de vari√°veis \\iidcom \\phi_{X_{1}}(s)<\\infty para |s|<\\delta . Ent√£o podemos tentar estimar, para a>0 e |s|<\\delta , \\begin{split}P\\Big{[}&\\frac{X_{1}+\\dots+X_{n}}{n}-E(X_{1})\\geq a\\Big{]}=P\\Big{% [}X_{1}+\\dots+X_{n}\\geq(a+E(X_{1}))n\\Big{]}\\\\ &\\quad=P\\Big{[}\\ex{s(X_{1}+\\dots+X_{n})}\\geq\\ex{s(a+E(X_{1}))n}\\Big{]}\\\\ &\\quad\\leq\\phi_{X_{1}+\\dots+X_{n}}(s)\\ex{-s(a+E(X_{1}))n}=\\phi_{X_{1}}^{n}(s)% \\ex{-s(a+E(X_{1}))n}.\\end{split} O primeiro fator na estimativa acima pode crescer exponencialmente com n , enquanto o segundo decresce. Gostar√≠amos que o comportamento do segundo predominasse, o que podemos concluir do seguinte argumento. Sabemos que \\phi_{X_{1}}(s) √© diferenci√°vel em zero e que \\phi^{\\prime}_{X_{1}}(0)=E(X_{1}) . Logo, existe s>0 tal que \\phi_{X_{1}}(s)<1+(E(X_{1})+\\tfrac{a}{2})s , donde \\begin{split}P\\Big{[}&\\frac{X_{1}+\\dots+X_{n}}{n}-E(X_{1})\\geq a\\Big{]}\\leq% \\phi_{X_{1}}^{n}(s)\\ex{-s(a+E(X_{1}))n}\\\\ &\\quad\\leq\\big{(}1+(E(X_{1})+\\frac{a}{2})s\\big{)}^{n}\\ex{-s(E(X_{1})+a)n}\\\\ &\\quad\\leq\\exp\\Big{\\{}s\\Big{(}E(X_{1}+\\frac{a}{2}-E(X_{1})-a)n\\Big{)}\\Big{\\}}=% \\ex{-san/2}.\\end{split} Isso nos garante um decaimento exponencial da probabilidade da m√©dia dos X_{i} se desviar da esperan√ßa. {exercise} Aplique o m√©todo acima para vari√°veis X_{i} \\iidcom distribui√ß√£o \\Ber(1/2) e encontre s(a) que otimize o decaimento da probabilidade P\\big{[}\\sum_{i=1}^{n}X_{i}>(1/2+a)n\\big{]} . Poder√≠amos nos perguntar se a cota acima √© suficientemente boa. Talvez pud√©ssemos esperar um decaimento ainda melhor que exponencial. Para responder a essa pergunta, vamos considerar o seguinte exemplo. Sejam (X_{i})_{i\\geq 1} vari√°veis \\iidcom X_{1}\\distr\\Ber(1/2) . Nesse caso temos por exemplo P\\Big{[}\\big{|}\\frac{X_{1}+\\dots+X_{n}}{n}-\\frac{1}{2}\\big{|}\\geq\\frac{1}{4}% \\Big{]}\\geq P[X_{i}=1,\\forall i\\leq n]=2^{-n}. (3.74) Dessa forma, sabemos que n√£o podemos esperar um decaimento melhor que exponencial, mesmo para vari√°veis bem simples (como Bernoulli) que satisfazem \\phi_{X}(s)<\\infty para todo s\\in\\mathbb{R} . Note que para vari√°veis com distribui√ß√£o \\Ber(1/2) , obtivemos acima cotas exponenciais em n (superior e inferior), mas elas possuem expoentes diferentes. Resta agora tentar entender qual √© o expoente correto para o decaimento da probabilidade P[X_{1}+\\dots+X_{n}\\geq n(E(X_{1})+a)] , o que ser√° feito na pr√≥xima se√ß√£o. \\todosec T√≥pico: Processos de ramifica√ß√£ofazer‚Ä¶ Previous page Next page"],[["index.html","Ch3.html","Ch3.S7.html"],"3.7 Princ√≠pio de Grandes Desvios ‚Ä£ Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Princ√≠pio de Grandes Desvios 3.7 Princ√≠pio de Grandes Desvios A primeira tarefa nossa ser√° otimizar a estimativa grosseira feita na se√ß√£o anterior. Essas estimativas s√£o chamadas de estimativas de grandes desvios, pois se referem a probabilidades que a m√©dia emp√≠rica de X_{i} se desvie de sua esperan√ßa por um valor constante a . Futuramente no curso estudaremos as probabilidades de que esse desvio seja de ordem a_{n}\\to 0 que s√£o chamados de desvios moderados ou flutua√ß√µes, dependendo se a probabilidade de desvio converge a zero ou n√£o. {theorem} [Princ√≠pio de Grandes Desvios - cota superior] Consideramos vari√°veis aleat√≥rias \\iid X_{1},X_{2},\\dots tais que \\phi_{X_{1}}(s)<\\infty , para todo s\\in(-\\delta,\\delta) . Ent√£o, para a>0 , P\\big{[}X_{1}+\\dots+X_{n}\\geq\\big{(}m+a\\big{)}n\\big{]}\\leq\\ex{-\\psi_{X_{1}}(m+% a)n}, (3.75) onde m=E(X_{1}) e \\psi_{X_{1}}(x)=\\sup_{s\\geq 0}\\big{\\{}xs-\\log\\big{(}\\phi_{X_{1}}(s)\\big{)}\\big% {\\}} (3.76) √© chamada fun√ß√£o taxa. √â importante observar que para estimar P\\big{[}X_{1}+\\dots+X_{n}\\leq(m-a)n\\big{]} , basta considerarmos X^{\\prime}_{i}=-X_{i} ao utilizar o teorema acima. Demonstra√ß√£o. J√° sabemos que, para todo s\\geq 0 , \\begin{split}P\\big{[}X_{1}&+\\dots+X_{n}\\geq\\big{(}m+a\\big{)}n\\big{]}\\leq\\phi_{% X_{1}}^{n}(s)\\ex{-s(m+a)n}\\\\[2.84526pt] &=\\ex{\\log\\big{(}\\phi_{X_{1}}(s)\\big{)}n-s(m+a)n}\\\\ &=\\ex{-\\big{(}(m+a)s-\\log\\big{(}\\phi_{X_{1}}(s)\\big{)}\\big{)}n}\\\\ \\end{split} (3.77) O que termina a prova do teorema se tomamos o √≠nfimo em s\\geq 0 . ‚àé {exercise} Calcule \\psi_{X}(a) quando X √© distribu√≠da como \\Ber(p) , U_{[0,1]} e \\Exp(\\lambda) . {exercise} Na Nova Caled√¥nia, temos k habitantes. Seja f:\\{1,\\dots,k\\}\\to\\{0,1\\} uma fun√ß√£o que indica a inten√ß√£o de voto de cada cidad√£o. Mais precisamente, para cada habitante i\\in\\{1,\\dots,k\\} , se f(i)=0 , ent√£o i vota no candidato 0 , enquanto se f(i)=1 , o cidad√£o i vota no candidato 1 . Para estimar o n√∫mero k_{1}=\\#f^{-1}(\\{1\\}) de pessoas que votam em 1 , n√≥s escolhemos vari√°veis aleat√≥rias Y_{i} i.i.d. com distribui√ß√£o uniforme em \\{1,\\dots,k\\} e queremos estimar \\text{Err}_{n}(\\epsilon)=P\\Big{[}\\Big{|}\\frac{1}{n}\\sum_{i=1}^{n}f(Y_{i})-% \\frac{k_{1}}{k}\\Big{|}>\\epsilon\\Big{]}. (3.78) Sabendo que k √© par e k_{1}=k/2 , ent√£o ‚ÄÉa)‚Äãuse o m√©todo do segundo momento para obter um n tal que \\text{Err}_{n}(0.01)<0.02 e um n tal que \\text{Err}_{n}(0.01)<10^{-12} , ‚ÄÉb)‚Äãuse o m√©todo do momento exponencial para obter resolver o √≠tem acima. Compare os quatro resultados obtidos acima. Vamos agora tomar um exemplo concreto para an√°lise. Sejam X_{1},X_{2},\\dots vari√°veis aleat√≥rias \\iidcom distribui√ß√£o \\Ber(1/2) , donde \\phi_{X_{1}}(s)=\\frac{1}{2}(1+e^{s})\\quad\\text{e}\\quad\\psi_{X_{1}}(x)=\\sup_{s% \\geq 0}\\{xs-\\log(1+e^{s})+\\log(2)\\}. (3.79) Um c√°lculo simples nos mostra que, se x<1 , o m√≠nimo acima √© atingido no √∫nico ponto s_{\\text{max}}=\\log(\\tfrac{x}{1-x}) . Portanto, podemos concluir do Teorema¬†3.7 que \\begin{split}P[X_{1}+\\dots&+X_{n}>1/2+a]\\leq\\ex{-\\psi_{X_{1}}(s_{\\text{max}})n% }\\\\ &=\\exp\\Big{\\{}-n\\Big{(}b\\log(b)+(1-b)\\log(1-b)+\\log(2)\\Big{)}\\Big{\\}}\\end{split} (3.80) Note que P[X_{1}+\\dots+X_{n}=n]=2^{-n}=\\ex{-\\log(2)n}=\\ex{-\\psi_{X_{1}}(1-)n} . Isso nos d√° um forte ind√≠cio de que talvez nossas cotas superiores n√£o estejam t√£o longe de ser precisas. Para confirmar essa hip√≥tese, precisamos obter cotas inferiores parecidas. b 1 \\log(2) 0 \\psi_{X}(b) b 1 0 \\psi_{X^{\\prime}}(b) \\log(4/3) \\log(4) Figura 3.1: Fun√ß√µes taxa \\psi_{X}(b) de uma vari√°vel X com distribui√ß√£o \\Ber(1/2) , e \\psi_{X^{\\prime}}(b) de uma vari√°vel com distribui√ß√£o \\Ber(3/4) , para b\\in(0,1) . Antes de buscar cotas inferiores para as probabilidades de desvio, vamos estabelecer algumas propriedades da fun√ß√£o \\psi_{X}(b) . Primeiramente, quando podemos dizer que o supremo na defini√ß√£o de \\psi_{X} √© atingido em algum s_{\\text{max}} ? Certamente, esse nem sempre √© o caso, por exemplo se X=m quase certamente, ent√£o \\phi_{X}(s)=e^{sm} e o supremo definindo \\psi_{X}(b) n√£o √© atingido se b\\neq m . {lemma} Seja X uma vari√°vel aleat√≥ria tal que \\phi_{X}(s)<\\infty para todo s\\in(-\\delta,\\delta) . Supondo a\\geq 0 √© tal que P[X>m+a]>0 , ent√£o existe s_{\\text{max}}\\geq 0 tal que \\psi_{X}(m+a)=(m+a)s_{\\text{max}}-\\log\\big{(}\\phi_{X}(s_{\\text{max}})\\big{)}. (3.81) Demonstra√ß√£o. Por hip√≥tese, existe x>m+a tal que p=P[X\\geq x]>0 , donde \\phi_{X}(s)\\geq pe^{s(m+a)} . Dessa forma, (m+a)s-\\log\\big{(}\\phi_{X}(s)\\big{)}\\leq(m+a-x)s-\\log(p) , que converge a menos infinito quando s diverge. Isso, junto com a continuidade de \\phi_{X} implica a exist√™ncia do s_{\\text{max}} desejado. ‚àé {lemma} Seja X uma vari√°vel aleat√≥ria tal que \\phi_{X}(s)<\\infty para todo s\\in(-\\delta,\\delta) . Ent√£o o conjunto onde a fun√ß√£o \\psi_{X}(s) √© finita √© um intervalo, na qual \\psi_{X} √© convexa e portanto cont√≠nua. Demonstra√ß√£o. Primeiramente, supomos que a<b s√£o tais que \\psi_{X}(a) e \\psi_{X}(b) s√£o finitas. Logo, para todo c\\in(a,b) , temos que a fun√ß√£o linear cs √© menor ou igual a as\\vee bs , da√≠ \\begin{split}\\psi_{X}(c)&=\\sup_{s\\geq 0}\\{cs-\\log(\\phi_{X}(s))\\}\\leq\\sup_{s% \\geq 0}\\{(as\\vee bs)-\\log(\\phi_{X}(s))\\}\\\\ &\\leq\\sup_{s\\geq 0}\\{as-\\log(\\phi_{X}(s))\\}\\vee\\sup_{s\\geq 0}\\{bs-\\log(\\phi_{X% }(s))\\}<\\infty.\\end{split} (3.82) Para mostrar que \\psi_{X} √© convexa, observe que \\psi_{X}(x) √© dada pelo supremo (para s\\geq 0 ) das fun√ß√µes afins x\\mapsto xs-\\psi_{X}(s) . Como o supremo de fun√ß√µes convexas √© tamb√©m convexo, obtemos o enunciado do lemma. ‚àé {exercise} Suponha que se \\phi_{X}(s) √© finita para todo s\\in(-\\delta,\\delta) e mostre que ‚ÄÉa)‚Äãna defini√ß√£o de \\psi_{X}(a) , poder√≠amos tomar o √≠nfimo em todos s\\in\\mathbb{R} (ao inv√©z de s\\geq 0 ) sem mudar o valor de \\psi_{X}(a) , ‚ÄÉb)‚Äãa fun√ß√£o \\psi_{X}(s) √© n√£o negativa, semi-cont√≠nua inferior e convexa em seu dom√≠nio ‚ÄÉc)‚Äã \\psi_{X}(a) se anula somente em a=0 e \\psi_{X} √© crescente no seu dom√≠nio. Buscaremos agora cotas inferiores para a probabilidade de obter um grande desvio. Gostar√≠amos que essas estimativas fossem o mais pr√≥ximas poss√≠veis das estimativas superiores obtidas acima. Certamente n√£o podemos obter algo como ``P\\big{[}X_{1}+\\dots+X_{n}\\geq\\big{(}m+a\\big{)}n\\big{]}\\geq\\exp\\{-\\psi_{X_{1}% }(a)n\\}\", (3.83) pois sen√£o isso nos daria uma igualdade o que √© imposs√≠vel, pois perdemos um pouco de precis√£o ao utilizar a desigualdade de Markov na cota superior. Contudo, gostar√≠amos de entender se ao menos o expoente \\psi_{X_{1}}(a) na cota superior tamb√©m possui algum papel na cota inferior. Isso √© confirmado no seguinte resultado. {theorem} [Princ√≠pio de Grandes Desvios - cota inferior] Sejam X_{1},X_{2},\\dots vari√°veis aleat√≥rias \\iidcom \\phi_{X_{1}}(s)<\\infty , para todo s\\in\\mathbb{R} . Ent√£o, para todo a>0 , \\liminf_{n\\to\\infty}\\frac{1}{n}\\log P\\big{[}X_{1}+\\dots+X_{n}\\geq\\big{(}m+a% \\big{)}n\\big{]}\\geq-\\psi_{X_{1}}(m+a), (3.84) onde novamente m=E(X_{1}) e \\psi_{X_{1}}(x) √© definida como no Teorema¬†3.7. Note que o resultado do teorema acima √© mais fraco que o que vemos na equa√ß√£o (3.83), mas mostra que \\psi_{X_{1}}(a) √© realmente o expoente correto no decaimento da probabilidade de grandes desvios. Um corol√°rio dos Teoremas¬†3.7 e 3.1 √© o seguinte {corollary} Se X_{1},X_{2},\\dots vari√°veis aleat√≥rias \\iidcom \\phi_{X_{1}}(s)<\\infty , para todo s\\in\\mathbb{R} , ent√£o \\lim_{n\\to\\infty}\\frac{1}{n}\\log P\\big{[}X_{1}+\\dots+X_{n}\\geq\\big{(}m+a\\big{)% }n\\big{]}=-\\psi_{X_{1}}(m+a). (3.85) A id√©ia da prova √© transformar a distribui√ß√£o de X_{i} , usando uma exponencial como derivada de Radon-Nikodim. Essa nova distribui√ß√£o possuir√° esperan√ßa maior que m+a , de forma que se tomamos a m√©dia de vari√°veis \\iid X^{\\prime}_{1},\\dots,X^{\\prime}_{n} distribu√≠das dessa forma, obteremos algo que se concentra acima de m+a . Finalmente, o pre√ßo pago para que as vari√°veis X_{i} se comportem como as X^{\\prime}_{i} ser√° aproximadamente \\exp\\{-\\psi_{X_{1}}(m+a)\\} , como desejado para nossa cota inferior. Demonstra√ß√£o. Primeiramente, consideraremos o caso P[X_{1}\\leq m+a]=1 , que se assemelha ao caso que analizamos acima (\\Ber(1/2)\\leq 1) . Nesse caso, temos \\begin{split}P\\big{[}X_{1}+\\dots+X_{n}\\geq\\big{(}m+a\\big{)}n\\big{]}&=P[X_{i}=m% +a,\\text{ para todo $i\\leq n$}]\\\\ &=P[X_{1}=m+a]^{n}.\\end{split} Donde o limite acima √© igual a \\log(P[X_{1}=m+a]) . Mas por outro lado, \\begin{split}-\\psi_{X_{1}}(m+a)&=\\inf_{s\\geq 0}\\big{\\{}\\log\\big{(}E(\\ex{s(X_{1% })})\\big{)}-(m+a)s\\big{\\}}=\\inf_{s\\geq 0}\\big{\\{}\\log\\big{(}E(\\ex{s(X_{1}-m-a)% })\\big{)}\\big{\\}}\\\\ &\\leq\\liminf_{s\\to\\infty}\\;\\log\\big{(}E(\\ex{s(X_{1}-m-a)})\\big{)}=\\log\\big{(}P% [X_{1}=m+a]\\big{)},\\end{split} pelo Teorema da Converg√™ncia Dominada, demonstrando o teorema nesse caso especial. Suponhamos agora que P[X_{1}>m+a]>0 , o que implica que para b>m+a suficientemente pr√≥ximo de m+a , temos P[X_{1}>b]>0 . Observe que basta mostrar que para todo b>a satisfazendo P[X_{1}>b]>0 e para todo \\delta>0 , temos \\liminf_{n}\\frac{1}{n}\\log\\Big{(}P\\Big{[}\\frac{X_{1}+\\dots+X_{n}}{n}\\in(b-% \\delta,b+\\delta)\\Big{]}\\Big{)}\\geq-\\psi_{X_{1}}(b), (3.86) pois a fun√ß√£o \\psi_{X_{1}}(x) √© convexa, portanto cont√≠nua. Vamos definir uma nova distribui√ß√£o \\nu com derivada de Radon-Nikodim \\frac{\\d{\\nu}}{\\d{P}_{X_{1}}}=\\frac{1}{Z_{\\sigma}}\\ex{\\sigma x}. (3.87) Observamos primeiramente que o valor de \\sigma ainda n√£o foi escolhido. Al√©m disso ap√≥s escolhido \\sigma , teremos que calcular a constante de normaliza√ß√£o Z_{\\sigma} de forma que \\nu seja uma probabilidade. Escolheremos \\sigma\\geq 0 como no Lema¬†3.7, isto √©, tal que \\psi_{X_{1}}(b)=b\\sigma-\\log\\big{(}\\phi_{X_{1}}(\\sigma)\\big{)} . Isso nos d√° imediatamente que Z_{\\sigma}=E[\\ex{\\sigma X_{1}}]=\\phi_{X_{1}}(\\sigma) por defini√ß√£o. Por diferenciabilidade de \\phi_{X_{1}} , o m√°ximo deve ser assumido em um ponto de derivada zero para a fun√ß√£o \\psi_{X_{1}} , ou seja b=\\frac{\\phi_{X_{1}}^{\\prime}(\\sigma)}{\\phi_{X_{1}}(\\sigma)}\\overset{\\text{% Prop.\\leavevmode\\nobreak\\ \\ref{p:propried_phi}}}{=}\\frac{E(X\\ex{\\sigma X})}{E(% \\ex{\\sigma X})}=\\frac{E(X\\ex{\\sigma X})}{Z_{\\sigma}}=\\int x\\nu(\\d{x}). (3.88) Isso implica que se uma vari√°vel aleat√≥ria tem distribui√ß√£o \\nu , sua esperan√ßa √© b . √â poss√≠vel verificar que uma tal vari√°vel aleat√≥ria X^{\\prime} satisfaz obrigatoriamente \\phi_{X^{\\prime}}(s)<\\infty para todo s\\geq 0 , donde X^{\\prime}\\in\\mathcal{L}^{p} para todo p>1 . Como prometido, consideramos vari√°veis X_{1}^{\\prime},X_{2}^{\\prime},\\dots \\iidcom distribui√ß√£o \\nu . Pela lei fraca dos grandes n√∫meros, para qualquer \\delta>0 , \\lim_{n}P\\Big{[}\\frac{X_{1}^{\\prime}+\\dots+X_{n}^{\\prime}}{n}\\in(b-\\delta,b+% \\delta)\\Big{]}=1. (3.89) Finalmente vamos relacionar essa probabilidade √† probabilidade definida em termos de X_{i} , na qual estamos interessados. \\begin{split}P\\Big{[}&\\frac{X_{1}+\\dots+X_{n}}{n}\\in(b-\\delta,b+\\delta)\\Big{]}% =\\int_{x_{i};\\big{|}\\tfrac{1}{n}\\sum_{i\\leq n}x_{i}-b\\big{|}<\\delta}\\;\\;% \\bigotimes_{i=1}^{n}(X_{1}\\circ P)(\\d{x}_{i})\\\\ &=Z_{\\sigma}^{n}\\int_{x_{i};\\big{|}\\tfrac{1}{n}\\sum_{i\\leq n}x_{i}-b\\big{|}<% \\delta}\\;\\;\\ex{-\\sigma\\textstyle{\\sum_{i=1}^{n}x_{i}}}\\bigotimes_{i=1}^{n}(X_{% 1}^{\\prime}\\circ P)(\\d{x}_{i})\\\\[5.69054pt] &\\geq Z_{\\sigma}^{n}\\exp\\{-(b+\\delta)\\sigma n\\}P\\Big{[}\\frac{X_{1}^{\\prime}+% \\dots+X_{n}^{\\prime}}{n}\\in(b-\\delta,b+\\delta)\\Big{]}.\\end{split} Tomando o logar√≠tmo, dividindo por n e tomando o liminf quando n vai a infinito, recuperamos \\begin{split}\\lim_{n}\\frac{1}{n}\\log\\Big{(}P\\Big{[}&\\frac{X_{1}+\\dots+X_{n}}{n% }\\in(b-\\delta,b+\\delta)\\Big{]}\\Big{)}\\geq\\log(Z_{\\sigma})-(b+\\delta)\\sigma\\\\ &=\\log(\\phi_{X_{1}}(\\sigma))-(b+\\delta)\\sigma=-\\psi_{X_{1}}(\\sigma)-\\delta% \\sigma.\\end{split} (3.90) Como isso vale para todo \\delta>0 , provamos (3.86) o que conclui a prova do teorema. ‚àé {exercise} Mostre o Teorema¬†3.1 no caso em que \\phi_{X_{1}}(s)<\\infty , para todo s\\in(-\\delta,\\delta) . Previous page Next page"],[["index.html","Ch3.html","Ch3.S8.html"],"3.8 O Teorema Central do Limite ‚Ä£ Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. O Teorema Central do Limite 3.8 O Teorema Central do Limite At√© o presente momento, j√° sabemos por exemplo que m√©dias de vari√°veis aleat√≥rias \\iid, suficientemente regulares convergem para sua esperan√ßa quase certamente. Vamos fazer contudo um experimento para visualizar esse fen√¥meno. Nesse experimento, jogamos 100 moedas e contamos quantas caras obtivemos. Pelo que discutimos anteriormente, esperamos que esse n√∫mero se encontre por volta de 50 , que √© a esperan√ßa desta soma de vari√°veis \\iid. Vamos portanto repetir esse experimento mil vezes e observar quantas vezes obtemos algo pr√≥ximo de 50 , veja Figura¬†3.2. 10 20 30 40 50 60 70 50 100 150 200 250 300 Figura 3.2: V√°rios ensaios de uma vari√°vel \\Bin(100,0.5) , pra ser mais preciso 1000 ensaios. Cada barra representa o n√∫mero de ensaios que ca√≠ram no intervalo determinado pela base da barra. Note que apesar dos experimentos se concentrarem em torno da m√©dia, alguns se afastam um pouco (obviamente pois o experimento √© aleat√≥rio). Nessa se√ß√£o estudaremos esses desvios espont√¢neos, que s√£o chamados de flutua√ß√£oes. Nosso objetivo nessa se√ß√£o ser√° obter qual √© o tamanho t√≠pico das flutua√ß√µes em torno da m√©dia dessa soma de vari√°veis aleat√≥rias. Ao contr√°rio do que fizemos ao estudar Grandes Desvios, n√≥s agora estamos buscando flutua√ß√µes menores, que acontecem espontaneamente e n√£o com baixa probabilidade. Note tamb√©m que apesar de observarmos uma aleatoriedade na Figura¬†3.2, tamb√©m notamos uma certa regularidade que muitas vezes √© chamada de ‚Äôforma de sino‚Äô no histograma apresentado. 3.8.1 A distribui√ß√£o normal Come√ßaremos estudando qual poderia ser uma poss√≠vel forma limite para o histograma da Figura¬†3.2. Como uma primeira tentativa, suponha que \\sum_{i=1}^{\\infty}Z_{i} possui uma certa distribui√ß√£o \\mu (veremos posteriormente que isso somente pode acontecer em casos triviais). Mas se esse fosse o caso, poder√≠amos dividir a soma nos termos pares e √≠mpares X=\\sum_{i\\text{ par}}Z_{i} e Y=\\sum_{i\\text{ \\'{\\i}mpar}}Z_{i} . Nesse caso ter√≠amos X e Y independentes e tamb√©m distribu√≠dos como \\mu (pois s√£o dados por uma soma que tem a mesma distribui√ß√£o daquela que define \\mu ). O seguinte lema mostra que isso somente pode acontecer na situa√ß√£o trivial em que \\mu=\\delta_{0} . {lemma} Sejam X e Y vari√°veis aleat√≥rias em \\mathcal{L}^{2} , \\iidcom distribui√ß√£o \\mu . Nesse caso, se X+Y tamb√©m tem distribui√ß√£o \\mu , ent√£o \\mu=\\delta_{0} . Demonstra√ß√£o. Sabemos que \\begin{split}E(X+Y)&=E(X)+E(Y)=2E(X)\\text{ e}\\\\ \\Var(X+Y)&=\\Var(X)+\\Var(Y)=2\\Var(X).\\end{split} (3.95) Mas como X+Y tem a mesma distribui√ß√£o de X , ent√£o E(X)=2E(X) e \\Var(X)=2\\Var(X) , donde ambas s√£o zero. Usando o m√©todo dos segundo momento, para todo a>0 , P[|X|\\geq a]\\leq\\frac{\\Var(X)}{a^{2}}=0, (3.96) terminando a prova de que X=0 quase certamente. ‚àé A intui√ß√£o dessa prova √© que quando somamos duas vari√°veis n√£o determin√≠sticas, a incerteza da soma (medida atrav√©s da vari√¢ncia) tende a aumentar. Dessa forma n√£o podemos obter a mesma distribui√ß√£o ap√≥s a soma. Mas existe uma maneira simples de tornar esse problema interessante novamente. Digamos que X e Y pertencem a \\mathcal{L}^{2} e s√£o i.i.d. Ent√£o \\Var\\Big{(}\\frac{X+Y}{\\sqrt{2}}\\Big{)}=2\\Var\\Big{(}\\frac{X}{\\sqrt{2}}\\Big{)}=% \\Var(X). (3.97) Ent√£o podemos nos perguntar se {question} Existe alguma distribui√ß√£o n√£o trivial \\mu em \\mathcal{L}^{2} tal que, se X e Y s√£o independentes e distribu√≠das de acordo com \\mu , temos \\frac{X+Y}{\\sqrt{2}}\\distr\\mu\\;? (3.98) Pelo menos sabemos agora que a vari√¢ncia n√£o se altera atrav√©s dessa opera√ß√£o. Ou em outras palavras, queremos saber se existe algum ponto fixo para o operador \\Gamma que toma uma distribui√ß√£o \\mu em \\mathbb{R} e retorna \\Gamma(\\mu)=\\Big{(}\\frac{X_{1}+X_{2}}{\\sqrt{2}}\\Big{)}\\circ\\mu\\otimes\\mu. (3.99) Para tentar responder a essa quest√£o, vamos estudar mais a fundo qual √© a distribui√ß√£o da soma de duas vari√°veis aleat√≥rias independentes. Para isso, considere a distribui√ß√£o (X,Y)\\circ P do par, que coincide com \\mu\\otimes\\mu , nos dando P\\Big{[}\\frac{X+Y}{\\sqrt{2}}\\leq z\\Big{]}=\\mu\\otimes\\mu\\big{(}\\big{\\{}(x,y);% \\tfrac{x+y}{\\sqrt{2}}\\leq z\\big{\\}}\\big{)}. (3.100) Note tamb√©m que a transforma√ß√£o linear (x,y)\\mapsto\\tfrac{1}{\\sqrt{2}}\\big{(}x+y,x-y\\big{)} √© uma rota√ß√£o r√≠gida em \\mathbb{R}^{2} , o que nos motiva a propor a pergunta mais simples. {question} Existe alguma distribui√ß√£o n√£o trivial \\mu em \\mathcal{L}^{2} tal que, se X e Y s√£o independentes e distribu√≠das de acordo com \\mu , a distribui√ß√£o do par (X,Y) √© invariante por rota√ß√µes? Ainda estamos numa busca n√£o rigorosa de tal distribui√ß√£o, ent√£o vamos supor algumas outras propriedades, como por exemplo que \\mu seja absolutamente cont√≠nua com respeito a Lebesgue, isto √© \\d{\\mu}=f(x)\\d{x} . Nesse caso, j√° vimos que (X,Y)\\distr f(x)f(y)\\d{x}\\d{y} e no fundo estamos procurando uma fun√ß√£o f tal que f(x)f(y)=h(x^{2}+y^{2}),\\text{ para todo $x,y\\in\\mathbb{R}$ e alguma $h:% \\mathbb{R}_{+}\\to\\mathbb{R}_{+}$.} (3.101) Para trasformar o produto f(x)f(y) em uma soma, definimos g=\\log f e k=\\log h e o que gostar√≠amos que acontecesse √© g(x)+g(y)=k(x^{2}+y^{2}) . Como ainda n√£o estamos preocupados com unicidade de \\mu e apenas com a exist√™ncia, j√° podemos encontrar nossa resposta para nossa pergunta, escolhendo uma fun√ß√£o quadr√°tica, tal como g(x)=\\alpha x^{2}-\\beta . Mas temos ainda que cuidar para que f(x)=\\ex{\\alpha x^{2}-\\beta} seja uma densidade, ou seja \\int f\\d{x}=1 . Para isso, precisamos que \\alpha seja negativo e, fixado \\alpha , o valor de \\beta j√° estar√° determinado por normaliza√ß√£o. Tudo isso motiva finalmente a seguinte defini√ß√£o. {definition} Dizemos que X tem distibui√ß√£o normal can√¥nica, se X\\distr\\frac{1}{\\sqrt{2\\pi}}\\exp\\big{\\{}-x^{2}/2\\big{\\}}\\d{x}. (3.102) Al√©m disso, para m\\in\\mathbb{R} e \\sigma\\geq 0 , dizemos que Y\\distr\\mathcal{N}(m,\\sigma^{2}) se Y tem a mesma distribui√ß√£o de \\sigma X+m , onde X tem distribui√ß√£o normal can√¥nica \\mathcal{N}(0,1) . Note que \\mathcal{N}(m,0)=\\delta_{m} . Muitas vezes chamamos essa distribui√ß√£o de gaussiana, obviamente em homenagem a Gauss. Vamos rapidamente observar que a defini√ß√£o acima realmente descreve uma distribui√ß√£o de probabilidade, ou seja que a integral dessa densidade √© um. Para tanto, vamos usar um truque conhecido, que consiste em retornar ao plano. Obviamente, \\begin{split}\\Big{(}\\int\\exp\\big{\\{}-x^{2}/2\\big{\\}}\\d{x}\\Big{)}^{2}&=\\int\\int% \\exp\\big{\\{}-(x^{2}+y^{2})/2\\big{\\}}\\d{x}\\d{y}\\\\ &=\\int_{0}^{2\\pi}\\int_{0}^{\\infty}\\exp\\{-r^{2}/2\\}r\\d{r}\\d{\\theta}\\overset{2s% \\;=\\;r^{2}}{=}2\\pi.\\end{split} (3.103) Donde a constante em (3.102) est√° de fato correta. {exercise} Mostre que a distribui√ß√£o \\mathcal{N}(m,\\sigma^{2}) , tem densidade \\frac{1}{\\sigma\\sqrt{2\\pi}}\\ex{-(x-m)^{2}/(2\\sigma^{2})}. (3.104) {exercise} Mostre que Y\\distr\\mathcal{N}(m,\\sigma^{2}) tem esperan√ßa m e vari√¢ncia \\sigma^{2} . Para confirmar que de fato as distribui√ß√µes normais se comportam bem com respeito a somas independentes, apresentamos o seguinte resultado. {proposition} Se X\\distr\\mathcal{N}(m,\\sigma^{2}) e Y\\distr\\mathcal{N}(\\bar{m},\\bar{\\sigma}^{2}) s√£o independentes, ent√£o X+Y tem distribui√ß√£o \\mathcal{N}(m+\\bar{m},\\sigma^{2}+\\bar{\\sigma}^{2}) . Em particular, \\mu √© um ponto fixo do operador \\Gamma definido em (3.99). Demonstra√ß√£o. O caso em que \\sigma ou \\bar{\\sigma} se anulam √© trivial, portanto vamos considerar que ambas s√£o positivas. N√£o √© dif√≠cil ver que podemos tamb√©m supor que m=\\bar{m}=0 . Podemos ent√£o calcular P[X+Y\\leq a]=P[\\sigma W+\\bar{\\sigma}Z\\leq a], (3.105) onde W e Z s√£o independentes com distribui√ß√£o \\mathcal{N}(0,1) . Assim, a probabilidade acima pode ser escrita como \\mathcal{N}(0,1)\\otimes\\mathcal{N}(0,1)\\Big{(}\\big{\\{}(w,z)\\in\\mathbb{R}^{2};% \\sigma w+\\bar{\\sigma}z\\leq a\\big{\\}}\\Big{)}. (3.106) Agora aplicaremos a rota√ß√£o r√≠gida A:\\mathbb{R}^{2}\\to\\mathbb{R}^{2} dada por A(w,z)=\\frac{1}{\\sqrt{\\sigma^{2}+\\bar{\\sigma}^{2}}}\\big{(}\\sigma w+\\bar{\\sigma% }z,\\bar{\\sigma}w-\\sigma z\\big{)}. (3.107) Como sabemos que a densidade f de (W,Z) √© invariante por A , ou seja f\\circ A=f , ent√£o podemos escrever (3.106) como \\begin{split}\\mathcal{N}(0,1)&\\otimes\\mathcal{N}(0,1)\\Big{(}A\\big{(}\\big{\\{}(w% ,z)\\in\\mathbb{R}^{2};\\sigma w+\\bar{\\sigma}z\\leq a\\big{\\}}\\big{)}\\Big{)}\\\\ &=\\mathcal{N}(0,1)\\otimes\\mathcal{N}(0,1)\\Big{(}\\Big{\\{}(w,z);\\frac{1}{\\sqrt{% \\sigma^{2}+\\bar{\\sigma}^{2}}}w\\leq a\\Big{\\}}\\Big{)}\\\\ &=\\mathcal{N}(0,1)\\big{(}(-\\infty,a\\sqrt{\\sigma^{2}+\\bar{\\sigma}^{2}}\\big{]}% \\big{)}=\\mathcal{N}(0,\\sigma^{2}+\\bar{\\sigma}^{2})\\big{(}(-\\infty,a\\big{]}\\big% {)},\\end{split} terminando a prova da proposi√ß√£o. ‚àé Podemos obter um corol√°rio interessante sobre a soma de normais i.i.d. {corollary} Sejam X_{1},X_{2},\\dots vari√°veis \\iidcom distribui√ß√£o \\mathcal{N}(m,\\sigma^{2}) , ent√£o X_{1}+\\dots+X_{n}\\distr\\mathcal{N}(nm,n\\sigma^{2}). (3.108) Como consequ√™ncia \\frac{\\sum_{i=1}^{n}X_{i}-nE(X_{1})}{\\sigma\\sqrt{n}}\\distr\\mathcal{N}(0,1). (3.109) Lembrando da Lei dos Grandes N√∫meros, se dividimos a soma dos X_{i}-E(X_{i}) por n , essa fra√ß√£o vai a zero quase certamente. O que conclu√≠mos acima √© que ao dividir por \\sqrt{n} obtemos um limite n√£o trivial (nem zero, nem infinito) e aleat√≥rio (n√£o determin√≠stico). Mais uma observa√ß√£o curiosa: nossa motiva√ß√£o para a defini√ß√£o da distribui√ß√£o normal passou por invari√¢ncia por rota√ß√µes e podemos extender essa invari√¢ncia para n normais independentes. Note que somar as coordenadas can√¥nicas √© equivalente a tomar o produdo escalar com o vetor (1,1,\\dots,1) , que tem norma euclideana \\sqrt{n} . Uma outra maneira de entender o corol√°rio acima √© que a normal √© um ponto fixo da opera√ß√£o seguinte ‚ÄÉa)‚Äãtome uma distribui√ß√£o \\mu\\in\\mathcal{L}^{2} , ‚ÄÉb)‚Äãconsidere X_{1},\\dots,X_{n} \\iidcom distribui√ß√£o \\mu e ‚ÄÉc)‚Äãretorne a distribui√ß√£o de \\frac{X_{1}+\\dots+X_{n}-nE(X_{1})}{\\sqrt{n}}. (3.110) Na Quest√£o¬†3.8.1, nos perguntamos quais seriam os outros poss√≠veis pontos fixos de \\Gamma e isso ser√° considerado depois. Mas uma outra quest√£o bastante importante √© se o ponto fixo \\mathcal{N}(0,1) √© atrator, ou seja se come√ßando com outras distribui√ß√µes poder√≠amos nos aproximar de \\mathcal{N}(0,1) √† medida que iteramos \\Gamma . Isso √© estudado no Teorema Central do Limite (TCL) que provaremos posteriormente. Mas antes, precisamos desenvolver uma boa defini√ß√£o de converg√™ncia para distribui√ß√µes, ou em outras palavras definir uma topologia. Esse ser√° o nosso pr√≥ximo t√≥pico. 3.8.2 Converg√™ncia fraca Em muitos casos √© importante termos bem definida uma no√ß√£o de converg√™ncia de medidas de probabilidade. Supondo por exemplo no espa√ßo mensur√°vel (E,\\mathcal{A}) , tenhamos uma sequ√™ncia de probabilidades \\mu_{n} e gostar√≠amos de saber se ela converge a uma determinada \\mu . Um candidato natural para dara sentido a essa converg√™ncia poderia se a dist√¢ncia de varia√ß√£o total entre duas medidas d_{\\VT}(\\mu,\\nu)=\\sup_{A\\in\\mathcal{A}}|\\mu(A)-\\nu(A)|. (3.111) N√£o √© dif√≠cil mostrar que a defini√ß√£o acima induz uma m√©trica, mas ela possui alguns problemas que descreveremos a seguir. {exercise} Mostre que d_{\\VT} define uma m√©trica. {exercise} Sejam \\mu e \\nu absolutamente cont√≠nuas com respeito a uma medida fixa \\eta , tendo densidades \\rho e \\pi respectivamente. Encontre uma f√≥rmula para d_{\\VT}(\\mu,\\nu) em termos das densidades. Essa f√≥rmula nos remete a qual dist√¢ncia entre fun√ß√µes? Digamos que o espa√ßo amostral E j√° seja provido de uma m√©trica d e \\mathcal{A} seja a \\sigma -√°lgebra dos borelianos em E . Qualquer que seja a no√ß√£o de converg√™ncia que iremos considerar, gostar√≠amos de dizer que \\delta_{x_{n}} converge a \\delta_{x} sempre que x_{n}\\to x em E . Esse por√©m n√£o √© o caso para d_{\\VT} , pois se x_{n}\\neq x para todo n e \\{x\\}\\in\\mathcal{A} , ter√≠amos d_{\\VT}(\\delta_{x_{n}},\\delta_{x})\\geq|\\delta_{x_{n}}(\\{x\\})-\\delta_{x}(\\{x\\})% |=|0-1|=1. (3.112) Aqueles que j√° viram o conceito de converg√™ncia fraca achar√£o natural que a converg√™ncia de \\mu_{n} para \\mu seja definida em termos da converg√™ncia das integrais \\int f\\d{\\mu}_{n} para \\int f\\d{\\mu} . Por√©m, como mencionamos no exemplo das medidas \\delta_{x_{n}} acima, gostar√≠amos tamb√©m de a converg√™ncia respeitasse a topologia original do espa√ßo E , o que torna natural o seguinte conceito. {definition} Dizemos que uma sequ√™ncia de medidas de probabilidade \\mu_{n} converge fracamente (ou converge em distribui√ß√£o) para uma probabilidade \\mu se \\lim_{n\\to\\infty}\\int f\\d{\\mu}_{n}=\\int f\\d{\\mu},\\text{ para toda $f:E\\to% \\mathbb{R}$ cont\\'{\\i}nua e limitada.} (3.113) Essa converg√™ncia muitas vezes √© denotada por \\mu_{n}\\Rightarrow\\mu . Essa defini√ß√£o fica ainda mais natural para aqueles que conhecem o Teorema da Representa√ß√£o de Riesz. Com isso em mente, podemos relacionar a converg√™ncia em distribui√ß√£o com a converg√™ncia fraca- \\star no espa√ßo de medidas finitas. {exercise} Mostre que em (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) , temos que \\tfrac{1}{n}\\sum_{i=1}^{n}\\delta_{i/n}\\Rightarrow U_{[0,1]} . {exercise} Considere a fun√ß√£o \\phi do espa√ßo de medidas em ([0,1],\\mathcal{B}([0,1])) nele mesmo, dada por: \\phi(\\mu)(A)=\\tfrac{1}{2}\\big{(}\\mu(3A)+\\mu(3A-2)\\big{)}. (3.114) Identifique o limite em distribui√ß√£o de \\phi^{(n)}(\\delta_{0}) . Mostre que ‚ÄÉa)‚Äãa fun√ß√£o de distribui√ß√£o acumulada associada ao limite √© cont√≠nua, ‚ÄÉb)‚Äão limite n√£o √© absolutamente cont√≠nuo com respeito √† medida de Lebesgue. {exercise} Sejam X_{1},X_{2},\\dots i.i.d. distribuidas como \\text{Exp}(1) e defina M_{n}=\\max_{i=1,\\dots,n}X_{i}. (3.115) Mostre que M_{n}-\\log(n) converge fracamente e identifique o limite. Observe que n√£o precisamos dividir M_{n}-\\log(n) por nada para obter a converg√™ncia. N√≥s algumas vezes denotamos X_{n}\\Rightarrow X quando X_{n} e X s√£o elementos aleat√≥rios de (\\Omega,\\mathcal{F},P) para descrever a converg√™ncia fraca de suas respectivas distribui√ß√µes. Mais precisamente, X_{n}\\circ P\\Rightarrow X\\circ P . 3.8.3 Converg√™ncia fraca em \\mathbb{R} No caso especial em que E=\\mathbb{R} , temos v√°rios outras maneiras de caracterizar converg√™ncia em distribui√ß√£o. A primeira √© dada pela seguinte {proposition} Se \\int g\\d{\\mu}_{n} converge para \\int g\\d{\\mu} para toda g\\in C^{3} limitada e com as tr√™s primeiras derivadas limitadas, ent√£o \\mu_{n}\\Rightarrow\\mu . Demonstra√ß√£o. Primeiramente, vamos ver que podemos nos concentrar em um conjunto compacto da reta. Para isso fixe um \\varepsilon>0 e tome M^{\\prime} tal que \\mu\\big{(}[-M^{\\prime},M^{\\prime}]\\big{)}>1-\\varepsilon/3 . Tomando uma fun√ß√£o g satisfazendo as hip√≥teses do teorema e tal que \\1{[-M^{\\prime},M^{\\prime}]}\\leq g\\leq\\1{[-M^{\\prime}-1,M^{\\prime}+1]}, (3.116) concluimos que \\mu_{n}\\big{(}[-M^{\\prime}-1,M^{\\prime}+1]\\big{)}\\geq 1-\\varepsilon/2, (3.117) para todo n suficientemente grande. Se tomamos M\\geq M^{\\prime} suficientemente grande, podemos obter a cota acima para todo n (com M no lugar de M^{\\prime}+1 e \\varepsilon no lugar de \\varepsilon/2 ). Fixamos agora uma f:\\mathbb{R}\\to\\mathbb{R} cont√≠nua e limitada. Sabemos que √© poss√≠vel aproximar f por uma fun√ß√£o g\\in C^{3} de suporte compacto, com \\lVert g\\rVert_{\\infty}\\leq 2\\lVert f\\rVert_{\\infty} e |g-f|\\leq\\varepsilon/M uniformemente no intervalo [-M,M] . Essa g certamente satisfaz as hip√≥teses do teorema. Portanto, \\begin{split}\\Big{|}\\int f\\d{\\mu}_{n}-\\int f\\d{\\mu}\\Big{|}&\\leq 2\\varepsilon% \\lVert f\\rVert_{\\infty}+\\Big{|}\\int_{-M}^{M}f\\d{\\mu}_{n}-\\int_{-M}^{M}f\\d{\\mu}% \\Big{|}\\\\ &\\leq 2\\varepsilon\\lVert f\\rVert_{\\infty}+\\frac{\\varepsilon}{M}2M+\\Big{|}\\int_% {-M}^{M}g\\d{\\mu}_{n}-\\int_{-M}^{M}g\\d{\\mu}\\Big{|}\\\\ &\\leq 2\\varepsilon\\lVert f\\rVert_{\\infty}+2\\varepsilon+\\Big{|}\\int g\\d{\\mu}_{n% }-\\int\\d{\\mu}\\Big{|}.\\end{split} Como o √∫ltimo termo converge a zero e \\varepsilon foi escolhido arbitrariamente, isso conclui a prova da proposi√ß√£o. ‚àé 3.8.4 O TCL para uma sequ√™ncia i.i.d. {theorem} [Teorema Central do Limite] Considere em (\\Omega,\\mathcal{F},P) , uma sequ√™ncia X_{1},X_{2},\\dots de vari√°veis aleat√≥rias \\iidem \\mathcal{L}^{3} . Nesse caso, se definimos m=E(X_{1}) e \\sigma^{2}=\\Var(X_{1}) , temos \\frac{\\sum_{i=1}^{n}(X_{i}-m)}{\\sigma\\sqrt{n}}\\Rightarrow\\mathcal{N}(0,1). (3.118) Demonstra√ß√£o. Primeiramente, observe que podemos supor que m=0 , pois de qualquer forma iremos subtrair a m√©dia da distribui√ß√£o na qual nos interessamos. Uma outra observa√ß√£o importante √© que podemos supor \\sigma=1 , pois no caso geral de qualquer forma estamos somando X_{i}/\\sigma no enunciado. Como vimos na Proposi√ß√£o¬†3.8.3, basta mostrar a converg√™ncia das integrais de fun√ß√µes g\\in C^{3} , que possuam todas as tr√™s primeiras derivadas limitadas. Considerando a fun√ß√£o \\phi^{n}(x_{1},\\dots,x_{n}):=g\\Big{(}\\frac{x_{1}+\\dots+x_{n}}{\\sqrt{n}}\\Big{)}, (3.119) nos basta provar a converg√™ncia das sequ√™ncias de n√∫meros reais \\lim_{n}\\int\\phi^{n}(X_{1},\\dots,X_{n})\\d{P}=\\int g(s)\\mathcal{N}(0,1)(\\d{s}). (3.120) Vale lembrar que no Corol√°rio¬†3.8.1 j√° estabelecemos algo mais forte para vari√°veis normais. Mais precisamente, suponha que extendemos nosso espa√ßo de probabilidade para (\\Omega^{\\prime},\\mathcal{F}^{\\prime},P^{\\prime}) , onde exista uma sequ√™ncia Y_{1},Y_{2},\\dots de vari√°veis aleat√≥rias \\iidcom distribui√ß√£o \\mathcal{N}(0,1) independente de X_{1},X_{2},\\dots Ent√£o, para todo n\\geq 1 , \\int\\phi^{n}(Y_{1},\\dots,Y_{n})\\d{P}^{\\prime}=\\int g(s)\\mathcal{N}(0,1)(\\d{s}), (3.121) o que tornaria o limite em (3.120) trivial para tais vari√°veis. A nossa estrat√©gia ser√° aproximar \\phi^{n}(X_{1},\\dots,X_{n}) por \\phi(Y_{1},\\dots,Y_{n}) , e faremos isso trocando uma vari√°vel de cada vez. Para entender o que acontece quando trocamos uma das vari√°veis X_{i} por Y_{i} , temos que expandir g em s√©rie de pot√™ncias, isto √©, escrever g(s)=g(s_{0})+g^{\\prime}(s_{0})(s-s_{0})+g^{\\prime\\prime}(s_{o})(s-s_{0})^{2}/% 2+r_{s_{0}}(s-s_{0}), (3.122) onde r_{s_{0}}(h)/h^{3} √© limitada por M , uniformemente em h e s_{0} em consequ√™ncia das nossas suposi√ß√µes sobre g . Denotando z_{i}=(y_{1},\\dots,y_{i-1},x_{i},\\dots x_{n}) , z_{i}^{o}:=(y_{1},\\dots,y_{n-1},0,x_{n+1},\\dots,x_{n}) e s_{i}^{o}=y_{1}+\\dots+y_{n-1}+x_{n+1}+\\dots x_{n} , temos \\phi^{n}(z_{i})=\\phi^{n}(z_{i}^{o})+g^{\\prime}\\Big{(}\\frac{s_{i}^{o}}{\\sqrt{n}% }\\Big{)}\\frac{x_{i}}{\\sqrt{n}}+g^{\\prime\\prime}\\Big{(}\\frac{s_{i}^{o}}{\\sqrt{n% }}\\Big{)}\\frac{x_{i}^{2}}{2n}+r_{\\frac{s_{i}^{o}}{\\sqrt{n}}}\\Big{(}\\frac{x_{i}% }{\\sqrt{n}}\\Big{)}, (3.123) N√≥s propositalmente expandimos \\phi^{n} at√© ordem dois, pois X_{i} e Y_{i} possuem os mesmos momentos de ordem um ( m=0 ) e dois ( \\sigma^{2}=1 ). Integrando os dois lados da igualdade acima com respeito a Z_{i}\\circ P (denotamos como antes, Z_{i}=(Y_{1},\\dots,Y_{i-1},X_{i},\\dots,X_{n}) e Z_{i}^{o} , S_{i}^{o} analogamente), teremos \\int\\phi^{n}(Z_{i})\\d{P}^{\\prime}=\\int\\phi^{n}(Z_{i}^{o})\\d{P}^{\\prime}+\\frac{% 1}{2n}v_{i}+k_{i}, (3.124) onde as quantidades v e k , se escrevem como v_{i}=\\int g^{\\prime\\prime}\\Big{(}\\frac{S_{i}^{o}}{\\sqrt{n}}\\Big{)}\\d{P}^{% \\prime}\\quad\\text{ e }\\quad k_{i}=\\int r_{S_{i}^{o}/\\sqrt{n}}\\Big{(}\\frac{X_{i% }}{\\sqrt{n}}\\Big{)}\\d{P}^{\\prime}. (3.125) Note que v_{i} n√£o depende de X_{i} e que |k_{i}|\\leq\\Big{|}\\int\\Big{(}\\frac{X_{i}^{3}}{n^{3/2}}\\Big{)}\\Big{(}\\frac{n^{3% /2}}{X_{i}^{3}}\\Big{)}r_{S_{i}^{o}/\\sqrt{n}}\\Big{(}\\frac{X_{i}}{\\sqrt{n}}\\Big{% )}\\d{P}^{\\prime}\\Big{|}\\leq\\frac{M}{n^{3/2}}E(|X_{i}^{3}|). (3.126) As observa√ß√µes acima s√£o o ponto mais importante da prova de que essa aproxima√ß√£o funciona e uma outra maneira de coloc√°-las √© a seguinte. Como X_{i} e Y_{i} possuem os dois primeiros momentos iguais, os dois primeiros termos de Taylor coincidem ap√≥s a integra√ß√£o (o primeiro se anula e o segundo √© v_{i} tanto para X_{i} quanto para Y_{i} ). O resto √© de ordem muito pequena para influir no limite. De fato, se retiramos o termo Y_{i} de Z_{i+1} , fazendo a mesma expans√£o que para X_{i} , obtemos \\int\\phi^{n}(Z_{i+1})\\d{P}^{\\prime}=\\int\\phi^{n}(Z_{i}^{o})\\d{P}^{\\prime}+% \\frac{1}{2n}v_{i}+k^{\\prime}_{i}, (3.127) com o termo de ordem superior k^{\\prime}_{i} sendo definido exatamente como k_{i} , mas com Y_{i} no lugar de X_{i} . Estamos prontos agora para a computa√ß√£o final \\begin{split}\\Big{|}\\int\\phi^{n}&(X_{1},\\dots,X_{n})\\d{P}-\\int g(s)\\mathcal{N}% (0,1)(\\d{s})\\Big{|}\\\\ &=\\Big{|}\\int\\phi^{n}(Z_{0})\\d{P}^{\\prime}-\\int\\phi^{n}(Z_{n})\\d{P}^{\\prime}% \\Big{|}\\\\ &\\leq\\sum_{i=0}^{n-1}\\Big{|}\\int\\phi^{n}(Z_{i})\\d{P}^{\\prime}-\\int\\phi^{n}(Z_{% i+1})\\d{P}^{\\prime}\\Big{|}=\\sum_{i=0}^{n-1}|k_{i}-k^{\\prime}_{i}|\\\\ &\\leq n\\frac{M}{n^{3/2}}\\big{(}E(|X_{1}|^{3})+E(|Y_{1}|^{3})\\big{)},\\end{split} que claramente converge a zero, provando o teorema. ‚àé {corollary} A \\mathcal{N}(0,1) √© a √∫nica distribui√ß√£o \\mu que possui esperan√ßa zero, vari√¢ncia 1 e √© tal que se X,Y s√£o \\iidcom distribui√ß√£o \\mu , ent√£o (X+Y)/\\sqrt{2} tamb√©m possuem distribui√ß√£o \\mu . Em outras palavras, \\mathcal{N}(0,\\sigma^{2}) , para \\sigma\\geq 0 , s√£o os √∫nicos pontos fixos de \\Gamma em \\mathcal{L}^{3} . Demonstra√ß√£o. Usando a invari√¢ncia enunciada acima, temos que \\frac{X_{1}+\\dots+X_{2^{k}}}{\\sqrt{2^{k}}}\\distr\\mu. (3.128) Mas pelo Teorema central do limite, a distribui√ß√£o dessa combina√ß√£o de X_{i} deve convergir a \\mathcal{N}(0,1) , logo temos \\mu=\\mathcal{N}(0,1) . ‚àé Vamos terminar essa se√ß√£o com uma aplica√ß√£o do teorema acima. {exercise} Digamos que jogamos 100 moedas honestas e independentes, como foi proposto no in√≠cio da se√ß√£o, obtendo finalmente uma vari√°vel aleat√≥ria Y\\distr\\Bin(100,1/2) . Usando o O TCL para uma sequ√™ncia i.i.d., estime P[Y\\geq 55] usando uma aproxima√ß√£o por uma \\mathcal{N}(0,1) . Calcule numericamente o valor real desta probabilidade e compare ambas as estimativas. 55todo: 5 falar de Tao Vu, se os momentos batem a distrib de auto-val √© proxima + funcao zeta. \\todosec T√≥pico: Mec√¢nica estat√≠stica do g√°s idealMostrar a equival√™ncia de ensembles. \\todosec T√≥pico: Fun√ß√µes caracter√≠sticas???funcoes caracteristicas e tomografia‚Ä¶ Previous page Next page"],[["index.html","Ch3.html","Ch3.Sx1.html"],"T√≥pico: Contando tri√¢ngulos ‚Ä£ Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. T√≥pico: Contando tri√¢ngulos T√≥pico: Contando tri√¢ngulos Vimos como a Lei Fraca dos Grandes N√∫meros seguiu de uma estimativa de segundo momento (mais precisamente usando a vari√¢ncia). Nessa se√ß√£o iremos mostrar como esse m√©todo √© mais geral, se aplicando mesmo em situa√ß√µes onde as vari√°veis n√£o s√£o necessariamente independentes duas a duas. Seja V_{n}=\\{1,\\dots,n\\} com n\\geq 3 e \\mathcal{E}_{n}=\\big{\\{}\\{x,y\\}\\subseteq V_{n};x\\neq y\\big{\\}} . Chamamos o par (V_{n},\\mathcal{E}_{n}) de grafo completo em n v√©rtices. Definimos em um certo espa√ßo de probabilidade P_{n} , as vari√°veis aleat√≥rias (X_{e})_{e\\in\\mathcal{E}_{n}} de maneira \\iidcom distribui√ß√£o \\Ber(p) , onde p\\in[0,1] . Essas vari√°veis induzem um subgrafo aleat√≥rio (V_{n},\\mathcal{E}_{n}^{\\prime}) , onde \\mathcal{E}_{n}^{\\prime}=\\big{\\{}e\\in\\mathcal{E}_{n};X_{e}=1\\big{\\}}. (3.39) Dizemos que os elos e , tais que X_{e}=1 s√£o abertos. Definimos nesse espa√ßo a vari√°vel aleat√≥ria T_{n}=\\#\\big{\\{}\\text{tri\\^{a}ngulos em $(V_{n},\\mathcal{E}_{n}^{\\prime})$}% \\big{\\}}. (3.40) Essa vari√°vel claramente pode ser escrita como T_{n}=\\sum_{x,y,z\\in V_{n}\\text{ distintos}}\\1_{A_{\\{x,y,z\\}}}, (3.41) onde A_{\\{x,y,z\\}}=\\big{[}\\text{\\{x,y,z\\} formam um tri\\^{a}ngulo em $(V_{n},% \\mathcal{E}_{n}^{\\prime})$}\\big{]} . Gostar√≠amos de entender algo sobre a distribui√ß√£o de T_{n} e come√ßamos calculando \\begin{split}E^{n}(T_{n})&=\\sum_{\\{x,y,z\\}\\text{ distintos}}P^{n}(A_{\\{x,y,z\\}% })\\\\ &=\\binom{n}{3}p^{3}=\\frac{n(n-1)(n-2)}{6}p^{3}.\\end{split} (3.42) Logo, P[T_{n}>a]\\leq n(n-1)(n-2)p^{3}/6a . Mais ainda, \\begin{split}E^{n}(T_{n}^{2})&=\\sum_{\\{x,y,z\\}\\text{ distintos}}\\quad\\sum_{\\{x% ^{\\prime},y^{\\prime},z^{\\prime}\\}\\text{ distintos}}P^{n}(A_{\\{x,y,z\\}}\\cap A_{% \\{x^{\\prime},y^{\\prime},z^{\\prime}\\}})\\\\ &=\\underbrace{\\binom{n}{6}\\binom{6}{3}p^{6}}_{\\text{todos distintos}}+% \\underbrace{\\binom{n}{5}\\binom{5}{3}\\binom{3}{1}p^{6}}_{\\text{$1$-comum}}+% \\underbrace{\\binom{n}{4}\\binom{3}{2}\\binom{4}{3}p^{5}}_{\\text{$2$ em comum}}+% \\underbrace{\\binom{n}{3}p^{3}}_{\\text{iguais}}\\end{split} (3.43) Donde \\Var^{n}(T_{n})=\\frac{1}{36}n^{6}p^{6}-\\frac{1}{36}n^{6}p^{6}+cn^{5}p^{5}+...% \\leq c(n^{5}p^{5}+n^{3}p^{3}), (3.44) para todos p\\in[0,1] e n\\geq 1 se escolhemos bem a constante c>0 . Isso nos permite por exemplo estimar o que acontece em alguns regimes, como por exemplo, se p=1/2 , ent√£o E^{n}(T_{n})=\\frac{n(n-1)(n-2)}{48}, (3.45) que cresce como n^{3} , e \\Var^{n}(T_{n})\\leq cn^{5} , logo P^{n}\\Big{[}\\Big{|}T_{n}-E^{n}(T_{n})\\Big{|}>\\varepsilon n^{3}\\Big{]}\\leq\\frac% {\\Var^{n}(T_{n})}{\\varepsilon^{2}n^{6}}\\leq\\frac{c}{\\varepsilon^{2}n}. (3.46) \\todosec T√≥pico: An√°lise de DNAfazer \"computational molecular biology- Pevzner se√ß√£o 5.5‚Ä¶ \\todosec T√≥pico: M√©todo Probabil√≠stico Revisitadousando segundo momento agora Previous page Next page"],[["index.html","Ch3.html","Ch3.Sx2.html"],"T√≥pico: Fun√ß√µes caracter√≠sticas 1 footnote 1 1 footnote 1 Somos gratos a Rangel Baldasso por escrever essa se√ß√£o. ‚Ä£ Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. T√≥pico: Fun√ß√µes caracter√≠sticas T√≥pico: Fun√ß√µes caracter√≠sticas 11 1 Somos gratos a Rangel Baldasso por escrever essa se√ß√£o. Esta se√ß√£o trata da fun√ß√£o caracter√≠stica de uma vari√°vel aleat√≥ria, que pode ser vista como um an√°logo complexo da trasformada de Laplace, ou tamb√©m como a transformada de Fourier de uma distribui√ß√£o em \\mathbb{R} . Vamos estudar suas principais propriedades e demonstrar que a fun√ß√£o caracter√≠sticas determinam unicamente a distribui√ß√£o da vari√°vel aleat√≥ria. {definition} Dada uma vari√°vel aleat√≥ria X , a fun√ß√£o caracter√≠stica de X , \\widebar{\\phi}_{X}:\\mathbb{R}\\rightarrow\\mathbb{C} , √© definida por \\widebar{\\phi}_{X}(t)=\\mathbb{E}(e^{itX}),\\qquad t\\in\\mathbb{R}. (3.91) Vamos come√ßar estudando as propriedades b√°sicas de \\widebar{\\phi}_{X} . {exercise} Prove que a fun√ß√£o \\widebar{\\phi}_{X} √© absolutamente cont√≠nua. {exercise} Suponha que \\mathbb{E}(|X|^{n})<+\\infty . Prove que a fun√ß√£o \\widebar{\\phi}_{X} √© n vezes diferenci√°vel em t=0 e que \\widebar{\\phi}_{X}^{(n)}(0)=i^{n}\\mathbb{E}(X^{n}) . {exercise} Se X_{1},X_{2},\\ldots,X_{n} s√£o independentes e a_{1},a_{2},\\ldots,a_{n}\\in\\mathbb{R} , ent√£o \\widebar{\\phi}_{a_{1}X_{1}+a_{2}X_{2}+\\cdots+a_{n}X_{n}}(t)=\\widebar{\\phi}_{X_% {1}}(a_{1}t)\\widebar{\\phi}_{X_{2}}(a_{2}t)\\cdots\\widebar{\\phi}_{X_{n}}(a_{n}t). (3.92) Como vamos ver agora, a fun√ß√£o caracter√≠stica nos permite recuperar a distribui√ß√£o de X : {exercise} Use a seguinte igualdade \\lim_{T\\rightarrow+\\infty}\\int_{0}^{T}\\frac{\\sin(tz)}{t}\\,dz=\\begin{cases}1&% \\text{se }z>0\\\\ 0&\\text{se }z=0\\\\ -1&\\text{se }x<0\\\\ \\end{cases} (3.93) para provar que se a<b s√£o pontos de continuidade da fun√ß√£o de distribui√ß√£o de X , F_{X} , ent√£o F_{X}(b)-F_{X}(a)=\\lim_{T\\rightarrow+\\infty}\\frac{1}{2\\pi}\\int_{-T}^{T}\\frac{e% ^{-itb}-e^{-ita}}{-it}\\widebar{\\phi}_{X}(t)\\,dt. (3.94) Conclua que a distribui√ß√£o de X √© determinada por \\widebar{\\phi}_{X} . O pr√≥ximo exerc√≠cio consiste em calcular algumas fun√ß√µes caracter√≠sticas. {exercise} Calcule as fun√ß√µes caracter√≠sticas das seguintes distribui√ß√µes: i.‚Äã X\\sim Ber(p) ; ii.‚Äã X\\sim Poisson(\\lambda) ; iii.‚Äã X\\sim N(0,1) . Dica: fixe z\\in\\mathbb{R} , calcule \\mathbb{E}(e^{zX}) e use o Princ√≠pio da continua√ß√£o anal√≠tica. Previous page Next page"],[["index.html","Ch3.html","Ch3.Sx3.html"],"T√≥pico: O Teorema de Portmanteau ‚Ä£ Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. T√≥pico: O Teorema de Portmanteau T√≥pico: O Teorema de Portmanteau O pr√≥ximo resultado √© bastante √∫til para provar converg√™ncia fraca, pois nos fornece uma cole√ß√£o de equival√™ncias muitas vezes mais f√°ceis de verificar. {theorem} [Teorema de Portmanteau] Sejam (\\mu_{n})_{n\\geq 1} e \\mu medidas de probabilidade em (E,\\mathcal{A}) . S√£o equivalentes: a)‚Äã \\mu_{n}\\Rightarrow\\mu , a‚Äô)‚Äã \\int f\\d{\\mu}_{n}\\to\\int f\\d{\\mu} , para toda f unifmormemente cont√≠nua e limitada, b)‚Äã \\limsup_{n}\\mu_{n}(F)\\leq\\mu(F), para todo F\\subseteq E fechado, b‚Äô)‚Äã \\liminf_{n}\\mu_{n}(G)\\geq\\mu(G), para todo F\\subseteq E aberto, c)‚Äã \\lim_{n}\\mu_{n}(A)=\\mu(A), para todo A\\in\\mathcal{A} com \\mu(\\partial A)=0 . Para memorizar o teorema acima, √© conveniente lembrar dos dois exemplos: ‚ÄÉi)‚Äãse x_{n}\\to x com x_{n}\\neq x , F=\\{x\\} e G=B(x,\\delta)\\setminus\\{x\\} temos, para n grande, \\mu_{n}(F)=\\mu(G)=0<1=\\mu(F)=\\mu_{n}(G), (3.129) ‚ÄÉii)‚Äãem (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) , seja \\mu_{2n}=\\delta_{n} e \\mu_{2n+1}=\\mu=\\delta_{0} . Obviamente \\mu_{n} n√£o converge fracamente a \\mu . Contudo, para todo A\\in\\mathcal{B}(\\mathbb{R}) , \\begin{split}\\liminf_{n}\\mu_{n}(A)&\\leq\\liminf_{n}\\mu_{2n}(A)=\\mu(A)\\text{ e}% \\\\ \\limsup_{n}\\mu_{n}(A)&\\geq\\limsup_{n}\\mu_{2n}(A)=\\mu(A).\\end{split} (3.130) Prova do Teorema¬†3. Obviamente, (a\\Rightarrow a^{\\prime}) , pois a^{\\prime}) somente sup√µe a converg√™ncia das integrais para fun√ß√µes f que sejam uniformemente cont√≠nuas, portanto √© um requisito mais fraco que a) . Observamos tamb√©m que (b\\Leftrightarrow b^{\\prime}) . De fato, basta tomarmos complementos e observar a mudan√ßa nos sinais das desigualdades. Ent√£o, para a prova do teorema, basta mostrar que (a^{\\prime}\\Rightarrow b) , (b+b^{\\prime}\\Rightarrow c) e (c\\Rightarrow a) . Come√ßamos com (a^{\\prime}\\Rightarrow b) e para tanto, consideramos F\\subseteq E fechado. Seja \\delta>0 e defina a fun√ß√£o f_{\\delta}:E\\to\\mathbb{R} dada por f_{\\delta}(x)=\\max\\Big{\\{}1-\\frac{d(x,F)}{\\delta},0\\Big{\\}}. (3.131) Claramente, f √© uniformemente cont√≠nua e vale \\1{F}\\leq f_{\\delta}\\leq\\1{B(F,\\delta)} . Dessa desigualdade, temos \\limsup_{n}\\mu_{n}(F)\\leq\\limsup_{n}\\int f_{\\delta}\\d{\\mu}_{n}=\\int f_{\\delta}% \\d{\\mu}\\leq\\mu(B(F,\\delta)) . Tomando agora o limite com \\delta\\to 0 , obtemos b) por continuidade da probabilidade \\mu . Para mostrar (b+b^{\\prime}\\Rightarrow c) , seja A\\in\\mathcal{A} tal que \\mu(\\partial A)=0 . Nesse caso, sabemos que \\begin{split}\\limsup_{n}\\mu_{n}(A)&\\leq\\limsup_{n}\\mu_{n}(\\bar{A})\\leq\\mu(\\bar% {A})=\\mu(\\mathring{A})\\\\ &\\leq\\liminf\\mu_{n}(\\mathring{A})\\leq\\liminf_{n}\\mu_{n}(A),\\end{split} o que mostra o limite em c) . Finalmente, resta mostrar (c\\Rightarrow a) e, para tanto, consideramos uma fun√ß√£o f:E\\to\\mathbb{R} cont√≠nua e limitada. Digamos, com \\lVert f\\rVert_{\\infty}=M . Sabemos que os conjuntos \\{f^{-1}(\\{a\\})\\}_{a\\in\\mathbb{R}} s√£o disjuntos, logo os conjuntos f^{-1}(\\{a\\}) podem ter medida \\mu positiva apenas para uma cole√ß√£o enumer√°vel de valores a\\in\\mathbb{R} . Obtemos assim uma cole√ß√£o finita b_{0}<b_{1}<\\dots<b_{k} , tal que \\begin{array}[]{c}b_{0}<-M\\text{ e }b_{k}>M,\\quad b_{i+1}-b_{i}\\leq\\delta\\text% { e}\\\\ \\mu\\big{(}f^{-1}(\\{b_{i}\\})\\big{)}=0\\text{ para todo $i\\leq k$}.\\end{array} (3.132) x f(x) Figura 3.3: Uma fun√ß√£o cont√≠nua e limitada f , os pontos b_{i} e um conjunto A_{i} . Iremos aproximar f por uma fun√ß√£o da forma f_{\\delta}=\\sum_{i}b_{i}\\1_{A_{i}} , onde os conjuntos A_{i}=f^{-1}\\big{(}[b_{i},b_{i+1})\\big{)} s√£o disjuntos. Obviamente f_{\\delta}\\leq f\\leq f_{\\delta}+\\delta , donde \\liminf\\int f_{\\delta}\\d{\\mu}_{n}\\leq\\liminf\\int f\\d{\\mu}_{n}\\leq\\limsup\\int f% \\d{\\mu}_{n}\\leq\\liminf\\int f_{\\delta}\\d{\\mu}_{n}+\\delta. Mas como \\int f_{\\delta}\\d{\\mu}_{n}=\\sum_{i}b_{i}\\mu_{n}(A_{i}) , a prova estar√° concluida se mostrarmos que \\mu_{n}(A_{i})\\to\\mu(A_{i}) para todo i\\leq k . Isso segue de d) , pois \\partial A_{i}\\subseteq f^{-1}(\\{b_{i},b_{i+1}\\}) , que tem medida zero. ‚àé {exercise} Lembrando que em (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) , temos \\tfrac{1}{n}\\sum_{i=1}^{n}\\delta_{i/n}\\Rightarrow U_{[0,1]} , use o √≠tem d) do Teorema¬†3 para dar uma caracteriza√ß√£o dos conjuntos Riemann-mensur√°veis. Mais precisamente, encontre os A\\subseteq\\mathbb{R} tais que \\tfrac{1}{n}\\sum_{i=1}^{n}\\delta_{i/n}(A) converge para a medida de Lebesgue de A . \\todosec T√≥pico: An√°lise de componentes principaisvari√°veis gaussianas e principal component analysis‚Ä¶ Previous page Next page"],[["index.html","Ch3.html"],"Cap√≠tulo 3 Somas de vari√°veis independentes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Somas de vari√°veis independentes Cap√≠tulo 3 Somas de vari√°veis independentes Nesse cap√≠tulo introduziremos v√°rias t√©cnicas e resultados que ser√£o √∫teis em geral, mas que aparecem naturalmente no estudo de somas de vari√°veis aleat√≥rias independentes, que por sua vez √© um assunto de extrema import√¢ncia em teoria e aplica√ß√µes de probabilidade. Previous page Next page"],[["index.html","Ch4.html","Ch4.S1.html"],"4.1 Esperan√ßa condicional ‚Ä£ Cap√≠tulo 4 Esperan√ßa condicional ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Esperan√ßa condicional 4.1 Esperan√ßa condicional Como j√° foi dito anteriormente, a estrutura de \\sigma -√°lgebra tem um papel muito importante em probabilidade. Durante o curso de Teoria da Medida, muitas vezes o conceito de \\sigma -√°lgebra parece uma tecnicalidade que simplesmente dificulta nosso acesso ao conte√∫do realmente interessante do curso. Em alguns momentos, chegamos a desejar que tudo fosse mensur√°vel e n√£o tiv√©ssemos que nos preocupar com tais formalidades. Contudo, no estudo que iniciaremos agora, nos restringiremos a \\sigma -√°lgebras menores de maneira proposital. Ficar√° claro em particular, que o estudo de mensurabilidade n√£o √© uma mera tecnicalidade, mas sim uma ferramenta importante. Esse interesse, vem da necessidade de representar situa√ß√µes de ‚Äúinforma√ß√£o incompleta‚Äù, onde podemos apenas observar uma parte da realidade. Isso certamente √© de suma import√¢ncia em diversas aplica√ß√µes, desde a estat√≠stica, f√≠sica e computa√ß√£o at√© a teoria de jogos. Vamos come√ßar com um exemplo simples. Suponha que \\Omega=\\mathbb{R}^{2} √© dotado da \\sigma -√°lgebra de Borel e denotamos por X_{1},X_{2} as coordenadas can√¥nicas. Como podemos representar matematicamente a afirma√ß√£o ‚Äúuma pessoa somente conhece o valor de X_{1} e n√£o de X_{2} ‚Äù? Digamos por exemplo que essa pessoa dever√° tomar uma decis√£o (por exemplo escolher um elemento de E ) baseando-se apenas nessa informa√ß√£o incompleta. A maneira que modelamos isso matem√°ticamente √© dizendo que a decis√£o da pessoa deve ser uma fun√ß√£o f:\\Omega\\to E mensur√°vel com respeito a \\sigma(X_{1}) . Nossa primeira utiliza√ß√£o desse conceito ser√° feita agora ao introduzirmos a no√ß√£o de espera√ßa condicional, que generaliza o conceito de esperan√ßa. Relembrando o c√°lculo (3.22), n√≥s podemos pensar em E(X) como uma boa maneira de aproximar X por um n√∫mero real. Isso por exemplo poderia ser √∫til se n√£o temos nenhuma informa√ß√£o sobre o que ocorreu, mas ainda sim temos que tentar adivinhar o valor de X . Mas vamos agora imaginar uma outra situa√ß√£o, onde temos um pouco de informa√ß√£o sobre o que ocorreu. Voltando ao exemplo em que \\Omega=\\mathbb{R}^{2} , digamos que n√≥s podemos observar o valor de X_{1} , mas gostar√≠amos de estimar o valor de X_{2} . De acordo com o que discutimos acima, nossa estimativa agora n√£o precisa mais ser apenas um n√∫mero real, podendo ser qualquer fun√ß√£o mensur√°vel com respeito a \\sigma(X_{1}) . Vamos no que segue tornar esse discuss√£o rigorosa, mas antes lembramos um lema b√°sico de Teoria da Medida. {lemma} Se f,f^{\\prime} s√£o fun√ß√µes mensur√°veis tais que \\int_{A}f\\d{\\mu}=\\int_{A}f^{\\prime}\\d{\\mu},\\text{ para todo $A\\in\\mathcal{F}^{% \\prime}$,} (4.1) ent√£o f=f^{\\prime} \\mu -quase certamente. Demonstra√ß√£o. Aplicando a hip√≥tese para A=[f>f^{\\prime}] , vemos que \\int_{A}f-f^{\\prime}\\d{\\mu}=0, (4.2) mas no conjunto A acima, o integrando √© positivo. Portanto, f=f^{\\prime} , \\mu -quase certamente em A . Aplicando o mesmo racioc√≠nio para [f<f^{\\prime}] obtemos que f=f^{\\prime} quase certamente. ‚àé O lema acima nos diz que se soubermos integrar f em todos os eventos A , ent√£o podemos recuperar a fun√ß√£o f propriamente dita. O que aconteceria se soub√©ssemos integrar f apenas para eventos A em uma sub- \\sigma -√°lgebra? √â isso que estudaremos √† partir de agora. {definition} Seja uma vari√°vel aleat√≥ria X\\in\\mathcal{L}^{1}(P) e uma sub- \\sigma -√°lgebra \\mathcal{F}^{\\prime}\\subseteq\\mathcal{F} . Dizemos que uma vari√°vel aleat√≥ria Y √© a esperan√ßa condicional de X com respeito a \\mathcal{F}^{\\prime} (ou a esperan√ßa condicional de X dada \\mathcal{F}^{\\prime} ) se ‚ÄÉa)‚Äã Y √© \\mathcal{F}^{\\prime} -mensur√°vel e ‚ÄÉb)‚Äã E(X\\1_{A})=E(Y\\1_{A}) para todo A\\in\\mathcal{F}^{\\prime} . Nesse caso, escrevemos Y=E(X|\\mathcal{F}^{\\prime}). (4.3) Observe que faz sentido escrever E\\big{(}Y|\\mathcal{F}^{\\prime}\\big{)}(\\omega) , pois E(X|\\mathcal{F}^{\\prime}) √© uma vari√°vel aleat√≥ria. Interpretamos informalmente a defini√ß√£o acima como ‚Äú Y √© a melhor aproxima√ß√£o \\mathcal{F}^{\\prime} -mensur√°vel de X ‚Äù. Ou Y √© a melhor aproxima√ß√£o que podermos fazer de X se ‚Äúconhecemos apenas \\mathcal{F}^{\\prime} ‚Äù. {example} Se \\mathcal{F}^{\\prime}=\\{\\varnothing,\\Omega\\} , ent√£o Y=E(X) (uma vari√°vel aleat√≥ria constante) √© esperan√ßa condicional de X dado \\mathcal{F}^{\\prime} , pois ‚ÄÉa)‚Äã Y √© \\mathcal{F}^{\\prime} -mensur√°vel (por ser constante). Al√©m disso ‚ÄÉb)‚Äã E(X\\1_{\\varnothing})=0=E(Y\\1_{\\varnothing}) e E(X\\1_{\\Omega})=E(X)=E(Y\\1_{\\Omega}) . Uma propriedade muito importante que segue da Defini√ß√£o¬†4.1 √© dada pela seguinte {proposition} Se Y satisfaz as a) e b) em Defini√ß√£o¬†4.1, ent√£o Y\\in\\mathcal{L}^{1}(P) . Demonstra√ß√£o. Tomamos A=[Y\\geq 0] e A^{\\prime}=[Y<0] que est√£o em \\mathcal{F}^{\\prime} e estimamos \\int|Y|\\d{P}=\\int_{A}Y\\d{P}+\\int_{A^{\\prime}}Y\\d{P}=\\int_{A}X\\d{P}+\\int_{A^{% \\prime}}X\\d{P}\\leq\\int|X|\\d{P}<\\infty (4.4) O que mostra a proposi√ß√£o. ‚àé Al√©m caso trivial dado acima pelo Exemplo¬†4.1, quando podemos esperar que existam esperan√ßas condicionais? {theorem} Dada X\\in\\mathcal{L}^{1}(P) e \\mathcal{F}^{\\prime}\\subseteq\\mathcal{F} uma \\sigma -√°lgebra, ent√£o existe a esperan√ßa condicional E(X|\\mathcal{F}^{\\prime}) . Al√©m disso ela √© √∫nica P -quase certamente. Demonstra√ß√£o. Vamos primeiro mostrar a unicidade quase certa. Para isso, supomos que existam Y e Y^{\\prime} satisfazendo as condi√ß√µes da Defini√ß√£o¬†4.1 (logo em \\mathcal{L}^{1} ). Iremos proceder como no Lema¬†4.1 acima, definindo A=[Y>Y^{\\prime}] , donde conclu√≠mos que E\\big{(}(Y-Y^{\\prime})\\1_{A}\\big{)}=E(Y\\1_{A})-E(Y^{\\prime}\\1_{A})=0. (4.5) Mas como Y>Y^{\\prime} em A , vemos que Y\\leq Y^{\\prime} quase certamtente. A prova da unicidade pode ser completa trocando os pap√©is de Y e Y^{\\prime} acima. Vamos agora para a prova da exist√™ncia. Como X\\in\\mathcal{L}^{1}(P) , podemos introduzir \\mu(A)=E(X\\1_{A}), (4.6) que define uma medida com sinal em (\\Omega,\\mathcal{F}) , com varia√ß√£o total finita. Caso o leitor n√£o se sinta familiarizado com o conceito de medida com sinal, poder√° decompor X em partes positiva e negativa e proceguir sem problemas. Um passo importante da prova √© observar que \\mu tamb√©m define uma medida no espa√ßo (\\Omega,\\mathcal{F}^{\\prime}) . Estamos portanto propositalmente restringindo nossa \\sigma -√°lgebra. Como P(A)=0 implica que \\mu(A)=0 , temos que \\mu\\ll P e podemos aplicar o Teorema de Radon-Nikodim para obter uma derivada Y:\\Omega\\to\\mathbb{R} tal que ‚ÄÉa)‚Äã Y √© \\mathcal{F}^{\\prime} -mensur√°vel e ‚ÄÉb)‚Äã \\mu(A)=\\int_{A}Y\\d{P} . Agora √© s√≥ observar que as afirma√ß√µes acima correspondem √†s condi√ß√µes da Defini√ß√£o¬†4.1. ‚àé Observe que a condi√ß√£o de \\mathcal{F}^{\\prime} -mensurabilidade √© essencial para a unicidade. De fato, X obviamente satisfaz a segunda condi√ß√£o da Defini√ß√£o¬†4.1, mas n√£o necessariamente a primeira. {exercise} Mostre que se X\\in\\mathcal{F}^{\\prime} , ent√£o E(X|\\mathcal{F}^{\\prime})=X quase certamente. {exercise} Seja P a probabilidade uniforme em \\{(x_{1},x_{2})\\in[0,1]^{2};x_{1}\\geq x_{2}\\} . Calcule E(X_{2}|X_{1}) . Previous page Next page"],[["index.html","Ch4.html","Ch4.S2.html"],"4.2 Propriedades b√°sicas da esperan√ßa condicional ‚Ä£ Cap√≠tulo 4 Esperan√ßa condicional ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Propriedades b√°sicas da esperan√ßa condicional 4.2 Propriedades b√°sicas da esperan√ßa condicional Nessa se√ß√£o justificaremos, em certa medida, a nomenclatura ‚Äúesperan√ßa condicional‚Äù. Faremos isso mostrando que ela satisfaz v√°rias propriedades que j√° conhecemos para a esperan√ßa tradicional. Mas como podemos mostrar propriedades simples tais como a linearidade da esperan√ßa condicional? Vamos come√ßar com um exemplo {proposition} Se X,X^{\\prime}\\in\\mathcal{L}^{1}(P) , ent√£o E(X+X^{\\prime}|\\mathcal{F}^{\\prime})=E(X|\\mathcal{F}^{\\prime})+E(X^{\\prime}|% \\mathcal{F}^{\\prime}),\\text{ $P$-quase certamente.} (4.7) Note que a igualdade acima √© uma igualdade entre vari√°veis aleat√≥rias. Demonstra√ß√£o. Sabemos que Y=E(X|\\mathcal{F}^{\\prime})+E(X^{\\prime}|\\mathcal{F}^{\\prime}) √© uma vari√°vel aleat√≥ria bem definida. Mais do que isso, sabemos que ela √© uma candidata muito boa a E(X+X^{\\prime}|\\mathcal{F}^{\\prime}) . Logo, por unicidade da esperan√ßa condicional, basta verificar que Y satisfaz as condi√ß√µes da Defini√ß√£o¬†4.1 com respeito a X+X^{\\prime} . De fato ‚ÄÉa)‚Äã Y √© \\mathcal{F}^{\\prime} -mensur√°vel, por ser uma soma de duas vari√°veis \\mathcal{F}^{\\prime} -mensur√°veis e ‚ÄÉb)‚Äãpor linearidade da esperan√ßa (n√£o da esperan√ßa condicional), temos \\begin{split}E(Y\\1_{A})&=E\\big{(}E(X|\\mathcal{F}^{\\prime})\\1_{A}+E(X^{\\prime}|% \\mathcal{F}^{\\prime})\\1_{A}\\big{)}\\\\ &=E\\big{(}E(X|\\mathcal{F}^{\\prime})\\1_{A}\\big{)}+E\\big{(}E(X^{\\prime}|\\mathcal% {F}^{\\prime})\\1_{A}\\big{)}\\\\ &=E(X\\1_{A})+E(X^{\\prime}\\1_{A})=E\\big{(}(X+X^{\\prime})\\1_{A}\\big{)}.\\end{split} (4.8) Isso termina a prova do proposi√ß√£o. ‚àé {exercise} Dados X\\in\\mathcal{L}^{1} e \\alpha\\in\\mathbb{R} , mostre que E(\\alpha X|\\mathcal{F}^{\\prime})=\\alpha E(X|\\mathcal{F}^{\\prime}) . Uma outra propriedade bem simples da esperan√ßa condicional √© a monotonicidade. {lemma} Se X\\geq X^{\\prime} em \\mathcal{L}^{1}(P) , ent√£o E(X|\\mathcal{F}^{\\prime})\\geq E(X^{\\prime}|\\mathcal{F}^{\\prime}),\\text{$P$-% quase certamente.} (4.9) Em particular, se X\\geq 0 , ent√£o E(X|\\mathcal{F}^{\\prime})\\geq 0 quase certamente. Demonstra√ß√£o. Seja A=[E(X^{\\prime}|\\mathcal{F}^{\\prime})-E(X|\\mathcal{F}^{\\prime})>0] , que pertence a \\mathcal{F}^{\\prime} . Ent√£o 0\\leq E\\big{(}(E(X^{\\prime}|\\mathcal{F}^{\\prime})-E(X|\\mathcal{F}^{\\prime}))\\1% _{A}\\big{)}=E\\big{(}(X^{\\prime}-X)\\1_{A}\\big{)}\\leq 0, (4.10) o que implica que P(A)=0 . ‚àé {proposition} Se X,ZX\\in\\mathcal{L}^{1}(P) , com Z\\in\\mathcal{F}^{\\prime} , temos E(XZ|\\mathcal{F}^{\\prime})=ZE(X|\\mathcal{F}^{\\prime})\\text{ $P$-quase % certamente}. (4.11) Em particular, E(\\alpha X|\\mathcal{F}^{\\prime})=\\alpha E(X|\\mathcal{F}^{\\prime}) , para todo \\alpha\\in\\mathbb{R} . Uma outra consequ√™ncia interessante √© que ZE(X|\\mathcal{F}^{\\prime}) estar√° automaticamente em \\mathcal{L}^{1} . De maneira bastante informal, vamos dar uma intui√ß√£o para o resultado acima. Ao considerarmos a esperan√ßa condicional dada \\mathcal{F}^{\\prime} , n√≥s j√° conhecemos as vari√°veis aleat√≥rias \\mathcal{F}^{\\prime} -mensur√°veis, portanto elas se comportam como constantes. Demonstra√ß√£o. Mais uma vez, basta verificar que ZE(X|\\mathcal{F}^{\\prime}) satisfaz as condi√ß√µes que definem a esperan√ßa condicional. A primeira √© trivial, pois ZE(X|\\mathcal{F}^{\\prime}) √© \\mathcal{F}^{\\prime} -mensur√°vel por ser um produto de fun√ß√µes \\mathcal{F}^{\\prime} -mensur√°veis. Para provar a segunda condi√ß√£o, come√ßamos com o caso Z=\\1_{B} , implicando que B\\in\\mathcal{F}^{\\prime} , donde E\\big{(}ZE(X|\\mathcal{F}^{\\prime})\\1_{A}\\big{)}=E\\big{(}E(X|\\mathcal{F}^{% \\prime})\\1_{A\\cap B}\\big{)}=E(X\\1_{A\\cap B})=E(ZX\\1_{A}). Por linearidade, j√° sabemos que o resultado vale para fun√ß√µes Z simples e gostar√≠amos de extender para quaisquer Z positivas via Teorema da Converg√™ncia Mon√≥tona. Um problema aqui √© que mesmo que Z seja positiva, n√£o sabemos se E(X|\\mathcal{F}^{\\prime}) tamb√©m ser√° positiva. Portanto, trataremos primeiramente do caso X\\geq 0 . Para tais X , sabemos pelo Lema¬†4.2 que E(X|\\mathcal{F}^{\\prime})\\geq 0 quase certamente. Da√≠, podemos concluir que ZE(X|\\mathcal{F}^{\\prime})=E(ZX|\\mathcal{F}^{\\prime}) para toda Z\\geq 0 , podemos aproxim√°-la por baixo por Z_{n} simples e, pelo Teorema da Converg√™ncia Mon√≥tona, \\begin{array}[]{e}E\\big{(}ZE(X|\\mathcal{F}^{\\prime})\\big{)}&\\overset{\\text{TCM% }}{=}&\\lim_{n}E\\big{(}Z_{n}E(X|\\mathcal{F}^{\\prime})\\big{)}\\\\ &=&\\lim_{n}E\\big{(}E(Z_{n}X|\\mathcal{F}^{\\prime})\\big{)}\\overset{\\text{TCM}}{=% }E\\big{(}E(ZX|\\mathcal{F}^{\\prime})\\big{)}.\\end{array} (4.12) O que mostra o resultado sempre que X\\geq 0 . Al√©m disso, pela Proposi√ß√£o¬†4.1, sabemos que ZE(X|\\mathcal{F}^{\\prime})\\in\\mathcal{L}^{1} . Podemos finalmente concluir a prova por linearidade decompondo X=X_{+}-X_{-} . ‚àé O pr√≥ximo resultado tenta corroborar nossa afirma√ß√£o que a esperan√ßa condicional √© uma boa maneira de aproximar uma vari√°vel aleat√≥ria. {lemma} Se X\\in\\mathcal{L}^{2}(P) e \\mathcal{F}^{\\prime}\\subseteq\\mathcal{F} , ent√£o E(X|\\mathcal{F}^{\\prime}) √© a proje√ß√£o ortogonal de X no espa√ßo vetorial H_{\\mathcal{F}^{\\prime}} . Onde H_{\\mathcal{F}^{\\prime}}=\\{Y\\in\\mathcal{L}^{2};Y\\text{ \\'{e} $\\mathcal{F}^{% \\prime}$-mensur\\'{a}vel}\\} . Demonstra√ß√£o. Temos que verificar que X-E(X|\\mathcal{F}^{\\prime}) √© ortogonal a H_{\\mathcal{F}^{\\prime}} . Ou seja, mostrar que para todo Z\\in H_{\\mathcal{F}^{\\prime}} , temos E\\big{(}XZ-E(X|\\mathcal{F}^{\\prime})Z\\big{)}=0. (4.13) Note que n√£o √© claro que essa esperan√ßa faz sentido, pois n√£o sabemos que ZE(X|\\mathcal{F}^{\\prime})\\in\\mathcal{L}^{1} . Mas isso segue facilmente da Proposi√ß√£o¬†4.2. Mas E\\big{(}E(X|\\mathcal{F}^{\\prime})Z\\big{)}=ZE\\big{(}E(X|\\mathcal{F}^{\\prime})\\1% _{\\Omega}\\big{)}=ZE\\big{(}X\\1_{\\Omega}\\big{)} , provando o resultado. 66todo: 6 Adicionar footnote. ‚àé Vimos acima uma metodologia que se repete frequentemente. Digamos que queremos provar que uma determinada express√£o nos d√° a esperan√ßa condicional de algo. Podemos come√ßar provando esse resultado para fun√ß√µes indicadoras, depois para fun√ß√µes simples usando a linearidade provada acima. Por√©m ainda falta um ingrediente bastante importante para construir ou verificar que determinadas vari√°veis s√£o esperan√ßas condicionais. {theorem} [Converg√™ncia Mon√≥tona para Esperan√ßas Condicionais] Se as vari√°veis X_{n} satisfazem X_{n}\\uparrow X e est√£o todas em \\mathcal{L}^{1}(P) , ent√£o \\lim_{n}E(X_{n}|\\mathcal{F}^{\\prime})=E(X|\\mathcal{F}^{\\prime}). (4.14) Demonstra√ß√£o do Teorema¬†4.2. Sabemos que E(X_{n+1}|\\mathcal{F}^{\\prime})\\geq E(X_{n}|\\mathcal{F}^{\\prime}) , donde conclu√≠mos que E(X_{n}|\\mathcal{F}^{\\prime})\\uparrow Y . Vamos demosntrar que Y=E(X|\\mathcal{F}^{\\prime}) . ‚ÄÉa)‚ÄãPor ser um limite de fun√ß√µes \\mathcal{F}^{\\prime} mensur√°veis, Y √© \\mathcal{F}^{\\prime} -mensur√°vel. ‚ÄÉb)‚ÄãDado A\\in\\mathcal{F}^{\\prime} , temos \\begin{split}E(Y\\1_{A})&=E(\\lim_{n}E(X_{n}|\\mathcal{F}^{\\prime})\\1_{A})% \\overset{\\text{TCM}}{=}\\lim_{n}E\\big{(}E(X_{n}|\\mathcal{F}^{\\prime})\\1_{A}\\big% {)}\\\\ &=\\lim_{n}E(X_{n}\\1_{A})\\overset{\\text{TCM}}{=}E(X\\1_{A}).\\end{split} (4.15) O que termina a prova do teorema. ‚àé No que segue, muitas vezes escreveremos E(X|Z) para representar a esperan√ßa condicional E(X|\\sigma(Z)) . {exercise} Sejam X_{1} e X_{2} as coordenadas can√¥nicas em \\mathbb{R}\\times E e definimos a probabilidade \\d{P}=\\rho(x,y)\\d{\\mu}_{1}\\d{\\mu}_{2} , onde \\rho:\\mathbb{R}\\times E\\to\\mathbb{R}_{+} √© uma densidade. D√™ sentido √† express√£o abaixo e mostre que el√° √© E(X_{1}|X_{2}) : \\frac{\\int x\\rho(x,X_{2})\\mu_{1}(\\d{x})}{\\int\\rho(x,X_{2})\\mu_{1}(\\d{x})}. (4.16) {exercise} Seja E enumer√°vel com uma \\sigma -√°lgebra \\mathcal{F}^{\\prime} . Mostre que \\mathcal{F}^{\\prime}=\\sigma(A_{i},i\\geq 1),\\text{ com $A_{i}\\subseteq E$ % disjuntos}. (4.17) Suponha que todos conjuntos A_{i} tem probabilidade positiva e mostre que E(X|\\mathcal{F}^{\\prime})=\\sum_{i}E^{i}(X)\\1_{A_{i}}, (4.18) onde E^{i} √© a esperan√ßa com respeito √† probabilidade P(\\cdot|A_{i}) . Em breve extenderemos esse tipo de resultado a espa√ßos quaisquer. Uma outra propriedade que a esperan√ßa condicional herda da integral √© a {proposition} [Desigualdade de Jensen] Se \\phi:\\mathbb{R}\\to\\mathbb{R} √© convexa, X,\\phi(X)\\in\\mathcal{L}^{1}(P) , ent√£o \\phi\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{)}\\leq E\\big{(}\\phi(X)|\\mathcal{F}^{% \\prime}\\big{)}. (4.19) Demonstra√ß√£o. Se \\phi for uma fun√ß√£o linear, o resultado segue da linearidade que j√° provamos para a esperan√ßa condicional. Al√©m disso, se temos uma fun√ß√£o \\psi:\\mathbb{R}\\to\\mathbb{R} linear e tal que \\psi(x)\\leq\\phi(x) para todo x\\in\\mathbb{R} , ent√£o E\\big{(}\\phi(X)|\\mathcal{F}^{\\prime}\\big{)}\\geq E\\big{(}\\psi(X)|\\mathcal{F}^{% \\prime}\\big{)}=\\psi\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{)}. (4.20) Tomamos finalmente o supremo em todas as \\psi lineares com \\psi\\leq\\phi dos dois lados da desigualdade acima, obtendo E\\big{(}\\phi(X)|\\mathcal{F}^{\\prime}\\big{)}\\geq\\sup_{\\begin{subarray}{c}\\psi% \\leq\\phi\\\\ \\psi\\text{ linear}\\end{subarray}}\\psi\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{)}=% \\phi\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{)}, (4.21) terminando a prova da proposi√ß√£o. ‚àé {corollary} Se X\\in\\mathcal{L}^{1}(P) , ent√£o \\big{|}E(X|\\mathcal{F}^{\\prime})\\big{|}\\leq E\\big{(}|X|\\big{|}\\mathcal{F}^{% \\prime}\\big{)} . Uma outra propriedade interessante da esperan√ßa condicional diz respeito a sua rela√ß√£o com independ√™ncia. {proposition} Se X\\in\\mathcal{L}^{1}(P) √© independente de \\mathcal{F}^{\\prime} , ent√£o E(X|\\mathcal{F}^{\\prime})=E(X)\\text{ $P$-quase certamente.} (4.22) Demonstra√ß√£o. Fun√ß√µes constantes s√£o sempre mensur√°veis. Al√©m disso, se A\\in\\mathcal{F}^{\\prime} , ent√£o E(X\\1_{A})=E(X)P(A)=E\\big{(}E(X)\\1_{A}\\big{)}, (4.23) concluindo a prova. ‚àé Terminamos essa se√ß√£o com o que chamamos da propriedade de torre da esperan√ßa condicional. {proposition} Se \\mathcal{F}^{\\prime}\\subseteq\\mathcal{F}^{\\prime\\prime} s√£o ambas sub- \\sigma -√°lgebras de \\mathcal{F} , ent√£o para X\\in\\mathcal{L}^{1}(P) , temos E\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{|}\\mathcal{F}^{\\prime\\prime}\\big{)}=E(X|% \\mathcal{F}^{\\prime})=E\\big{(}E(X|\\mathcal{F}^{\\prime\\prime})\\big{|}\\mathcal{F% }^{\\prime}\\big{)}, (4.24) ou em outras palavras, independentemente da ordem, prevalece a condi√ß√£o na menor \\sigma -√°lgebra. Consequentemente, E\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{)}=E(X) . Demonstra√ß√£o. Como E(X|\\mathcal{F}^{\\prime}) √© \\mathcal{F}^{\\prime\\prime} -mensur√°vel, a Proposi√ß√£o¬†4.2, aplicada com X=1 , mostra a primeira igualdade em (4.24). Falta mostrar que E\\big{(}E(X|\\mathcal{F}^{\\prime\\prime})\\big{|}\\mathcal{F}^{\\prime}\\big{)} √© a esperan√ßa condicional de X dada \\mathcal{F}^{\\prime} . Obviamente ela √© \\mathcal{F}^{\\prime} -mensur√°vel, e nos resta verificar a segunda condi√ß√£o. Mas para todo A\\in\\mathcal{F}^{\\prime} , lembrando que A tamb√©m pertence a \\mathcal{F}^{\\prime\\prime} e usando a defini√ß√£o de esperan√ßa condicional duas vezes, E\\Big{(}E\\big{(}E(X|\\mathcal{F}^{\\prime\\prime})\\big{|}\\mathcal{F}^{\\prime}\\big% {)}\\1_{A}\\Big{)}=E\\big{(}E(X|\\mathcal{F}^{\\prime\\prime})\\1_{A}\\big{)}=E(X\\1_{A% }). (4.25) O que termina a prova da proposi√ß√£o. ‚àé {lemma} Se X:\\Omega\\to E √© um elemento aleat√≥rio e f:\\Omega\\to\\mathbb{R} √© \\sigma(X) -mensur√°vel, ent√£o existe uma g:E\\to\\mathbb{R} mensur√°vel tal que f=g\\circ X . Demonstra√ß√£o. Como de costume, consideramos primeiramente o caso f=\\1_{A} Claramente A tem que pertencer a \\sigma(X) , ou seja A=X^{-1}(B) para algum B\\in\\mathcal{A} . Neste caso colocamos g=\\1_{B} , donde obtemos f(\\omega)=1\\Leftrightarrow\\omega\\in A\\Leftrightarrow X(\\omega)\\in B% \\Leftrightarrow g\\circ X=1 . No caso em que f √© simples, temos f=\\sum_{i}a_{i}(g_{i}\\circ X)=(\\sum_{i}a_{i}g_{i})\\circ X . Se f √© positiva, ent√£o ela √© um limite crescente de fun√ß√µes do tipo g_{n}\\circ X , al√©m disso podemos tomar g_{n} crescentes, pois f_{n+1}=f_{n+1}\\vee f_{n}=(g_{n+1}\\circ X)\\vee(g_{n}\\circ X)=(g_{n}\\vee g_{n+1% })\\circ X. (4.26) Finalmente usamos a linearidade da composi√ß√£o novamente para resolver o caso geral f=f_{+}-f_{-} . ‚àé Se X:\\Omega\\to E √© elemento aleat√≥rio, ent√£o E(Y|\\sigma(X)) √© obviamente \\sigma(X) -mensur√°vel. Pelo lema anterior, E(Y|\\sigma(X))=g\\circ X para alguma g:E\\to\\mathbb{R} . Nesse caso denotamos E(Y|X=x)=g(x). (4.27) {exercise} Mostre que g √© √∫nica X\\circ P -quase certamente. Gostar√≠amos de dizer que E(Y|X=x) satisfaz alguma propriedade que justifique essa nota√ß√£o. Apesar de que apenas na pr√≥xima se√ß√£o poderemos justificar completamente essa nomenclatura, nesse momento j√° podemos mostrar a seguinte rela√ß√£o E(Y)=E\\big{(}E(Y|X)\\big{)}=E\\big{(}E(Y|X=x)\\circ X\\big{)}=\\int E(Y|X=x)(X\\circ P% )(\\d{x}). Em outras palavras, para integrar Y , basta conhecermos a distribui√ß√£o de X e a esperan√ßa condicional de Y , dado que X=x . {exercise} Sejam X e Y as coordenadas can√¥nicas em E_{1}\\times E_{2} , com a probabilidade P=\\mu_{1}\\otimes\\mu_{2} e seja f:E_{1}\\times E_{2}\\to\\mathbb{R} em \\mathcal{L}^{1}(P) . Mostre que E(f|X=x)=\\int f(x,y)\\mu_{2}(\\d{y}). (4.28) {exercise} Se K √© um n√∫cleo de transi√ß√£o entre E_{1} e \\mathbb{R} e P_{1} √© uma probabilidade em E_{1} , mostre que em P_{1}\\star K temos E(X_{2}|X_{1}=x_{1})=\\int x_{2}K(x_{1},\\d{x}_{2}). (4.29) Um outro resultado bastante importante √© o seguinte {theorem} [Teorema da Converg√™ncia Dominada para Esperan√ßas Condicionais] Se X_{n}\\to X e existe Y\\in\\mathcal{L}^{1}(P) tal que |X_{n}|\\leq Y para todo n , ent√£o E(X_{n}|\\mathcal{F})\\to E(X|\\mathcal{F})\\text{ $P$-quase certamente.} (4.30) Demonstra√ß√£o. Seja Z_{n}=\\sup_{k\\geq n}|X_{k}-X| o erro m√°ximo √† partir de n . Claramente, Z_{n}\\downarrow 0 quase certamente e al√©m disso |Z_{n}|\\leq\\sup_{k\\geq 1}|X_{k}|+|X|\\leq 2Y, (4.31) donde E(Z_{n})\\to E(0)=0 , quase certamente pelo Teorema da Converg√™ncia Dominada. Obviamente E(Z_{n}|\\mathcal{F}) √© uma sequ√™ncia positiva e n√£o-crescente, logo decresce quase certamtente para algum Z . Da√≠, \\big{|}E(X_{n}|\\mathcal{F})-E(X|\\mathcal{F})\\big{|}\\leq E(Z_{n}|\\mathcal{F})% \\downarrow Z\\geq 0. (4.32) Mas E(Z)\\leq E\\big{(}E(Z_{n}|\\mathcal{F})\\big{)}=E(Z_{n}) . Como E(Z_{n}) vai a zero pelo Teorema da Converg√™ncia Dominada, temos que Z=0 quase certamente como gostar√≠amos. ‚àé {exercise} Sejam Z_{1},Z_{2},\\dots vari√°veis aleat√≥rias \\iidem \\mathcal{L}^{1}(P) com E(Z_{1})=0 . ‚ÄÉa)‚ÄãDefina X_{0}=0 e X_{n}=\\sum_{i=1}^{n}Z_{i},\\text{ para $n\\geq 1$.} (4.33) Mostre que E(X_{n+1}|Z_{1},\\dots,Z_{n})=X_{n} . ‚ÄÉb)‚ÄãSupondo agora que Z_{1}\\in\\mathcal{L}^{2}(P) e E(Z)=0 , defina Y_{0}=0 e Y_{n}=\\Big{(}\\sum_{i=1}^{n}Z_{i}\\Big{)}^{2}-nE(Z_{1}^{2}) (4.34) Mostre que E(Y_{n+1}|Z_{1},\\dots,Z_{n})=Y_{n} . \\todosec T√≥pico: Martingais a tempo discretofazer‚Ä¶ \\todosec T√≥pico: Propriedade fraca de Markovmostrar que cadeias = processos‚Ä¶ \\todosec T√≥pico: Recorr√™ncia e transi√™nciamarkov recorr√™ncia/transi√™ncia + periodicidade‚Ä¶ Previous page Next page"],[["index.html","Ch4.html","Ch4.S3.html"],"4.3 Probabilidade Condicional Regular ‚Ä£ Cap√≠tulo 4 Esperan√ßa condicional ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Probabilidade Condicional Regular 4.3 Probabilidade Condicional Regular J√° sabemos definir por exemplo E(\\1_{A}|X=x) . Gostar√≠amos por√©m de garantir que essa express√£o definisse uma probabilidade em A , e chamar√≠amos essa probabilidade de P(A|X=x) . Mas certamente gostar√≠amos que P(\\cdot|X=x) fosse uma fun√ß√£o \\sigma -aditiva. Essa especula√ß√£o parece promissora, por exemplo se A e B s√£o disjuntos, P(A\\cup B|\\mathcal{F}^{\\prime})=E(\\1_{A\\cup B}|\\mathcal{F}^{\\prime})=E(\\1_{A}|% \\mathcal{F}^{\\prime})+E(\\1_{B}|\\mathcal{F}^{\\prime})=P(A|\\mathcal{F}^{\\prime})% +P(B|\\mathcal{F}^{\\prime}). √ìtimo, mas ainda temos o seguinte problema. Lembramos que a equa√ß√£o acima est√° bem definida apenas quase certamente. Poder√≠amos portanto garantir que para uma classe enumer√°vel de conjuntos A\\in\\mathcal{F} , essa aditividade fosse satisfeita. Por√©m, a \\sigma -√°lgebra \\mathcal{F} √© frequentemente n√£o enumer√°vel, portanto n√£o conseguimos a \\sigma -aditividade plena. Isso pode ser contornado se o espa√ßo for can√¥nico, como afirma o nosso pr√≥ximo resultado. Ele nos ajudar√° bastante ao fazermos c√°lculos usando condicionais, de maneira semelhante √† Lei da Probabilidade Total. Esse √© o conte√∫do do seguinte resultado. {theorem} [Teorema da Desintegra√ß√£o] Sejam espa√ßos mensur√°veis (\\Omega,\\mathcal{F}) e (E,\\mathcal{A}) , com E can√¥nico. Se P √© uma probabilidade no espa√ßo produto (\\Omega\\times E,\\mathcal{F}\\otimes\\mathcal{A}) e denotamos por P_{\\Omega}=P\\circ X_{1} a primeira distribui√ß√£o marginal de P , ent√£o existe um n√∫cleo de transi√ß√£o K:\\Omega\\times\\mathcal{A}\\to[0,1] satisfazendo P=P_{\\Omega}\\star K, (4.35) Em particular, P(A\\times B)=\\int_{A}K(\\omega,B)P_{\\Omega}(\\d{\\omega})\\text{ para todo $A\\in% \\mathcal{F}$, $B\\in\\mathcal{A}$}. (4.36) Nesse caso denotamos K(\\omega,B) por P[X_{2}\\in B|X_{1}=\\omega] (como de costume X_{i} denota a i -√©sima coordenada can√¥nica). Demonstra√ß√£o. Como de costume, basta resolver o caso (E,\\mathcal{A})=(\\mathbb{R},\\mathcal{B}(\\mathbb{R})) . De fato, se assumimos a validade do teorema para a reta, podemos usar a fun√ß√£o bi-mensur√°vel \\phi:E\\to B\\in\\mathcal{B}(\\mathbb{R}) para concluir o caso geral. Nos restringiremos agora ao espa√ßo (\\Omega\\times\\mathbb{R},\\mathcal{F}\\otimes\\mathcal{B}(\\mathbb{R}),P) . Para cada q\\in\\mathbb{Q} , definimos P^{q}_{\\Omega}:\\mathcal{F}\\to[0,1] por P^{q}_{\\Omega}(A)=P\\big{(}(-\\infty,q]\\times A\\big{)}. (4.37) Observando que P^{q}_{\\Omega} √© absolutamente cont√≠nua com respeito a P_{\\Omega} , podemos definir F(\\omega,q)=\\frac{\\d{P}^{q}_{\\Omega}}{\\d{P}_{\\Omega}}(\\omega). (4.38) Observamos as seguintes propriedades de F : ‚ÄÉa)‚Äãpara cada q\\in\\mathbb{Q} , F(\\cdot,q)\\in[0,1] , P_{\\Omega} -quase certamente, pois P^{q}_{\\Omega}(A)\\leq P_{\\Omega}(A) para todo A\\in\\mathcal{F} , ‚ÄÉb)‚Äãpara q<q^{\\prime}\\in\\mathbb{Q} , F(\\cdot,q)\\leq F(\\cdot,q^{\\prime}) , P_{\\Omega} -quase certamente, pois P^{q}_{\\Omega}(A)\\leq P^{q^{\\prime}}_{\\Omega}(A) para todo A\\in\\mathcal{F} e ‚ÄÉc)‚Äã F(\\cdot,n)\\to 1 (analogamente F(\\cdot,-n)\\to 0 ) quando n tende a infinito, P_{\\Omega} -quase certamente. Para ver isso, note que a sequ√™ncia de vari√°veis aleat√≥rias F(\\cdot,n) √© quase certamente mon√≥tona n√£o decrescente, logo converge P_{\\Omega} -quase certamente. Sendo limitada, converge em \\mathcal{L}^{1} e como sua integral em P_{\\Omega} converge para um, F(\\cdot,n)\\to 1 , quase certamente (analogamente para F(\\cdot,-n) ). Existe pois um conjunto \\Omega^{\\prime}\\in\\mathcal{F} com P_{\\Omega}(\\Omega^{\\prime})=1 no qual as tr√™s hip√≥teses acima s√£o satisfeitas. Definimos \\hat{F}(\\omega,q) como sendo igual a F(\\omega,q) em \\Omega^{\\prime} e igual a F_{0}(q) (uma fun√ß√£o de distribui√ß√£o fixa) caso contr√°rio (que claramente ser√° mensur√°vel). Finalmente podemos definir \\tilde{F}(\\omega,x)=\\inf_{q\\in\\mathbb{Q};q\\downarrow x}\\hat{F}(\\omega,q) , que satisfaz para todo \\omega as hip√≥teses do Teorema¬†2.3. Logo, existe para cada \\omega\\in\\Omega uma medida K(\\omega,\\cdot) em (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) satisfazendo K(\\omega,(-\\infty,q])=F(\\omega,q) P_{\\Omega} -quase certamente. Precisamos mostrar que K √© um n√∫cleo, e para isso basta observar que F(\\omega,q) s√£o mensur√°veis e a fam√≠lia \\{(-\\infty,q];q\\in\\mathbb{Q}\\} forma um \\pi -sistema que gera \\mathcal{B}(\\mathbb{R}) . Finalmente, vamos verificar (4.36), notando que se A\\in\\mathcal{F} e B=(-\\infty,q] , \\int_{A}K(\\omega,B)P_{\\Omega}(\\d{\\omega})=\\int_{A}F(\\omega,q)P_{\\Omega}(\\d{% \\omega})=P^{q}_{\\Omega}(A)=P(A\\times B). (4.39) Como a classe B √© um \\pi -sistema gerando \\mathcal{B}(\\mathbb{R}) terminamos a prova. ‚àé Interpretamos P[X_{2}\\in B|X_{1}=\\omega] da seguinte forma. Se algu√©m tiver acesso √† \\sigma -√°lgebra \\sigma(X_{1}) , ou seja, essa pessoa √© capaz de observar o valor de \\omega , ela pode n√£o saber o valor de X_{2} , mas j√° pode atualizar sua distribui√ß√£o para P(X_{2}\\in\\cdot|X_{1}=\\omega) . Uma das grandes vantagens de ter um n√∫cleo de transi√ß√£o a determinar uma distribui√ß√£o conjunta, como foi feito acima, √© que podemos usar a vers√£o generalizada de Fubini. Antes, n√≥s somente podiamos usar Fubini para espa√ßos constru√≠dos atrav√©s de um n√∫cleo. {exercise} Se \\Omega=E_{1}\\times E_{2} com E_{2} can√¥nico √© dotado da probabilidade \\d{P}=\\rho(x_{1},x_{2})\\mu_{1}\\otimes\\mu_{2}(\\d{x}_{1}\\d{x}_{2}) , mostre que P(X_{2}\\in A|X_{1}=x_{1})=\\frac{\\int_{A}\\rho(x_{1},x_{2})\\mu_{2}(\\d{x}_{2})}{% \\int\\rho(x_{1},x_{2})\\mu_{2}(\\d{x}_{2})}, (4.40) (X_{1}\\circ P) -quase certamtente. {exercise} Sejam X_{1} e X_{2} as proje√ß√µes can√¥nicas em um espa√ßo produto \\Omega\\times E , com E can√¥nico. Ent√£o, se X_{1} e X_{2} s√£o independentes com respeito a P , vale P[X_{2}\\in B|X_{1}=\\omega]=P[X_{2}\\in B]\\text{ para $(X_{1}\\circ P)$-quase % todo $\\omega$}. (4.41) {exercise} Considere em (\\mathbb{R}^{2},\\mathcal{B}(\\mathbb{R}^{2})) as proje√ß√µes can√¥nicas X_{1} e X_{2} . Calcule, em cada um dos exemplos abaixo, a probabilidade condicional regular P[X_{1}\\in\\cdot|X_{2}=x_{2}] , justificando sua resposta, ‚ÄÉa)‚ÄãQuando P √© a medida uniforme em T=\\{(x,y)\\in[0,1]^{2};x\\leq y\\} (ou seja, a medida de Lebesgue em \\mathbb{R}^{2} restrita a T e normalizada para ser uma probabilidade). ‚ÄÉb)‚ÄãQuando P √© a medida U_{S^{1}} (uniforme em S^{1} ). Previous page Next page"],[["index.html","Ch4.html","Ch4.S4.html"],"4.4 Princ√≠pio da substitui√ß√£o ‚Ä£ Cap√≠tulo 4 Esperan√ßa condicional ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Princ√≠pio da substitui√ß√£o 4.4 Princ√≠pio da substitui√ß√£o O Teorema¬†4.3 √© bastante poderoso e nos permite definir e calcular diversas probabilidades, como faremos √† seguir. Nessa se√ß√£o construiremos nossa √∫ltima vers√£o de probabilidade condicional regular que n√£o se restringe a espa√ßos produtos e nos fornecer√° o que chamamos de Princ√≠pio da Substitui√ß√£o. {theorem} Sejam (\\Omega,\\mathcal{F},P) e (E,\\mathcal{A}) espa√ßos mensur√°veis can√¥nicos. Considere tamb√©m X:\\Omega\\to E um elemento aleat√≥rio, ent√£o existe um n√∫cleo de transi√ß√£o K de E a \\Omega tal que K(X(\\omega),F)=E[\\1_{F}|X],\\text{ para todo $F\\in\\mathcal{F}$}. (4.42) Tamb√©m denotamos esse n√∫cleo como K(x,F)=P[F|X=x] , que √© √∫nico no sentido que se K^{\\prime} tamb√©m satisfaz (4.42), ent√£o K(x,F)=K^{\\prime}(x,F) para (X\\circ P) -quase todo x\\in E . Al√©m disso vale o que chamamos de Princ√≠pio da Substitui√ß√£o: K(x,[X=x])=1,\\quad\\text{$X\\circ P$-quase certamente}. (4.43) Que pode ser dito de maneira estranha: P[X=x|X=x]=1 , quase certamente. \\Omega E x [X=x] Figura 4.1: O gr√°fico do elemento aleat√≥rio X representado horizontalmente. Os pontos marcados no eixo vertical representam o conjunto [X=x] que possui medida um segundo P[\\;\\cdot\\;|X=x] de acordo com o Teorema¬†4.4 Demonstra√ß√£o. Defina o elemento aleat√≥rio W:\\Omega\\to E\\times\\Omega , dado por W(\\omega)=(X(\\omega),\\omega) , que percorre o gr√°fico de X (representado horizontalmente). Observe que a medida P_{W}:=W\\circ P possui marginais (X_{1}\\circ P_{W})=(X\\circ P) e (X_{2}\\circ P_{W})=P . Como P_{W} satisfaz as condi√ß√µes do Teorema¬†4.3, existe um n√∫cleo K:E\\times\\mathcal{F}\\to[0,1] tal que para todo A\\in\\mathcal{A} , F\\in\\mathcal{F} , P_{W}(A\\times F)=\\int_{A}K(x,F)P_{X}(\\d{x}). (4.44) Fixado F\\in\\mathcal{F} , K(X(\\omega),F) √© obviamente \\sigma(X) mensur√°vel, por ser uma composi√ß√£o de uma fun√ß√£o mensur√°vel em E com X . Logo, para provar (4.42), basta mostrar a segunda propriedade de esperan√ßas condicionais. Se B\\in\\sigma(X) , podemos escrever B=[X\\in A] para algum A\\in\\mathcal{A} , donde \\begin{split}E\\big{[}K(X,F)\\1_{B}\\big{]}&=E\\big{[}K(X,F)\\1_{[X\\in A]}\\big{]}=% \\int_{A}K(x,F)P_{X}(\\d{x})\\\\ &=P_{W}(A\\times F)=E[\\1_{X\\in A}\\1_{F}]=E[\\1_{B}\\1_{F}],\\end{split} (4.45) concluindo a prova de (4.42). Para mostrarmos o Princ√≠pio da Substitui√ß√£o, vamos usar o seguinte lema. {lemma} Se X:\\Omega\\to E √© um elemento aleat√≥dio tomando valores em um espa√ßo E can√¥nico, ent√£o seu gr√°fico G=\\{(\\omega,X(\\omega));\\omega\\in\\Omega\\} √© mensur√°vel na \\sigma -√°lgebra produto \\mathcal{F}\\otimes\\mathcal{A} . Demonstra√ß√£o. Primeiramente, consideramos o caso (E,\\mathcal{A})=(\\mathbb{R},\\mathcal{B}(\\mathbb{R})) . Neste caso, vemos que G=\\bigcap_{n\\geq 1}\\bigcup_{j\\in\\mathbb{Z}}[X\\in\\big{(}j/2^{n},(j+1)/2^{n}\\big% {]}]\\times\\big{(}j/2^{n},(j+1l)/2^{n}\\big{]}, (4.46) que √© mensur√°vel. Caso E seja outro espa√ßo can√¥nico qualquer, existe \\phi:E\\to B\\in\\mathcal{B}(\\mathbb{R}) bi-mensur√°vel e G=\\Phi^{-1}(G_{\\phi\\circ X}) , onde G_{\\phi\\circ X} √© o gr√°fico de \\phi\\circ X e \\Phi(\\omega,x)=(\\omega,\\phi(x)) . Logo G tamb√©m √© mensur√°vel nesse caso. ‚àé Retornando √† prova de (4.43), j√° sabemos que G^{\\prime}=\\{(X(\\omega),\\omega);\\omega\\in\\Omega\\} √© mensur√°vel. Al√©m disso, por defini√ß√£o P_{W}(G^{\\prime})=P[(X(\\omega),\\omega)\\in G^{\\prime}]=P(\\Omega)=1 , ou seja a medida P_{W} tem suporte em G^{\\prime} . Logo podemos escrever \\begin{split}1=P_{W}(G^{\\prime})&=\\int\\int\\1_{G^{\\prime}}(x,\\omega)K(x,\\d{% \\omega})(X\\circ P)(\\d{x})\\\\ &=\\int K(x,[X=x])(X\\circ P)(\\d{x}).\\end{split} (4.47) Mas como o integrado acima pertence a [0,1] , essa integral s√≥ pode ser um se K(x,[X=x])=1 , (X\\circ P) -quase certamente, como desejado. ‚àé {exercise} Sejam X:\\Omega\\to E e Y:\\Omega\\to E^{\\prime} elementos aleat√≥rios com E can√¥nico. Ent√£o existe um n√∫cleo de transi√ß√£o K entre E e E^{\\prime} tal que K(X(\\omega),B)=E[\\1_{Y\\in B}|X],\\text{ para todo $B\\in\\mathcal{A}^{\\prime}$}. (4.48) Poder√≠amos chamar esse n√∫cleo de K(x,B)=P[Y\\in B|X=x] . {exercise} Mostre que se K(x,F)=P[F|X=x] , ent√£o \\int f(\\omega^{\\prime})K(X(\\omega),\\d{\\omega}^{\\prime})=E(f|X)(\\omega),\\text{ % para toda $f\\in\\mathcal{F}$}. (4.49) {exercise} Se Y √© vari√°vel aleat√≥ria e X:\\Omega\\to E √© um elemento aleat√≥rio can√¥nico, mostre que E(Y|X)=\\int yP(Y\\in\\d{y}|X=\\cdot)\\circ X,\\text{ $P$-q.c.} (4.50) Vamos agora mostrar uma aplica√ß√£o do que foi feito acima, tentando justificar o nome Princ√≠pio da Substitui√ß√£o. {lemma} Se X,Y s√£o vari√°veis aleat√≥rias independentes, ent√£o a fun√ß√£o de distribui√ß√£o acumulada F de X+Y √© dada por F(z)=P[X+Y\\leq z]=\\int_{-\\infty}^{\\infty}F_{Y}(z-x)(X\\circ P)(\\d{x}), (4.51) onde F_{Y}(y)=P[Y\\leq y] . Esse lema pode ser visto como uma generaliza√ß√£o do Exerc√≠cio¬†2.5.2 para o caso n√£o absolutamente cont√≠nuo. Vale a pena tentar diferenciar (n√£o rigorosamente) a equa√ß√£o acima em z . Demonstra√ß√£o. Vamos calcular \\begin{split}P[X+Y\\leq z]&=E\\big{(}E(\\1_{[X+Y\\leq z]}|X)\\big{)}\\\\ &=E\\big{(}E(\\1_{[X+Y\\leq z]}|X)\\big{)}\\\\ &=E\\Big{(}P[X+Y\\leq z|X=\\cdot)\\circ X\\Big{)}\\\\ &=E\\Big{(}P[X+Y\\leq z,X=x|X=\\cdot)\\circ X\\Big{)}\\\\ &=E\\Big{(}P[Y\\leq z-x|X=\\cdot]\\circ X\\Big{)},\\end{split} (4.52) onde P[Y+X\\leq z|X=\\cdot] representa a fun√ß√£o x\\mapsto P[Y+X\\leq z|X=x] . Agora vamos usar a hip√≥tese que X e Y s√£o independentes. Isso equivale a dizer que a distribui√ß√£o conjunta desse par √© igual a P_{X}\\otimes P_{Y} e pela unicidade da probabilidade condicional regular temos que P[Y\\in F|X=x]=P[Y\\in F] , (X\\circ P) -quase certamente, veja Exerc√≠cio¬†4.3. Portanto, P[X+Y\\leq z]=E\\big{(}P[Y\\leq z-\\cdot]\\circ X\\big{)}=\\int_{-\\infty}^{\\infty}F_{% Y}(z-x)(X\\circ P)(\\d{x}), (4.53) terminando a prova do lema. ‚àé {exercise} Considere as medidas \\mu_{a}=\\frac{\\delta_{-1}+\\delta_{1}}{2},\\qquad\\text{e}\\qquad\\mu_{b}=\\mathcal{% N}(0,1). (4.54) e K:\\mathbb{R}\\times\\mathcal{B}(\\mathbb{R})\\to[0,1] dada por K(x,A)=\\begin{cases}\\mu_{a}(A-x),&\\text{ se $x<0$,}\\\\ \\mu_{b}(A-x),&\\text{ se $x\\geq 0$,}\\end{cases} (4.55) Mostre que ‚ÄÉa)‚Äã K define um n√∫cleo de transi√ß√£o entre \\mathbb{R} em \\mathbb{R} . ‚ÄÉb)‚ÄãSe X_{1},X_{2},\\dots for uma cadeia de Markov em \\mathbb{R} com n√∫cleo de transi√ß√£o K , ent√£o calcule ‚ÄÉ‚ÄÉi)‚Äã E(X_{i}) , para todo i\\geq 1 e ‚ÄÉ‚ÄÉii)‚Äã \\text{Var}(X_{i}) , para todo i\\geq 1 . ‚ÄÉ‚ÄÉiii)‚ÄãMostre que \\frac{\\sum_{i=1}^{n}X_{i}}{\\sqrt{n}}\\Rightarrow\\mathcal{N}(0,1). (4.56) Previous page Next page"],[["index.html","Ch4.html","Ch4.Sx1.html"],"T√≥pico: Processos de Poisson em ‚Ñù ‚Ä£ Cap√≠tulo 4 Esperan√ßa condicional ‚Ä£ Notas de aula: Probabilidade I","Skip to content. T√≥pico: Processos de Poisson em T√≥pico: Processos de Poisson em \\mathbb{R} Nessa se√ß√£o aplicaremos o conceito de Probabilidade Condicional Regular e do Princ√≠pio da Substitui√ß√£o para estudarmos um importante processo de chegadas chamado Processo de Poisson. O Tenente Boavista est√° encarregado de vigiar o Sargento Pimenta, que frequentemente dorme durante sua vig√≠lia. Para isso, Boavista tem que decidir os momentos t_{1},t_{2},\\dots\\in\\mathbb{R} que ele ir√° verificar se Pimenta est√° cochilando. Uma primeira estrat√©gia poderia ser tomar intervalos igualmente espa√ßados, t_{1}=1,\\dots,t_{k}=k , mas o Sargento certamente iria dormir nos intevalos (k+\\varepsilon,k+1-\\varepsilon) sem se preocupar. Dado esse problema, o Tenente decide escolher tempos aleat√≥rios T_{1},T_{2},\\dots Mas √© importante lembrar que n√£o s√£o todas as distribui√ß√µes que funcionar√£o bem, por exemplo se T_{k}-T_{k-1}\\geq a quase certamente o Sargento ir√° se aproveitar desse intervalinho. A primeira simplifica√ß√£o que o Tenente imagina para esse problema √© a seguinte: dado que houve uma vistoria no instante t_{k} , ent√£o o que acontecer√° √† partir da√≠ ser√° o mesmo processo com o qual ele come√ßou. Isso pode ser traduzido de maneira rigorosa como P\\big{[}(T_{k+1}-t_{k},T_{k+2}-t_{k},\\dots)\\in A|T_{k}=t_{k}\\big{]}=P\\big{[}(T% _{1},T_{2},\\dots)\\in A\\big{]}, (4.57) T_{k}\\circ P -quase certamente. N√£o iremos entrar muito em detalhes sobre qual √© essa esperan√ßa condicional, pois no momento ainda estamos trabalhando heuristicamente, mas j√° podemos dizer que: \\begin{split}P\\big{[}T_{1}\\in A_{1},T_{2}-T_{1}\\in A_{2}\\big{]}&=E\\big{[}\\1_{T% _{1}\\in A_{1}}P[T_{2}-T_{1}\\in A_{2}|T_{1}=t_{1}]\\circ T_{1}\\big{]}\\\\ &\\overset{\\eqref{e:Poisson_incr_ind}}{=}E\\big{[}\\1_{T_{1}\\in A_{1}}P[T_{1}\\in A% _{2}]\\big{]}=P[T_{1}\\in A_{1}]P[T_{1}\\in A_{2}].\\end{split} (4.58) Procedendo de maneira an√°loga, podemos concluir que (T_{1},T_{2}-T_{1},T_{3}-T_{2},\\dots) s√£o uma cole√ß√£o \\iid. Agora o Tenente Boavista somente precisa escolher a distribui√ß√£o de T_{1} . Para essa escolha, ele sabe que se ele n√£o chegar em tempo t , ent√£o o Sargento Pimenta sabe que sua pr√≥xima chegada ter√° distribui√ß√£o P[T_{1}-t\\in A|T_{1}>t] . Como o Tenente Boavista gostaria que essa essa informa√ß√£o fosse in√∫til para o Sargento Pimenta, ele escolher√° P[T_{1}-t\\in A|T_{1}>t]=P[T_{1}\\in A]. (4.59) E sabemos que as distribui√ß√µes \\Exp(\\lambda) , para \\lambda>0 satisfazem isso, portanto j√° temos um candidato ao nosso processo de vistorias, mas antes vamos introduzir algumas nota√ß√µes. J√° podemos perceber por (4.58) que mais importante que os tempos T_{k} , ser√£o os intervalos entre visitas X_{k}=T_{k}-T_{k-1} . Seja \\mathcal{D}\\big{(}[0,\\infty)\\big{)} o espa√ßo de todas as fun√ß√µes c√†dl√†g em \\mathbb{N} , ou seja \\mathcal{D}\\big{(}[0,\\infty)\\big{)}=\\big{\\{}f:\\mathbb{R}_{+}\\to\\mathbb{N}:f% \\text{ \\'{e} cont\\'{\\i}nua \\`{a} direita e com limite \\`{a} esquerda}\\big{\\}}. Definiremos \\Gamma:\\mathbb{R}^{\\mathbb{N}}\\to\\mathcal{D}\\big{(}[0,\\infty)\\big{)} da seguinte forma: dados (x_{1},x_{2},\\dots)\\in\\mathbb{R}^{\\mathbb{N}} , seja \\Gamma(x_{1},\\dots)=N , tal que N_{t}=\\max\\{n;\\sum_{i=1}^{n}x_{i}\\leq t\\}, (4.60) que conta quantas visitas ocorreram antes de t , veja Figura¬†4.2. t_{1} t_{2} t_{3} t_{4} t_{5} t_{6} t_{7} Figura 4.2: A fun√ß√£o N_{t} definindo o n√∫mero de chegadas do Processo de pontos de Poisson. Note que N √© c√†dl√†g. Poder√≠amos nos perguntar qual √© a \\sigma -√°lgebra que estamos considerando no espa√ßo \\mathcal{D}\\big{(}[0,\\infty)\\big{)} , essa √© uma interessante quest√£o que deve ser abordada em estudos mais profundos desse espa√ßo. Mas por enquanto ser√° suficiente considerarmos a \\sigma -√°lgebra induzida pelo mapa \\Gamma (a maior que ainda o deixa mensur√°vel). Estamos prontos agora pra definir o nosso processo. {definition} Fixado \\lambda>0 , definimos um Processo de Poisson em \\mathbb{R} com par√¢metro \\lambda como a lei \\mathbb{P}_{\\lambda} em \\mathcal{D}\\big{(}[0,\\infty)\\big{)} , dada por \\Gamma\\circ\\Exp(\\lambda)^{\\otimes\\mathbb{N}} . Ou em outras palavras, o processo de contagem de chegadas N_{t} , no qual os intervalos entre chegadas s√£o independentes e distribu√≠dos como \\Exp(\\lambda) . Lembramos que como de costume definimos X_{1},X_{2},\\dots como sendo as proje√ß√µes can√¥nicas em \\mathbb{R}^{\\mathbb{N}} onde definimos \\Exp(\\lambda)^{\\otimes\\mathbb{N}} . Como esses representam os intervalos entre chegadas, definimos tamb√©m T_{k}=\\sum_{i=1}^{k}X_{i},\\text{ para $k\\geq 1$}. (4.61) Podemos agora enunciar o primeiro lema, que nos fornece a distribui√ß√£o do n√∫mero de chegadas em um dado tempo t\\geq 0 . {lemma} Se \\lambda>0 e t\\geq 0 , ent√£o N_{t}\\distr\\Poisson(\\lambda t) sob \\mathbb{P}_{\\lambda} . Demonstra√ß√£o. Vamos primeiramente ver que \\mathbb{P}_{\\lambda}[N_{t}=0]=\\mathbb{P}_{\\lambda}[X_{1}>t]=e^{-\\lambda t}, (4.62) que coincide com o caso poissoniano. Para verificar o caso arbitr√°rio [N_{t}=k] , utilizaremos indu√ß√£o e os resultados de esperan√ßa condicional regular que vimos anteriormente. Primeiro, observe que se x_{1}>s , ent√£o \\Gamma(x_{1},x_{2},\\dots)(r-s)=\\Gamma(x_{1}-s,x_{2},\\dots)(r). (4.63) Logo, \\begin{array}[]{e}\\mathbb{P}_{\\lambda}[N_{t}=k]&=&\\mathbb{P}_{\\lambda}[X_{1}% \\leq t,\\Gamma(X_{2},X_{3},\\dots)(t-X_{1})=k-1]\\\\ &=&\\mathbb{E}_{\\lambda}\\Big{[}\\1_{X_{1}\\leq t}\\mathbb{P}_{\\lambda}[\\Gamma(X_{2% },X_{3},\\dots)(t-X_{1})=k-1|X_{1}]\\Big{]}\\\\ &\\overset{\\textnormal{Subst.}}{=}&\\mathbb{E}_{\\lambda}\\Big{[}\\1_{X_{1}\\leq t}% \\mathbb{P}_{\\lambda}[\\Gamma(X_{2},X_{3},\\dots)(t-x_{1})=k-1|X_{1}=x_{1}]\\circ X% _{1}\\Big{]}\\\\ &\\overset{\\textnormal{induc.}}{=}&\\mathbb{E}_{\\lambda}\\Big{[}\\1_{X_{1}\\leq t}% \\big{(}\\Poisson(\\lambda(t-x_{1}))(\\{k-1\\})\\big{)}\\circ X_{1}\\Big{]}\\\\ &=&\\mathbb{E}_{\\lambda}\\Big{[}\\1_{X_{1}\\leq t}\\frac{(\\lambda(t-X_{1}))^{k-1}e^% {-\\lambda(t-X_{1})}}{(k-1)!}\\Big{]}\\\\ &=&\\int_{0}^{t}\\frac{(\\lambda(t-x_{1}))^{k-1}e^{-\\lambda(t-x_{1})}}{(k-1)!}% \\lambda e^{-\\lambda x_{1}}\\d{x}_{1}=\\frac{\\lambda^{k}e^{-\\lambda t}}{(k-1)!}% \\frac{t^{k}}{k},\\end{array} como quer√≠amos demonstrar. ‚àé Um outro resultado importante sobre esses processos se relaciona ao fato de reiniciar o sistema em tempo t>0 . Isso √© feito com o seguinte mapa \\theta_{t}:\\mathcal{D}\\big{(}[0,\\infty)\\big{)}\\to\\mathcal{D}\\big{(}[0,\\infty)% \\big{)} , que leva N em \\theta_{t}(N)(s)=N_{s+t}-N_{t}. (4.64) {exercise} Mostre que o mapa \\theta_{t} √© mensur√°vel. {lemma} Fixe \\lambda,t>0 e seja N um processo de Poisson de taxa \\lambda . Ent√£o, para k\\in\\mathbb{Z}_{+} e A mensur√°vel, \\mathbb{P}_{\\lambda}[N_{t}=k,\\theta_{t}\\circ N\\in A]=\\mathbb{P}_{\\lambda}[N_{t% }=k]\\mathbb{P}_{\\lambda}[N\\in A]. (4.65) Em particular, isso mostra que a distribui√ß√£o do processo de Poisson N √© invariante pelo mapa \\theta_{t} . Demonstra√ß√£o. Come√ßamos reescrevendo o evento e condicionando em T_{k} como abaixo \\begin{split}\\mathbb{P}_{\\lambda}&[N_{t}=k,\\theta_{t}\\circ N\\in A]\\\\ &=\\mathbb{P}_{\\lambda}[T_{k}\\leq t,T_{k+1}>t,\\theta_{t}\\circ N\\in A]\\\\ &=\\mathbb{E}_{\\lambda}\\big{[}{\\bf 1}_{T_{k}\\leq t}\\mathbb{E}_{\\lambda}[X_{k+1}% >t-t_{k},\\theta_{t}\\circ N\\in A|T_{k}=t_{k}]\\circ T_{k}\\big{]}\\\\ &=\\mathbb{E}_{\\lambda}\\Big{[}{\\bf 1}_{T_{k}\\leq t}\\mathbb{E}_{\\lambda}\\big{[}X% _{k+1}>t-t_{k},\\Gamma(X_{k+1}-(t-t_{k}),X_{k+2},X_{k+3},\\dots)\\in A|T_{k}=t_{k% }\\big{]}\\circ T_{k}\\Big{]},\\\\ \\intertext{que, usando que $X_{i}$ s\\~{a}o independentes e $X_{k+1}$ n\\~{a}o % tem sem mem\\'{o}ria, \\'{e} igual a}&=\\mathbb{E}_{\\lambda}\\Big{[}{\\bf 1}_{T_{k}% \\leq t}\\mathbb{P}_{\\lambda}\\big{[}X_{k+1}>t-t_{k}|T_{k}=t_{k}\\big{]}\\circ T_{k% }\\Big{]}\\mathbb{P}_{\\lambda}[N\\in A]\\\\ &=\\mathbb{P}_{\\lambda}[N_{t}=t]\\mathbb{P}_{\\lambda}[N\\in A],\\end{split} terminando a prova do lema. ‚àé Como corol√°rio do lema acima, podemos deduzir que um processo de Poisson possui incrementos independentes. Mais precisamente, {corollary} Seja N um Processo de Poisson N com taxa \\lambda>0 . Considerando tamb√©m tempos 0=t_{0}<t_{1}<\\dots<t_{j} , e inteiros k_{1},\\dots,k_{j}\\geq 0 temos \\mathbb{P}_{\\lambda}\\big{[}N_{t_{1}}=k_{1},\\dots,N_{t_{j}}-N_{t_{j-1}}=k_{j}% \\big{]}=\\mathbb{P}_{\\lambda}[N_{t_{1}}=k_{1}]\\cdots\\mathbb{P}_{\\lambda}[N_{t_{% j}-t_{j-1}}=k_{j}] Demonstra√ß√£o. Basta observar que [N_{t_{2}}-N_{t_{1}},\\dots,N_{t_{j}}-N_{t_{j-1}}]=[N_{t_{2}-t_{1}},\\dots,N_{t_% {j}-t_{1}}-N_{t_{j-1}-t_{1}}]\\circ\\theta_{t_{1}} (4.66) e aplicar o lema para obter \\begin{split}\\mathbb{P}_{\\lambda}\\big{[}&N_{t_{1}}=k_{1},\\dots,N_{t_{j}}-N_{t_% {j-1}}=k_{j}\\big{]}\\\\ &=\\mathbb{P}_{\\lambda}[N_{t_{1}}=k_{1}]\\mathbb{P}_{\\lambda}[N_{t_{2}-t_{1}}=k_% {2},\\dots N_{t_{j}-t_{1}}-N{t_{j-1}-t_{1}}=k_{j}].\\end{split} Repetindo essa opera√ß√£o iterativamente, obtemos o resultado desejado. ‚àé T_{1},\\dots,T_{k}\\text{ under }\\mathbb{P}^{t,k}_{\\lambda}\\overset{d}{\\sim} (4.67) x_{1}=t_{1} , x_{2}=t_{2}-t_{1},\\dots,x_{k}=t_{k}-t_{k-1} \\begin{split}\\rho^{t,k}_{\\rho}(t_{1},\\dots,t_{k})&={\\bf 1}_{0\\leq t_{1}\\leq% \\dots\\leq t_{k}\\leq t}\\;\\frac{1}{\\mathbb{P}_{\\lambda}[N_{t}=k]}\\lambda e^{-% \\lambda x_{1}}\\lambda e^{-\\lambda x_{2}}\\cdots e^{-\\lambda x_{k}}e^{-\\lambda(t% -t_{k})}\\\\ &={\\bf 1}_{0\\leq t_{1}\\leq\\dots\\leq t_{k}\\leq t}\\;\\frac{k!}{e^{-\\lambda t}(% \\lambda t)^{k}}\\lambda^{k}e^{-\\lambda t}={\\bf 1}_{0\\leq t_{1}\\leq\\dots\\leq t_{% k}\\leq t}\\;\\frac{k!}{t^{k}}.\\end{split} (4.68) Note que n√£o depende de \\lambda . Considere vari√°veis uniformes U_{1},\\dots,U_{k} no intervalo [0,t] \\rho^{t,k}(u_{1},\\dots,u_{k})={\\bf 1}_{\\tilde{u}_{1},\\dots,\\tilde{u}_{k}\\in[0,% t]}\\;\\frac{1}{t^{k}} (4.69) Seja \\tilde{U}_{1}<\\dots<\\tilde{U}_{k} a vers√£o ordenada das U_{i} ‚Äôs. (\\tilde{U}_{1},\\dots,\\tilde{U}_{k})\\overset{q.c.}{=}\\sum_{\\sigma\\text{ perm. % de $\\{1,\\dots,k\\}$}}(U_{\\sigma_{1}},\\dots,U_{\\sigma_{k}}){\\bf 1}_{0\\leq U_{% \\sigma_{1}}\\leq\\dots\\leq U_{\\sigma_{k}}\\leq t} (4.70) Ent√£o, \\begin{split}\\tilde{\\rho}^{t,k}&={\\bf 1}_{0\\leq\\tilde{u}_{1}\\leq\\dots\\leq% \\tilde{u}_{k}\\leq t}\\;\\frac{1}{t^{k}}\\sum_{\\sigma\\text{ perm. de $\\{1,\\dots,k% \\}$}}\\rho^{t,k}(\\tilde{u}_{\\sigma_{1}},\\dots,\\tilde{u}_{\\sigma_{k}})\\\\ &={\\bf 1}_{0\\leq\\tilde{u}_{1}\\leq\\dots\\leq\\tilde{u}_{k}\\leq t}\\;\\frac{k!}{t^{k% }}\\end{split} (4.71) \\todosec T√≥pico: Processos de Markov em tempo cont√≠nuofazer‚Ä¶ \\todosec T√≥pico: Sistemas de part√≠culasfazer‚Ä¶ Previous page Next page"],[["index.html","Ch4.html"],"Cap√≠tulo 4 Esperan√ßa condicional ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Esperan√ßa condicional Cap√≠tulo 4 Esperan√ßa condicional Previous page Next page"],[["index.html","Ch5.html"],"Cap√≠tulo 5 Solu√ß√µes de exerc√≠cios ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Solu√ß√µes de exerc√≠cios Cap√≠tulo 5 Solu√ß√µes de exerc√≠cios Solu√ß√£o de 3.3 Primeiramente, vamos ver qual √© a distribui√ß√£o de R_{0} . Vamos escrever R_{0}=E_{0}+D_{0} , onde E_{0} √© o n√∫mero de casas acess√≠veis √† esquerda e D_{0} √† direita. Note que E_{0} e D_{0} s√£o independentes e identicamente distribu√≠das, com P[D_{0}=l]=P[X_{l}=1,X_{i}=0\\text{ para $i=0,\\dots,l-1$}]=p(1-p)^{l}. (5.1) Podemos agora calcular P[R_{0}=k]=\\sum_{l=0}^{k}P[D_{0}=l,E_{0}=k-l]=\\sum_{l=0}^{k}p^{2}(1-p)^{k}=p^{% 2}k(1-p)^{k}. (5.2) Al√©m disso, E(R_{0})=2E(D_{0})=\\sum_{l=0}^{\\infty}lP[D_{0}=l]=2p\\sum_{l=0}^{\\infty}l(1-p)^% {l}=\\frac{2(1-p)}{p}=:m. (5.3) O que resolve o primeiro item. A grande dificuldade do segundo item √© que as vari√°veis R_{i} n√£o s√£o independentes, veja por exemplo que P[R_{0}=0,R_{1}=2,R_{2}=0]=0 . Nesse caso, o m√©todo do segundo momento deve ser feito com aten√ß√£o. Chamando de S_{n}=\\sum_{i=1}^{n}R_{i} , temos P\\Big{[}\\Big{|}\\frac{1}{n}S_{n}-E(R_{0})\\Big{|}>a\\Big{]}\\leq\\frac{\\text{Var}(S% _{n})}{a^{2}n^{2}}, (5.4) mas a vari√¢ncia da soma n√£o se torna a soma das vari√¢ncias. De fato \\begin{split}\\text{Var}(S_{n})&=E\\Big{(}\\big{(}\\sum_{i=1}^{n}(R_{i}-E(R_{i}))% \\big{)}^{2}\\Big{)}=\\sum_{i=1}^{n}\\sum_{j=1}^{n}E\\Big{(}\\big{(}R_{i}-E(R_{i})% \\big{)}\\big{(}R_{j}-E(R_{j})\\big{)}\\Big{)}\\\\ &=\\sum_{i=1}^{n}\\sum_{j=1}^{n}\\text{Cov}(R_{i},R_{j})=n\\text{Var}(R_{0})+2\\sum% _{k=1}^{n-1}(n-k)\\text{Cov}(R_{0},R_{k}).\\end{split} (5.5) Aqui j√° temos metade da estimativa resolvida, mas ainda falta obter uma estimativa expl√≠cita. Ent√£o precisamos estimar superiormente \\text{Cov}(R_{i},R_{j})=\\text{Cov}(R_{0},R_{j-1}) . Podemos calcular essa quantidade explicitamente, mas vamos evitar contas chatas fazendo uma estimativa do tipo \\text{Cov}(R_{0},R_{k})\\leq c\\exp\\{-c^{\\prime}k\\},\\text{ para todo $k\\geq 1$}. (5.6) O que nos daria que \\text{Var}(S_{n})\\leq n\\text{Var}(R_{0})+2\\sum_{k=1}^{n-1}(n-k)c\\exp\\{-c^{% \\prime}k\\}\\leq c^{\\prime\\prime}n. (5.7) Donde a probabilidade que quer√≠amos estimar √© no m√°ximo {c}/{a^{2}n} , como no caso independente. Para obter a prometida cota para a covari√¢ncia, observe que podemos truncar D_{0} e E_{k} para obter independ√™ncia. Definindo \\tilde{R_{0}}=E_{0}+(D_{0}\\wedge\\lfloor k/2\\rfloor)\\text{ e }\\tilde{R}_{k}=D_{% k}+(E_{k}\\wedge\\lfloor k/2\\rfloor), (5.8) temos que \\tilde{R}_{0} e \\tilde{R}_{k} s√£o independentes (pois dependem de elos disjuntos). Da√≠ \\begin{split}\\text{Cov}(R_{0},R_{k})&=E(R_{0}R_{k})-m^{2}\\\\ &=E(\\tilde{R}_{0}\\tilde{R_{k}})+E(R_{0}R_{k}\\1{[R_{0}\\neq\\tilde{R}_{0}]\\cup[R_% {k}\\neq\\tilde{R}_{k}]})-m^{2}\\\\ &\\leq E(\\tilde{R}_{0})^{2}-m^{2}+E\\big{(}(E_{0}+D_{0})(E_{k}+D_{k})\\1{[R_{0}% \\neq\\tilde{R}_{0}]\\cup[R_{k}\\neq\\tilde{R}_{k}]}\\big{)}\\\\ &\\leq E\\big{(}(E_{0}+k+D_{k})^{2}\\1{[R_{0}\\neq\\tilde{R}_{0}]\\cup[R_{k}\\neq% \\tilde{R}_{k}]}\\big{)}\\\\ &=E\\big{(}(E_{0}+k+D_{k})^{2}\\big{)}P\\big{(}[R_{0}\\neq\\tilde{R}_{0}]\\cup[R_{k}% \\neq\\tilde{R}_{k}]\\big{)}\\\\ &\\leq\\big{(}2E(E_{0}^{2})+k^{2}+2kE(E_{0})+E(E_{0})^{2}\\big{)}\\cdot 2\\cdot P[R% _{0}\\neq\\tilde{R}_{0}]\\\\ &\\leq ck^{2}(1-p)^{\\lfloor k/2\\rfloor}\\leq c\\exp\\{-c^{\\prime}k\\}.\\end{split} (5.9) Finalizando a cota para a covari√¢ncia. Previous page Next page"],[["index.html","Chx1.html"],"Licen√ßa ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Licen√ßa Licen√ßa Esse trabalho √© licenciado nos termos da licen√ßa Creative Commons Atribui√ß√£o-CompartilhaIgual 3.0 N√£o Adaptada (CC BY-SA 3.0). Assim, qualquer um pode usar, distribuir e modificar o conte√∫do em obras derivadas livremente, incluindo para fins comerciais, desde com a devida cita√ß√£o da fonte. Qualquer viola√ß√£o dos termos da licen√ßa citada ser√° considerado uso ilegal. Previous page Next page"],[["index.html","Chx2.html"],"Contribui√ß√µes ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Contribui√ß√µes Contribui√ß√µes Somos gratos especialmente a Hubert Lacoin, pela revis√£o do texto, assim como pelas colabora√ß√µes autorais. Tamb√©m gostar√≠amos de agradecer Roberto Imbuzeiro de Oliveira Milton Jara Cl√°udio Landim Conrado Costa Rangel Baldasso por diversas discuss√µes, sugest√µes e corre√ß√µes. Previous page Next page"],[["index.html","bib.html"],"Refer√™ncias ‚Ä£ Notas de aula: Probabilidade I","Skip to content. Refer√™ncias Refer√™ncias [1] B. Bollob√°s and O. Riordan (2006) Percolation. Cambridge University Press. External Links: ISBN 9780521872324, LCCN 2006287798, Link Cited by: Cap√≠tulo 2. [2] G. Grimmett (1999) Percolation. Second edition, Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences], Vol. 321, Springer-Verlag, Berlin. External Links: ISBN 3-540-64902-6, MathReview (Neal Madras) Cited by: Cap√≠tulo 2. Previous page Next page"],[["index.html","idx.html"],"√çndice Remissivo ‚Ä£ Notas de aula: Probabilidade I","Skip to content. √çndice Remissivo √çndice Remissivo ] ¬ß1.1 anel de conjuntos ¬ß2.6.1 bi-mensur√°vel ¬ß2.10 Cadia de Markov Cap√≠tulo 2 c√†dl√†g item¬†c condi√ß√£o de compatibilidade ¬ß2.6.2 conjunto livre de somas Cap√≠tulo 2 continuidade no vazio ¬ß2.6.1 converg√™ncia fraca ¬ß3.8.2 coordenadas can√¥nicas ¬ß2.6.2 densidade ¬ß2.2 Desigualdade de Markov ¬ß3.1.1 distribui√ß√£o ¬ß1.4.1 binomial item¬†b conjunta ¬ß2.7 de Bernoulli item¬†a de Poisson Cap√≠tulo 2 exponencial item¬†b geom√©trica item¬†c, ¬ß2.8 marginal ¬ß2.6.2 normal ¬ß3.8.1 uniforme item¬†a \\d{P}=\\rho\\d{\\mu} ¬ß2.2 elemento aleat√≥rio ¬ß1.4 espa√ßo mensur√°vel ¬ß1.1 espa√ßo amostral ¬ß1.1 can√¥nico ¬ß2.10 polon√™s ¬ß2.10.1 esperan√ßa ¬ß3.1 condicional ¬ß4.1 aditividade ¬ß4.2 desigualdade de Jensen ¬ß4.2 monotonicidade ¬ß4.2 T.C.D. ¬ß4.2 T.C.M. ¬ß4.2 torre ¬ß4.2 evento Cap√≠tulo 1, ¬ß1.1 flutua√ß√µes Figura 3.2 fun√ß√£o geradora de momentos ¬ß3.6 taxa ¬ß3.7 fun√ß√£o de distribui√ß√£o ¬ß2.3 F_{X} ¬ß2.3 inclus√£o e exclus√£o item¬†c independ√™ncia de elementos ¬ß2.5.2 de eventos ¬ß2.5, ¬ß2.5.1, ¬ß2.5.1 de \\sigma -√°lgebras ¬ß2.5.2 \\lambda -sistema ¬ß1.3 Lei \\{0,1\\} de Kolmogorov ¬ß3.5 dos Pequenos N√∫meros Cap√≠tulo 2 Forte dos Grandes N√∫meros ¬ß3.4 Fraca dos Grandes N√∫meros ¬ß3.3 M√©todo Probabil√≠stico Cap√≠tulo 2 momento primeiro ¬ß3.2 segundo Cap√≠tulo 3 \\lVert\\mu_{1}-\\mu_{2}\\rVert Cap√≠tulo 2 n√∫cleo de transi√ß√£o ¬ß2.9 Paradoxo de Bertrand Cap√≠tulo 1 passeio aleat√≥rio simples Cap√≠tulo 2 \\pi -sistema ¬ß1.3 Princ√≠pio da Substitui√ß√£o ¬ß4.4, Cap√≠tulo 4 de Grandes Desvios ¬ß3.7 Princ√≠pio de Grandes Desvios ¬ß3.7 probabilidade ¬ß1.2 condicional ¬ß2.8 Processo de Poisson Cap√≠tulo 4 sequ√™ncias intercambi√°veis Cap√≠tulo 2 \\sigma -√°lgebra ¬ß1.1 caudal ¬ß3.5 de borel ¬ß1.1 gerada por \\mathcal{G} ¬ß1.1 trivial ¬ß3.5 Teorema Central do Limite ¬ß3.8.4 da Desintegra√ß√£o ¬ß4.3 da Extens√£o de Caratheodory ¬ß2.6.1 da Extens√£o ¬ß2.10, ¬ß2.6.2 de Dynkin ¬ß1.3 de Fubini para N√∫cleos ¬ß2.9 de Portmanteau Cap√≠tulo 3 trasformada de Laplace ¬ß3.6 varia√ß√£o total Cap√≠tulo 2 vari√¢ncia ¬ß3.2 vari√°vel aleat√≥ria item¬†a integr√°vel ¬ß3.1 X\\distr\\mu item¬†b X\\distr Y item¬†a Previous page"],[["index.html"],"Notas de aula: Probabilidade I","Skip to content. Notas de aula: Probabilidade I Notas de aula: Probabilidade I Augusto Teixeira Next page"]]