[[["index.html","Ch1.html","Ch1.S1.html"],"1.1 Espaços mensuráveis ‣ Capítulo 1 Fundamentos ‣ Notas de aula: Probabilidade I","Skip to content. Espaços mensuráveis 1.1 Espaços mensuráveis Denotaremos sempre por \\Omega o nosso espaço amostral (a princípio qualquer conjunto). Um ponto nesse espaço corresponde por exemplo a um possível resultado do nosso experimento aleatório. {example} Possíveis exemplos de espaço amostral  a)​ \\Omega_{1}=\\{1,2,\\dots,6\\} ,  b)​ \\Omega_{2}=\\mathbb{R}_{+} ,  c)​ \\Omega_{3}=\\{f:[0,1]\\to\\mathbb{R};\\text{$f$ \\'{e} cont\\'{\\i}nua}\\} . Os exemplos acima poderiam ser usados em modelar por exemplo: o resultado de um dado, o volume anual de chuva em uma cidade e o comportamento ao longo do dia do preço de uma ação na bolsa de valores. Consideraremos sempre \\Omega ’s equipados com uma \\sigma -álgebra denotada por \\mathcal{F} . Mais precisamente {definition} Dizemos que \\mathcal{F}\\subseteq\\mathcal{P}(\\Omega) é uma \\sigma -álgebra se  a)​ \\Omega\\in\\mathcal{F} ,  b)​ A\\in\\mathcal{F} implica que A^{c}\\in\\mathcal{F} e  c)​se A_{1},A_{2},\\dots\\in\\mathcal{F} , então \\cup_{i}A_{i}\\in\\mathcal{F} . Nesse caso, dizemos que (\\Omega,\\mathcal{F}) é um espaço mensurável e os elementos A\\in\\mathcal{F} são chamados de eventos. Se \\mathcal{G}\\subseteq\\mathcal{P}(\\Omega) (que chamamos de uma classe ou família), denotamos por \\sigma(\\mathcal{G}) a \\sigma -álgebra gerada por \\mathcal{G} , que é a menor \\sigma -álgebra contendo \\mathcal{G} (ou em outras palavras, a interseção de todas \\sigma -álgebras que contém \\mathcal{G} ). Um exemplo importante é dado pela \\sigma -álgebra de Borel , gerada pelos abertos de uma topologia em \\Omega . {example} Típicos exemplos de \\sigma -álgebra correspondentes aos espaços amostrais do Exemplo 1.1  a)​ \\mathcal{F}_{1}=\\mathcal{P}(\\Omega_{1}) ,  b)​ \\mathcal{F}_{2}=\\mathcal{B}([0,1]) e  c)​ \\mathcal{F}_{3}=\\mathcal{B}(C[0,1]) . {example} Alguns eventos de \\mathcal{F}_{1},\\mathcal{F}_{2} e \\mathcal{F}_{3} acima  a)​ \\{\\text{$x$ \\'{e} \\'{\\i}mpar}\\},\\{1\\}\\subset\\Omega_{1} ,  b)​ [0,1/2],\\{0\\},(\\mathbb{Q}\\cap[0,1])\\subset\\Omega_{2} e  c)​ \\{f:[0,1]\\to\\mathbb{R};f(1)>0\\}\\subset\\Omega_{3} . {exercise} Mostre que \\{f:[0,1]\\to\\mathbb{R};f(t)\\geq 0\\text{ para todo $t\\in[0,1]$}\\}\\subset\\Omega_% {3} é um evento (ou seja, pertence a \\mathcal{F}_{3} ). {notation} Se Q for uma condição qualquer sobre candidatos \\omega\\in\\Omega , escreveremos [\\text{$\\omega$ satisfaz $Q$}] para denotar \\{\\omega\\in\\Omega;\\text{ $\\omega$ satisfaz $Q$}\\} . Por exemplo, \\{f:[0,1]\\to\\mathbb{R};f(1)>0\\} pode ser escrita simplesmente como [f(1)>0] . Previous page Next page"],[["index.html","Ch1.html","Ch1.S2.html"],"1.2 Espaços de probabilidade ‣ Capítulo 1 Fundamentos ‣ Notas de aula: Probabilidade I","Skip to content. Espaços de probabilidade 1.2 Espaços de probabilidade Agora estamos prontos para introduzir o conceito moderno do que é uma probabilidade. {definition} Dado (\\Omega,\\mathcal{F}) espaço mensurável, dizemos que P:\\mathcal{F}\\to[0,1] é uma probabilidade se  a)​ P(\\Omega)=1 e  b)​Seja uma seqüência (A_{i})_{i\\in I} finita ou enumerável de eventos disjuntos ( A_{i}\\cap A_{j}=\\varnothing se i\\neq j ), então P\\big{(}{\\mcup\\nolimits_{i\\in I}}A_{i}\\big{)}=\\sum_{i\\in I}P(A_{i}). (1.1) Obviamente, isso nada mais é que uma medida que associa massa um ao espaço todo. {example} Probabilidades nos espaços do Exemplo 1.1  a)​ P_{1}(A)=(\\#A)/6 em (\\Omega_{1},\\mathcal{F}_{1}) . Ou mais geralmente P_{1}^{\\prime}(A)=\\sum_{i\\in A}p_{i} , onde p_{i}\\geq 0 e \\sum_{i}p_{i}=1 .  b)​ P_{2} pode ser a medida de Lebesgue em ([0,1],\\mathcal{B}([0,1])) . Mais geralmente também podemos ter P_{2}^{\\prime}(A)=\\int_{A}\\rho(x)\\d{x} , onde \\rho:[0,1]\\to\\mathbb{R}_{+} é uma função mensurável, chamada densidade, tal que \\int_{[0,1]}\\rho(x)\\d{x}=1 .  c)​ P_{3}=\\delta_{0} , que atribui o valor um se o evento contém a função identicamente nula ( f\\equiv 0 ) e zero caso contrário. Obviamente o terceiro exemplo é bastante artificial (e inútil). Mas, futuramente, estaremos prontos para introduzir medidas bem interessantes no espaço (\\Omega_{3},\\mathcal{F}_{3}) . {proposition} Valem as afirmativas seguintes  a)​Se A\\subseteq B então P(A)\\leq P(B) .  b)​A cota da união: para I finito ou enumerável P\\big{(}\\mcup\\nolimits_{i\\in I}A_{i}\\big{)}\\leq\\smash{\\sum\\limits_{i\\in I}}P(A% _{i}). (1.2)  c)​O que chamamos de princípio da inclusão e exclusão P\\big{(}\\mcup\\nolimits_{i=1}^{n}A_{i}\\big{)}=\\smash{\\sum\\limits_{k=1}^{n}}(-1)% ^{k-1}\\sum\\limits_{1\\leq i_{1}<\\dots<i_{k}\\leq n}P(A_{i_{1}}\\cap\\dots\\cap A_{i% _{k}}). (1.3) Demonstração. a) Como A\\cap(B\\setminus A)=\\varnothing , então P(B)=P(A\\cup(B\\setminus A))=P(A)+P(B\\setminus A)\\geq P(A). (1.4) b) P(A\\cup B)=P(A\\cup(B\\setminus A))=P(A)+P(B\\setminus A)\\leq P(A)+P(B) . Deixamos o caso enumerável como exercício abaixo. c) Chamamos de A a união dos A_{i} . Basta mostrar a validade da equação abaixo e depois integrar com respeito a P . \\1_{A}(\\omega)=\\sum_{k=1}^{n}(-1)^{k-1}\\sum_{\\begin{subarray}{c}I\\subseteq\\{1,% \\dots,n\\}\\\\ |I|=k\\end{subarray}}\\prod_{i\\in I}\\1_{A_{i}}(\\omega). (1.5) Para tanto, observe que para todo \\omega\\in\\Omega , (\\1_{A}-\\1_{A_{1}})\\cdot\\dots\\cdot(\\1_{A}-\\1_{A_{n}})(\\omega)=0. (1.6) Logo, expandindo o produto acima obtemos \\1_{A}+\\sum_{k=1}^{n}\\sum_{\\begin{subarray}{c}I\\subseteq\\{1,\\dots,n\\}\\\\ |I|=k\\end{subarray}}(-1)^{k}\\prod_{i\\in I}\\1_{A_{i}}(\\omega)=0, (1.7) que equivale a (1.5). ∎ {exercise} Mostre que P\\big{(}\\mcup\\nolimits_{i}A_{i}\\big{)}\\leq\\sum_{i}P(A_{i}) no caso enumerável. {exercise} Mostre que \\begin{split}P\\big{(}\\mcup\\nolimits_{i=1}^{n}A_{i}\\big{)}&\\leq\\sum\\limits_{k=1% }^{m}(-1)^{k-1}\\sum\\limits_{1\\leq i_{1}<\\dots<i_{k}\\leq n}P(A_{i_{1}}\\cap\\dots% \\cap A_{i_{k}})\\text{ se $m$ \\'{e} \\'{\\i}mpar e}\\\\ P\\big{(}\\mcup\\nolimits_{i=1}^{n}A_{i}\\big{)}&\\geq\\sum\\limits_{k=1}^{m}(-1)^{k-% 1}\\sum\\limits_{1\\leq i_{1}<\\dots<i_{k}\\leq n}P(A_{i_{1}}\\cap\\dots\\cap A_{i_{k}% })\\text{ se $m$ \\'{e} par.}\\end{split} {exercise} Seja n\\geq 1 um número inteiro e considere \\Omega=\\{0,1\\}^{n} , o hipercubo de dimensão n (cada \\omega\\in\\Omega pode ser visto como uma função \\omega:\\{1,\\dots,n\\}\\to\\{0,1\\} ). Para cada i\\in\\{1,\\dots,n\\} , definimos o evento A_{i}=\\{\\omega\\in\\Omega;\\omega(i)=1\\} . Dadas duas probabilidades P e P^{\\prime} em (\\Omega,\\mathcal{P}(\\Omega)) , mostre que se P(B)=P^{\\prime}(B) para todos conjuntos B dados por interseções de A_{i} ’s, então P=P^{\\prime} . {proposition} Toda probabilidade P é contínua, isto é:  a)​Se A_{1}\\subseteq A_{2}\\subseteq\\dots\\in\\mathcal{F} for uma sequência crescente de eventos, então \\lim_{n\\to\\infty}P(A_{n})=P(\\mcup\\nolimits_{n=1}^{\\infty}A_{n}) .  b)​Também, se A_{1}\\supseteq A_{2}\\supseteq\\dots\\in\\mathcal{F} , temos \\lim\\limits_{n\\to\\infty}P(A_{n})=P(\\mcap\\nolimits_{n=1}^{\\infty}A_{n}) . Demonstração. a) Observe que \\mcup_{n=1}^{\\infty}A_{n}=\\mcup_{n=1}^{\\infty}\\Big{(}A_{n}\\setminus\\big{(}% \\mcup_{i=1}^{n-1}A_{i}\\big{)}\\Big{)}, (1.8) que são disjuntos. Logo \\begin{split}P\\big{(}\\mcup\\nolimits_{n=1}^{\\infty}A_{n}\\big{)}&=\\sum_{n=1}^{% \\infty}P\\Big{(}A_{n}\\setminus\\big{(}\\mcup\\nolimits_{i=1}^{n-1}A_{i}\\big{)}\\Big% {)}\\\\ &=\\lim_{n\\to\\infty}P({\\mcup\\nolimits_{i=1}^{n}}A_{i})=\\lim_{n\\to\\infty}P(A_{n}% ).\\end{split} (1.9) b) A prova é análoga à de (a) . ∎ {lemma} [Borel-Cantelli - primeira parte] Sejam A_{1},A_{2},\\dots\\in\\mathcal{F} satisfazendo \\sum_{i=1}^{\\infty}P(A_{i})<\\infty . Então P[\\text{$A_{i}$ para infinitos $i$}]:=P\\big{(}{\\mcap\\nolimits_{n=1}^{\\infty}}(% {\\mcup\\nolimits_{i\\geq n}}A_{i})\\big{)}=0. (1.10) Demonstração. Estimamos P\\Big{(}{\\mcap_{n=1}^{\\infty}}\\big{(}{\\mcup\\nolimits_{i\\geq n}}A_{i}\\big{)}% \\Big{)}=\\lim_{n\\to\\infty}P\\big{(}{\\mcup\\nolimits_{i\\geq n}}A_{i}\\big{)}\\leq% \\lim_{n\\to\\infty}{\\textstyle\\sum\\limits_{i\\geq n}}P(A_{i})=0. (1.11) O que termina a prova do lemma. ∎ Demonstração. Sejam A_{1},A_{2},\\dots\\in\\mathcal{F} satisfazendo \\sum_{i=1}^{\\infty}P(A_{i})<\\infty , e defina, para n\\geq 1 , f_{n}=\\sum_{k=1}^{n}\\textbf{1}_{A_{k}}, (1.12) de modo que \\big{[}\\text{$A_{i}$ para infinitos $i$}\\big{]}=\\big{[}\\lim_{n}f_{n}=\\infty% \\big{]}. (1.13) Note agora que (f_{n})_{n\\geq 1} forma uma sequência monótona de funções com \\lim_{n}f_{n}=\\sum_{k=1}^{\\infty}\\textbf{1}_{A_{k}} . Em particular, o Teorema da convergência monótona implica que \\int\\sum_{k=1}^{\\infty}\\textbf{1}_{A_{k}}=\\lim_{n}\\int f_{n}\\d{P}=\\lim_{n}\\sum% _{k=1}^{n}P(A_{i})=\\sum_{i=1}^{\\infty}P(A_{i})<\\infty. (1.14) Isto nos dá que P\\big{(}\\lim_{n}f_{n}=\\infty)=0, (1.15) e completa a demonstração. ∎ Imagine que jogamos todos os dias em uma loteria e que nossa probabilidade de ganhar no dia i é p_{i} . Então se \\sum_{i}p_{i}<\\infty , sabemos que certamente não ganharemos infinitas vezes. Previous page Next page"],[["index.html","Ch1.html","Ch1.S3.html"],"1.3 Sistemas 𝜆-𝜋 ‣ Capítulo 1 Fundamentos ‣ Notas de aula: Probabilidade I","Skip to content. Sistemas 1.3 Sistemas \\lambda - \\pi Uma importante ferramenta para provar fatos teóricos sobre probabilidades é o Teorema de Dynkin que apresentaremos nessa seção. Ele trata de classes de eventos que não são necessariamente \\sigma -álgebras, mas sistemas \\lambda ou \\pi como definidos abaixo. {definition} Dizemos que uma classe \\mathcal{A}\\subseteq\\mathcal{P}(\\Omega) é um \\pi -sistema se for fechado por interseções finitas, isto é: para todos A,B\\in\\mathcal{A} temos A\\cap B\\in\\mathcal{A} . {definition} Dizemos que \\mathcal{A}\\subseteq\\mathcal{P}(\\Omega) é um \\lambda -sistema, se  a)​ \\Omega\\in\\mathcal{A} ,  b)​Sempre que A\\in\\mathcal{A} temos A^{c}\\in\\mathcal{A} .  c)​Para A_{1},A_{2},\\dots\\in\\mathcal{A} disjuntos dois a dois, temos \\cup_{i}A_{i}\\in\\mathcal{A} . {exercise} Dê um exemplo de \\lambda -sistema que não seja uma \\sigma -álgebra. Definimos para \\mathcal{A}\\subseteq\\mathcal{P}(\\Omega) , o menor \\lambda -sistema contendo \\mathcal{A} , ou seja, \\lambda(\\mathcal{A})=\\bigcap_{\\begin{subarray}{c}\\text{$\\mathcal{B}$ $\\lambda$% -sistema}\\\\ \\mathcal{A}\\subseteq\\mathcal{B}\\end{subarray}}\\mathcal{B}. (1.16) É fácil ver que \\lambda(\\mathcal{A}) é sempre um \\lambda -sistema. {theorem} [Dynkin] Se \\mathcal{A} é um \\pi -sistema, então \\lambda(\\mathcal{A})=\\sigma(\\mathcal{A}) . Note pelo Exercício 1.3 que a hipótese de que \\mathcal{A} é um \\pi -sistema é necessária em geral. Demonstração. Obviamente, basta mostrar é que \\lambda(\\mathcal{A}) é fechado por uniões não necessariamente disjuntas. Na verdade, vamos ver que é suficiente provar que \\lambda(\\mathcal{A})\\text{ \\'{e} um $\\pi$-sistema}. (1.17) De fato, caso isso seja provado teremos que \\lambda(\\mathcal{A}) é fechado por diferenças (pois A\\setminus B=A\\cap B^{c} ). Assim, podemos mostrar que \\lambda(\\mathcal{A}) é fechado por uniões enumeráveis, pois se A_{1},A_{2},\\dots\\in\\lambda(\\mathcal{A}) , definimos B_{n}=\\cup_{i=1}^{n}A_{i}=(\\cap_{i=1}^{n}A_{i}^{c})^{c}\\in\\lambda(\\mathcal{A}) e escrevemos \\mcup_{n=1}^{\\infty}A_{n}=\\mcup_{n=1}^{\\infty}\\big{(}A_{n}\\setminus B_{n-1}% \\big{)}, (1.18) que é uma união disjunta de termos em \\lambda(\\mathcal{A}) , logo está em \\lambda(\\mathcal{A}) . Isso mostra que \\lambda(\\mathcal{A}) é uma \\sigma -álgebra e que de fato é suficiente demonstrar (1.17). Vamos primeiramente mostrar que \\lambda(\\mathcal{A}) é fechado por interseções com \\mathcal{A} . Para tanto, definimos \\mathcal{B}=\\big{\\{}B\\in\\lambda(\\mathcal{A});\\text{$B\\cap A\\in\\lambda(\\mathcal% {A})$ para todo $A\\in\\mathcal{A}$})\\big{\\}} e veremos que B=\\lambda(\\mathcal{A}). (1.19) Obviamente, \\mathcal{A}\\subseteq\\mathcal{B} , pois \\mathcal{A} é um \\pi -sistema. Então basta mostrar que \\mathcal{B} é um \\lambda -sistema.  a)​ \\Omega obviamente pertence a \\mathcal{B} .  b)​Se B\\in\\mathcal{B} e A\\in\\mathcal{A} , então B^{c}\\cap A=A\\setminus(B\\cap A)=(A^{c}\\cup(B\\cap A))^{c} . Mas como B\\in\\mathcal{B} , (B\\cap A)\\in\\lambda(\\mathcal{A}) e usando o fato que \\lambda -sistemas são fechados por complementos e uniões disjuntas, B^{c}\\cap A\\in\\lambda(\\mathcal{A}) . Como isso vale para todo A\\in\\mathcal{A} , temos B^{c}\\in\\mathcal{B} por definição.  c)​Se B_{1},B_{2},\\dots\\in\\mathcal{B} são disjuntos e A\\in\\mathcal{A} , então \\big{(}\\mcup\\nolimits_{n=1}^{\\infty}B_{n}\\big{)}\\cap A=\\mcup_{n=1}^{\\infty}% \\big{(}B_{n}\\cup A\\big{)}\\in\\lambda(\\mathcal{A}), (1.20) pois a união acima é disjunta. Logo \\mcup_{n=1}^{\\infty}B_{n}\\in\\mathcal{B} . Isso mostra que \\mathcal{B} é um \\lambda -sistema com \\mathcal{A}\\subseteq\\mathcal{B}\\subseteq\\lambda(\\mathcal{A}) , mostrando (1.19). No próximo passo, definimos \\bar{\\mathcal{B}}=\\{A\\in\\lambda(A);\\text{$B\\cap A\\in\\lambda(A),\\;\\forall B\\in% \\lambda(A)$}\\} e mostraremos que \\bar{\\mathcal{B}}=\\lambda(\\mathcal{A}), (1.21) que vai na direção de provar (1.17). Primeiramente, observe que \\mathcal{A}\\subseteq\\bar{\\mathcal{B}} pois \\mathcal{B}=\\lambda(\\mathcal{A}) (veja a definição de \\mathcal{B} ). Mostraremos agora que \\text{$\\bar{\\mathcal{B}}$ \\'{e} um $\\lambda$-sistema}. (1.22) Para tanto, verificaremos  a)​ \\Omega\\in\\bar{\\mathcal{B}} , que é claro.  b)​Tomando A\\in\\bar{\\mathcal{B}} e B\\in\\lambda(\\mathcal{A}) , A^{c}\\cap B=B\\setminus(A\\cap B)=\\big{(}B^{c}\\cup(A\\cap B)\\big{)}^{c}\\in\\lambda% (\\mathcal{A}) , por um argumento análogo ao apresentado para \\mathcal{B} . Logo A^{c}\\in\\bar{\\mathcal{B}} .  c)​Também o caso de uniões disjuntas é bastante análogo ao feito para \\mathcal{B} . Isso mostra que \\bar{\\mathcal{B}} é um \\lambda -sistema com \\mathcal{A}\\subseteq\\bar{\\mathcal{B}}\\subseteq\\lambda(\\mathcal{A}) , estabelecendo (1.22). Finalmente mostraremos que \\lambda(\\mathcal{A}) é um \\pi -sistema. De fato, dado A\\in\\lambda(\\mathcal{A}) , segue da igualdade \\bar{\\mathcal{B}}=\\lambda(\\mathcal{A}) que A\\cap B\\in\\lambda(\\mathcal{A}) , para todo B\\in\\lambda(\\mathcal{A}) . Logo estabelecemos (1.17), terminando a prova do teorema. ∎ 1.3.1 Igualdade de probabilidades {proposition} Se P_{1} e P_{2} são probabilidades em (\\Omega,\\mathcal{F}) , tais que P_{1}(A)=P_{2}(A) para todo A\\in\\mathcal{A} e \\mathcal{A} é um \\pi -sistema, então P_{1}(B)=P_{2}(B) para todo B\\in\\sigma(\\mathcal{A}) . Demonstração. Seja \\mathcal{B}=\\{A\\in\\mathcal{F};P_{1}(A)=P_{2}(A)\\} . É fácil ver que \\mathcal{B} é um \\lambda -sistema. Logo \\mathcal{B} contém \\lambda(\\mathcal{A}) que é igual a \\sigma(\\mathcal{A}) por Dynkin. ∎ {corollary} Se P_{1} e P_{2} são probabilidades em (\\Omega_{1}\\times\\Omega_{2},\\mathcal{F}_{1}\\otimes\\mathcal{F}_{2}) , tais que P_{1}(A_{1}\\times A_{2})=P_{2}(A_{1}\\times A_{2}),\\text{ para todos $A_{1}\\in% \\mathcal{F}_{1}$, $A_{2}\\in\\mathcal{F}_{2}$,} (1.23) então P_{1}=P_{2} . Demonstração. Obviamente as caixas do tipo A_{1}\\times A_{2} formam um \\pi -sistema que gera \\mathcal{F}_{1}\\otimes\\mathcal{F}_{2} (por definição). ∎ {example} Observe portanto que é importante que \\mathcal{A} seja um \\pi -sistema na Proposição 1.3.1. Imagine por exemplo que \\Omega=\\{0,1\\}^{2} e P_{1}=\\tfrac{1}{4}\\sum_{x\\in\\Omega}\\delta_{x} e P_{2}=\\tfrac{1}{2}(\\delta_{(0,0)}+\\delta_{(1,1)}) . Nesse caso P_{1}(A)=P_{2}(A)=1/2=P_{1}(B)=P_{2}(B), (1.24) com A=\\{(0,0),(0,1)\\} e B=\\{(0,0),(1,0)\\} . Contudo, P_{1}\\neq P_{2} , mesmo tendo \\mathcal{P}(\\Omega)=\\sigma(\\{A,B\\}) . Previous page Next page"],[["index.html","Ch1.html","Ch1.S4.html"],"1.4 Elementos aleatórios ‣ Capítulo 1 Fundamentos ‣ Notas de aula: Probabilidade I","Skip to content. Elementos aleatórios 1.4 Elementos aleatórios Muitas vezes não estamos interessados no resultado exato do nosso experimento aleatório, mas sim em uma determinada medição ou função de \\omega\\in\\Omega . Por exemplo, no caso do Exemplo 1.1 c) , talvez não nos interesse toda a função f , mas apenas o seu valor no fim do dia f(1) . Essas medições são ditas elementos aleatórios que definimos à seguir. Seja (E,\\mathcal{A}) um espaço mensurável. Nesse caso, se X:\\Omega\\to E é uma função (\\mathcal{F},\\mathcal{A}) -mensurável, dizemos que X é um elemento aleatório em (\\Omega,\\mathcal{F}) tomando valores em E , ou um E -elemento aleatório. {example} Consideramos os casos  a)​ X:\\Omega\\to\\mathbb{R} mensurável é dita variável aleatória.  b)​ X:\\Omega\\to\\mathbb{R}^{d} mensurável é dito vetor aleatório ( d -dimensional).  c)​ X:\\Omega\\to C[0,1] mensurável é dita função aleatória. Seguindo a motivação do Exemplo 1.1 c) , poderia ser que, por exemplo, estivéssemos interessados apenas na variável aleatória X:\\Omega_{3}\\to\\mathbb{R} dada por X(f)=f(1) . {exercise} Mostre que X:\\Omega_{3}\\to\\mathbb{R} dada por X(f)=f(1) é uma variável aleatória. Citando Kingman em seu livro Poisson Processes: “a random elephant is a function from \\Omega into a suitable space of elephants.” Relembrando a nossa notação: P[X\\in A]=P(\\{\\omega\\in\\Omega;X(\\omega)\\in A\\}) . {proposition} Seja X:\\Omega\\to E onde (E,\\mathcal{A}) é um espaço mensurável com \\mathcal{A}=\\sigma(\\mathcal{G}) . Então para verificar que X é um elemento aleatório, basta provar que X^{-1}(G)\\in\\mathcal{F} para todo G\\in\\mathcal{G} . Demonstração. Teoria da Medida. ∎ {example} Se \\Omega e E são espaços topológicos dotados das correspondentes \\sigma -álgebras de Borel, então toda função contínua é um E -elemento aleatório. 1.4.1 Distribuição de elementos aleatórios {definition} Se X:\\Omega\\to E é um elemento aleatório e \\Omega é dotado de uma probabilidade P , então denotamos por X_{*}P , a chamada distribuição de X , a medida de probabilidade X_{*}P(A):=P\\big{(}\\{\\omega\\in\\Omega;X(\\omega)\\in A\\}\\big{)}=P[X\\in A]. (1.25) no espaço mensurável (E,\\mathcal{A}) . {remark} Essa definição corresponde com a de medida imagem vista no curso de integração que tem um papel ainda mais importante em probabilidade. Fica como exercício verificar que X_{*}P é de fato uma probabilidade em E . {exercise} Seja X:[0,1]\\to\\{0,1\\} dada por X(\\omega)=\\1_{A}(\\omega) . Nesse caso, mostre que X_{*}P=\\Ber(p) para algum p\\in[0,1] . Calcule o valor de p . Duas notações importantes nesse contexto são:  a)​Sejam (\\Omega,\\mathcal{F},P) e (\\Omega^{\\prime},\\mathcal{F}^{\\prime},P^{\\prime}) dois espaços de probabilidade e X e Y dois elementos aleatórios. Dizemos que X\\stackrel{{\\scriptstyle d}}{{=}}Y , quando X_{*}P=Y_{*}P^{\\prime} . Note que X e Y nem ao menos precisam pertencer ao mesmo espaço de probabilidade para dizermos que são igualmente distribuídos, mas precisam ser elementos aleatórios de mesmo tipo (ou seja, possuir o mesmo contradomínio).  b)​Escrevemos X\\distr\\mu , que lê-se X é distribuída como \\mu , onde \\mu é uma probabilidade em E , caso X_{*}P=\\mu . {exercise} Sejam X e Y variáveis aleatórias tais que X é nula quase certamente. Mostre que X+Y tem a mesma distribuição de Y . O exercício acima é bastante simples, mas o usaremos para fazer uma importante observação sobre como são enunciados tipicamente os resultados de probabilidade. Raramente encontramos teoremas que explicitam qual é o espaço de probabilidades \\Omega em questão. Como no exercício acima, o contexto de um teorema frequentemente é dado apenas em termos de elementos aleatórios em \\Omega e de suas distribuições. Dessa forma, podemos utilizar o resultado em vários contextos diferentes, desde que possamos encontrar elementos aleatórios que satisfaçam as hipóteses. Com o tempo, passamos até mesmo a considerar menos relevante a escolha específica do espaço amostral, focando cada vez mais na distribuição de seus elementos aleatórios. Previous page Next page"],[["index.html","Ch1.html","Ch1.Sx1.html"],"Tópico: O paradoxo de Bertrand ‣ Capítulo 1 Fundamentos ‣ Notas de aula: Probabilidade I","Skip to content. Tópico: O paradoxo de Bertrand Tópico: O paradoxo de Bertrand Vamos estudar um problema que realça a importância do jeito em que escolhemos o espaço amostral. Queremos calcular a probabilidade que uma corda “uniformemente distribuida” em um círculo seja maior do que o lado do triângulo equilátero inscrito nesse círculo (no caso do círculo unitário, o comprimento desse lado vale \\sqrt{3} ). Bertrand propôs dois métodos para realizar esse cálculo. 11 1 Somos gratos a Hubert Lacoin por sugerir e redigir esse tópico.  a)​Escolher as duas extremidades da corda uniformemente no círculo.  b)​Escolher o centro da corda uniformemente no interior do disco. No caso a) , uma vez que uma extremidade é fixada, o comprimento da corda fica maior do que \\sqrt{3} somente se o segundo ponto ficar num setor angular de comprimento 2\\pi/3 . Logo, essa probabilidade vale (2\\pi/3)/(2\\pi)=1/3 . No caso b) , pra que a corda fique maior do que \\sqrt{3} , o centro dela deve ficar no circulo inscrito dentro do triângulo equilátero, cujo raio é 1/2 . Então a probabilidade vale a razão dessas áreas, que é 1/4 . Obtemos então duas respostas diferentes para essa pergunta simples, o que não é nada surpreendente: a) e b) correspondem a dois experimentos diferentes com espaços amostrais diferentes. {exercise}  a)​Descreva o espaço amostral e as lei de probabilidade associadas aos experimentos a) e b)  b)​Calcule a lei de probabilidade do comprimento da corda em cada caso.  c)​Repita os ítens anteriores para o seguinte caso: Escolhemos uniformemente um raio do disco. Depois escolhemos o centro da corda uniformemente ao longo desse raio. Previous page Next page"],[["index.html","Ch1.html"],"Capítulo 1 Fundamentos ‣ Notas de aula: Probabilidade I","Skip to content. Fundamentos Capítulo 1 Fundamentos A probabilidade moderna se baseia fortemente na Teoria da Medida e supomos durante esse curso que o leitor esteja bem familiarizado com conceitos tais como: Medida de Lebesgue, extensões de medida e teoremas de convergência. Iremos agora justificar brevemente a escolha da Teoria da Medida para o estudo de probabilidade. No início da Teoria da Probabilidade, a maioria dos fenômenos estudados apresentava apenas um número finito de resultados possíveis, como por exemplo ao se jogar um dado de seis lados ou sortear uma carta em um baralho. Em tais casos é desnecessário o uso de ferramentas sofisticadas pra modelar tais situações. Por exemplo, podemos simplesmente dizer que a probabilidade de se obter cada um dos lados do dado é igual a 1/6 . Mas digamos por exemplo que queremos um modelo para estudar o volume de chuva em uma cidade durante um ano. Obviamente, esse volume poderia ser qualquer número real positivo e não podemos simplesmente atribuir valores positivos de probabilidade a cada número real (lembramos que somas não enumeráveis de termos positivos são sempre infinitas). Mas como podemos continuar nossa modelagem se nem ao menos podemos dizer qual é a probabilidade de chover um determinado volume esse ano, por exemplo (\\pi/19)mm ? A solução para tal dilema, se baseia no fato de que na verdade nunca estamos interessados no exato resultado do nosso experimento. Gostaríamos sim de responder perguntas do tipo: qual é a probabilidade de que chova entre zero e 37mm ? Estamos portanto interessados em atribuir probabilidades não a valores exatos do experimento, mas a certos conjuntos de possíveis valores. Chamamos tais conjuntos de eventos. Voltando ao caso do dado de seis lados, poderíamos nos interessar por exemplo pela probabilidade dos seguintes eventos: o lado sorteado foi ímpar ( P(\\{1,3,5\\})=1/2 ) ou o lado serteado foi dois ( P(\\{2\\})=1/6 ). E percebemos rapidamente que para eventos disjuntos a probabilidade de sua união é a soma de suas probabilidades (no caso acima, P(\\{1,2,3,5\\})=1/2+1/6=2/3 ). Esse caráter aditivo da probabilidade certamente nos remete aos conceitos básicos de Teoria da Medida. Vamos agora formalizar a discussão acima com mais calma, sob a ótica dessa teoria. Previous page Next page"],[["index.html","Ch2.html","Ch2.S1.html"],"2.1 Caso enumerável ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Caso enumerável 2.1 Caso enumerável Quando \\Omega é finito ou enumerável, tipicamente definimos sobre \\Omega a \\sigma -álgebra das partes, ou seja \\mathcal{F}=\\mathcal{P}(\\Omega)=\\sigma(\\{\\omega\\}_{\\omega\\in\\Omega}) . Além disso podemos definir probabilidades sobre (\\Omega,\\mathcal{F}) de maneira simples tomando (p_{\\omega})_{\\omega\\in\\Omega} tais que  a)​ p_{\\omega}\\geq 0 para todo \\omega\\in\\Omega e  b)​ \\sum_{\\omega\\in\\Omega}p_{\\omega}=1 . De fato, nesse caso definimos P(A)=\\sum_{\\omega\\in A}p_{\\omega} que claramente define uma probabilidade. {exercise} Mostre que se \\Omega é finito ou enumerável, toda probabilidade sobre (\\Omega,\\mathcal{P}(\\Omega)) é dada como na descrição acima. {example}  a)​Dado p\\in[0,1] , definimos a medida \\Ber(p) (em homenagem a Bernoulli) em \\{0,1\\} com p_{1}=p,p_{0}=1-p .  b)​Dados n\\geq 1 e p\\in[0,1] , definimos a medida \\Bin(n,p) (binomial) em \\Omega=\\{0,1,\\dots,n\\} com p_{i}=\\binom{n}{i}p^{i}(1-p)^{n-i},\\text{ para $i\\in\\Omega$.} (2.1)  c)​Dado p\\in(0,1] , em \\Omega=\\{0,1,\\dots\\} definimos a medida \\Geo(p) (geométrica) em \\Omega induzida pelos pesos p_{i}=(1-p)^{i}p,\\text{ para $i\\geq 1$.} (2.2) {exercise} Seja \\Omega=\\{0,1\\}^{n} e p_{\\omega}=\\tfrac{1}{2^{n}} para todo \\omega\\in\\Omega (ou seja a probabilidade uniforme). Considere X:\\Omega\\to\\{0,1,\\dots,n\\} dada por X(\\omega_{1},\\dots,\\omega_{n})=\\sum_{i=1}^{n}\\omega_{i} . Obtenha a distribuição P_{X} . Dê um exemplo de medida em \\omega para a qual a distribuição de X seja \\Bin(n,p) . Previous page Next page"],[["index.html","Ch2.html","Ch2.S10.html"],"2.10 Espaços canônicos ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Espaços canônicos 2.10 Espaços canônicos Em várias áreas da matemática, existe um importante conceito de equivalência entre duas estruturas, como por exemplo: homeomorfismos, isometrias e isomorfismos. Nessa seção estudaremos o caso análogo para espaços mensuráveis, que nos trará uma grande surpresa. {definition} Uma função \\phi:E\\to E^{\\prime} entre dois espaços mensuráveis é dita bi-mensurável quando \\phi é uma bijeção mensurável, com inversa mensurável. Vamos agora tentar classificar os espaços a menos de bi-mensurabilidade. Descobriremos que na verdade os borelianos da reta incluem praticamente tudo em que podemos estar interessados. Começamos com a seguinte definição. {definition} Dizemos que o espaço mensurável (E,\\mathcal{A}) é canônico se existe uma função \\phi:E\\to B bi-mensurável para algum B\\in\\mathcal{B}(\\mathbb{R}) . Antes de mostrar que essa classe de espaços canônicos inclui muitíssimos exemplos, vamos motivar a definição acima exemplificando como esse conceito pode ser utilizado. {theorem} [Extensão de Kolmogorov Extendida] Se (E_{1},\\mathcal{F}_{1}),(E_{2},\\mathcal{F}_{2}),\\dots são espaços mensuráveis canônicos, então o Teorema 2.6.2 (da extensão de Kolmogorov) também é válido no espaço produto \\Omega=E_{1}\\times E_{2}\\times\\dots : Se a seguinte condição de consistência for válida \\forall n\\geq 0,\\forall A\\in\\bigotimes_{i=1}^{n}\\mathcal{F}_{i},\\quad P_{n+1}(% A\\times E_{n+1})=P_{n}(A). (2.103) então existe uma probabilidade P em \\Omega tal que \\forall n\\geq 0,\\forall A\\in\\bigotimes_{i=1}^{n}\\mathcal{F}_{i},\\quad P(A% \\times E_{n+1}\\times E_{n+2}\\times\\dots)=P_{n}(A). (2.104) Demonstração. Sejam \\phi_{i}:E_{i}\\to B_{i}\\in\\mathcal{B}(\\mathbb{R}) bijeções bi-mensuráveis e defina \\widebar{\\phi}_{n}:E_{1}\\times\\dots\\times E_{n}\\to\\mathbb{R}^{n} por \\widebar{\\phi}_{n}(\\omega_{1},\\dots,\\omega_{n})=\\big{(}\\phi_{1}(\\omega_{1}),% \\dots,\\phi_{n}(\\omega_{n})\\big{)} . Assim podemos introduzir as medidas de probabilidade \\widebar{P}_{n}=(\\widebar{\\phi}_{n})_{*}P_{n},\\text{ em $\\mathbb{R}^{n}$}. (2.105) É fácil verificar que as \\widebar{P}_{n} são consistentes como em (2.58). Logo, existe \\widebar{P} em (\\mathbb{R}^{\\mathbb{N}},\\mathcal{F}) extendendo \\widebar{P}_{n} . Vamos agora definir uma medida em \\prod_{i=1}^{\\infty}E_{i} . Para tanto, primeiramente fixamos para cada i\\geq 1 um elemento arbitrário w_{i} de E_{i} e definimos \\psi_{i}:\\mathbb{R}\\to E_{i} por \\psi_{i}(x)=\\begin{cases}\\phi_{i}^{-1}(x),\\quad&\\text{se $x\\in B_{i}$,}\\\\ w_{i}&\\text{no caso contr\\'{a}rio}.\\end{cases} Como B_{i}\\in\\mathcal{B}(\\mathbb{R}) , concluimos que \\psi_{i} é mensurável. Finalmente, consideramos o mapa \\Psi:\\mathbb{R}^{\\mathbb{N}}\\to\\Omega dado por \\Psi(x_{1},x_{2},\\dots)=(\\psi_{1}(x_{1}),\\psi_{2}(x_{2}),\\dots). (2.106) Resta mostrar que a medida P=\\Psi_{*}\\widebar{P} estende as probabilidades P_{n} . Observe que \\begin{split}P\\big{(}A_{1}\\times\\dots\\times A_{n}\\times&E_{n+1}\\times\\dots\\big% {)}=\\widebar{P}\\big{(}\\Psi^{-1}(A_{1}\\times\\dots\\times A_{n}\\times E_{n+1}% \\times\\dots)\\big{)}\\\\ &=\\widebar{P}\\big{(}\\psi^{-1}_{1}(A_{1})\\times\\dots\\times\\psi^{-1}_{n}(A_{n})% \\times\\mathbb{R}\\times\\dots\\big{)}\\\\ &=\\widebar{P}_{n}(\\psi^{-1}_{1}(A_{1})\\times\\dots\\times\\psi^{-1}_{n}(A_{n}))\\\\ &=P_{n}\\big{(}\\phi^{-1}_{1}\\big{(}\\psi^{-1}_{1}(A_{1}))\\times\\dots\\times\\phi^{% -1}_{n}\\big{(}\\psi_{n}^{-1}(A_{n})\\big{)}\\big{)}\\\\ &=P_{n}(A_{1}\\times\\dots\\times A_{n}),\\end{split} concluindo a prova do teorema. ∎ Uma ferramenta importante para construirmos espaços canônicos é a seguinte. {lemma} Seja (E,\\mathcal{A}) é um espaço canônico e A\\in\\mathcal{A} , então A também é canônico quando dotado da \\sigma -álgebra \\{A\\cap C\\,:\\,C\\in\\mathcal{A}\\} induzida por \\mathcal{A} em A . Demonstração. Seja \\phi:E\\to B\\in\\mathcal{B}(\\mathbb{R}) uma função bi-mensurável que mostra que E é canônico. Consideramos \\phi^{\\prime}:A\\to\\mathbb{R} dada pela restrição de \\phi a A e precisamos mostrar as seguintes afirmativas:  a)​ \\phi^{\\prime} é injetiva.  b)​ \\phi^{\\prime} é mensurável.  c)​ \\phi(A)\\in\\mathcal{B}(\\mathbb{R}) .  d)​A inversa de \\phi^{\\prime} (chamada \\psi^{\\prime} ) de \\phi^{\\prime}(A) em A é mensurável. Vejamos,  a)​ \\phi ser injetiva implica que \\phi^{\\prime} também o é.  b)​Dado D\\in\\mathcal{B}(\\mathbb{R}) , (\\phi^{\\prime})^{-1}(D)=A\\cap\\phi^{-1}(D) which is of the form A\\cap C with C\\in\\mathcal{B}(\\mathbb{R}^{d}) .  c)​Denotando por \\psi:B\\to E a inversa de \\phi , temos que \\phi(A)=\\psi^{-1}(A)\\in\\mathcal{B}(B) pois \\psi é mensurável.  d)​Finalmente, se D\\in\\mathcal{B}(A) , então (\\psi^{\\prime})^{-1}(D)=\\psi^{-1}(D)\\in\\mathcal{B}(B) , novamente pela mensurabilidade de \\psi . Concluindo portanto a bi-mensurabilidade de \\phi^{\\prime} quando o seu contra-domínio é restrito a sua imagem. ∎ A seguir daremos um exemplo de espaço canônico que será importante na seção seguinte. {lemma} O espaço produto E=\\mathbb{N}\\times\\mathbb{N}\\times\\dots , dotado da \\sigma -álgebra produto é canônico. Demonstração. Primeiramente definimos em E a Métrica de Hamming: d_{H}(x,y)=\\sum_{i\\geq 1}\\frac{1}{2^{i+1}}\\1_{\\{x_{i}\\neq y_{i}\\}}. (2.107) Fica como exercício mostrar que a \\sigma -álgebra dos borelianos induzida por essa métrica coincide com a \\sigma -álgebra produto em E . Definimos agora o mapa \\phi:E\\to\\mathbb{R} dado por \\phi(n_{1},n_{2},\\dots)=2^{-n_{1}}+2^{-1-n_{1}-n_{2}}+\\dots+2^{-k-\\sum_{i=1}^{% k}n_{i}}+\\dots (2.108) Também deixamos a cargo do leitor mostrar que \\phi define um homeomorfismo entre (E,d_{H}) e um boreliano de \\mathbb{R} . ∎ 2.10.1 Espaços poloneses Nessa seção mostraremos que todos espaços chamados poloneses são canônicos. {definition} Um espaço métrico (E,d) é dito polonês se é separável e completo. {example}  a)​Todo espaço enumerável \\Omega pode ser feito em um espaço métrico polonês de forma que a \\sigma -álgebra de Borel seja \\mathcal{P}(\\Omega) .  b)​ \\mathbb{R}^{n} e C([0,1]) são notoriamente poloneses. {exercise} Se (E_{i},d_{i})_{i=1}^{\\infty} é uma sequencia de espaços métricos poloneses, mostre que E=\\prod_{i=1}^{\\infty}E_{i} com a métrica d(x,y)=\\sum_{i=1}^{\\infty}\\frac{1}{2^{i+1}}\\frac{d_{i}(x_{i},y_{i})}{1+d_{i}(x% _{i},y_{i})} (2.109) também é polonês. Mostre também que a topologia induzida por essa métrica é equivalente à topologia produto em E . Outros exemplos de espaços poloneses são dados pelo seguinte lema, que também será útil para provar o resultado principal desta seção. {lemma} Seja (E,d) um espaço polonês e G,F\\subseteq E um aberto e um fechado de E respectivamente. Então, existe uma métrica d^{\\prime} em F\\cap G tal que  a)​ d e d^{\\prime} são equivalentes em F\\cap G (induzem a mesma noção de convergência),  b)​ d(x,y)\\leq d^{\\prime}(x,y) para todo x,y\\in F\\cap G e  c)​ (F\\cap G,d^{\\prime}) é polonês. Demonstração. A primeira observação que faremos é que F\\cap G é separável com respeito a d . Isso segue do fato de separabilidade ser equivalente à existência de uma base enumerável. Vamos definir para x,y em G , d^{\\prime}(x,y)=d(x,y)+\\Big{|}\\frac{1}{d(x,G^{c})}-\\frac{1}{d(y,G^{c})}\\Big{|}, (2.110) onde d(x,A)=\\inf\\{d(x,x^{\\prime})\\,:\\,x^{\\prime}\\in A\\} . Não é difícil ver que com a definição acima (e deixamos como exercício) que:  a)​As métricas d e d^{\\prime} são equivalentes em G .  b)​ F\\cap G é separável quando dotado da métrica d^{\\prime} .  c)​ (F\\cap G,d^{\\prime}) é completo. Isso termina a prova do lema. ∎ {example} Um importante exemplo é dado por espaços produto. Seja (E_{i},d_{i})_{i=1}^{\\infty} uma sequência de espaços poloneses e introduza em E=\\prod_{i=1}^{\\infty}E_{i} a métrica d definida em (2.109). Então, se A_{1}\\subseteq E_{1} , \\dots , A_{k}\\subseteq E_{k} forem abertos, o retângulo R=A_{1}\\times\\dots\\times A_{k}\\times E_{k+1}\\times\\dots é aberto. Dessa forma vemos que tanto R como R^{c} podem ser dotados de métricas com as quais se tornam espaços poloneses. Além disso tais métricas podem ser escolhidas satisfazendo as hipóteses do Lema 2.10.1 O próximo lema é o ingrediente chave para provarmos o resultado principal dessa seção. Ele nos dá uma maneira de fatiar um espaço polonês em uma partição de espaços poloneses pequenos. {lemma} Seja (E,d) um espaço polonês e r>0 . Então existe uma partição finita ou enumerável (A_{i})_{i\\in I} de A e métricas (d_{i})_{i\\in I} nesses respectivos subconjuntos de forma que para todo i\\in I ,  a)​ (A_{i},d_{i}) são espaços poloneses disjuntos.  b)​ d_{i} e d são equivalentes em A_{i} e d_{i}\\geq d .  c)​O diâmetro de A_{i} (com respeito a d ) é menor ou igual a r . Observe que podemos sempre escolher I=\\mathbb{N} mas nesse caso os A_{i} podem ser vazios. Demonstração. Obtemos através da separabilidade de E , uma coleção de bolas (B_{i})_{i\\geq 1} com diâmetros limitados por r e cobrindo E . Então definimos A_{1}=B_{1},\\quad\\text{e}\\quad A_{n}=B_{n}\\setminus\\mcup_{i=0}^{n-1}B_{i}\\quad% \\text{para $n\\geq 1$.} (2.111) Agora podemos dotar cada um dos A_{i} com a métrica d_{i} obtida através do Lema 2.10.1 (observe para tanto que os A_{i} são dados por interseções de um aberto com um fechado). As propriedades enunciadas no lema são trivialmente satisfeitas. ∎ Terminamos essa seção com esse importante resultado, que confirma nossa afirmação de que quase todos os espaços mensuráveis que podemos nos interessar são canônicos. {theorem} Todo sub-conjunto boreliano de espaço polonês (E,d) é canônico. Demonstração. Primeiramente, pelo Lema 2.10, basta mostrar que todo espaço E polonês é canônico. Pelo Lema 2.10 e novamente o Lema 2.10, {display} basta construir uma função bi-mensurável \\phi:E\\to B\\in\\mathcal{B}(\\mathbb{N}^{\\mathbb{N}}) e depois compô-la com uma função bi-mensurável \\phi^{\\prime}:B\\to C\\in\\mathcal{B}(\\mathbb{R}) . Para começar, construiremos uma partição encaixada de E . Mais precisamente, defina os conjuntos M_{n} que serão utilizados como índices M_{n}=\\mathbb{N}^{n}\\quad\\text{para $n\\geq 1$ e}\\quad M=\\cup_{n}M_{n}. (2.112) Vamos definir borelianos A_{m} de E e métricas d_{m} em A_{m} para cada m\\in M . Faremos isso da seguinte forma:  a)​se m=i\\in M_{1} , então definimos A_{1},A_{2},A_{3},\\dots e d_{1},d_{2},d_{3},\\dots como no Lema 2.10.1 com r=1 ,  b)​se (A_{m},d_{m}) já foi definido para algum m\\in M_{n} , então utilizamos também o Lema 2.10.1 com r=1/n para particionar o conjunto A_{m} (com a métrica d_{m} ) em A_{(m,1)},A_{(m,2)},\\dots com suas respectivas métricas d_{(m,1)},d_{(m,2)},\\dots Obviamente suporemos que são válidas as propriedades de tais métricas garantidas pelo Lema 2.10.1. Podemos desde já definir \\phi:E\\to\\mathbb{N}^{\\mathbb{N}} e para tanto, considere x\\in E . Indutivamente  a)​como \\{A_{m}\\}_{m\\in M_{1}} formam uma partição de E , definimos \\phi_{1}(x) como o único índice tal que x\\in A_{\\phi_{1}(x)} ,  b)​se já encontramos \\phi_{1}(x),\\dots,\\phi_{n}(x) tal que x\\in A_{(\\phi_{1}(x),\\dots,\\phi_{n}(x))} , então o fato que particionamos o último conjunto na definição de A_{m} , m\\in M_{n+1} nos garante que podemos definir unicamente \\phi_{n+1}(x) de forma a continuar a indução. Da maneira acima já obtivemos \\phi(x)=(\\phi_{1}(x),\\phi_{2}(x),\\dots) . Para terminar, devemos mostrar que \\phi é bi-mensurável quando seu contra-domínio é restrito à sua imagem. Isso começa com a prova de que \\phi é injetiva. Se \\phi(x)=\\phi(y) , então existe uma sequência m_{n}\\in M_{n} tal que x,y\\in A_{m_{n}} para todo n . Mas isso não é possível dado que o diâmetro de A_{m_{n+1}} é menor ou igual a 1/n na métrica d_{m_{n}}\\geq d . Isso mostra que x=y . Vejamos agora que \\phi é mensurável. Seja w\\in\\mathbb{N}^{\\mathbb{N}} tal que \\phi(x)=w e tome G\\subseteq\\mathbb{N}^{\\mathbb{N}} com G=\\{(w_{1},\\dots,w_{l})\\}\\times\\mathbb{N}^{\\mathbb{N}} (esses conjuntos geram a \\sigma -álgebra canônica em \\mathbb{N}^{\\mathbb{N}} ). Claramente, \\phi^{-1}(G)=A_{(\\phi_{1}(x),\\dots,\\phi_{l}(x))} , de forma que mostramos que \\phi é mensurável. Para mostrar que sua inversa \\psi:\\phi(E)\\to E é mensurável, veremos que ela é de fato contínua com respeito à Métrica de Hamming definida em (2.107). Dado n\\geq 1 , tomamos \\delta<2^{-n} . Se w,w^{\\prime}\\in\\phi(E) são tais que d_{H}(w,w^{\\prime})<\\delta em \\mathbb{N}^{\\mathbb{N}} , então w_{i}=w^{\\prime}_{i} para todo i\\leq n , de forma que \\phi^{-1}(w) e \\phi^{-1}(w^{\\prime}) pertencem a A_{(w_{1},\\dots,w_{n})} . A continuidade de \\phi^{-1} segue do fato que o diâmetro de A_{(w_{1},\\dots,w_{n})} é no máximo 1/n (com respeito a d_{(w_{1},\\dots,w_{n-1})} e portanto com respeito a d ). Mas atenção, apesar de que parece que provamos o teorema, ainda falta mostrar que \\phi(E) é mensurável. Para tanto, afirmamos que \\phi(E)=\\mathbb{N}^{\\mathbb{N}}\\setminus\\Big{(}\\bigcup_{(w_{1},\\dots,w_{k})\\in% \\mathcal{E}}\\{w_{1}\\}\\times\\{w_{k}\\}\\times\\mathbb{N}\\times\\dots\\Big{)}, (2.113) onde \\mathcal{E}:=\\{(w_{1},\\dots,w_{k})\\in\\bigcup_{n\\geq 1}\\mathbb{N}^{n}\\,:\\,A_{% \\omega_{1},\\dots,\\omega_{k}}=\\emptyset\\}. A igualdade acima será mostrada no que segue. Dado w\\in\\phi(E) existe x\\in E tal que \\phi(x)=w . Como x\\in A_{w_{1},\\dots,w_{n}} para todo n\\geq 1 , esses conjuntos não são vazios. Logo w não pertence à união em (2.113), mostrando o lado ( \\subseteq ) da equalidade. Finalmente, suponha que w=(w_{1},w_{2},\\dots) é tal que para todo k\\geq 1 , A_{w_{1},\\dots,w_{k}}\\neq\\varnothing . Tomamos portanto para todo k\\geq 1 um ponto x_{k}\\in A_{w_{1},\\dots,w_{k}} . Afirmamos que para todo n , (x_{k})_{k\\geq n} é Cauchy em (A_{w_{1},\\dots,w_{n}},d_{w_{1},\\dots,w_{n}}) , (2.114) o que segue logo do fato que por k\\geq n+1 , x_{k}\\in A_{w_{1},\\dots,w_{k}} cujo d_{w_{1},\\dots,w_{n}} -diâmetro é menor que 1/k . Consideramos x^{n} o limite de (x_{k})_{k\\geq n} em (A_{w_{1},\\dots,w_{n}},d_{w_{1},\\dots,w_{n}}) . É fácil de mostrar que x^{n}=x^{0}:=x (o limite da sequência em (E,d) ) para todo valor de n . É suficiente ver que d(x^{n},x_{k})\\leq d_{w_{1},\\dots,w_{n}}(x^{n},x_{k}) , para todo k\\geq n , o que implica que x^{n} é o limite em (E,d) . Como consequência podemos concluir que x\\in A_{w_{1},\\dots,w_{n}} para todo n e então que \\phi(x)=\\omega , o que conclui a prova do teorema. ∎ Previous page Next page"],[["index.html","Ch2.html","Ch2.S2.html"],"2.2 Caso absolutamente contínuo ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Caso absolutamente contínuo 2.2 Caso absolutamente contínuo Uma outra maneira simples de definir um espaço de probabilidade é partindo de um espaço de medida. Seja (\\Omega,\\mathcal{F},\\mu) um espaço de medida e \\rho:\\Omega\\to\\mathbb{R}_{+} uma função mensurável com \\int\\rho(x)\\mu(\\d{x})=1 . Então podemos definir a probabilidade induzida P(A)=\\int_{A}\\rho(x)\\mu(\\d{x}). (2.8) Nesse caso, chamamos \\rho de a densidade de P com respeito a \\mu . Uma outra possível notação para a equação acima é \\d{P}=\\rho(x)\\d{\\mu} (lembrando a derivada de Radon-Nikodym). Observe que o caso discreto pode ser definido em termos de uma densidade, onde \\rho(\\omega)=p_{\\omega} e \\mu é a medida da contagem em \\Omega . {example} Vários exemplos podem ser obtidos via (2.8) se tomamos \\Omega\\subseteq\\mathbb{R} e \\mu a medida de Lebesgue restrita a \\Omega . Nesses casos, escrevemos P=\\rho(x)\\d{x} em \\Omega . Alguns exemplos importantes são:  a)​Para a<b\\in\\mathbb{R} , definimos a medida U[a,b] usando \\rho(x)=\\tfrac{1}{b-a}\\1_{[a,b]}(x) .  b)​Para \\lambda>0 , definimos a medida \\Exp(\\lambda) (chamada exponencial de parâmetro \\lambda ) por meio da densidade \\rho(x)=\\lambda\\exp\\{-\\lambda x\\} em [0,\\infty) . Podemos também usar a distribuição de um elemento aleatório para construir outras probabilidades, como mostra o seguinte exemplo. {example} Considere por exemplo X:[0,2\\pi]\\to\\mathbb{C} dada por X(t)=\\exp\\{-it\\} . A distribuição imagem X_{*}U_{[0,2\\pi]} é o que chamamos de distribuição uniforme em \\mathbb{S}^{1} , também denotada por U_{S^{1}} . {exercise} Mostre que U_{\\mathbb{S}^{1}} não é absolutamente contínua com respeito à medida de Lebesgue em \\mathbb{C}\\sim\\mathbb{R}^{2} . {exercise} Mostre que U_{\\mathbb{S}^{1}} é invariante por rotações rígidas de \\mathbb{C} , isto é, se T:\\mathbb{C}\\to\\mathbb{C} é uma isometria linear, T_{*}U_{\\mathbb{S}^{1}}=U_{\\mathbb{S}^{1}} . {exercise} Construa uma probabilidade em S^{2} invariante por rotações. Previous page Next page"],[["index.html","Ch2.html","Ch2.S3.html"],"2.3 Funções acumuladas de distribuição ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Funções acumuladas de distribuição 2.3 Funções acumuladas de distribuição Um caso muito importante de espaço amostral é \\Omega=\\mathbb{R} , principalmente por nos ajudar a entender distribuições de variáveis aleatórias. Para tanto, precisaremos de uma boa ferramenta para descrever probabilidades em \\mathbb{R} . {definition} Dada P em \\mathbb{R} , definimos F_{P}:\\mathbb{R}\\to[0,1] por F_{P}(x)=P\\big{(}(-\\infty,x]\\big{)} . Essa função é chamada a função de distribuição acumulada de P . {notation} Se X:\\Omega\\to\\mathbb{R} é uma variável aleatória num espaço (\\Omega,\\mathcal{F},P) , denotamos por F_{X} a função de distribuição acumulada correspondente à distribuição X_{*}P . Lembramos que uma probabilidade em \\mathbb{R} é uma função P:\\mathcal{B}(\\mathbb{R})\\to[0,1] e o domínio dessa função é bastante complicado. Por exemplo se quisermos representar uma distribuição de uma variável aleatória no computador através dessa função P , teríamos problemas. Contudo, a função F_{P} (ou F_{X} ) é muito mais simples de ser compreendida ou representada, por seu domínio ser \\mathbb{R} . {example} Não é difícil verificar que F_{\\delta_{x_{0}}}=\\begin{cases}0&\\text{ se $x<x_{0}$,}\\\\ 1&\\text{ se $x\\geq x_{0}$}\\end{cases} (2.9) e que F_{U_{[0,1]}}=\\begin{cases}0&\\text{ se $x\\leq 0$,}\\\\ x&\\text{ se $x\\in[0,1]$ e}\\\\ 1&\\text{ se $x\\geq 1$.}\\end{cases} (2.10) {exercise} Calcule F_{\\Exp(\\lambda)} . {proposition} F_{P} (e obviamente F_{X} ) satisfazem:  a)​ \\smash{\\lim\\limits_{x\\to-\\infty}}F(x)=0 , \\smash{\\lim\\limits_{x\\to\\infty}}F(x)=1 ,  b)​ F é monótona não-decrescente e  c)​ F é contínua à direita e possui limite à esquerda (càdlàg, do francês). Demonstração.  a)​Se x_{n}\\to-\\infty monotonamente, então A_{n}=(-\\infty,x_{n}] são encaixados e de interseção vazia. Logo, pela Proposição 1.2, temos P(A_{n})\\to 0 . O outro caso é análogo.  b)​Se x\\leq x^{\\prime} então (-\\infty,x]\\subseteq(-\\infty,x^{\\prime}] , donde F(x)\\leq F(x^{\\prime}) .  c)​Continuidade à direita (càd) - Se x_{n}\\downarrow x monotonamente, então A_{n}=(-\\infty,x_{n}]\\downarrow(-\\infty,x] (eles são encaixados). Logo F(x_{n})\\to F(x) . Limite à esquerda (làg) - Segue do fato de F ser monótona e limitada. ∎ {theorem} Se F satisfaz as três propriedades listadas na Proposição 2.3, então existe uma única P em (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) tal que F=F_{P} . Poderíamos usar o Teorema da Extensão de Caratheodory para provar tal resultado, de maneira similar ao que foi feito no caso da Medida de Lebesgue. Mas escolhemos abaixo um método mais simples, que parte da existência de U_{[0,1]} . Demonstração. A unicidade de tal P segue da Proposição 1.3.1 (consequêcia do Teorema de Dynkin), pois se P e P^{\\prime} são tais que F_{P}=F_{P^{\\prime}} , então temos que P\\big{(}(-\\infty,x]\\big{)}=P^{\\prime}\\big{(}(-\\infty,x]\\big{)} . Mas a classe de intervalos semi-infinitos da forma (-\\infty,x] forma um \\pi -sistema que gera a \\sigma -álgebra dos borelianos, logo P=P^{\\prime} . Para construir uma P tal que F_{P}=F , definiremos S:(0,1)\\to\\mathbb{R} , a inversa generalizada de F , por S(u)=\\sup\\{x\\in\\mathbb{R}\\,:\\,F(x)<u\\}. (2.11) u u S(u) S(u) Figura 2.1: Ilustração da definição de S(u) . Seja P=S_{*}U_{[0,1]} , isto é P(A)=U_{[0,1]}(S^{-1}(A)) e mostraremos que F_{P}=F . Para tanto, basta ver que \\{u\\in[0,1]\\,:\\,S(u)\\leq x\\}=\\{u\\in[0,1]\\,:\\,u\\leq F(x)\\},\\text{ para todo $x% \\in\\mathbb{R}$}. (2.12) Pois isso implicaria que F_{P}(x)=U_{[0,1]}[S(u)\\leq x]=U_{[0,1]}[u\\leq F(x)]=F(x) . Vamos agora checar (2.12) observando que:  a)​Se u\\leq F(x) então todo x^{\\prime} tal que F(x^{\\prime})<u é menor que x . Logo S(u)\\leq x .  b)​Por outro lado, se x\\geq S(u) então todo x^{\\prime}>x satisfaz F(x^{\\prime})>u . Pois por continuidade a direita F(x)\\geq u . Isso prova (2.12), terminando a prova da proposição. ∎ {exercise} Mostre o resultado acima usando o Teorema de Extensão de Caratheodory. Previous page Next page"],[["index.html","Ch2.html","Ch2.S4.html"],"2.4 Espaços produto finito ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Espaços produto finito 2.4 Espaços produto finito Dados espaços \\Omega_{1},\\dots,\\Omega_{n} com suas respectivas \\sigma -álgebras \\mathcal{F}_{1},\\dots,\\mathcal{F}_{n} , podemos definir o espaço mensurável produto (\\widebar{\\Omega},\\widebar{\\mathcal{F}}) da seguinte forma \\widebar{\\Omega}=\\prod_{i=1}^{n}\\Omega_{i}\\quad\\text{e}\\quad\\widebar{\\mathcal{% F}}=\\sigma\\Big{(}\\{A_{1}\\times\\cdots\\times A_{n}\\,:\\,\\forall i\\in\\{1,\\dots,n\\}% ,\\ A_{i}\\in\\mathcal{F}_{i}\\}\\Big{)}. (2.13) Essa \\sigma -álgebra é chamada de \\sigma -álgebra produto e denotaremos ela por \\bigotimes_{i=1}^{n}\\mathcal{F}_{i} , ou \\mathcal{F}_{1}\\otimes\\mathcal{F}_{2} quando n=2 . {proposition} Se (\\Omega_{1},\\mathcal{F}_{1},P_{1}),\\dots,(\\Omega_{n},\\mathcal{F}_{n},P_{n}) são espaços de probabilidade, então existe uma única probabilidade \\widebar{P} no espaço mensurável (\\widebar{\\Omega},\\widebar{\\mathcal{F}}) tal que \\widebar{P}(A_{1}\\times\\cdots\\times A_{n})=\\prod_{i=1}^{n}P_{i}(A_{i}),\\text{ % para todos $A_{i}\\in\\mathcal{F}_{i}$, $i\\leq n$.} (2.14) Essa probabilidade é chamada probabilidade produto. Usaremos a notação \\bigotimes_{i=1}^{n}P_{i} o P_{1}\\otimes P_{2}\\otimes\\dots\\otimes P_{n} . Demonstração. Teoria da Medida. ∎ Note que a unicidade do produto pode ser concluída por exemplo usando o Corolário 1.3.1. {exercise} Mostre que o produto de n cópias de (\\{0,1\\},\\mathcal{P}(\\{0,1\\}),\\Ber(1/2)) é a distribuição uniforme em \\{0,1\\}^{n} . Previous page Next page"],[["index.html","Ch2.html","Ch2.S5.html"],"2.5 Independência ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Independência 2.5 Independência Nossa intuição nos diz que quando jogamos duas moedas, o resultado de cada uma delas não deve depender um do outro. Dessa forma, a probabilidade de obtermos um determinado resultado (como por exemplo duas caras) deve ser um quarto, ou seja, meio vezes meio. Em geral, definimos dois eventos como independentes da seguinte forma. {definition} Dizemos que dois eventos A,B\\in\\mathcal{F} são independentes se P(A\\cap B)=P(A)P(B). (2.15) {example} Se \\Omega=\\{1,\\dots,6\\} é dotada da \\sigma -álgebra das partes e P(A)=\\#A/6 , então os eventos A=[\\omega\\text{ \\'{e} impar}] e B=[\\omega\\geq 5] satisfazem P(A\\cap B)=P(\\{5\\})=1/6=(1/2)(1/3)=P(A)P(B). (2.16) Logo tais eventos são independentes. {exercise} Seja \\Omega=\\{0,1\\}^{n} com P(A)=\\#A/2^{n} e X_{i}(\\omega_{1},\\dots,\\omega_{n})=\\omega_{i} para i=1,\\dots,n . Mostre que P[X_{i}=a,X_{j}=b]=P[X_{i}=a]P[X_{j}=b], (2.17) onde [A,B] denota a interseção A\\cap B . 2.5.1 Coleções de eventos 22todo: 2 discutir a alternativa I=\\{1,\\dots,k\\} que é ruim (basta adicionar \\varnothing que qq coisa fica indep). {definition} Sejam A_{1},A_{2},\\dots,A_{k} eventos. Dizemos que eles formam uma coleção independente se para todo I\\subseteq\\{1,\\dots,k\\} não vazio P\\big{(}\\mcap\\nolimits_{i\\in I}A_{i}\\big{)}=\\prod\\limits_{i\\in I}P(A_{i}). (2.18) Vale observar que independência dois a dois não implica independência. Mais precisamente {example} Seja \\Omega=\\{1,2,3,4\\} com P(A)=\\#A/4 e sejam os seguintes eventos: A_{1}=\\{1,2\\} , A_{2}=\\{2,3\\} e A_{3}=\\{1,3\\} . Nesse caso,  a)​ P(A_{i})=1/2 para i=1,2,3 ,  b)​ P(A_{i}\\cap A_{j})=1/4 para todo i\\neq j mas  c)​ P(A_{1}\\cap A_{2}\\cap A_{3})=0\\neq 1/8=P(A_{1})P(A_{2})P(A_{3}) . {definition} Dizemos que uma coleção infinita de eventos (A_{n})_{n\\geq 1} é independente se toda sub-coleção finita de tais eventos forem independentes. {lemma} Se (A_{n})_{n\\geq 1} forma uma sequencia de eventos independentes, então P\\Big{(}\\mcap_{i=1}^{\\infty}A_{i}\\Big{)}=\\prod\\limits_{i=1}^{\\infty}P(A_{i}). (2.19) Demonstração. De fato, P\\Big{(}\\mcap_{i=1}^{\\infty}A_{i}\\Big{)}=\\lim_{n\\to\\infty}P\\Big{(}\\mcap_{i=1}^% {n}A_{i}\\Big{)}=\\lim_{n\\to\\infty}\\prod\\limits_{i=1}^{n}P(A_{i})=\\prod\\limits_{% i=1}^{\\infty}P(A_{i}).\\qed {exercise} Mostre que se A\\in\\mathcal{F} , então \\{B\\in\\mathcal{F}\\,:\\,B\\text{ \\'{e} independente de }A\\} é um \\lambda -sistema. {exercise} Mostre que se B é independente de A para todo B\\in\\mathcal{B} , com \\mathcal{B} um \\pi -sistema, então B é independente de A para todo B\\in\\sigma(\\mathcal{B}) . 2.5.2 Independência de \\sigma -álgebras {definition} Dado um espaço de probabilidade (\\Omega,P,\\mathcal{F}) Dizemos que as \\sigma -álgebra \\mathcal{F}_{1},\\dots,\\mathcal{F}_{n}\\subset\\mathcal{F} são independentes se \\forall\\mathcal{A}_{1}\\in\\mathcal{F}_{1},\\dots,\\mathcal{A}_{n}\\in\\mathcal{F}_{% n},\\ P(\\cap_{i=1}^{n}A_{i})=\\prod_{i=1}^{n}P(A_{i}). (2.20) Nessa definição podemos tomar uma coleção infinita. {exercise} Em um espaço produto (\\Omega_{1}\\times\\Omega_{2},\\mathcal{F}_{1}\\otimes\\mathcal{F}_{2},P_{1}\\otimes P% _{2}) , podemos definir \\begin{split}\\widebar{\\mathcal{F}}_{1}&=\\{A\\times\\Omega_{2}\\,:\\,A\\in\\mathcal{F% }_{1}\\},\\\\ \\widebar{\\mathcal{F}}_{2}&=\\{\\Omega_{1}\\times B\\,:\\,B\\in\\mathcal{F}_{2}\\}.\\end% {split} (2.21) Mostre que essas \\sigma -álgebras são independentes. Podemos extender esse conceito a elementos aleatórios, ou seja: {definition} Dizemos que X_{1},\\dots,X_{k} são elementos aleatórios independentes se as respectivas \\sigma -álgebras \\sigma(X_{1}),\\dots,\\sigma(X_{k}) o forem. Quando X_{1},\\dots,X_{k} são elementos aleatórios independentes e com a mesma distribuição, escrevemos que X_{i} são \\iid(independentes e identicamente distribuídos). {exercise} Com a notação do exercício anterior, mostre que as funções X_{i}:\\Omega_{1}\\times\\Omega_{2}\\to\\Omega_{i} dadas por X_{1}(x,y)=x\\text{ e }X_{2}(x,y)=y, (2.22) são elementos aleatórios e são independentes. {exercise} Mostre que as coordenadas canônicas do exercício anterior no caso X_{i}:\\mathbb{R}^{2}\\to\\mathbb{R} não são independentes segundo a medida U_{\\mathbb{S}^{1}} . Mas o são segundo U_{[0,1]^{2}} (que é a medida de Lebesgue em \\mathbb{R}^{2} restrita a [0,1]^{2} ). {exercise} Seja \\Omega=\\{0,1\\}^{n} com P(A)=\\#A/2^{n} e X_{i}(\\omega_{1},\\dots,\\omega_{n})=\\omega_{i} para i=1,\\dots,n . Mostre que os X_{i} são independentes. {exercise} Sejam (X_{i})_{i\\geq 1} elementos aleatórios independentes tomando valores em espaços (E_{i})_{i\\geq 1} , respectivamente. Mostre que para funções mensuráveis (f_{i})_{i\\geq 1} temos que (f_{i}(X_{i}))_{i\\geq 1} são independentes. {exercise} Mostre que se X,Y são elementos aleatórios e se X é constante quase certamente então X e Y são independentes. {exercise} Sejam X e Y variáveis aleatórias independentes com distribuição \\Exp(1) , calcule a distribuição de  a)​ \\min\\{X,Y\\} e  b)​ X+Y . {exercise} Seja um espaço produto de medidas (\\Omega_{1}\\times\\Omega_{2},\\mathcal{F}_{1}\\otimes\\mathcal{F}_{2},\\mu_{1}% \\otimes\\mu_{2}) e defina a probabilidade P através de \\d{P}=\\rho(x,y)\\d{(}\\mu_{1}\\otimes\\mu_{2}). (2.23) Mostre nesse caso que as coordenadas canônicas X_{1} e X_{2} são independentes se e somente se existem \\rho_{1} e \\rho_{2} em \\Omega_{1} e \\Omega_{2} respectivamente, tais que \\rho(x,y)=\\rho_{1}(x)\\rho_{2}(y) quase certamente com respeito a \\mu_{1}\\otimes\\mu_{2} . {exercise} Sejam X,Y variáveis aleatórias tais que P[X\\leq x,Y\\leq y]=\\begin{cases}0&\\quad\\text{if $x<0$,}\\\\ (1-e^{-x})\\Big{(}\\frac{1}{2}+\\frac{1}{\\pi}\\tan^{-1}y\\Big{)},&\\quad\\text{if $x% \\geq 0$}.\\end{cases} (2.24)  a)​Mostre que a distribuição conjunta \\mu_{(X,Y)} é absolutamente contínua com relação à medida de Lebesgue em \\mathbb{R}^{2} .  b)​Mostre que X e Y são independentes. {exercise} Mostre que se X,Y são variáveis aleatórias independentes com distribuições X\\distr f_{X}(x)\\d{x} e Y\\distr f_{Y}(y)\\d{y} , então X+Y tem distribuição absolutamente contínua com respeito a Lebesgue e f_{X+Y}(z)=\\int_{-\\infty}^{\\infty}f_{Y}(z-x)f_{X}(x)\\d{x}. (2.25) 33todo: 3 mandar para depois de produtos infinitos? {lemma} [Borel-Cantelli - segunda parte] Se A_{1},A_{2},\\dots\\in\\mathcal{F} são independentes e p_{i}=P(A_{i}) satisfazem \\sum_{i}p_{i}=\\infty , então P[A_{i}\\text{ infinitas vezes}]=1. (2.26) Demonstração. Queremos mostrar que P\\Big{(}\\big{(}\\mcap_{n}\\mcup_{i=n}^{\\infty}A_{i}\\big{)}^{c}\\Big{)}=0, (2.27) mas P\\Big{(}\\big{(}\\mcap_{n}\\mcup_{i=n}^{\\infty}A_{i}\\big{)}^{c}\\Big{)}=P\\Big{(}% \\mcup_{n}\\mcap_{i=n}^{\\infty}A_{i}^{c}\\Big{)}\\leq\\sum\\limits_{n}P\\Big{(}\\mcap_% {i=n}^{\\infty}A_{i}^{c}\\Big{)}. (2.28) Logo basta mostrar que a probabilidade à direita é zero para todo n . Mas \\begin{split}P\\Big{(}\\mcap_{i=n}^{\\infty}A_{i}^{c}\\Big{)}&=\\prod\\limits_{i=n}^% {\\infty}P(A_{i}^{c})=\\prod\\limits_{i=n}^{\\infty}(1-p_{i})\\\\ &\\leq\\prod\\limits_{i=n}^{\\infty}\\exp\\{-p_{i}\\}=\\exp\\big{\\{}-\\sum_{i=n}^{\\infty% }p_{i}\\big{\\}}=0.\\end{split} (2.29) Terminando a prova do lema. ∎ \\todosec Tópico: Uma dinâmica em [0,1] fazer dinâmica 2x mod 1 e relações Lebesgue[0,1] com produtos de bernoulli Previous page Next page"],[["index.html","Ch2.html","Ch2.S6.html"],"2.6 Espaços produto infinito ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Espaços produto infinito 2.6 Espaços produto infinito Nessa seção estudaremos \\Omega que são dados por produtos enumeráveis de outros espaços de probabilidade. Mas antes iremos recordar o Teorema da Extensão de Caratheodory. 2.6.1 Recordar é viver… Vamos lembrar o enunciado do Teorema da Extensão de Caratheodory . Antes, vamos relembrar uma definição definição importante. Uma família \\mathcal{G}\\subseteq\\mathcal{P}(\\Omega) é dita uma álgebra de conjuntos se valem:  a)​ \\Omega\\in\\mathcal{G} .  b)​Se A\\in\\mathcal{G} , então A^{c}\\in\\mathcal{G} .  c)​Para todo n\\geq 1 , se A_{1},\\dots,A_{n}\\in\\mathcal{G} , então \\bigcup_{i=1}^{n}A_{i}\\in\\mathcal{G} . {theorem} [Teorema da Extensão de Caratheodory] Seja \\mathcal{G}\\subseteq\\mathcal{P}(\\Omega) uma álgebra de conjuntos em \\Omega e suponha que \\mu:\\mathcal{G}\\to\\mathbb{R}_{+} satisfaça a seguinte propriedade: {display} Se (A_{i})_{i\\in I} e uma familia finita ou enumerável de elementos disjuntos de \\mathcal{G} tal que \\cup_{i\\in I}A_{i}\\in\\mathcal{G} , temos \\mu(\\cup_{i\\in I}A_{i})=\\sum_{i\\in I}\\mu(A_{i}) . Então existe uma medida \\widebar{\\mu}:\\sigma(\\mathcal{G})\\to\\mathbb{R}_{+} tal que \\widebar{\\mu}(A)=\\mu(A) para todo A\\in\\mathcal{G} . Mostraremos agora uma consequência simples do teorema acima, que é muito utilizada em probabilidade. {lemma} [Extensão por continuidade no vazio] Seja \\mathcal{G}\\subseteq\\mathcal{P}(\\Omega) uma álgebra de conjuntos em \\Omega e suponha que P:\\mathcal{G}\\to\\mathbb{R}_{+} satisfaça as seguintes propriedades:  a)​ P(\\Omega)=1 ,  b)​ P é finitamente aditiva e  c)​sempre que B_{1}\\supseteq B_{2}\\supseteq\\dots\\in\\mathcal{G} forem tais que \\cap_{i}B_{i}=\\varnothing (denotamos isso por B_{i}\\downarrow\\varnothing ), temos que \\lim_{i}\\mu(B_{i})=0 . Então existe uma única medida \\widebar{P}:\\sigma(\\mathcal{G})\\to\\mathbb{R}_{+} tal que \\widebar{P}(A)=P(A) para A\\in\\mathcal{G} . Observe que P(\\Omega)=1 somente é necessário para provar a unicidade de \\widebar{P} , então poderíamos tentar mostrar uma versão mais geral desse lema. Mas no contexto de medidas infinitas, não é de se esperar que B_{i}\\downarrow\\varnothing implique \\lim_{i}\\mu(B_{i})=0 , como foi assumido acima (veja também a Proposição 1.2). Portanto resolvemos escrever o enunciado com probabilidades. {exercise} Dê um exemplo de medida que não satisfaz a terceira hipótese do Lema 2.6.1. Demonstração. Primeiro observe que a unicidade segue da Proposição 1.3.1, já que \\mathcal{G} é um \\pi -sistema. Iremos agora mostrar que a propriedade (2.6.1) é válida para P , logo tome A_{1},A_{2},\\dots\\in\\mathcal{G} disjuntos e tais que A=\\cup_{i\\in\\mathbb{N}}A_{i}\\in\\mathcal{G} . Definimos o “resto da união” por B_{n}=A\\setminus\\mcup_{i=1}^{n}A_{i}. (2.52) Claramente  a)​ B_{n}\\downarrow\\varnothing e  b)​ B_{n}\\in\\mathcal{G} , pois \\mathcal{G} é uma álgebra. Logo podemos escrever A como a união disjunta A=\\bigcup_{i=1}^{n}A_{i}\\cup B_{n} e já que P é finitamente aditiva, P(A)=\\sum_{i=1}^{n}P(A_{i})+P(B_{n}), (2.53) mas como \\lim_{n\\to\\infty}P(B_{n})=0 , temos P(\\cup_{i=1}^{\\infty}A_{i})=\\sum_{i=1}^{\\infty}P(A_{i}), (2.54) mostrando a propriedade (2.6.1) e concluindo o teorema. ∎ 2.6.2 Teorema da Extensão de Kolmogorov O objetivo desta seção é provar um resultado que nos permitirá construir probabilidades em espaços produtos infinitos. Antes precisaremos de introduzir algumas notações. Dada uma coleção de espaços (E_{i})_{i\\in\\mathbb{N}} , definimos o espaço produto \\Omega=\\prod_{i=1}^{\\infty}E_{i}=\\big{\\{}(\\omega_{i})_{i\\in\\mathbb{N}}\\,:\\,% \\omega_{i}\\in E_{i}\\text{ para todo $i\\geq 1$}\\big{\\}} (2.55) e os mapas X_{i}:\\Omega\\to E_{i} , definidos para i=1,2,\\dots por X_{i}(\\omega_{1},\\omega_{2},\\dots)=\\omega_{i}, (2.56) que chamamos de coordenadas canônicas associadas ao produto \\Omega . Se cada E_{i} é dotado de uma \\sigma -álgebra \\mathcal{A}_{i} , então definimos \\mathcal{F}=\\sigma((X_{i})_{i\\geq 1}), (2.57) que é claramente uma \\sigma -álgebra em \\Omega . Chamamos \\mathcal{F} de \\sigma -álbegra canônica. {exercise} Mostre que em (\\mathbb{R}^{\\mathbb{N}},\\mathcal{F}) temos que os conjuntos  a)​ A=\\{\\liminf_{n\\to\\infty}X_{n}\\notin\\{\\infty,-\\infty\\}\\} ,  b)​ B=\\{\\lim_{n\\to\\infty}X_{n}=4\\} e  c)​ C=\\{\\lim_{n\\to\\infty}\\tfrac{1}{n}X_{n}\\text{ existe}\\} são todos mensuráveis (eventos) com respeito a \\mathcal{F} . Além disso Y=\\1_{A}\\liminf_{n\\to\\infty}X_{n} é uma variável aleatória em (\\Omega,\\mathcal{F}) . {exercise} Verifique as seguinte afirmações  a)​ \\mathcal{F}=\\sigma\\big{(}A_{1}\\times\\dots\\times A_{k}\\times E_{k+1}\\times E_{k% +2}\\times\\dots\\,:\\,k\\geq 1,A_{i}\\in\\mathcal{A}_{i},i\\leq k\\big{)} , os chamados eventos retangulares.  b)​ \\mathcal{F}=\\sigma\\big{(}A\\times E_{k+1}\\times E_{k+2}\\times\\dots\\,:\\,k\\geq 1,% A\\in\\mathcal{A}_{i}\\otimes\\dots\\otimes\\mathcal{A}_{k}\\big{)} , conhecidos como eventos cilíndricos. {definition} Seja \\Omega=\\prod_{i\\in I}E_{i} um espaço produto (infinito ou finito) dotado de uma probabilidade P . Se X_{i} é uma coordenada canônica, então chamamos a probabilidade (X_{i})_{*}P de distribuição marginal de P na coordenada i . {theorem} [Extensão de Kolmogorov] Seja para cada n\\geq 1 uma medida de probabilidade P_{n} em \\mathbb{R}^{n} tal que seja satisfeita a seguinte condição de compatibilidade P_{n+1}(A\\times\\mathbb{R})=P_{n}(A),\\text{ para todo $A\\in\\mathcal{B}(\\mathbb{% R}^{n})$}. (2.58) Então existe uma única probabilidade P no espaço produto infinito (\\Omega,\\mathcal{F}) tal que P(A\\times\\mathbb{R}\\times\\dots)=P_{n}(A) para todo n e todo boreliano A de \\mathbb{R}^{n} . Demonstração. Considere a classe de conjuntos \\mathcal{S}_{l}=\\Big{\\{}\\mcup_{j=1}^{k}[a_{1,j},b_{1,j})\\times\\dots\\times[a_{l% ,j},b_{l,j})\\subseteq\\mathbb{R}^{l}\\,:\\,a_{i,j}\\in\\mathbb{R}\\cup\\{-\\infty\\},\\ % b_{i,j}\\in\\mathbb{R}\\cup\\{\\infty\\}\\Big{\\}}. Que é obviamente uma álgebra em \\mathbb{R}^{l} e seja também \\mathcal{S}=\\big{\\{}A\\times\\mathbb{R}\\times\\dots\\,:\\,\\text{ onde }l\\geq 1\\text% { e }A\\in\\mathcal{S}_{l}\\big{\\}}. (2.59) Claramente, \\mathcal{S} também é uma álgebra. Se B=A\\times\\mathbb{R}\\times\\dots\\in\\mathcal{S} com A\\in\\mathcal{S}_{l} como acima, definimos P(B)=P_{l}(A). (2.60) Note que por (2.58) essa definição independe da escolha de l que usamos na definição de B . Gostaríamos agora de utilizar o Lemma 2.6.1. Para tanto, tome uma sequência encaixada B_{1}\\supseteq B_{2}\\supseteq\\dots\\in\\mathcal{S} e, supondo que P(B_{n})\\geq\\delta>0 para todo n\\geq 1 , temos de mostrar que sua interseção não pode ser vazia. Como B_{n}\\in\\mathcal{S} , podemos escrever B_{n}=A_{n}\\times\\mathbb{R}\\times\\dots,\\text{ onde $A_{n}\\in\\mathcal{S}_{l_{n}% }$ e $n\\geq 1$.} (2.61) Podemos obviamente supor que l_{n} são estritamente crescentes. (2.62) A fim de obter um ponto na interseção de B_{n} , gostaríamos de aproximá-lo usando conjuntos compactos encaixados. Para tanto definimos os conjuntos C_{n}=C_{n}^{*}\\times\\mathbb{R}\\times\\dots,\\text{ com $C_{n}^{*}\\in\\mathcal{S}% _{l_{n}}$} (2.63) de forma que C_{n}^{*} seja compacto, C_{n}^{*}\\subseteq A_{n} e P(B_{n}\\setminus C_{n})\\leq\\frac{\\delta}{2^{l_{n}+1}}, (2.64) o que pode ser feito graças à continuidade de P_{l_{n}} , que é uma probabilidade. Temos ainda um problema, pois os conjuntos C_{n} não são encaixados, e isso nos impede de utilizar resultados sobre interseções de compactos. Introduzimos pois D_{n}=\\bigcap_{i=1}^{n}C_{i} , que obviamente pertence à álgebra \\mathcal{S} , e estimamos P(B_{n}\\setminus D_{n})=P\\big{(}\\mcup\\nolimits_{i=1}^{n}(B_{n}\\setminus C_{i})% \\big{)}\\leq\\sum_{i=1}^{n}P(B_{n}\\setminus C_{i})\\leq\\frac{\\delta}{2}, (2.65) donde P(D_{n})=P(B_{n})-P(B_{n}\\setminus D_{n})\\geq\\delta/2 . De forma que os D_{n} são encaixados e não vazios. Nosso próximo obstáculo vem do fato de que os conjuntos D_{n} estão definidos em \\mathbb{R}^{\\mathbb{N}} , e gostaríamos de ter conjuntos em espaços de dimensão finita. Isso pode ser feito observando que podemos escrever D_{n}=D_{n}^{*}\\times\\mathbb{R}\\times\\mathbb{R}\\times\\dots , onde D_{n}^{*}\\in\\mathcal{S}_{l_{n}} e D_{n}^{*}=\\underbrace{C_{n}^{*}}_{\\mathclap{\\text{compacto}}}\\mcap\\underbrace{% \\Big{(}\\mcap_{i=1}^{n-1}C_{i}^{*}\\times\\mathbb{R}^{l_{n}-l_{i}}\\Big{)}}_{\\text% {fechado}}, (2.66) de forma que os D_{n}^{*}\\subseteq\\mathbb{R}^{l_{n}} são compactos e não vazios. Para cada n\\geq 1 considere um \\omega^{n}\\in D_{n} . Usando um argumento de diagonal de Cantor, podemos obter um \\omega\\in\\Omega e uma sub-sequência de \\omega^{n_{j}} que convirja para \\omega\\in\\Omega coordenada a coordenada (observe que \\omega^{n_{j}}\\in\\mathbb{R}^{\\smash{l_{n_{j}}}} ). Para concluir a prova mostramos que \\omega\\in\\bigcap_{n\\geq 1}B_{n} . Para isso e suficiente mostrar (lembramos que por definição C_{n}\\subseteq B_{n} ) que para todo n\\in\\mathbb{N} \\omega=(\\omega_{1},\\omega_{2},\\dots)\\in C_{n}. O que e equivalente a (\\omega_{1},\\omega_{2},\\dots,\\omega_{n})\\in C^{*}_{n} , que vale por compacidade. ∎ Observe que usamos muito poucos atributos de \\mathbb{R} na prova. Poderíamos na verdade substituir \\mathbb{R} por um espaço métrico que satisfaça certas propriedades, como por exemplo a existência de uma álgebra cujos conjuntos possam ser aproximados por compactos. Contudo, decidimos não apresentar essa versão mais geral aqui porque muito em breve obteremos uma versão bem mais geral do Teorema de Kolmogorov usando apenas o resultado para \\mathbb{R} . {exercise} Mostre que a hipótese (2.58) pode ser substituida por P_{n+1}(I_{1}\\times\\dots,\\times I_{n}\\times\\mathbb{R})=P_{n}(I_{1}\\times\\dots% \\times I_{n}), (2.67) para todo n\\geq 1 e I_{i}=(-\\infty,b_{i}] , onde b_{i}\\in\\mathbb{R} , i\\leq n . Um importante exemplo do uso deste teorema é o seguinte. {example} Se P_{i} são probabilidades em (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) , podemos definir \\mathbb{P}_{n}=\\bigotimes_{i=1}^{n}P_{i} (relembrando, \\mathbb{P}_{n} é a única distribuição em \\mathbb{R}^{n} tal que \\mathbb{P}_{n}(A_{1}\\times\\dots\\times A_{n})=\\prod_{i=1}^{n}P_{i}(A_{i}) ). Não é difícil verificar que essa lei satisfaz as equações de consistência (2.58). Desta forma, podemos construir uma única \\mathbb{P} em \\mathbb{R}^{\\mathbb{N}} para os quais as coordenadas canônicas X_{i} são independentes e possuem distribuições marginais P_{i} . Denotamos nesse caso \\mathbb{P}=\\bigotimes_{i\\geq 1}P_{i} . Mais adiante no texto daremos outros exemplos bastante interessantes do uso do Teorema 2.6.2. {exercise} Mostre que se p>0 e \\mathbb{P}=\\bigotimes_{i\\geq 1}\\Ber(p) em \\mathbb{R}^{\\mathbb{N}} , então \\limsup_{n\\to\\infty}X_{n}=1 quase certamente. (2.68) {exercise} Mostre que se \\mathbb{P}=\\bigotimes_{i\\geq 1}U_{[0,1]} em \\mathbb{R}^{\\mathbb{N}} , então \\limsup_{n\\to\\infty}X_{n}=1 quase certamente. (2.69) {exercise} Mostre que se \\mathbb{P}=\\bigotimes_{i\\geq 1}\\Exp(i) em \\mathbb{R}^{\\mathbb{N}} , então \\limsup_{n\\to\\infty}X_{n}<\\infty quase certamente. (2.70) Previous page Next page"],[["index.html","Ch2.html","Ch2.S7.html"],"2.7 Distribuições conjuntas ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Distribuições conjuntas 2.7 Distribuições conjuntas Um caso bastante importante de distribuição de um elemento aleatório é o caso de vetores. Digamos por exemplo que temos dois elementos aleatórios X:\\Omega\\to E e Y:\\Omega\\to E^{\\prime} . Já sabemos a definição de X_{*}P e Y_{*}P (vamos também usar a notação P_{X} e P_{Y} ) que nada mais são que as distribuições de X e Y , respectivamente. Mas podemos considerar o vetor (X,Y) que será um elemento aleatório tomando valores em E\\times E^{\\prime} e possui também sua própria distribuição dada por (X,Y)_{*}P (também denotada por P_{(X,Y)} ). A essa probabilidade em E\\times E^{\\prime} damos o nome de distribução conjunta deste par. . Vejamos as relações que existem entre P_{X} , P_{Y} e P_{(X,Y)} . Primeiramente, é fácil ver que a distribução conjunta nos fornece as demais, pois para todo A\\subseteq E mensurável P_{(X,Y)}(A\\times E^{\\prime})=P[(X,Y)\\in A\\times E^{\\prime}]=P[X\\in A]=P_{X}(A) (2.77) e analogamente para P_{Y} . De acordo com a Definição 2.6.2, as distribuições P_{X} e P_{Y} nada mais são do que as marginais da distribuição conjunta. Apesar de podermos extrair as marginais P_{X} e P_{Y} de P_{(X,Y)} , o contrário não é sempre possível como mostra o seguinte exemplo. {example} Sejam X,Y \\iidcom distribuição \\Ber(1/2) . Então (X,Y) não tem a mesma distribuição de (X,X) , apesar de que esses vetores possuem as mesmas marginais. {exercise} Mostre que se X e Y são independentes, então P_{(X,Y)}=P_{X}\\otimes P_{Y} . {exercise} Sejam X,Y \\iidcom distribuição U_{[0,1]} e calcule P_{(X,X+Y)} . Note que a discussão acima se extende naturalmente para coleções maiores de elementos aleatórios. Mais precisamente, considere um conjunto I qualquer (finito, enumerável ou não enumerável) de índices e seja (X_{i})_{i\\in I} uma coleção de elementos aleatórios tomando valores em (E_{i})_{i\\in I} . Então a distribuição conjunta destes elementos aleatórios é P_{(X_{i})_{i\\in I}} . {exercise} Mostre que no caso acima, se P_{(X_{i})_{i\\in J}}=P_{(X^{\\prime}_{i})_{i\\in J}} para todo J\\subseteq I finito, então P_{(X_{i})_{i\\in I}}=P_{(X^{\\prime}_{i})_{i\\in I}} . Previous page Next page"],[["index.html","Ch2.html","Ch2.S8.html"],"2.8 Probabilidades condicionais ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Probabilidades condicionais 2.8 Probabilidades condicionais Uma outra maneira de se construir espaços de probabilidade é através de condicionamento, como mostra a seguinte definição. {definition} Se (\\Omega,\\mathcal{F},P) é espaço de probabilidade e B\\in\\mathcal{F} é tal que P(B)>0 , então definimos a probabilidade P(\\cdot|B):\\mathcal{F}\\to[0,1] por P(A|B)=\\frac{P(A\\cap B)}{P(B)}, (2.78) chamada probabilidade condicional dado o evento B . Obviamente P(\\cdot|B) é uma probabilidade em (\\Omega,\\mathcal{F}) e podemos entendê-la de duas formas: como uma normalização ou como uma tentativa de sucesso. Explicaremos abaixo cada uma dessas interpretações. Quando restringimos o espaço amostral \\Omega ao conjunto B (e associamos a A\\in\\mathcal{F} o valor P(A\\cap B) ), temos uma sub-probabilidade, isto é, possivelmente P(\\Omega\\cap B)<1 . Logo podemos entender o denominador de (2.78) como uma normalização para obtermos novamente uma probabilidade. Mas a interpretação mais natural de (2.78) é dada pela seguinte proposição. Para enunciá-la, considere (\\Omega,\\mathcal{F},P) um espaço de probabilidade e defina o produto infinito \\widebar{\\Omega}=\\Omega^{\\mathbb{N}},\\qquad\\widebar{\\mathcal{F}}=\\mathcal{F}^{% \\otimes\\mathbb{N}}\\quad\\text{e}\\quad\\widebar P=P^{\\otimes\\mathbb{N}}. (2.79) Na verdade somente definimos esse produto para \\Omega=\\mathbb{R} , mas como mencionamos abaixo do Teorema da Extensão de Kolmogorov, isso pode ser facilmente generalizado e o faremos posteriormente. {proposition} Na situação acima, seja B\\in\\mathcal{F} com P(B)>0 e defina T:\\widebar{\\Omega}\\to\\mathbb{N} por T(\\omega)=\\inf\\{n\\geq 1\\,:\\,X_{n}(\\omega)\\in B\\} , onde os X_{n} são as coordenadas canônicas. Então T<\\infty quase certamente e X_{T(\\omega)}(\\omega) é um elemento aleatório em \\Omega com distribuição P(\\cdot|B) . (2.80) A intuição desta proposição é que se repetimos o experimento (\\Omega,\\mathcal{F},P) independentemente até obter uma amostra em B , essa terá a distribuição condicional. Demonstração. Sejam os eventos A_{n}=[X_{n}\\in B] , n\\geq 1 que são claramente independentes segundo \\widebar{P} . Logo, como \\sum_{n}\\widebar{P}(A_{n})=\\sum_{n}P(B)=\\infty , temos pelo Lema de Borel-Cantelli (segunda parte) que \\widebar{P}(\\text{$A_{n}$ infinitas vezes})=1 , logo T<\\infty quase certamente. Para ver que X_{T(\\omega)}(\\omega) é um elemento aletório, basta escrever [X_{T}\\in A]=\\mcup_{t=1}^{\\infty}[X_{t}\\in A,T=t], (2.81) e observar que tanto [X_{t}\\in A] quanto [T=t]=[X_{1}\\not\\in B,\\dots,X_{t-1}\\not\\in B,X_{t}\\in B] são mensuráveis. Finalmente podemos usar a decomposição (disjunta) acima para calcular \\begin{split}\\widebar{P}[X_{T}\\in A]&=\\sum_{t=1}^{\\infty}\\widebar{P}[X_{t}\\in A% ,T=t]\\\\ &=\\sum_{t=1}^{\\infty}\\widebar{P}[X_{t}\\in A,X_{t}\\in B,X_{s}\\not\\in B\\text{ % for $s<t$}]\\\\ &=\\sum_{t=1}^{\\infty}P(A\\cap B)P(B^{c})^{t-1}=\\frac{P(A\\cap B)}{1-P(B^{c})}=P(% A|B),\\end{split} (2.82) terminando a prova da proposição. ∎ {exercise} Sejam \\lambda>0 e X\\distr\\Exp(\\lambda) (lembrando a definição da distribuição exponencial: \\Exp(\\lambda)(\\d{x})=\\lambda\\exp\\{-\\lambda x\\}\\d{x} ). Mostre que as variáveis com distribuição exponencial não possuem memória, ou seja: P[X>t+s\\,|\\,X>t]=P[X>s],\\text{ para todo $s,t>0$}. (2.83) Ou em outras palavras, sabendo que X é maior que t , a distribuição condicional de X-t ainda é \\Exp(\\lambda) . Definimos a distribuição geométrica de parâmetro p\\in(0,1] por \\Geo(p)=\\sum_{i=1}^{\\infty}(1-p)^{i-1}p\\delta_{i}. (2.84) {exercise} Inspirado no exercício anterior, mostre que a distribuição geométrica \\Geo(p) também satisfaz (2.83) para todos t,s\\in\\mathbb{N} . Mostre que essas são as únicas distribuições com suporte em \\mathbb{N} satisfazendo tal propriedade {exercise} Sejam Y_{i} , para i\\geq 1 , \\iidcom distribuição \\Ber(p) e defina T=\\inf\\{i\\,:\\,Y_{i}=1\\}. (2.85) Mostre que T\\overset{d}{\\sim}\\Geo(p) . {exercise} Barry James: Cap. 2-5, Ex: 5, 10, 21, 22 (a) e (b). {exercise} [Porta dos desesperados] Nas tardes da década de 80, as crianças tinham poucas opções de entretenimento além de assistir Sérgio Malandro, que todos os dias apresentava o seguinte jogo. O participante era apresentado a três portas ( \\Omega=\\{1,2,3\\} ) e apenas uma delas (chamada de X ) continha um prêmio X\\distr U_{\\Omega} e o jogo seguia três fases:  a)​O participante escolhia uma porta arbitrariamente (digamos y\\in\\Omega ),  b)​o Sérgio Malandro abria uma porta X^{\\prime} que não fosse a escolhida nem a premiada ( X^{\\prime}\\distr U_{\\Omega\\setminus\\{y,X\\}} )  c)​ao participante era dada a oportunidade de trocar sua porta X pela porta restante em \\Omega\\setminus\\{X,X^{\\prime}\\} . Mostre que o participante sempre aumenta suas chances ao trocar sua escolha. Tente interpretar esse aparente paradoxo tomando o número de portas para infinito. {exercise} Emílio e Cristina tiveram dois filhos cujos sexos X,X^{\\prime} são \\iide distribuidos como U_{\\{\\male,\\female\\}} . Enunciando hipóteses adequadas se for necessario, calcule  a)​ P[X,X^{\\prime}=\\male|\\text{ pelo menos um \\'{e} $\\male$}] e  b)​ P[X,X^{\\prime}=\\male|\\text{ pelo menos um \\'{e} $\\male$ e nasceu em uma % segunda-feira}] . Interprete esses resultados trocando “segunda-feira” por “primeiro de abril”. 22 2 Gratos ao Ricardo Misturini por sugerir esse problema {exercise} Supondo que P(A\\cap B)>0 , mostre que “ P(\\cdot|A|B)=P(\\cdot|B|A) ”. Mais precisamente, podemos condicionar P em B e depois a probabilidade resultante em A ou vice-versa. {exercise} Sejam X,Y variáveis aleatórias em um espaço (\\Omega,\\mathcal{F},P) , independentes e com distribuição U_{[0,1]} .  a)​Calcule P_{X+Y} .  b)​Considere P^{\\prime}(\\cdot)=P\\big{(}\\cdot\\,|\\,X+Y\\leq 1\\big{)} e calcule X_{*}P^{\\prime} . 44todo: 4 Falar de Lei da Probabilidade Total, com exemplos. 2.8.1 Regra de Bayes Frequentemente definimos um espaço de probabilidade através de probabilidades condicionais. Consideramos por exemplo um exame médico para detectar uma doença, caso em que temos \\Omega=\\{(\\text{doente},+),(\\text{doente},-),(\\text{saud\\'{a}vel},+),(\\text{% saud\\'{a}vel},-)\\}, (2.86) com obviamente a \\sigma -álgebra das partes. Contudo, ao contrário do que fizemos anteriormente, não daremos probabilidades p_{\\omega}\\in[0,1] para cada \\omega\\in\\Omega . Poderíamos por exemplo fornecer P(\\text{doente})=0.005,\\quad P(+|\\text{saud\\'{a}vel})=0.01,\\quad P(-|\\text{% doente})=0.05. (2.87) Obviamente podemos obter as probabilidades dos complementos dos eventos acima. As probabilidades acima podem ser facilmente estimadas num laboratório e as duas últimas são chamadas respectivamente de probabilidades de falso positivo e falso negativo. Outra vantagem da representação em (2.87) é que as probabilidades descritas são mais “compartimentadas” no seguinte sentido. Note que P(\\text{doente}) somente depende da população em questão, enquanto as outras duas dependem apenas do exame e não da população. Isso não pode ser dito das probabilidades de pontos individuais em \\Omega . Agora fica fácil construir nosso espaço de probabilidade escrevendo, para r\\in\\{+,-\\} e e\\in\\{\\text{saud\\'{a}vel},\\text{doente}\\} , P(r\\cap e)=P(r|e)P(e). (2.88) E as probabilidades do lado direito da equação acima estão todas determinadas em (2.87) (possivelmente tomando complementos). Contudo, o que estamos interessado muitas vezes é em como interpretar resultados de um exame. Por exemplo, quanto vele P(\\text{doente}|+) ? Isso nos é fornecido em geral pela regra de Bayes enunciada na seguinte proposição. {proposition} Se (A_{j})_{j\\in I} formam uma partição (finita o enumeável) de \\Omega e B\\in\\mathcal{F} tem probabilidade positiva, então P(A_{i}|B)=\\frac{P(A_{i})P(B|A_{i})}{\\sum_{j\\in I}P(A_{j})P(B|A_{j})}. (2.89) Demonstração. Basta notar que P(A_{i}|B)=\\frac{P(A_{i})P(B|A_{i})}{P(B)}=\\frac{P(A_{i})P(B|A_{i})}{\\sum_{j% \\in I}P(B\\cap A_{j})}=\\frac{P(A_{i})P(B|A_{i})}{\\sum_{j\\in I}P(A_{j})P(B|A_{j}% )}. (2.90) ∎ {exercise} Utilize a fórmula acima para calcular P(\\text{doente}|+) com os dados em (2.87). Comente o resultado. {exercise} Barry James: Cap. 1, Ex: 18 e 19. \\todosec Tópico: Distribuições de Extremosfazer… \\todosec AcoplamentosTalvez valha a pena escrever sobre acoplamentos de maneira geral. Talvez pegando algo do Pascal Massart. Vale a pena tentar escrever algo sobre: composiçao de acoplamentos, quando um acoplamento “dá errado”… Previous page Next page"],[["index.html","Ch2.html","Ch2.S9.html"],"2.9 Núcleos de transição ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Núcleos de transição 2.9 Núcleos de transição Já focamos bastante energia em variáveis aleatórias independentes. Por exemplo, estudamos em detalhes o que acontece com a soma de tais variáveis. Agora passaremos a estudar elementos aleatórios dependentes e o primeiro passo para isso é obter um método geral de construí-los. Definiremos agora um núcleo de transição. Intuitivamente, ele nos dá uma maneira de usar um elemento aleatório em um espaço para induzir uma probabilidade em outro espaço. Um exemplo em que poderíamos utilizar essa construção seria o seguinte. Digamos que estamos preocupados com a possibilidade de um deslizamento de terra em uma determinada região. A ocorrência desse deslizamento é algo aleatório, mas que certamente depende da quantidade de chuva no período, que também podemos modelar como sendo aleatória. Após estudarmos alguns trabalhos anteriores, descobrimos uma função F:\\mathbb{R}_{+}\\to[0,1] que nos dá a probabilidade de um deslizamento ocorrer, como função da quantidade de chuva em milímetros. Lendo o histórico pluvial da região, podemos estimar a distribuição Q em \\mathbb{R}_{+} correspondente à quantidade de chuva naquele período. A lei F_{*}Q (também chamada de Q_{F} ) é uma lei em [0,1] que nos dá a distribuição da probabilidade de deslizamento, mas como seguimos em frente para obter a probabilidade de deslizamento (um número entre zero e um)? Saberemos como fazer isso ao terminar essa seção. Sejam (E_{1},\\mathcal{A}_{1}) e (E_{2},\\mathcal{A}_{2}) espaços mensuráveis. {definition} Um núcleo de transição entre E_{1} e E_{2} é uma função K:E_{1}\\times\\mathcal{A}_{2}\\to[0,1], (2.91) tal que  a)​para todo y\\in E_{1} , K(y,\\cdot) é uma probabilidade em (E_{2},\\mathcal{A}_{2}) e  b)​para todo A\\in\\mathcal{A}_{2} , a função K(\\cdot,A):E_{1}\\to[0,1] é \\mathcal{A}_{1} -mensurável. {example} Daremos agora o exemplo da probabilidade de deslizamento como função de F (que será possivelmente uma variável aleatória). Nesse caso, seja E_{1}=[0,1] e E_{2}=\\{0,1\\} com as \\sigma -álgebras naturais e defina K(p,A)=\\big{(}(1-p)\\delta_{0}+p\\delta_{1}\\big{)}(A). (2.92) Vamos verificar que K definido acima é um núcleo de transição. De fato,  i)​ K(p,\\cdot) é a distribuição Bernoulli com parâmetro p , que obviamente é uma probabilidade,  ii)​além disso, K(\\cdot,\\Omega)=1 , K(\\cdot,\\varnothing)=1 e K(\\cdot,\\{0\\})=1-p=1-K(\\cdot,\\{1\\}) , que obviamente são mensuráveis. Isso prova que esse K específico é um núcleo de transição {example} [Caso discreto] Sejam E_{1} e E_{2} espaços finitos ou enumeráveis. Se p:E_{1}\\times E_{2}\\to[0,1] é tal que para todo y\\in E_{1} temos \\sum_{z\\in E_{2}}p(y,z)=1 , então K(y,A):=\\sum_{z\\in A}p(y,z)\\text{ \\'{e} um n\\'{u}cleo de transi\\c{c}\\~{a}o % entre $E_{1}$ e $E_{2}$.} (2.93) Nesse caso p(y,z) representa a probabilidade que a segunda coordenada seja z , se a primeira é y . {exercise} Mostre que se E_{1} e E_{2} são enumeráveis então todo núcleo entre E_{1} e E_{2} pode ser escrito na forma do exemplo acima. {example} [Caso absolutamente contínuo] Digamos que E_{1} e E_{2} sejam dotados de medidas \\mu_{1} e \\mu_{2} \\sigma -finitas. Seja \\rho:E_{1}\\times E_{2}\\to\\mathbb{R}_{+} mensurável e tal que para \\mu_{1} -quase todo y\\in E_{1} , tenhamos \\int_{E_{2}}\\rho(y,z)\\mu_{2}(\\d{z})=1 . Então K(y,A):=\\int_{A}\\rho(y,z)\\mu_{2}(\\d{z})\\text{ \\'{e} um n\\'{u}cleo de transi\\c{% c}\\~{a}o entre $E_{1}$ e $E_{2}$.} (2.94) Note que K(\\cdot,A) está bem definido para \\mu_{2} -quase todo ponto pelo Teorema de Fubini. {exercise} Prove que os dois exemplos acima de fato definem um núcleo. Tipicamente, definimos os núcleos de transição introduzindo K(y,\\cdot) como sendo uma medida que depende de y . Nesse caso, uma das condições para que K seja um núcleo está automaticamente satisfeita, restando apenas mostrar que K(\\cdot,A) é mensurável para quaisquer A\\in\\mathcal{A}_{2} . Mas obviamente o conjunto \\mathcal{A}_{2} pode ser muito complexo, então gostaríamos de apenas verificar que K(\\cdot,A) é mensurável para os conjuntos A em uma classe rica o suficiente. {proposition} Seja K:E_{1}\\times\\mathcal{A}_{2}\\to[0,1] , tal que K(y,\\cdot) é uma medida para todo y\\in E_{1} . Se K(\\cdot,A) é mensurável para todo A\\in\\mathcal{G} , onde \\mathcal{G} é um \\pi -sistema que gera \\mathcal{A}_{2} , então K é um núcleo de transição. Demonstração. Como de costume, vamos definir \\mathcal{B}=\\{B\\in\\mathcal{A}_{2}\\,:\\,K(\\cdot,B)\\text{ \\'{e} $\\mathcal{A}_{1}$% -mensur\\'{a}vel}\\}. (2.95) Obviamente, como K(y,\\cdot) é uma probabilidade, vale que  a)​ \\Omega\\in\\mathcal{B} , pois a função constante igual a um é mensurável.  b)​Se B\\in\\mathcal{B} , então B^{c}\\in\\mathcal{B} , pois 1-f é mensurável se f o é.  c)​E se B_{1},B_{2},\\dots,B_{n}\\in\\mathcal{B} são disjuntos, então \\mcup_{i=1}^{n}B_{i}\\in\\mathcal{B} , pois a soma de funções mensuráveis também é mensurável. A discussão acima mostra que \\mathcal{B} é um \\lambda -sistema que contém o \\pi -sistema \\mathcal{G} . Daí, vemos pelo Teorema 1.3 que \\mathcal{A}_{2}=\\sigma(\\mathcal{G})\\subseteq\\mathcal{B} , provando a proposição. ∎ {exercise} Seja K:\\mathbb{R}\\times\\mathcal{B}(\\mathbb{R})\\to[0,1] dada por K(y,\\cdot)=U_{[y-1,y+1]} . Mostre que K define um núcleo de transição. Apesar de interessante, a definição acima ainda não nos permitiu definir espaços de probabilidade novos. Isso será possibilitado pelo próximo resultado, que pode ser visto como uma generalização do Teorema de Fubini. \\chooseoptpar{theorem} [Fubini para Núcleos de Transição] Dado um núcleo \\optde transição K de (E_{1},\\mathcal{A}_{1}) para (E_{2},\\mathcal{A}_{2}) e uma probabilidade P_{1} em E_{1} , existe uma única probabilidade P em (E_{1}\\times E_{2},\\mathcal{A}_{1}\\otimes\\mathcal{A}_{2}) tal que \\int_{E_{1}\\times E_{2}}fdP=\\int_{E_{1}}\\int_{E_{2}}f(y,z)K(y,\\d{z})P_{1}(\\d{y% }), (2.96) para toda f:E_{1}\\times E_{2}\\to\\mathbb{R}_{+} . Em particular, P(A_{1}\\times A_{2})=\\int_{A_{1}}K(y,A_{2})P_{1}(\\d{y}) . Nesse caso escrevemos P=P_{1}\\star K . Antes de iniciar a prova do teorema, vamos ver que as integrais do lado direito de (2.96) estão bem definidas. Para isso, definimos para y\\in E_{1} a função fatiadora \\phi_{y}:E_{2}\\to E_{1}\\times E_{2} dada por \\phi_{y}(z)=(y,z) . Obviamente essa função é mensurável, pois \\phi_{y}^{-1}(A_{1}\\times A_{2})=\\begin{cases}\\varnothing,\\quad&\\text{ se $y% \\not\\in A_{1}$ e}\\\\ A_{2},&\\text{ se $y\\in A_{1}$}.\\end{cases} (2.97) Dessa forma, para definirmos \\int f(y,z)K(y,\\d{z}) , introduzimos f_{y}:A_{2}\\to\\mathbb{R}_{+} dada por f_{y}(z)=f(y,z) , que é mensurável pois f_{y}=f\\circ\\phi_{y} . Assim, gostaríamos de integrar a função y\\mapsto\\int f_{y}(z)K(y,\\d{z}) , que está obviamente bem definida. Porém resta a pergunta, será que essa expressão define uma função mensurável de y ? {lemma} Se K é um núcleo de transição, então para toda f:E_{1}\\times E_{2}\\to\\mathbb{R}_{+} que seja \\mathcal{A}_{1}\\otimes\\mathcal{A}_{2} mensurável, temos que g^{f}:A_{1}\\to\\mathbb{R}_{+} dada por g^{f}(y)=\\int f_{y}(z)K(y,\\d{z}) (2.98) é \\mathcal{A}_{1} -mensurável. Demonstração. Se f=\\1_{A_{1}\\times A_{2}} para A_{i}\\in\\mathcal{A}_{i} , i=1,2 , então temos que g^{f}(y)=K(y,A_{2})\\1_{A_{1}} , que obviamente é mensurável pois K é um núcleo. Definimos \\mathcal{D}=\\{B\\in\\mathcal{A}_{1}\\otimes\\mathcal{A}_{2}\\,:\\,g^{\\1_{B}}\\text{ % \\'{e} $\\mathcal{A}_{1}$-mensur\\'{a}vel}\\} . É fácil ver que \\mathcal{D} é um \\lambda -sistema que contém o \\pi -sistema dos retângulos, logo \\mathcal{D}=\\mathcal{A}_{1}\\otimes\\mathcal{A}_{2} . Acabamos de ver que g^{f} é mensurável para toda f indicadora, donde o mesmo vale para f simples por linearidade e para toda f positiva pelo Teorema da Convergência Monótona (lembre que limite de funções mensuráveis é mensurável). ∎ Estamos prontos agora para fornecer a Demonstração do Teorema 2.9. Já sabemos que a integral do lado direito de (2.96) está bem definida (assumindo possivelmente o valor infinito). A unicidade vale obviamente pois (2.96) aplicado a funções indicadoras temos necessariamente para todos B P(B)=\\int_{E_{1}}\\int_{E_{2}}\\1_{B}K(y,\\d{z})P_{1}(\\d{y}). (2.99) Só temos que verificar a fórmula acima nos define uma probabilidade em (E_{1}\\times E_{2},\\mathcal{A}_{1}\\otimes\\mathcal{A}_{2}) . De fato,  a)​obviamente P(\\Omega)=\\int_{E_{1}}\\int_{E_{2}}K(y,\\d{z})P_{1}(\\d{y})=1 e  b)​se (B_{i})_{i\\in I} e uma família finita ou enumerável de eventos disjuntos (em \\mathcal{A}_{1}\\otimes\\mathcal{A}_{2} ) então \\1_{\\bigcup_{i\\in I}B_{i}}=\\sum_{i\\in I}\\1_{B_{i}} a \\sigma -aditividade de P segue das propriedades básicas (linearidade e Teorema de convergência monótona) da integração. Isto demonstra o teorema. ∎ {exercise} Considere duas probabilidades P_{i} em (E_{i},\\mathcal{A}_{i}) para i=1,2 e K:E_{1}\\times\\mathcal{A}_{2}\\to[0,1] dado por K(y,A)=P_{2}(A) . Mostre que K é núcleo e que P_{1}\\star K=P_{1}\\otimes P_{2} . Relacione esse resultado ao Teorema de Fubini clássico para produtos de medidas. {exercise} Considere o núcleo do Exemplo 2.9 e calcule:  a)​ U_{[0,1]}\\star K[X_{2}=1] ,  b)​ P_{1}\\star K[X_{2}=1] , onde \\d{P}_{1}=2x\\d{x} e  c)​encontre a distribuição de (X_{1})_{*}\\big{(}U_{[0,1]}\\star K[\\;\\cdot\\;|X_{2}=1]\\big{)} . Interprete o resultado. {exercise} Seja P=P_{1}\\star K como acima e Q(\\cdot)=P[\\cdot|X_{2}=1] . Calcule \\int_{[0,1]\\times\\{0,1\\}}X_{1}\\d{Q} (2.100) {exercise} Para 0\\leq a<b\\leq 1 , definimos a probabilidade U_{[a,b]} em ([0,1],\\mathcal{B}([0,1])) através da seguinte fórmula U_{[a,b]}(B)=\\mathcal{L}(B\\cap[a,b])/(b-a) . Consideramos também a função K:[0,1]\\times\\mathcal{B}([0,1])\\to[0,1] dada por K(x,\\cdot)=U_{[0,x]}(\\cdot) , se x>0 e K(0,\\cdot)=\\delta_{0}(\\cdot) .  a)​Mostre que K é um núcleo de transição.  b)​Calcule U_{[0,1]}\\star K[X_{1}<1/2] e U_{[0,1]}\\star K[X_{2}<1/2] , onde X_{1} e X_{2} são as projeções canônicas em [0,1]^{2} .  c)​Mostre que U_{[0,1]}\\star K é absolutamente contínua com respeito à medida de Lebesgue em [0,1]^{2} e calcule sua densidade. {exercise} Considere K:E_{1}\\times\\mathcal{A}_{2}\\to[0,1] dada por K(p,\\cdot)=\\Exp(p) . Mostre que K é núcleo de transição e calcule U_{[0,1]}\\star K[X_{2}>1] . {exercise} Se K é um núcleo de transição entre E_{1} e E_{2} e \\{y\\}\\in\\mathcal{A}_{1} satisfaz P_{1}(\\{y\\})>0 , mostre que P_{1}\\star K[X_{2}\\in\\cdot|X_{1}=y]=K(y,\\cdot). (2.101) Ou em outras palavras, K nos dá a distribuição condicional de X_{2} dado X_{1}=y . Posteriormente extenderemos o resultado acima para o caso P_{1}(\\{y\\})=0 , mas isso demandará algum esforço. Vamos introduzir uma última notação com respeito a núcleos de transição. Muitas vezes, não estamos interessados na distribuição conjunta de P_{1}\\star K em E_{1}\\times E_{2} , mas apenas na distribuição marginal da segunda coordenada. No nosso problema da chuva por exemplo, talvez poderíamos estar interessados apenas na probabilidade final de ocorrer um deslizamento. Nesse caso, é conveniente escrever P_{1}K:=(X_{2})_{*}(P_{1}\\star K)=(P_{1}\\star K)_{X_{2}}. (2.102) {exercise} Seja K:\\mathbb{R}_{+}\\times\\mathcal{B}(\\mathbb{R}_{+})\\to[0,1] dada pela equação K(x,A)=\\int_{A}x\\exp\\{-xt\\}\\d{t} .  a)​Prove que K é um núcleo de transição.  b)​Seja P dada por P=\\textnormal{Exp}(1)\\star K . Obtenha P[X_{2}>x_{2}] para todo x_{2}\\geq 0 (lembrando que X_{2} denota a segunda coordenada no espaço produto onde está definida P ). Compare a probabilidade acima com K(1,[x_{2},\\infty)) .  c)​Mostre que P[X_{1}+X_{2}\\geq z]=\\int_{0}^{z}\\exp\\{-x(z-x+1)\\}\\d{x}+\\exp\\{-z\\} . Previous page Next page"],[["index.html","Ch2.html","Ch2.Sx1.html"],"Tópico: Método Probabilístico ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Tópico: Método Probabilístico Tópico: Método Probabilístico Uma importante ferramenta em várias áreas da matemática, tais como Teoria dos Números, Combinatória e Teoria da Computação é o que chamamos de Método Probabilístico. Em várias situações, nós precisamos de mostrar a existência de objetos satisfazendo determinadas propriedades, mas não temos informação suficiente ou capacidade para construí-los explicitamente. Nesse caso, podemos recorrer ao Método Probabilístico, que simplesmente nos sugere tomar um objeto aleatório de uma maneira esperta e mostrar que com probabilidade positiva as propriedades desejadas serão satisfeitas. Esse método, apesar de muito ingênuo, é muito eficiente e em diversos casos provê os melhores exemplos conhecidos de certos objetos (para embaraço da comunidade científica). Nessa seção daremos um exemplo em Teoria dos Números provido primeiramente por Erdõs11 1 Somos gratos a Robert Morris por sugerir esse teorema como exemplo do Método Probabilístico.. {theorem} [Erdös] Para todo conjunto finito A\\subset\\mathbb{N} , existe um sub-conjunto B\\subseteq A satisfazendo  a)​ \\#B\\geq\\frac{\\#A}{3} e tal que  b)​não existem x,y e z\\in B com x+y=z . A propriedade b) acima é o que chamamos de um conjunto ser livre de somas. Certamente não temos muita informação sobre A , então vamos usar o método probabilístico para a prova desse teorema. Demonstração. Fixamos p um número primo maior que três vezes o maior elemento de A e considere o espaço \\mathbb{Z}_{p} dos inteiros módulo p . Seja X um elemento aleatório de \\mathbb{Z}_{p} com distribuição uniforma, isto é U_{\\{0,\\dots,p-1\\}} . {exercise} Mostre que para todo a\\in A , a multiplicação por a é uma bijeção em \\mathbb{Z}_{p} , ou seja \\mathbb{Z}_{p}\\cdot a=\\mathbb{Z}_{p}. (2.3) onde o produto \\mathbb{Z}_{p}\\cdot a é entendido elemento a elemento. Conclua que P\\Big{[}X\\cdot a\\in\\big{[}\\tfrac{p}{3},\\tfrac{2p}{3}\\big{)}\\Big{]}\\geq\\frac{1}% {3}-\\frac{1}{p}. (2.4) Definimos o conjunto aleatório \\mathcal{B}=\\{a\\in A\\ |X\\cdot a\\in[\\tfrac{p}{3},\\tfrac{2p}{3})\\}. (2.5) Esse conjunto é livre de soma: se X=0 o conjunto é vazio e, nos outros casos, se a,b\\in\\mathcal{B} então X(a+b)\\in[\\tfrac{2p}{3},\\tfrac{4p}{3}) (2.6) que é o complemento de [\\tfrac{p}{3},\\tfrac{2p}{3}) em \\mathbb{Z}_{p} . Basta portanto mostrar que com probabilidade positiva \\#\\mathcal{B}\\geq\\tfrac{\\#A}{3} , que segue do seguinte argumento. Note inicialmente que \\int\\#\\mathcal{B}\\d{P}=\\int\\sum_{a\\in A}\\1_{\\big{[}X\\cdot a\\in[p/3,2p/3)\\big{]% }}\\d{P}\\\\ =\\sum_{a\\in A}P\\Big{[}X\\cdot a\\in\\big{[}\\tfrac{p}{3},\\tfrac{2p}{3}\\big{)}\\Big{% ]}\\geq\\frac{\\#A}{3}-\\frac{\\#A}{p}>\\frac{\\#A-1}{3}, mas, para qualquer variável aleatória, P[Y\\geq\\int Y\\d{P}]>0 . Nesse caso, isso implica P[\\#\\mathcal{B}\\geq\\tfrac{\\#A}{3}]=P[\\#\\mathcal{B}>\\tfrac{\\#A-1}{3}]\\geq P\\Big% {[}\\#\\mathcal{B}>\\int\\#\\mathcal{B}\\d{P}\\Big{]}>0. (2.7) ∎ 11todo: 1 Adicionar contexto histórico: citar artigo Erdos e o Annals of Math que mostra que não é possível com \\#A(1/3+\\varepsilon) . Previous page Next page"],[["index.html","Ch2.html","Ch2.Sx2.html"],"Tópico: Lei dos pequenos números ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Tópico: Lei dos pequenos números Tópico: Lei dos pequenos números Nessa seção estudaremos como se comportam limites de algumas variáveis aleatórias bastante importantes, mas primeiramente, uma breve intuição. Apesar de que descreveremos a nossa motivação a partir desse exemplo do estudo de um material radioativo, podemos encontrar aplicações com justificativas bastante semelhantes para outros problemas, como: chegada de carros em um sinal de trânsito, número de mutações em um gene, número de mortes por ano em uma faixa etária… Digamos que estamos observando um material radioativo que esporadicamente emite fótons que podemos detectar através de um aparelho. A razão dessas emissões pode ser aproximada pelo seguinte modelo. Na amostra temos um número n grande de átomos instáveis ( n\\sim 10^{23} ) e em um determinado tempo de observação, cada um deles tem probabilidade muito baixa de decair emitindo um fóton (digamos p\\sim 10^{-23} ). Nesse caso, supondo que todos decidam emitir de maneira independente, temos para p\\in[0,1] , \\Omega_{n}=\\{0,1\\}^{n},\\quad\\mathcal{F}_{n}=\\mathcal{P}(\\Omega)\\quad\\text{e}% \\quad P_{p}=\\otimes_{i=1}^{n}Ber(p). (2.30) Dessa forma, o número total de emissões observadas para \\omega=(\\omega_{1},\\dots,\\omega_{n})\\in\\Omega é X_{n}(\\omega)=\\sum_{i=1}^{n}\\omega_{i}. (2.31) E gostaríamos de entender como se comporta essa distribuição, que nada mais é que \\Bin(n,p) . Uma primeira tentativa seria modelar esse processo dizendo que o número de átomos n é tão grande, que somente estamos interessados no comportamento assintótico quando n vai para infinito. Mas para manter o número de emissões sob controle, também gostaríamos que p=p_{n} , que converge a zero. Poderíamos por exemplo escolher p_{n}=\\frac{\\lambda}{n}. (2.32) Mas a discussão que se segue é muito mais geral que essa escolha específica. Como estaremos interessados em um regime assintótico da distribuição de X_{p} (lembre que apesar do espaço amostral de X_{n} variar com n , sua distribuição é sempre uma probabilidade em \\mathbb{N} ), precisamos de definir uma noção de distância entre duas distribuições em \\mathbb{N} . {definition} Dadas duas distribuições \\mu_{1} e \\mu_{2} em (\\Omega,\\mathcal{A}) , definimos \\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}=\\sup_{A\\in\\mathcal{A}}|\\mu_{1}(A)-\\mu_{2}(A)|, (2.33) chamada de distância em variação total entre \\mu_{1} e \\mu_{2} . No nosso caso, \\Omega é enumerável. Vamos ver que nesse caso é possível reescrever a definição acima de modo a ver mais facilmente que se trata de uma distância no espaço de probabilidades em \\Omega . {lemma} Se \\Omega for finito ou enumerável, então podemos escrever \\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}=\\frac{1}{2}\\sum_{x\\in\\Omega}|\\mu_{1}(x)-\\mu_% {2}(x)|. (2.34) Demonstração. Para mostrar que o lado esquerdo é maior ou igual ao direito, escolhemos A=\\{x\\in\\Omega\\,:\\,\\mu_{2}(x)\\leq\\mu_{1}(x)\\} . Assim \\begin{split}\\sum_{x\\in A}\\mu_{1}(x)-\\mu_{2}(x)&=|\\mu_{1}(A)-\\mu_{2}(A)|\\\\ &=|\\mu_{1}(A^{c})-\\mu_{2}(A^{c})|=\\sum_{x\\in A^{c}}\\mu_{2}(x)-\\mu_{1}(x),\\end{split} (2.35) donde \\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}\\geq|\\mu_{1}(A)-\\mu_{2}(A)|=\\frac{1}{2}\\sum_{% i}|\\mu_{1}(x_{i})-\\mu_{2}(x_{i})|. (2.36) Na outra direção, observe que para todo B\\subseteq\\Omega , \\begin{split}\\sum_{i}|\\mu_{1}(x_{i})-\\mu_{2}(x_{i})|&\\geq\\sum_{x\\in B}\\mu_{1}(% x)-\\mu_{2}(x)+\\sum_{x\\in B^{c}}\\mu_{2}(x)-\\mu_{1}(x)\\\\ &=\\mu_{1}(B)-\\mu_{2}(B)+(1-\\mu_{2}(B))-(1-\\mu_{1}(B))\\\\ &=2(\\mu_{1}(B)-\\mu_{2}(B)).\\end{split} (2.37) O que termina a prova do lema. ∎ Fica agora claro que \\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT} determina uma distância. {exercise} Mostre um lema análogo ao anterior para (\\Omega,\\mathcal{A}) qualquer, desde que \\mu_{1} e \\mu_{2} sejam absolutamente contínuas com relação à uma medida fixa nesse espaço mensurável. Nesse caso utilizaremos as derivadas de Radon–Nikodym. Como estaremos interessados em variáveis independentes, precisamos de um resultado que relacione a distância em variação total com produtos de medida. Isso é parte do seguinte {lemma} Sejam \\mu_{1},\\mu_{2} distribuições em \\Omega e \\nu_{1},\\nu_{2} distribuições em \\Omega^{\\prime} ambos enumeráveis. Então \\lVert\\mu_{1}\\otimes\\nu_{1}-\\mu_{2}\\otimes\\nu_{2}\\rVert_{\\VT}\\leq\\lVert\\mu_{1}% -\\mu_{2}\\rVert_{\\VT}+\\lVert\\nu_{1}-\\nu_{2}\\rVert_{\\VT}. (2.38) Demonstração. Basta expandir \\begin{split}2\\lVert\\mu_{1}&\\otimes\\nu_{1}-\\mu_{2}\\otimes\\nu_{2}\\rVert_{\\VT}=% \\sum_{x\\in\\Omega,y\\in\\Omega^{\\prime}}|\\mu_{1}(x)\\nu_{1}(y)-\\mu_{2}(x)\\nu_{2}(y% )|\\\\ &\\leq\\sum_{x\\in\\Omega,y\\in\\Omega^{\\prime}}|\\mu_{1}(x)\\nu_{1}(y)-\\mu_{1}(x)\\nu_% {2}(y)|+|\\mu_{1}(x)\\nu_{2}(y)-\\mu_{2}(x)\\nu_{2}(y)|\\\\ &\\leq 2\\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}+2\\lVert\\nu_{1}-\\nu_{2}\\rVert_{\\VT},% \\end{split} (2.39) onde acima usamos que \\mu_{1} e \\nu_{2} são probabilidades. Isso termina a prova do lema. ∎ Finalmente, gostaríamos de entender como a distância de variação total se comporta com respeito à soma de variáveis independentes. Isso estará ligado à convolução de distribuições: {definition} Dadas, \\mu e \\nu distribuições em \\mathbb{Z} , definimos a distribuição (\\mu\\star\\nu)(x):=\\sum_{y\\in\\mathbb{Z}}\\mu(x-y)\\nu(y). (2.40) Essa definição se relaciona com a soma de variáveis independentes graças ao seguinte {exercise} Se X\\overset{d}{\\sim}\\mu e Y\\overset{d}{\\sim}\\nu são variáveis aleatórias inteiras e independentes, então X+Y\\overset{d}{\\sim}\\mu\\star\\nu . Dica: particione o espaço amostral nos eventos [X=j] , para j\\in\\mathbb{Z} , como na prova do Lema 2 abaixo. {corollary} Se \\mu e \\nu são distribuições em \\mathbb{Z} , então \\mu\\star\\nu=\\nu\\star\\mu . Como prometido, obtemos a seguinte relação entre a convolução e a distância de variação total. {lemma} Sejam \\mu , \\nu duas medidas em \\Omega enumerável e X:\\ (\\Omega,\\mathcal{P}(\\Omega))\\to(E,\\mathcal{A}) um elemento aleatorio \\lVert X_{*}\\mu-X_{*}\\nu\\rVert_{\\VT}\\leq\\lVert\\mu-\\nu\\rVert_{\\VT}. (2.41) Em particular se \\mu_{1},\\mu_{2},\\nu_{1},\\nu_{2} são distribuições em \\mathbb{Z} , então \\lVert\\mu_{1}\\star\\nu_{1}-\\mu_{2}\\star\\nu_{2}\\rVert_{\\VT}\\leq\\lVert\\mu_{1}% \\otimes\\nu_{1}-\\mu_{2}\\otimes\\nu_{2}\\rVert_{\\VT} (2.42) Demonstração. O segundo ponto segue do primeiro aplicado ao caso \\Omega=\\mathbb{Z}^{2} , E=\\mathbb{Z} e X:\\ (x,y)\\mapsto(x+y) . Para o primeiro, observamos \\begin{split}2\\lVert X_{*}\\mu-X_{*}\\nu\\rVert_{\\VT}&=\\sum_{x\\in X(\\Omega)}\\Big{% |}\\mu(X(\\omega)=x)-\\nu(X(\\omega)=x)\\Big{|}\\\\ &=\\sum_{x\\in X(\\Omega)}\\Big{|}\\sum_{\\omega\\in\\Omega\\ :\\ X(\\omega)=x}\\mu(\\omega% )-\\nu(\\omega)\\Big{|}\\\\ &\\leq\\sum_{\\omega\\in\\Omega}\\big{|}\\mu(\\omega)-\\nu(\\omega)\\big{|}\\\\ &=2\\lVert\\mu-\\nu\\rVert_{\\VT},\\end{split} (2.43) provando o lema. ∎ Para enunciar o resultado principal dessa seção, vamos apresentar uma distribuição em \\mathbb{N} bastane importante, que em particular se comporta muito bem com respeito a somas de variáveis independentes, como veremos. {definition} Uma variável aleatória X é dita ter distribuição de Poisson com parâmetro \\lambda , se P[X=k]=\\frac{\\lambda^{k}e^{-\\lambda}}{k!},\\text{ para $k\\geq 0$ inteiro.} (2.44) Denotamos isso por X\\overset{d}{\\sim}\\Poisson(\\lambda) . A distribuição de Poisson se comporta bem com respeito a somas independentes, como mostra o seguinte {lemma} Sejam X\\overset{d}{\\sim}\\Poisson(\\lambda_{1}) e Y\\overset{d}{\\sim}\\Poisson(\\lambda_{2}) independentes, então X+Y\\overset{d}{\\sim}\\Poisson(\\lambda_{1}+\\lambda_{2}) . Demonstração. Basta calcular \\begin{split}P[X+Y=k]&=\\sum_{j=0}^{k}P[X=j,Y=k-j]=\\sum_{j=0}^{k}\\frac{\\lambda_% {1}^{j}e^{-\\lambda_{1}}\\lambda_{2}^{k-j}e^{-\\lambda_{2}}}{j!(k-j)!}\\\\ &=e^{-(\\lambda_{1}+\\lambda_{2})}\\frac{1}{k!}\\sum_{j=0}^{k}\\frac{k!}{j!(k-j)!}% \\lambda_{1}^{j}\\lambda_{2}^{k-j}=\\frac{e^{(\\lambda_{1}+\\lambda_{2})}(\\lambda_{% 1}+\\lambda_{2})^{k}}{k!},\\end{split} (2.45) mostrando o resultado. ∎ Nossa próxima tarefa é estimar a distância entre uma variável aleatória com distribuição \\Ber(p) e uma \\Poisson(p) , como segue. {lemma} Para p\\in[0,1] , seja \\mu_{1}=\\Ber(p) e \\mu_{2}=\\Poisson(p) , então, \\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}\\leq p^{2}. (2.46) Demonstração. Sabemos que \\begin{split}\\lVert\\mu_{1}-\\mu_{2}\\rVert_{\\VT}&=\\frac{1}{2}\\sum_{x}|\\mu_{1}(x)% -\\mu_{2}(x)|\\\\ &=\\frac{1}{2}\\Big{(}|\\mu_{1}(0)-\\mu_{2}(0)|+|\\mu_{1}(1)-\\mu_{2}(1)|+\\sum_{x% \\geq 2}\\mu_{2}(x)\\Big{)}\\\\ &=\\frac{1}{2}\\Big{(}e^{-p}-(1-p)+p(1-e^{-p})+(1-e^{-p}-pe^{-p})\\Big{)}\\\\ &=\\frac{2}{2}p(1-e^{-p})\\leq p^{2},\\end{split} (2.47) terminando a prova. ∎ O teorema principal de convergência dessa seção concerne a soma de variáveis Bernoulli. {theorem} [Lei dos Pequenos Números] Dado, n\\geq 1 e p\\in[0,1] , suponha que \\Omega_{n} , \\mathcal{F}_{n} e P_{p} sejam dados como em (2.30). Então, \\lVert\\Bin(n,p)-\\Poisson(pn)\\rVert_{\\VT}\\leq np^{2}. (2.48) Demonstração. Basta observar que \\begin{split}\\lVert X_{n}\\circ P_{p}-\\Poisson(pn)\\rVert_{\\VT}&\\overset{\\text{% Lema\\leavevmode\\nobreak\\ \\ref{l:soma_poisson}}}{=}\\lVert\\Ber(p)^{\\star n}-% \\Poisson(p)^{\\star n}\\rVert_{\\VT}\\\\ \\overset{\\text{Lema\\leavevmode\\nobreak\\ \\ref{l:vt_conv}}}{\\leq}&\\lVert\\Ber(p)^% {\\otimes n}-\\Poisson(p)^{\\otimes n}\\rVert_{\\VT}\\\\ \\overset{\\text{Lema\\leavevmode\\nobreak\\ \\ref{l:vt_produto}}}{\\leq}&n\\lVert\\Ber% (p)-\\Poisson(p)\\rVert_{\\VT}\\overset{\\text{Lema\\leavevmode\\nobreak\\ \\ref{l:vt_% ber_poiss}}}{\\leq}np^{2},\\end{split} (2.49) provando o teorema. ∎ {corollary} No mesmo contexto do teorema acima, se p=\\lambda/n , então temos \\lVert\\Bin(n,p)-\\Poisson(pn)\\rVert_{\\VT}\\leq\\lambda^{2}/n, (2.50) que converge a zero com n . Veremos mais tarde que existem outros tipos de convergência. {exercise} Fixado \\lambda>0 , seja N uma variável aleatória com distribuição Poisson( \\lambda ), isto é P[N=k]=\\frac{\\lambda^{k}e^{-\\lambda}}{k!}\\text{ para $k=0,1,\\dots$} (2.51) Considere no mesmo espaço de probabilidade uma sequência de variáveis aleatórias X_{1},X_{2},\\dots que sejam \\iid, com distribuição \\Ber(1/2) e independentes de N .  a)​Calcule a distribuição de Z=\\sum_{i=1}^{N}X_{i} .  b)​Mostre que Z e N-Z são independentes. Previous page Next page"],[["index.html","Ch2.html","Ch2.Sx3.html"],"Tópico: Percolação ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Tópico: Percolação Tópico: Percolação Imagine que gostaríamos de modelar o movimento de um líquido em um meio poroso, como uma rocha ou uma esponja. A primeira tarefa nesse estudo seria modelar esse meio poroso de maneira matematicamente rigorosa, que é o que faremos a seguir. Fixamos uma dimensão d\\geq 1 e consideramos o seguinte grafo (\\mathbb{Z}^{d},E) , onde a rede quadrada \\mathbb{Z}^{d} é o conjunto de vértices e o conjunto de elos é dado por E=\\big{\\{}\\{x,y\\}\\subset\\mathbb{Z}^{d}\\,:\\,|x-y|=1\\}, onde |\\cdot| representa a distância euclideana em \\mathbb{R}^{d} . No nosso modelo, esse grafo pode ser entendido como um cristal periódico onde cada vértice representa uma cavidade do material poroso e os elos são potenciais conexões entre poros vizinhos. Até agora nosso grafo é apenas uma rede periódica, mas as coisas começam a ficar interessantes à partir de agora. Imaginamos que nosso material poroso está sujeito a variações durante sua formação. Isso se reflete no fato que alguns elos de E podem estar abertos ou não aleatoriamente. Para o nosso modelo, o espaço amostral vai ser \\Omega:=\\{0,1\\}^{E} considerado com a \\sigma -algebra produto. Fixamos um p\\in[0,1] e definimos uma coleção de variáveis aleatórias \\omega_{e} , para e\\in E , que sejam \\iide com distribuição \\Ber(p) . Chamamos P_{p} a probabilidade correspondente. Essas variáveis aleatórias induzem um grafo aleatório G(\\omega)=(\\mathbb{Z}^{d},\\mathcal{E}(\\omega)) , subgrafo do grafo original, que corresponde a incluir apenas os elos e com \\omega_{e}=1 . Mais precisamente \\mathcal{E}(\\omega)=\\big{\\{}e\\in E\\,:\\,\\omega_{e}=1\\big{\\}}. (2.71) Podemos ver na Figura 2.2 algumas simulações desse grafo aleatório. Figura 2.2: Três simulações do grafo aleatório (\\mathbb{Z}^{d},\\mathcal{E}) , para valores de p=0,4 (esquerda), p=0,5 (centro) e p=0,6 (direita). Tente imaginar como seria caminhar nesse grafo como se ele fosse um labirinto. Agora que temos um modelo de meio poroso bem definido, precisamos pensar em quais perguntas nos interessam sobre \\mathcal{G}=(\\mathbb{Z}^{d},\\mathcal{E}) . Sendo esse um modelo para passagem de fluidos, as primeiras perguntas que faremos concerne a conectividade de \\mathcal{G} . {exercise} Mostre que quase certamente G(\\omega) é desconexo. Mais precisamente, mostre que existem quase certamente infinitos vértices isolados em G(\\omega) . Como não podemos esperar que G(\\omega) seja conexo, podemos nos perguntar algo mais fraco, como por exemplo se a componente conexa da origem 0\\in\\mathbb{Z}^{d} em G(\\omega) é infinita. Voltando à Figura 2.2 vemos que, dependendo do valor de p\\in[0,1] , pode ser bem difícil ou bem fácil encontrar um caminho longo à partir da origem. Isso é o que estudaremos em mais detalhes no que segue. Mais precisamente estamos interessados em: A=\\big{\\{}\\omega\\in\\Omega\\,:\\,\\text{ a componente conexa de $0\\in\\mathbb{Z}^{d% }$ em $G(\\omega)$ \\'{e} infinita}\\big{\\}}. (2.72) Para estudar A , vamos fazer uma aproximação de A por eventos mais simples A_{n}=\\big{\\{}\\omega\\in\\Omega\\,:\\,\\text{ a componente conexa de $0$ sai da % caixa $[-n,n]^{d}$}\\}, (2.73) para n\\geq 1 . {exercise} Mostre que A=\\cap_{n=1}^{n}A_{n} e consequentemente que A é de fato mensurável e P(A)=\\lim_{n\\to\\infty}P(A_{n}) . Definimos portanto a função \\theta:[0,1]\\to[0,1] por \\theta(p)=P_{p}(A), (2.74) onde P_{p} denota a probabilidade correspondente ao valor escolhido de p\\in[0,1] . {exercise} Mostre que \\theta(p)\\leq 1-(1-p)^{2d} . Nosso objetivo é entender algumas das propriedades de \\theta . A nossa intuição diz que quanto maior o valor de p , mais elos serão abertos em \\mathcal{G} e portanto maior será o valor de \\theta , ou em outras palavras, \\theta deve ser monótona não decrescente. {exercise} Construiremos nosso modelo de uma maneira alternativa num espaço de probabilidade maior. Definimos \\Omega_{0}:=[0,1]^{E} (com a \\sigma -álgebra produto correspondente), e (U_{e})_{e\\in E} uma coleção de variáveis aleatórias \\iidcom distribuição U[0,1] , e \\mathbb{P} a probabilidade corespondente. Definimos para cada p\\in[0,1] , X^{p}:\\Omega_{0}\\to\\Omega do jeito seguinte X^{p}_{e}=\\1_{[\\omega_{e}\\leq p]}. (2.75) Mostre que para todo p\\in[0,1] (X^{p})_{*}\\mathbb{P}=P_{p} . Use isso para concluir que \\theta é monótona não decrescente. Iremos agora mostrar a existência de um regime para o qual a componente conexa da origem não é infinita. {theorem} Para p<1/(2d) , temos que \\theta(p)=0 . Antes da prova, alguns exercícios. {exercise} Definimos um caminho como sendo uma sequência x_{1} , \\dots , x_{k} ( k\\in\\mathbb{N} ), tal que \\{x_{i},x_{i+1}\\}\\in E para todo i=1,\\dots,k-1 . Tal caminho é dito aberto se \\omega_{\\{x_{i},x_{i+1}\\}}=1 para todo i\\leq k-1 . E dizemos que ele é auto-evitante se x_{i}\\neq x_{j} para todo 1\\leq i<j<k . Mostre que \\begin{split}&A_{n}=\\Big{\\{}\\omega\\in\\Omega\\,:\\,\\text{ existe um caminho % aberto $(x_{i})_{i=1}^{k}$ com $x_{1}=0$ e $x_{k}\\not\\in[-n,n]^{d}$}\\Big{\\}}\\\\ &A_{n}=\\big{\\{}\\omega\\in\\Omega\\,:\\,\\text{ existe um caminho auto-evitante como% acima}\\big{\\}}.\\end{split} Demonstração. Dado p<1/(2d) e n\\in\\mathbb{N} , lembramos que \\begin{split}\\theta(p)&\\leq P_{p}(A_{n})=P_{p}\\Big{[}\\begin{array}[]{c}\\text{% existe $k\\in\\mathbb{N}$ e um caminho auto-evitante $(x_{i})_{i=1}^{k}$ }\\\\ \\text{aberto e com $x_{1}=0$ e $x_{k}\\not\\in[-n,n]^{d}$}\\end{array}\\Big{]}\\\\[5% .69054pt] &\\leq\\sum_{k\\geq n}\\;\\;\\sum_{(x_{i})_{i=1}^{k}\\text{ auto-evit.}}P_{p}[(x_{i})% _{i=1}^{k}\\text{ aberto}]=\\sum_{k\\geq n}\\;\\;\\sum_{(x_{i})_{i=1}^{k}\\text{ auto% -evit.}}p^{k}\\\\ &\\leq\\sum_{k\\geq n}\\;\\;\\sum_{(x_{i})_{i=1}^{k}\\text{ caminho}}P_{p}[(x_{i})_{i% =1}^{k}\\text{ aberto}]=\\sum_{k\\geq n}(2d)^{k}p^{k}.\\end{split} Como p<1/(2d) , a soma acima é finita e converge a zero quando n diverge, provando o teorema. ∎ Notas - O teorema acima ajuda a compreender o comportamento que observamos no lado esquerdo da Figura 2.2. Mais precisamente, ele nos diz que para valores de p baixos (na verdade 0,4 não é baixo o suficiente para podermos aplicar esse teorema) é difícil encontrar um caminho aberto do centro à borda da caixa. Na verdade, é possível mostrar que para d=2 , \\begin{split}&\\text{$\\theta(p)=0$ para todo $p\\leq 1/2$ e}\\\\ &\\text{$\\theta(p)>0$ para todo $p>1/2$,}\\end{split} (2.76) como foi mostrado por Harris e Kesten, veja por exemplo [2] e [1]. De fato, algo bastante interessante está acontecendo nesse modelo para p=1/2 , como nos mostrou o trabalho de grandes matemáticos, como: Oded Schramm, Wendelin Werner, Stanislav Smirnov, entre outros. \\todosec Tópico: Teorema de Uma Sériefazer… Previous page Next page"],[["index.html","Ch2.html","Ch2.Sx4.html"],"Tópico: Cadeias de Markov ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Tópico: Cadeias de Markov Tópico: Cadeias de Markov Um exemplo de como usar núcleos de transição é a construção de Cadeias de Markov. Esse tipo de processo é bastante útil em diversas aplicações, desde a biologia até a computação. Considere um espaço mensurável canônico fixo (E,\\mathcal{A}) e seja K um núcleo de E nele mesmo. Seria bastante intuitivo agora iterar K (já que ele está no mesmo espaço) e obter uma medida em \\Omega=E^{\\mathbb{N}} com a \\sigma -álgebra canônica. Para começar esse procedimento, seja \\mu_{0} uma medida inicial em (E,\\mathcal{A}) . Podemos então definir \\mu_{1}=\\mu_{0}\\star K o que é o primeiro passo da nossa construção, porém observe que não podemos escrever “ \\mu_{2}=\\mu_{1}\\star K ”, pois \\mu_{1}\\star K é uma medida em (E^{2},\\mathcal{A}^{\\otimes 2}) . Vamos com calma então. Observe que \\mu_{1}(A_{0}\\times A_{1})=\\int_{A_{0}}\\int_{A_{1}}K(x_{0},\\d{x}_{1})\\mu_{0}(% \\d{x}_{0}), (2.115) ou em outras palavras o valor de x_{0} determina a distribuição de x_{1} . Gostaríamos agora que x_{1} determinasse a distribuição de x_{2} via K , como por exemplo assim \\mu_{2}(A_{0}\\times A_{1}\\times A_{2})=\\int_{A_{0}}\\int_{A_{1}}\\int_{A_{2}}K(x% _{1},\\d{x}_{2})K(x_{0},\\d{x}_{1})\\mu_{0}(\\d{x}_{0}). (2.116) Mas essa notação fica bastante carregada à medida que iteramos. Para tornar essa notação mais simples, definimos a projeção \\phi_{n}:E^{n}\\to E por \\phi_{n}(x_{0},\\dots,x_{n-1})=x_{n-1} . Também precisamos de K_{n}:E^{n}\\times\\mathcal{A}\\to[0,1] dado por K_{n}(\\vec{x},A)=K\\big{(}\\phi_{n}(\\vec{x}),A\\big{)}\\quad\\big{(}=K(x_{n-1},A)% \\big{)}. (2.117) O fato de K_{n} ser um núcleo de transição segue imediatamente dessa propriedade para K . Note que, nessa notação, estamos dizendo que para irmos de E^{n} para E^{n+1} iremos olhar apenas para a última coordenada, na qual aplicaremos o núcleo K . Isso é o ponto mais importante que caracteriza uma Cadeia de Markov: a distribuição do estado futuro da cadeia depende apenas do estado atual e não do passado. Em alguns contextos essa propriedade é chamada de ausência de memória. Podemos finalmente definir \\mu_{n+1}=\\mu_{n}\\star K_{n},\\text{ para todo $n\\geq 1$}. (2.118) Mas resta a questão sobre a existência de uma \\mu^{\\infty} que será respondida com ajuda do próximo resultado. {lemma} As probabilidades \\mu_{n} definidas em (2.118) são compatíveis, mais precisamente \\mu_{n+1}(A\\times E)=\\mu_{n}(A) para todo A\\in\\mathcal{A}^{\\otimes n} . Demonstração. Basta observar que \\mu_{n+1}(A\\times E)=\\mu_{n}\\star K(A\\times E)=\\int_{A}\\underbrace{K_{n}(\\vec{% x},E)}_{1}\\mu_{n}(\\d{\\vec{}}{x})=\\mu_{n}(A), (2.119) provando o lema. ∎ Logo, o Teorema da Extensão de Kolmogorov (lembre que (E,\\mathcal{A}) foi suposto canônico) nos fornece uma única P em (\\Omega,\\mathcal{F}) tal que P_{(X_{0},\\dots,X_{n})}=\\mu_{n},\\text{ para todo $n\\geq 0$}. (2.120) Lembramos que X_{i} denotam as projeções canônicas em \\Omega=\\prod_{i=1}^{\\infty}E . Chamamos o processo X_{1},X_{2},\\dots sob a lei P da Cadeia de Markov com distribuição inicial \\mu_{0} e núcleo de transição K . {example} Suponha que E seja enumerável. Nesse caso recordamos do Exemplo 2.9 que o núcleo pode ser representado por uma matriz \\big{(}p(x,y)\\big{)}_{x,y\\in E} que nos retorna a probabilidade de saltar de x a y . Além disso, a distribuição inicial \\mu_{0} é determinada por P(\\{x\\})=p_{0}(x) , para alguma sequência \\big{(}p_{0}(x)\\big{)}_{x\\in E} . {exercise} Mostre que no exemplo acima temos P(X_{0}=x_{0},\\dots,X_{n}=x_{n})=p_{0}(x_{0})p(x_{0},x_{1})\\dots p(x_{n-1},x_{% n}). (2.121) {exercise} Defina K:\\mathbb{R}^{2}\\times\\mathcal{B}(\\mathbb{R}^{2})\\to[0,1] dada por K(x,A)=U_{S^{1}}(A-x). (2.122) Nesse contexto,  a)​mostre que K é um núcleo de transição e,  b)​considerando a cadeia com distribuição inicial \\mu_{0}=\\delta_{0} em \\mathbb{R}^{2} e núcleo K , mostre que X_{2} tem distribuição absolutamente contínua com respeito a Lebesgue e calcule sua densidade. {exercise} Mostre que para qualquer núcleo de transição K entre E e E , existe um núcleo de transição \\widebar{K} entre E e \\Omega=E^{\\mathbb{N}} , tal que para toda medida inicial \\mu_{0} , temos que \\mu_{0}\\star K é a distribuição de uma Cadeia de Markov começando de \\mu_{0} e com transição dada por K . Esse núcleo é útil se quisermos mudar a distribuição inicial \\mu_{0} e uma notação bastante comum para esse núcleo é P_{x}(\\cdot)=\\widebar{K}(x,\\cdot) . Vamos terminar essa seção dando uma interpretação bastante interessante para os núcleos de transição em analogia à álgebra linear. Fixe um núcleo de transição K entre E e E , uma medida inicial \\mu e uma função limitada f:E\\to\\mathbb{R} . Relembre a notação em (2.102) e defina Kf:E\\to\\mathbb{R} dada por Kf(x):=\\int f(y)K(x,\\d{y}), (2.123) que é obviamente limitada e já vimos ser mensurável no Teorema de Fubini. Então temos dois operadores definidos para núcleos, a multiplicação à esquerda por uma medida em E ( \\mu K que também é uma medida em E ) e a multiplicação à direita por uma função limitada e mensurável ( Kf que também é uma função limitada e mensurável). Podemos pensar em f como um vetor coluna e \\mu como um vetor linha, nesse caso K faria o papel de uma matriz. Essa analogia é real se E for um espaço enumerável. {exercise} No contexto de cadeias de Markov,  a)​mostre a relação de associatividade \\mu(Kf)=(\\mu K)f ,  b)​defina para todo n o núcleo K^{(n)} iterado (de E em E ), de forma que \\mu K^{(n)}f ainda seja associativa.  c)​Mostre que a medida \\mu K^{(n)} é a distribuição de X_{n} se começamos de \\mu ,  d)​que a função K^{(n)}f(\\cdot) é o valor esperado de f no tempo n se começamos no zero do ponto \\cdot e finalmente que  e)​o número real \\mu K^{(n)}f é a esperança de f no tempo n se começamos de \\mu . Vamos agora dar um exemplo simples de Cadeia de Markov que poderemos analisar em detalhes. Seja E=\\mathbb{Z} e considere K:\\mathbb{Z}\\times\\mathcal{P}(\\mathbb{Z})\\to[0,1] dado por K(x,\\cdot)=\\frac{\\delta_{x-1}+\\delta_{x+1}}{2}, (2.124) que obviamente define um núcleo pois toda função em \\mathbb{Z} é mensurável na \\sigma -álgebra das partes. Podemos portanto construir P em \\mathbb{Z}^{\\mathbb{N}} que nos fornece a lei de uma Cadeia de Markov em \\mathbb{Z} com distribuição inicial \\delta_{0} e núcleo de transição K . Chamamos esse processo de passeio aleatório simples simétrico. Poderíamos estar interessados em várias perguntas sobre esse processo, como por exemplo quão longe esperamos que o passeio aleatório pode ir depois de um determinado tempo? Para responder essa e várias outras questões, iremos mostrar outra construção do passeio simples simétrico através de uma soma de variáveis aleatórias. Introduzimos um espaço de probabilidade \\tilde{P} , variáveis Y_{1},Y_{2},\\dots \\iidcom distribuição (\\delta_{-1}+\\delta_{1})/2 e definimos S_{0}=0 e S_{n}=Y_{1}+\\dots+Y_{n} . {lemma} A distribuição da sequência infinita (X_{0},X_{1},\\dots) sob a lei P do passeio aleatório simples e simétrico é igual à distribuição de (S_{0},S_{1},\\dots) sob \\tilde{P} . Demonstração. Observamos primeiramente que basta mostrar a igualdade de distribuições para cilindros do tipo \\{x_{1}\\}\\times\\dots\\times\\{x_{n}\\}\\times\\mathbb{Z}^{\\mathbb{N}} , pois tais eventos compõem um \\pi -sistema que gera a \\sigma -álgebra produto em \\mathbb{Z}^{\\mathbb{N}} . Calculamos portanto \\begin{split}\\qquad P&[X_{1}=x_{1},\\dots,X_{n}=x_{n}]\\intertext{pela defini\\c{% c}\\~{a}o de Cadeia de Markov (via extens\\~{a}o de Kolmogorov),}&=\\mu_{n}[X_{1}% =x_{1},\\dots,X_{n}=x_{n}]\\\\ &=\\mu_{n-1}\\star K_{n}[X_{1}=x_{1},\\dots,X_{n}=x_{n}]\\intertext{por Fubini % para n\\'{u}cleos (Teorema\\leavevmode\\nobreak\\ \\ref{t:fubini}),}&=\\mu_{n-1}[X_{% 1}=x_{1},\\dots,X_{n-1}=x_{n-1}]K_{n}\\big{(}(x_{1},\\dots,x_{n-1}),\\{x_{n}\\}\\big% {)}\\\\ &=\\mu_{n-1}[X_{1}=x_{1},\\dots,X_{n-1}=x_{n-1}]K\\big{(}x_{n-1},\\{x_{n}\\}\\big{)}% \\\\ &=\\frac{1}{2}\\mu_{n-1}[X_{1}=x_{1},\\dots,X_{n-1}=x_{n-1}]\\1_{\\{|x_{n-1}-x_{n}|% =1\\}}\\\\ &=\\dots=2^{-n}\\prod_{i=1}^{n}\\1_{\\{|x_{i-1}-x_{i}|=1\\}}.\\end{split} Faremos agora esse cálculo para a distribuição de S_{i} ’s: \\begin{split}\\qquad\\tilde{P}&[S_{1}=x_{1},\\dots,S_{n}=x_{n}]\\\\ &=\\mu_{n}[Y_{1}=x_{1}-x_{0},Y_{2}=x_{2}-x_{1}\\dots,Y_{n}=x_{n}-x_{n-1}]\\\\ &=\\prod_{i=1}^{n}\\tilde{P}[Y_{i}=x_{i}-x_{i-1}]=2^{-n}\\prod_{i=1}^{n}\\1_{\\{|x_% {i-1}-x_{i}|=1\\}}.\\end{split} Isso mostra o enunciado do lemma. ∎ Podemos agora por exemplo estimar P[|X_{n}|\\geq\\varepsilon n]=\\tilde{P}[|S_{n}|\\geq\\varepsilon n]\\leq 2\\exp\\{-% \\psi_{(\\delta_{-1}+\\delta_{1})/2}(\\varepsilon)n\\}, (2.125) que responde nossa pergunta sobre a probabilidade de um passeio aleatório se distanciar muito da origem. Previous page Next page"],[["index.html","Ch2.html","Ch2.Sx5.html"],"Tópico: Urna de Pólya ‣ Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Tópico: Urna de Pólya Tópico: Urna de Pólya Um excelente exemplo de como Cadeias de Markov podem gerar interessantes modelos de situações reais são as chamadas Urnas de Pólya. Esse processo modela sistemas de física, biologia, computação e economia que apresentam o que chamamos de reforço. Tome por exemplo duas empresas que competem pelo mercado de aviões. Inicialmente, não temos nenhuma razão para escolher uma em detrimento da outra, portanto compramos nosso primeiro avião de cada empresa com probabilidade meio. Porém, depois que já compramos diversos aviões de uma determinada empresa, ela já recebeu bastante dinheiro que pode ser reinvestido para gerar melhor tecnologia e aumentar as chances que ela seja escolhida novamente no futuro. Isso é o que chamamos de reforço. Vamos agora apresentar rigorosamente um modelo para situações desse tipo. O nosso modelo começa com uma urna contendo duas bolas, uma vermelha e uma azul. No cada passo do processo, escolheremos uma bola da urna ao acaso, olharemos sua cor e retornaremos essa bola para dentro urna junto com mais uma bola da mesma cor. Isso pode será formalizado à seguir. Vamos construir uma medida em \\{0,1\\}^{\\mathbb{N}} , dotado da \\sigma -álgebra produto. Fixada uma sequência finita w_{1},\\dots,w_{n} em \\{0,1\\} , definimos N_{x}(w_{1},\\dots,w_{n})=\\#\\big{\\{}j\\in\\{1,\\dots,n\\}\\,:\\,w_{j}=x\\big{\\}}+1, (2.126) que nada mais é que o número de bolas do tipo x que se encontram na urna no tempo n . Quando tivermos uma sequência infinita de w_{i} ’s, escreveremos N^{n}_{x} para denotar N_{x}(w_{1},\\dots,w_{n}) . Para cada n\\geq 1 , definimos K_{n}:\\{0,1\\}^{n}\\to\\mathcal{P}(\\{0,1\\}) por K_{n}(w_{1},\\dots,w_{n})=\\Ber\\big{(}\\tfrac{N_{1}}{n}\\big{)}. (2.127) Ou seja, dadas cores w_{1},\\dots,w_{n} , escolheremos uma bola de cor 1 proporcionalmente ao número N_{1} de bolas de cor 1 que já foram sorteadas. {exercise} Mostre que todos K_{n} acima definem núcleos de transição. Além disso a seguinte sequência de medidas é compatível no sentido de Kolmogorov: •​ P_{1}=\\Ber(1/2) , •​ P_{2}=P_{1}\\star K_{1} , •​ P_{3}=P_{2}\\star K_{2},\\dots Conclua que existe a medida P em \\{0,1\\}^{\\mathbb{N}} que define o modelo de Pólya. Podemos agora fazer perguntas como por exemplo: será que escolheremos bolas de ambas as cores para sempre, ou a partir de um certo momento escolheremos bolas de apenas uma cor com certa probabilidade. Mais precisamente, qual é a probabilidade de [X_{i}=1,\\text{ infinitas vezes}] ? Para responder perguntas desse tipo, iremos mostrar algo muito curioso, que pode ser entendido como uma outra maneira de representar o modelo descrito acima. Mas antes, vamos colecionar alguns fatos sobre o modelo da Urna de Pólya. Primeiramente vamos olhar para os seguintes eventos. Fixamos n\\geq 1 e uma sequência w_{1},\\dots,w_{n}\\in\\{0,1\\} e seja A o evento \\{w_{1}\\}\\times\\dots\\times\\{w_{n}\\}\\times\\{0,1\\}\\times\\dots Note que os eventos desse tipo (junto com o evento \\varnothing ) formam um \\pi -sistema que gera a \\sigma -álgebra canônica de \\{0,1\\}^{\\mathbb{N}} , portanto essa coleção é bastante completa para identificar a distribuição da Urna de Pólya. Podemos calcular a probabilidade do evento A acima \\begin{split}P(A)&=\\frac{N^{1}_{w_{1}}}{2}\\frac{N^{2}_{w_{1}}}{3}\\dots\\frac{N^% {n}_{w_{n}}}{n+1}=\\frac{1}{(n+1)!}\\prod_{i=1}^{n}N^{i}_{w_{i}}\\\\ &=\\frac{N^{n}_{1}!(n-N^{n}_{1})!}{(n+1)!}=\\frac{1}{(n+1)}\\binom{n}{N^{n}_{1}}^% {-1}.\\end{split} (2.128) O que é muito interessante sobre a equação acima é que ela nos remete a problemas combinatórios ao notarmos o fator binomial acima. Vamos portanto construir um processo completamente diferente que apresenta as mesmas probabilidades que o anterior. Seja \\mathcal{S}_{N} o conjunto de todas as permutações \\sigma de \\{1,\\dots,N\\} . É fácil ver que \\frac{1}{(n+1)}\\binom{n}{j}^{-1}=U_{\\mathcal{S}_{n+1}}\\Big{[}\\sigma(n+1)=j+1,% \\sigma(i)\\leq j\\text{ se e s\\'{o} se }\\;i\\leq j\\Big{]}. Um método muito interessante de se produzir uma permutação uniforme é dado pelos seguintes exercícios. {exercise} Seja n\\geq 1 um inteiro, P uma probabilidade em (E,\\mathcal{A}) , \\sigma uma permutação fixa em \\mathcal{S}_{n} . Então (X_{1},\\dots,X_{n})\\distr(X_{\\sigma(1)},\\dots,X_{\\sigma(n)}), (2.129) onde X_{i} como sempre representam as coordenadas canônicas em (E^{n},\\mathcal{A}^{\\otimes n},P^{\\otimes n}) . Ou em outras palavras, aplicar uma permutação fixa a uma sequência \\iidnão altera sua distribuição. Sequências de elementos aleatórios (não necessariamente \\iid’s) que satisfazem (2.129) são ditas intercambiáveis. Um outro exercício interessante nesse tópico é o seguinte {exercise} Seja n\\geq 1 e F:[0,1]^{n}\\to\\mathcal{S}_{n} dada por F(x_{1},\\dots,x_{n})=\\begin{cases}(1,2,\\dots,n),\\qquad\\text{se existe $i\\neq j% $ com $x_{i}=x_{j}$, }\\\\ \\text{o \\'{u}nico $\\sigma$ tal que $x_{\\sigma(1)}<\\dots<x_{\\sigma(n)}$,}\\qquad% \\text{caso contr\\'{a}rio.}\\end{cases} Mostre que F_{*}(U_{[0,1]}^{\\otimes n})=U_{\\mathcal{S}_{n}} . Ou seja, ordenar uma sequência de uniformes independentes nos fornece uma permutação uniforme. Como prometido, isso nos dá uma maneira de construir uma permutação uniforme de \\{1,\\dots,n\\} à partir de uma sequência \\iid(que é algo que já estamos começando a entender melhor). Podemos agora escrever nossa probabilidade de observar uma sequência no modelo da Urna de Pólya em termos de uma sequência \\iidde variáveis aleatórias. \\begin{split}\\frac{1}{(n+1)}&\\binom{n}{N^{n}_{1}}^{\\mathclap{\\;-1}}=F_{*}U_{[0% ,1]}^{\\otimes n+1}\\Big{[}\\sigma(n+1)=N^{n}_{1}+1,\\sigma(i)\\leq N^{n}_{1}\\text{% se e s\\'{o} se }i\\leq N^{n}_{1}\\Big{]}\\\\ &=U^{\\otimes n+1}_{[0,1]}\\Big{[}\\text{$X_{i}<X_{n+1}$, para $i\\leq N^{n}_{1}$ % e $X_{i}>X_{n+1}$, para $i\\geq N^{n}_{1}+1$}\\Big{]}.\\end{split} Agora estamos prontos para provar o resultado principal que nos ajudará a calcular probabilidades no modelo da Urna de Pólya. Dado u\\in[0,1] , seja P_{u}=\\Ber(u)^{\\otimes\\mathbb{N}} , ou seja a probabilidade que nos dá uma sequência infinita de moedas independentes com probabilidade u de sucesso. Definimos agora \\widebar{K}:[0,1]\\times(\\mathcal{P}(\\{0,1\\})^{\\otimes\\mathbb{N}})\\to[0,1] dada por \\widebar{K}(u,A)=P_{u}(A). (2.130) {lemma} A função \\widebar{K} definida acima é um núcleo entre [0,1] e \\{0,1\\}^{\\mathbb{N}} . Demonstração. Usando a Proposição 2.9, basta ver que {display} para todo k\\geq 1 e w_{1},\\dots,w_{k}\\in\\{0,1\\} , temos que P_{u}(X_{1}=w_{1},\\dots,X_{k}=w_{k}) é uma função mensurável de u\\in[0,1] . Mas é fácil ver que P_{u}(X_{1}=w_{1},\\dots,X_{k}=w_{k})=u^{N_{1}(w_{1},\\dots,w_{k})}(1-u)^{N_{0}(% w_{1},\\dots,w_{k})}, (2.131) que obviamente é mensurável, provando assim o lema. ∎ O resultado muito curioso a qual nos referimos é o seguinte. {lemma} A lei P definida no Exercício 2 é igual a U_{[0,1]}\\widebar{K} . Em outras palavras, digamos que realizamos os seguintes experimentos. Primeiramente João realiza o processo da Urna de Pólya e anota a sequência das cores obtidas. Depois Maria sorteia uma variável aleatória X de distribuição uniforme em [0,1] e depois joga infinitas vezes uma moeda com probabilidade X de obter vermelho e (1-X) de obter azul, anotando também quais cores foram obtidas. Finalmente, não seríamos capazes de distinguir essas duas sequências (mesmo que pudéssemos repetir várias vezes esse experimento) pois elas tem a mesma distribuição em \\{0,1\\}^{\\mathbb{N}} . Demonstração. Já sabemos que basta mostrar a igualdade para eventos do tipo A=\\{w_{1}\\}\\times\\dots\\times\\{w_{n}\\}\\times\\{0,1\\}^{\\mathbb{N}} . Sabemos pelo Teorema de Fubini para Núcleos que U_{[0,1]}\\widebar{K}(A)=\\int_{0}^{1}K(u,A)\\d{u}\\overset{\\eqref{e:Polya_% binomial}}{=}\\int_{0}^{1}u^{N_{1}(w_{1},\\dots,w_{k})}(1-u)^{N_{0}(w_{1},\\dots,% w_{k})}\\d{u}. (2.132) Por outro lado , sabemos (usando simetria entre 0 e 1 ) que P(A)=U^{\\otimes n+1}_{[0,1]}\\Big{[}\\text{$X_{i}<X_{n+1}$, para $i\\leq N^{n}_{0% }$ e $X_{i}>X_{0}$, para $i\\geq N^{n}_{0}+1$}\\Big{]} (2.133) Se definirmos \\tilde{K}:[0,1]\\times\\mathcal{B}([0,1]^{n}) , dado por \\tilde{K}(u,B)=U^{\\otimes n}_{[0,1]} , sabemos que isso define um núcleo pelo Exercício 2.9. Mais ainda, esse mesmo exercício nos diz que U_{[0,1]}\\star\\tilde{K}=U^{\\otimes}_{[0,1]} , de forma que \\begin{split}P(A)&=U_{[0,1]}\\star\\tilde{K}\\Big{[}\\text{$X_{i}<X_{0}$, para $i% \\leq N^{n}_{0}$ e $X_{i}>X_{0}$, para $i\\geq N^{n}_{0}+1$}\\Big{]}\\\\ &=\\int_{0}^{1}U^{\\otimes n}_{[0,1]}\\Big{[}\\text{$X_{i}<u$, para $i\\leq N^{n}_{% 0}$ e $X_{i}>u$, para $i\\geq N^{n}_{0}+1$}\\Big{]}\\d{u}\\\\ &=\\int_{0}^{1}u^{N^{n}_{0}}(1-u)^{n-N^{n}_{0}}\\d{u},\\end{split} que coincide com U_{[0,1]}\\widebar{K}(A) , provando o lema. ∎ {exercise} Mostre que a probabilidade, segundo o modelo da Urna de Pólya, de que observemos infinitas bolas de ambas as cores é um. Previous page Next page"],[["index.html","Ch2.html"],"Capítulo 2 Construção de espaços de probabilidade ‣ Notas de aula: Probabilidade I","Skip to content. Construção de espaços de probabilidade Capítulo 2 Construção de espaços de probabilidade Nessa seção descreveremos diversas maneiras diferentes de construir um espaço de probabilidade, dando diversos exemplos de como elas podem ser usadas na modelagem de diferentes processos reais. Previous page Next page"],[["index.html","Ch3.html","Ch3.S1.html"],"3.1 Esperança ‣ Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. Esperança 3.1 Esperança {definition} Se X é uma variável aleatória com \\int_{\\Omega}|X|\\d{\\omega}<\\infty , dizemos que X é integrável e definimos E(X)=\\int_{\\Omega}X(\\omega)P(\\d{\\omega}), (3.1) a chamada esperança de X . Nesse caso também dizemos que X\\in\\mathcal{L}^{1} . Quando X\\geq 0 , também podemos supor que E(X) está bem definida, mesmo que possivelmente tomando valor infinito. Não demonstraremos algumas propriedades conhecidas da integração de Lebesgue, tais como  a)​ E(X+\\alpha Y)=E(X)+\\alpha E(Y) (se estiverem bem definidas),  b)​Valem os Teoremas de Convergência (Monótona e Limitada). {exercise} Mostre que se X\\in\\mathcal{L}^{1} e P[X>x]=0 , então E(X)\\leq x . {lemma} A esperança de uma variável aleatória X\\in\\mathcal{L}^{1} depende somente de sua distribuição. Mais precisamente E(X)=\\int x\\;P_{X}(\\d{x}). (3.2) Demonstração. Vamos mostrar que E\\big{(}f(X)\\big{)}=\\int f(x)(X\\circ P)(\\d{x}), (3.3) para toda f:\\mathbb{R}\\to\\mathbb{R} mensurável tal que f(X)\\in\\mathcal{L}^{1} . Para f=\\1_{A} , temos E\\big{(}f(X)\\big{)}=P[X\\in A]=(X\\circ P)(A), (3.4) por definição de X\\circ P . Agora podemos extender o teorema para funções f simples por linearidade, depois para funções positivas usando o Teorema da Convergência Monótona e finalmente escrevemos x=x\\1_{[0,\\infty)}-(-x)\\1_{(-\\infty,0)} . ∎ Vamos mostrar uma fórmula bastante simples de integração de variáveis tomando valores em um conjunto enumerável. Se X\\in\\{x_{1},x_{2},\\dots\\} P -quase certamente, então \\begin{split}E(X)&=\\int_{\\Omega}XP(\\d{\\omega})=\\int\\sum_{i}\\1_{[X=x_{i}]}XP(\\d% {\\omega})+\\int_{\\{x_{1},x_{2},\\dots\\}^{c}}XP(\\d{\\omega})\\\\ &=\\sum_{i}\\int_{[X=x_{i}]}x_{i}P(\\d{\\omega})+0=\\sum_{i}x_{i}P[X=x_{i}].\\end{split} (3.5) Para nos acostumar à notação de probabilidade, vamos agora mostrar o mesmo resultado da seguinte forma \\begin{split}E(X)&=E\\Big{(}\\sum_{i}X\\1_{[X=x_{i}]}\\Big{)}+E(X\\1_{\\{x_{1},x_{2}% ,\\dots\\}^{c}})\\\\ &=\\sum_{i}E[X;X=x_{i}]+0=\\sum_{i}x_{i}P[X=x_{i}].\\end{split} (3.6) Que é certamente muito útil quando nos habituamos a ela. Observe que acima usamos a notação E[X;\\mathcal{Q}]=E(X\\1_{[\\mathcal{Q}]}) . Também utilizaremos E[X;\\mathcal{Q}_{1},\\mathcal{Q}_{2},\\dots]=E(X\\1_{[\\mathcal{Q}_{1},\\mathcal{Q}% _{2},\\dots]}) {example} Se X\\overset{d}{\\sim}\\Ber(p) , então E(X)=0\\cdot P[X=0]+1P[X=1]=0+p=p . {example} Seja X\\overset{d}{\\sim}\\Bin(n,p) , então, para calcular E(X) , basta calcular E(Y) onde X\\overset{d}{\\sim}Y . Como vimos anteriormente, se Z_{1},Z_{2},\\dots,Z_{n} são variáveis \\iid(relembrando: independentes e identicamente distribuídos) com Z_{1}\\overset{d}{\\sim}\\Ber(p) , então Y=\\sum_{i}Z_{i}\\overset{d}{\\sim}\\Bin(n,p) . Logo E(X)=E(Y)=\\sum_{i}E(Z_{i})=np. (3.7) Se d(X\\circ P)=\\rho(x)\\d{x} (com \\rho\\geq 0 e \\int\\rho(x)\\d{x}=1 ), então E(X)=\\int x(X\\circ P)(\\d{x})=\\int x\\rho(x)\\d{x}. (3.8) {example} Se X\\overset{d}{\\sim}U_{[0,1]} , então sua densidade com respeito a Lebesgue é dada por d(X\\circ P)=\\1_{[0,1]}\\d{x} , donde E(X)=\\int_{0}^{1}x\\d{x}=1/2 . {proposition} Se X\\geq 0 P -q.c., então E(X)=\\int_{0}^{\\infty}P[X>x]\\d{x})=\\int_{0}^{\\infty}1-F(x)\\d{x}. (3.9) Demonstração. \\begin{split}E(X)&=E\\Big{(}\\int_{0}^{X}1\\d{x}\\Big{)}=E\\Big{(}\\int_{0}^{\\infty}% \\1_{[x<X]}\\d{x}\\Big{)}\\\\ &\\overset{\\text{Fubini}}{=}\\int_{0}^{\\infty}E(\\1_{[x<X]})\\d{x}=\\int_{0}^{% \\infty}P[x<X]\\d{x}.\\end{split} (3.10) ∎ {example} Se X\\overset{d}{\\sim}\\Exp(\\lambda) , então P[X\\geq x]=\\int_{x}^{\\infty}\\lambda e^{-\\lambda t}\\d{t}=e^{-\\lambda x}, (3.11) donde E(X)=\\int_{0}^{\\infty}e^{-\\lambda x}\\d{x}=\\frac{1}{\\lambda}. (3.12) {exercise} Se X\\in\\mathcal{L}^{1} e P[X\\geq x]=P[X\\leq-x] para todo x\\geq 0 , então E(X)=0 . {exercise} Marcelo coleciona figurinhas de futebol. O álbum completo conterá N figurinhas. No i -ésimo dia, ele compra uma nova carta X_{i}\\in\\{1,\\dots,N\\} . A coleção (X_{i})_{i\\geq 0} é distribuida de maneira \\iide uniforme nas figurinhas.  a)​Para j=1,\\dots,N , seja T_{j} o tempo passado até a aquisição da j -ésima nova figurinha, i.e. T_{1}=1\\quad\\text{ e }\\quad T_{j}=\\inf\\{i,X_{i}\\not\\in\\{X_{T_{j^{\\prime}}};j^{% \\prime}<j\\}\\}. (3.13) Mostre que T_{j} é finito quase certamente, para todo j\\leq N .  b)​Calcule a distribuição conjunta de (T_{1},T_{2}-T_{1},\\dots,T_{N}-T_{N-1}) .  c)​Calcule a esperança de T_{N} (o dia em que Marcelo completa seu álbum). {exercise} Sejam X_{1},X_{2},\\dots variáveis aleatórias \\iide defina o primeiro tempo de récorde como R=\\inf\\{i\\geq 2;X_{i}\\geq X_{1}\\}. (3.14) Supondo que X_{1} é absolutamente contínua com respeito à medida de Lebesgue, encontre E(R) . 3.1.1 Desigualdade de Markov {theorem} Se X\\geq 0 P -q.c., então para todo x>0 , P[X\\geq x]\\leq\\frac{E(X)}{x}. (3.15) Demonstração. Sabemos que X\\geq x\\1_{[X\\geq x]} , logo E(X)\\geq xE(\\1_{[X\\geq x]})=xP[X\\geq x], (3.16) que termina a prova. ∎ O próximo exemplo serve muito bem para mostrar porque estamos interessados em desigualdades como a do Teorema 3.1.1 acima. Em vários exemplos importantes, podemos ter dificuldade de calcular probabilidades explicitamente. Nesses casos, poderíamos gastar nossas energias tentando calculá-las a qualquer custo, ou podemos nos contentar em obter cotas superiores e inferiores para as probabilidades nas quais estamos interessados. Em vários casos, a segunda estratégia tem uma grande vantagem sobre a primeira, por possibilitar que estudemos problemas mais complexos (e consequentemente mais importantes/interessantes) e muitas vezes sem nos afastarmos da realidade (em vários exemplos as cotas superiores e inferiores são próximas o suficiente para que não nos preocupemos). {example} Sejam n patos e m caçadores. Cada caçador escolhe um pato aleatorea e uniformemente e atira (abatendo-o com probabilidade p ). Seja X=\\#\\{\\text{patos vivos}\\} , que pode ter uma distribuição complicada de calcular, mas \\begin{split}E(X)&=E\\Big{(}\\sum_{i=1}^{n}\\1_{[\\text{pato $i$ vive}]}\\Big{)}=% \\sum_{i=1}^{n}P[\\text{pato $i$ vive}]\\\\ &=nP[\\text{pato $1$ vive}]=P\\Big{(}\\mcap_{j=1}^{m}[\\text{ca\\c{c}ador $j$ n\\~{a% }o mata pato $1$}]\\Big{)}\\\\ &=nP[\\text{ca\\c{c}ador $j$ n\\~{a}o mata pato $1$}]^{m}=n\\Big{(}1-\\frac{p}{n}% \\Big{)}.\\end{split} (3.17) Observe que  a)​acima obtivemos uma igualdade e  b)​ [\\text{pato $i$ vive}] , i=1,\\dots,n não são independentes. Finalmente estimamos (digamos para n par) \\begin{split}&P[\\text{patos para o jantar}\\leq n/2]=P[X\\geq n/2]\\leq\\frac{E(X)% }{n/2}\\\\ &\\qquad=2\\frac{n}{n}\\Big{(}1-\\frac{p}{n}\\Big{)}^{m}\\leq 2\\exp\\{-\\frac{pm}{n}\\}% .\\end{split} (3.18) \\todosec Tópico: Grafos Aleatóriosfazer erdos renyi… \\todosec Tópico: Currie Weissfazer… 3.1.2 Esperança e independência {proposition} Sejam X e Y variáveis aleatórias independentes e em \\mathcal{L}^{2} , então E(XY)=E(X)E(Y). (3.19) Demonstração. Obviamente o resultado acima é válido para funções indicadoras, pois \\1_{A}\\1_{B}=\\1_{A\\cap B} . Por linearidade, o resultado também vale para funções simples e usando o Teorema da Convergência Monótona podemos extendê-lo para funções positivas. Finalmente, decompomos X=X_{+}-X_{-} e Y=Y_{+}-Y_{-} e lembramos que ambas estão em \\mathcal{L}^{2} para concluir a prova. ∎ {exercise} Mostre que E(XY) , E(X/Y) , E(X+Y) … dependem apenas da distribuição de (X,Y)\\in\\mathbb{R}^{2} . {exercise} Mostre que se X,Y\\in\\mathcal{L}^{1} , então também vale E(XY)=E(X)E(Y) . Previous page Next page"],[["index.html","Ch3.html","Ch3.S2.html"],"3.2 Variância ‣ Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. Variância 3.2 Variância Na seção anterior, limitamos P[X>a] usando E(X) (se X\\geq 0 ). Esse método é chamado de método do primeiro momento, de acordo com a seguinte {definition} Dada uma variável aleatória X , definimos o seu k -ésimo momento como E(X^{k}) , para k=1,2,\\dots Então, por exemplo, se X\\in\\mathcal{L}^{k} e X\\geq 0 , podemos estimar P[X\\geq x]=P[X^{k}\\geq x^{k}]\\leq\\frac{E(X^{k})}{x^{k}},\\text{ para quaisquer % $k\\geq 1$.} (3.20) Observe que quando o k -ésimo momento de X é finito, a razão acima decai mais rápido quando x diverge. {exercise} Mostre uma fórmula análoga à da Proposição 3.1. {exercise} Mostre que se a distribuição de X tem densidade \\rho e E(|f(X)|)<\\infty , então E(f(X))=\\int f(x)\\rho(x)\\d{x}. (3.21) Um caso bastante importante ocorre quando k=2 , por várias razões que descreveremos abaixo. Digamos que estamos interessados em aproximar uma variável aleatória por uma constante de forma a minimizar o erro da aproximação. Uma possível formulação desse problema é encontrar a de forma a minimizar E\\Big{(}(X-a)^{2}\\Big{)}=E(X^{2})-2aE(X)+a^{2}. (3.22) Essa equação obviamente possui um único mínimo em a=E(X) . Ao erro da aproximação acima damos o nome de variância {definition} Dada uma variável aleatória X\\in\\mathcal{L}^{2} , definimos sua variância como \\Var(X)=E\\Big{(}\\big{(}X-E(X)\\big{)}^{2}\\Big{)}=E(X^{2})-E(X)^{2}. (3.23) Observe pelas definições alternativas dadas acima que  a)​ \\Var(X)\\geq 0 e  b)​ E(X^{2})\\geq E(X)^{2} . {exercise} Mostre que se X\\in\\mathcal{L}^{2} , então \\Var(X)=0 se e somente se X=a quase certamente. Obviamente \\Var(aX)=E(a^{2}X^{2})-E(aX)^{2}=a^{2}\\Var(X). (3.24) Podemos alternativamente entender a variância da seguinte meneira. Sejam X e Y variáveis aleatórias independentes em \\mathcal{L}^{2} de mesma distribuição. Então, E\\big{(}(X-Y)^{2}\\big{)}=E(X^{2})-2E(XY)+E(X^{2})=E(X^{2})-E(X)^{2}=\\Var(X). (3.25) {exercise} Mostre que se X\\in\\mathcal{L}^{2} , então \\Var(X+b)=\\Var(X) . {exercise} Calcule Var(X) quando X tem distribuições \\Ber(p) , U[0,1] ou \\Exp(\\lambda) . A seguinte proposição mostra que a variância é uma maneira de estimar o quanto uma variável aleatória se desvia de sua média. {proposition} Se X\\in\\mathcal{L}^{2} e a>0 , então P[|X-E(X)|>a]\\leq\\frac{\\Var(X)}{a^{2}}. (3.26) Demonstração. A desigualdade segue trivialmente da cota de Markov, ao observarmos que  a)​ |X-E(X)|\\geq 0 ,  b)​ |X-E(X)|>a se e somente se |X-E(X)|^{2}>a^{2} e  c)​ E\\big{(}|X-E(X)|^{2}\\big{)}=E\\big{(}(X-E(X))^{2}\\big{)}=\\Var(X) , mostrando a proposição. ∎ Para variáveis aleatórias de média zero, a variância nada mais é que E(X^{2}) , ou em outras palavras \\lVert X\\rVert^{2}_{2} , o quadrado de sua norma em \\mathcal{L}^{2} . Isso nos motiva a olhar mais de perto para o produto interno em \\mathcal{L}^{2} , que se traduz a E(XY) . Mas para não nos restringirmos a variáveis de média zero, introduzimos a seguinte {definition} Se X,Y são variáveis em \\mathcal{L}^{2} , definimos \\Cov(X,Y)=E\\Big{(}\\big{(}X-E(X)\\big{)}\\big{(}Y-E(Y)\\big{)}\\Big{)}=E(XY)-E(X)E(% Y). (3.27) Uma observação importante é que se X e Y em \\mathcal{L}^{2} são independentes, então \\Cov(X,Y)=0 . (3.28) {exercise} Sejam X_{1} e X_{2} as coordenadas canônicas em \\mathbb{R}^{2} . Já vimos que elas não são independentes sob a distribuição U_{S^{1}} . Mostre que mesmo assim temos \\Cov(X_{1},X_{2})=0 . Uma outra propriedade bastante importante da variância é que ela se comporta bem com somas, no seguinte sentido {proposition} Se X_{1},\\dots,X_{n} são variáveis em \\mathcal{L}^{2} , então \\Var(X_{1}+\\dots+X_{n})=\\sum_{i=1}^{n}\\Var(X_{i})+\\sum_{i\\neq j}\\Cov(X_{i},X_{% j}). (3.29) Em particular, se as variáveis X_{i} forem independentes duas a duas, então \\Var(X_{1}+\\dots+X_{n})=\\sum_{i=1}^{n}\\Var(X_{i}). (3.30) Demonstração. Basta fazer o tedioso desenvolvimento \\begin{split}\\Var\\Big{(}\\sum_{i}X_{i}\\Big{)}&=E\\Big{(}\\Big{(}\\sum_{i}X_{i}-E% \\Big{(}\\sum_{i}X_{i}\\Big{)}\\Big{)}^{2}\\Big{)}\\\\ &=E\\Big{(}\\Big{(}\\sum_{i}X_{i}-E(X_{i})\\Big{)}^{2}\\Big{)}\\\\ &=\\sum_{i,j=1}^{n}E\\big{(}X_{i}-E(X_{i})\\big{)}E\\big{(}X_{j}-E(X_{j})\\big{)},% \\end{split} (3.31) o que termina a prova ao separarmos i=j de i\\neq j . ∎ {exercise} Calcule \\Var(X) quando X\\overset{d}{\\sim}\\Bin(n,p) . {exercise} Calcule E(X) quando X\\overset{d}{\\sim}\\Geo(p) . Um dito popular muito comum no Brasil é que não devemos deixar todos os “ovos no mesmo cesto”, o que nos remete à possibilidade de perdermos todos eles caso o cesto caia. Uma outra maneira de pensar nas vantagens de se dividir nossos riscos entre várias fontes independentes de incerteza, vem da equação (3.30), melhor explicada no exercício abaixo. {exercise} Imagine que X_{1},\\dots,X_{n} são variáveis \\iid, tomando valores em [0,1] e que temos um certo valor s\\in\\mathbb{R}_{+} que temos que guardar em n caixas (dividindo como quisermos em s_{1},\\dots,s_{n} ). Ao fim da semana, obteremos S=\\sum_{i}s_{i}X_{i} . Calcule E(S) e \\Var(S) ,  a)​se s_{1}=s e s_{i}=0 para todo i\\geq 2 e  b)​se s_{i}=s/n para todo i . Compare os resultados. {exercise} Calcule \\lim_{p\\to 0}F_{p}(x) onde F_{p} é a função de distribuição acumulada de pX_{p} com X_{p}\\overset{d}{\\sim}\\Geo(p) . Você reconhece esse limite? Previous page Next page"],[["index.html","Ch3.html","Ch3.S3.html"],"3.3 Lei fraca dos grandes números ‣ Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. Lei fraca dos grandes números 3.3 Lei fraca dos grandes números Nessa seção iremos mostrar um dos resultados mais importantes da Teoria da Probabilidade. O que nossa intuição tem a nos dizer sobre a probabilidade de obtermos um resultado em um dado é 1/6 ? Uma possível explicação seria por simetria, mas e o que podemos dizer no caso de um dado viciado? Se dizemos a alguém que a probabilidade de obter 6 em um certo dado é 1/10 , naturalmente a pessoa pode se perguntar como descobrimos isso. Um bom jeito de obter tal medida seria jogar o dado várias vezes independentemente e calcular em qual proporção dos ensaios ele retornou um seis. O objetivo desta seção é confirmar a validade desse experimento de maneira quantitativa. {theorem} Se X_{1},X_{2},\\dots são i.i.d.s em \\mathcal{L}^{2} e definimos S_{n}=\\sum_{i=1}^{n}X_{i}, (3.32) então para todo \\varepsilon>0 \\lim_{n\\to\\infty}P\\Big{[}\\Big{|}\\frac{S_{n}}{n}-E(X_{1})\\Big{|}>\\varepsilon% \\Big{]}=0. (3.33) Ou seja, \\tfrac{S_{n}}{n}\\to E(X_{1}) em medida (que também chamamos de “em probabilidade”). Demonstração. Sabemos que P\\Big{[}\\Big{|}\\frac{S_{n}}{n}-E(X_{1})\\Big{|}>\\varepsilon\\Big{]}\\leq\\frac{% \\Var(\\tfrac{S_{n}}{n})}{\\varepsilon^{2}}, (3.34) pois E(S_{n}/n)=1/nE(X_{1}+\\dots+X_{n})=E(X_{1}) . Mas como \\Var(S_{n}/n)=1/n^{2}\\Var(X_{1}+\\dots+X_{n})=(n/n^{2})\\Var(X_{1}) , temos o resultado. ∎ Observe que nós apenas utilizamos que as variáveis X_{i} eram independentes duas a duas. Além disso, obtivemos o seguinte resultado quantitativo que vale mesmo para valores finitos de n : {scholia} Se X_{1},X_{2},\\dots são i.i.d.s em \\mathcal{L}^{2} e definimos S_{n}=\\sum_{i=1}^{n}X_{i} como acima, então, para todo \\varepsilon>0 e n\\geq 1 , temos P\\Big{[}\\Big{|}\\frac{S_{n}}{n}-E(X_{1})\\Big{|}>\\varepsilon\\Big{]}\\leq\\frac{% \\Var(X_{1})}{\\varepsilon^{2}n}. (3.35) {corollary} Se A_{1},A_{2},\\dots são eventos independentes dois a dois com P(A_{i})=p\\in[0,1] para todo i , então \\lim_{n\\to\\infty}P\\Big{[}\\Big{|}\\frac{\\#\\{i\\leq n;\\omega\\in A_{i}\\}}{n}-p\\Big{% |}>\\varepsilon\\Big{]}=0, (3.36) ou em outras palavras a proporção de ensaios onde o evento A_{i} ocorre converge em probabilidade para p . Demonstração. Basta tomar X_{i}=\\1_{A_{i}} no Teorema 3.3. ∎ {exercise} Sejam (X_{i})_{i\\geq 1} variáveis \\iidcom distribuição Ber (p) , p\\in[0,1] . Mostre que \\lim_{N\\to\\infty}\\frac{1}{N}\\sum_{i=1}^{N}X_{i}X_{i+1}=p^{2},\\text{ em % probabilidade.} (3.37) {exercise} Sejam X_{1},\\dots,X_{n} e Y_{1},\\dots,Y_{n} variáveis independentes com distribuição \\Ber(p) . Defina agora Z_{i,j}=X_{i}Y_{j} , para i,j\\in\\{1,\\dots,n\\} e  a)​calcule a esperança de S_{n}=\\tfrac{1}{n^{2}}\\sum_{i=1}^{n}\\sum_{j=1}^{n}Z_{i,j} e  b)​estime P[|S_{n}-E(S_{n})|>a] usando o método do segundo momento. Como esse resultado se compara com o caso em que os Z_{i,j} são i.i.d.? {exercise} Considere uma rua infinita com casas i\\in\\mathbb{Z} . Para todo i\\in\\mathbb{Z} , existia uma rua entre as casas i e i+1 , mas após uma grande tempestade essas ruas foram danificadas. Mais precisamente, para cada i\\in\\mathbb{Z} , temos variáveis aleatórias X_{i} que são i.i.d. com distribuição \\text{Ber}(p) , onde X_{i}=1 indica que o trecho da rua entre as casas i e i+1 foi danificado e não pode ser utilizado. Defina, para i\\in\\mathbb{Z} , R_{i} como sendo o número de casas que continuaram acessíveis à casa i após a tempestade. Por exemplo, se X_{-2} e X_{0}=1 e X_{-1}=0 , temos que a casa 0 somente pode acessar a casa -1 , logo R_{0}=1 . Nesse contexto,  a)​Calcule a distribuição e a esperança de R_{0} ,  b)​Use o método do segundo momento para estimar a probabilidade P\\Big{[}\\Big{|}\\frac{1}{n}\\sum_{i=1}^{n}R_{i}-E(R_{0})\\Big{|}>a\\Big{]}. (3.38) Previous page Next page"],[["index.html","Ch3.html","Ch3.S4.html"],"3.4 Lei forte dos grandes números ‣ Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. Lei forte dos grandes números 3.4 Lei forte dos grandes números {theorem} [Lei Forte dos Grandes Números] Sejam X_{1},X_{2},\\dots \\iidem \\mathcal{L}^{1} , com m=E(X_{1}) . Então, \\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{i=1}^{n}X_{n}=m,\\text{ $P$-quase certamente.} (3.47) Antes de começar a prova, buscando inspiração no Teorema das Três Séries, mostraremos que basta considerar versões truncadas das variáveis X_{i} . Isso é feito no próximo {lemma} Sejam Y_{i}=X_{i}\\1_{[|X_{i}|\\leq i]} . Então, para demonstrar o Teorema 3.4, basta provar que \\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{i=1}^{n}Y_{i}=m,\\text{ $P$-quase certamente.} (3.48) Prova do Lema 3.4. Consideramos os eventos A_{i}=[X_{i}\\neq Y_{i}] . Obviamente, \\sum_{i}P(A_{i})=\\sum_{i}P[|X_{i}|\\geq i]\\leq\\int_{0}^{\\infty}P[|X_{i}|\\geq t]% \\d{t}=E\\big{(}|X_{i}|)<\\infty. (3.49) Logo, pelo Lema de Borel-Cantelli, temos que P -quase certamente A_{i} acontece apenas finitas vezes. Digamos que A_{i} não acontece para i>N(\\omega) . Dessa forma, para qualquer n\\geq 1 , \\Big{|}\\frac{1}{n}\\sum_{i=1}^{n}(X_{i}-Y_{i})\\Big{|}\\leq\\frac{1}{n}\\sum_{i=1}^% {n}|X_{i}-Y_{i}|\\leq\\frac{1}{n}\\sum_{i\\leq N(\\omega)}|X_{i}|, (3.50) que converge para zero P -quase certamente, mostrando o resultado. ∎ O próximo passo para a prova da Lei Forte dos Grandes Números é cuidar da esperança das novas variáveis Y_{i} . {lemma} Sejam Z_{i}=Y_{i}-E(Y_{i}) , para i\\geq 1 como acima. Então, para demosntrar o Teorema 3.4, basta mostrar que \\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{i=1}^{n}Z_{i}=0,\\text{ $P$-quase certamente.} (3.51) Demonstração. Supondo a convergência em (3.51), sabemos que \\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{i=1}^{n}Y_{i}-E(Y_{i})=0,\\text{ $P$-quase % certamente.} (3.52) Mas E(Y_{i})=E(X_{i}\\1_{[|X_{i}|\\leq i]}) que converge a E(X_{i})=m , pelo Teorema da Convergência Dominada, donde concluímos que \\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{i=1}^{n}E(Y_{i})=m. (3.53) Dessa forma, obtemos que \\tfrac{1}{n}\\sum_{i=1}^{n}Y_{i} converge quase certamente a m , donde concluímos a prova do Teorema 3.4 por meio do Lema 3.4. ∎ Gostaríamos de utilizar os teoremas das séries para mostrar a convergência de \\tfrac{1}{n}\\sum_{n}Z_{n} , mas obviamente, o fator \\tfrac{1}{n} que precede a soma nos impede de fazê-lo. O próximo resultado é um simples exercício de análise real, que nos permite reduzir a prova de (3.51) para uma simples convergência de uma série sem pré-fatores. {lemma} [Lema de Kronecker] Suponha que x_{n}\\in\\mathbb{R} e b_{n}>0 sejam tais que b_{n}\\uparrow\\infty e \\sum_{i=1}^{\\infty}\\frac{x_{i}}{b_{i}} convirja a s\\in\\mathbb{R} . Então \\lim_{n\\to\\infty}\\frac{1}{b_{n}}\\sum_{i=1}^{n}x_{i}=0. (3.54) Demonstração. Definindo s_{0}=0 e s_{n}=\\tfrac{x_{1}}{b_{1}}+\\dots+\\tfrac{x_{n}}{b_{n}} , temos, por integração por partes, \\sum_{i=1}^{n}x_{i}=\\sum_{i=1}^{n}b_{i}\\frac{x_{i}}{b_{i}}=\\sum_{i=1}^{n}b_{i}% s_{i}-\\sum_{i=1}^{n}b_{i}s_{i-1}=b_{n}s_{n}+\\sum_{i=1}^{n-1}(b_{i}-b_{i+1})s_{% i}. (3.55) Escolhemos agora, para qualquer \\varepsilon>0 , um n_{0}\\geq 1 tal que |s_{n}-s|<\\varepsilon para todo n\\geq n_{0} . Dessa forma, \\begin{split}\\frac{1}{b_{n}}\\sum_{i=1}^{n}x_{i}&=s_{n}-\\frac{1}{b_{n}}\\sum_{i=% 1}^{n-1}(b_{i+1}-b_{i})s_{i}\\\\ &=s_{n}-\\frac{1}{b_{n}}\\underbrace{\\sum_{i=1}^{n_{0}-1}(b_{i+1}-b_{i})}_{% \\Delta_{n_{0}}}s_{i}-\\frac{1}{b_{n}}\\sum_{i=n_{0}}^{n-1}(b_{i+1}-b_{i})s_{i}\\\\ &=\\underbrace{s_{n}}_{\\to s}-\\underbrace{\\frac{1}{b_{n}}\\Delta_{n_{0}}}_{\\to 0% }-\\underbrace{\\frac{1}{b_{n}}\\sum_{i=n_{0}}^{n-1}(b_{i+1}-b_{i})s}_{=\\tfrac{(b% _{n}-b_{n_{0}})s}{b_{n}}\\to s}-\\underbrace{\\frac{1}{b_{n}}\\sum_{i=n_{0}}^{n-1}% (b_{i+1}-b_{i})(s_{i}-s)}_{\\leq\\varepsilon\\tfrac{(b_{n}-b_{n_{0}})}{b_{n}}\\leq% \\varepsilon},\\end{split} onde os limites indicados acima representam o que acontece quando n\\to\\infty . A prova segue do fato de \\varepsilon ter sido escolhido arbitrariamente. ∎ Estamos agora em posição de finalizar a Prova do Teorema 3.4. De acordo com o Lema de Kronecker e o Lema 3.4, é suficiente mostrar que \\sum_{i=1}^{n}\\frac{Z_{i}}{i},\\text{ converge quase certamente}. (3.56) Por outro lado, como os Z_{i} ’s tem média zero, o Teorema de Uma Série diz que é suficiente mostrar que \\sum_{i=1}^{n}\\Var\\Big{(}\\frac{Z_{i}}{i}\\Big{)}=\\sum_{i=1}^{n}\\frac{1}{i^{2}}% \\Var(Z_{i})<\\infty. (3.57) Isso segue da seguinte estimativa \\begin{split}\\sum_{i=1}^{n}\\frac{1}{i^{2}}\\Var(Z_{i})&=\\sum_{i=1}^{n}\\frac{1}{% i^{2}}\\Var(Y_{i})\\leq\\sum_{i=1}^{n}\\frac{1}{i^{2}}E\\big{(}X_{i}^{2}\\1_{[|X_{i}% |\\leq i]}\\big{)}\\\\ &=\\sum_{i=1}^{n}\\frac{1}{i^{2}}\\sum_{k=1}^{i}E\\big{(}X_{i}^{2}\\1_{[k-1<|X_{i}|% \\leq k]}\\big{)}\\\\ &=\\sum_{k=1}^{n}E\\big{(}X_{1}^{2}\\1_{[k-1<|X_{i}|\\leq k]}\\big{)}\\sum_{i=k}^{n}% \\frac{1}{i^{2}}\\\\ &\\leq 2\\sum_{k=1}^{n}\\frac{1}{k}E\\big{(}X_{1}^{2}\\1_{[k-1<|X_{i}|\\leq k]}\\big{% )}\\\\ &\\leq 2\\sum_{k=1}^{n}E\\big{(}X_{1}\\1_{[k-1<|X_{i}|\\leq k]}\\big{)}\\leq 2E(X_{1}% )<\\infty.\\end{split} (3.58) Isso nos permite concluir a prova de (3.51) via o Lema de Kronecker. Consequentemente, obtemos o Teorema 3.4 via o Lema 3.4. ∎ {exercise} Sejam Y_{k} variáveis aleatórias independentes e com a seguinte distribuição: P[Y_{k}=i]=\\begin{cases}\\frac{1}{2}-\\frac{1}{k^{2}}\\quad&\\text{se $i=1$ or $i=% -1$},\\\\ \\frac{2}{k^{2}}&\\text{se $i=3$.}\\end{cases} (3.59) Mostre que P\\Big{[}\\frac{1}{n}\\sum_{k=1}^{n}Y_{k}\\text{ converge a zero}\\Big{]}=1. (3.60) {exercise} [Depende de Tópico: Urna de Pólya] Mostre que segundo a lei P construida no Exercício 2, vale que P\\big{[}\\tfrac{1}{n}\\sum_{i-1}^{n}X_{i}\\text{ converge}]=1. (3.61) Além disso calcule a distribuição do limite acima. \\todosec Tópico: Teorema de Weierstrassprovar o teorema de Weierstrass de aproximação de funções contínuas por polinômios (prova probabilística). Ele é usado em convergência fraca em \\mathbb{R} \\todosec Tópico: Entropia de Shannonfazer… \\todosec Tópico: Processos de renovaçãofazer… Previous page Next page"],[["index.html","Ch3.html","Ch3.S5.html"],"3.5 Lei {0,1} de Kolmogorov ‣ Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. Lei 3.5 Lei \\{0,1\\} de Kolmogorov Ao estudarmos o Lema de Borel-Cantelli, vimos que se os eventos (A_{i})_{i\\geq 1} são independentes então a probabilidade de [A_{i}\\text{ infinitas vezes}] somente pode assumir os valores zero ou um (dependendo da somabilidade de P(A_{i}) ). Nessa seção iremos estudar outros tipos de evento que assumem apenas esses dois valores. Esperamos que esse fenômeno se torne intuitivo ao final dessa discussão. No que se segue, consideraremos um espaço mensurável \\Omega=\\times_{i=1}^{\\infty}E , com a \\sigma -álgebra canônica \\mathcal{F} , isto é a \\sigma -álgebra gerada pelas coordenadas canõnicas (X_{i})_{i=1}^{\\infty} . {definition} Dizemos que um evento A\\in\\mathcal{F} é caudal se A\\in\\sigma\\big{(}X_{i};i\\geq n\\big{)},\\text{ para todo $n\\geq 1$}. (3.62) Também introduzimos a classe \\mathcal{F}_{\\infty} de tais eventos, que claramente é uma \\sigma -álgebra, pois pode ser escrita como \\mathcal{F}_{\\infty}=\\mcap_{n\\geq 1}\\sigma\\big{(}X_{i};i\\geq n\\big{)}. (3.63) Chamamos \\mathcal{F}_{\\infty} de \\sigma -álgebra caudal. Vejamos que, dados A_{i}\\in\\sigma(X_{i}) , i\\geq 1 , temos que [A_{i}\\text{ infinitas vezes}] é caudal. Para tanto, basta observar que para todo n\\geq 1 , temos que [A_{i}\\text{ infinitas vezes}]=\\big{[}\\#\\{i\\geq 1;\\omega\\in A_{i}\\}=\\infty\\big% {]}=\\big{[}\\#\\{i\\geq n;\\omega\\in A_{i}\\}=\\infty\\big{]}, que obviamente pertence a \\sigma(X_{i};i\\geq n) para todo n\\geq 1 . {exercise} Mostre que em \\Omega=\\mathbb{R}^{\\infty} , são caudais os seguintes eventos  a)​ [X_{i}\\text{ converge}] ,  b)​ \\big{[}\\tfrac{1}{n}\\sum_{i=1}^{n}X_{i}\\text{ converge}\\big{]} e  c)​ [\\#\\{i\\geq 1;X_{i}>0\\}<\\infty] . Podemos agora enunciar o pricipal teorema dessa seção {theorem} [Lei \\{0,1\\} de Kolmogorov] Se \\Omega=E^{\\infty} , onde E é um espaço canônico, for provido de uma lei produto P=\\otimes_{i=1}^{\\infty}P_{i} , então todo evento caudal tem probabilidade 0 ou 1 sob P . Quando uma \\sigma -álgebra \\mathcal{F} satisfaz P(A)\\in\\{0,1\\} para todo A\\in\\mathcal{F} , dizemos que \\mathcal{F} é trivial. Uma outra maneira de enunciar a conclusão do teorema acima é dizer que a \\sigma -álgebra caudal \\mathcal{F}_{\\infty} é trivial. Demonstração. A idéia da prova, apesar de soar um pouco estranha, é mostrar que se A\\in\\mathcal{F}_{\\infty} , então A é independente de si mesmo. Em outras palavras, P(A)=P(A\\cap A)=P(A)^{2} , donde P(A)\\in\\{0,1\\} . Mas vamos com calma. Fixe k\\geq 1 , A\\in\\mathcal{F}_{\\infty} e B\\in\\sigma(X_{1},\\dots,X_{k}) . Nesse caso, como o evento A pertence a \\sigma(X_{k+1},X_{k+2},\\dots) , temos que A e B são independentes. Fixe agora A\\in\\mathcal{F}_{\\infty} e considere a classe \\mathcal{B}_{A}=\\{B\\in\\mathcal{F};\\text{ $B$ \\'{e} independente de $A$}\\}. (3.64) Já sabemos que \\sigma(X_{1},\\dots,X_{k})\\subseteq\\mathcal{B}_{A} para todo k\\geq 1 . Obviamente \\Omega é independente de A , assim como B^{c}\\in\\mathcal{B}_{A} sempre que B\\in\\mathcal{B}_{A} . Além disso, suponha que B_{1},B_{2},\\dots in \\mathcal{B}_{A} são disjuntos, então, P\\big{(}(\\mcup_{i}B_{i})\\cap A\\big{)}=P\\big{(}\\mcup_{i}(B_{i}\\mcap A)\\big{)}% \\overset{\\text{disj.}}{=}\\sum_{i}P(B_{i}\\mcap A)\\overset{\\text{indep.}}{=}P(A)% P(\\mcup_{i}B_{i}). Logo \\mathcal{B}_{A} é um \\lambda -sistema. Lembrando que \\mathcal{B}_{A} contém o \\pi -sistema \\bigcup_{k}\\sigma(X_{1},\\dots,X_{k}) , isto é dos eventos cilíndricos, temos que todos eventos são indepentes de A , inclusive o próprio A . Isso termina a prova do teorema. ∎ {exercise} Dizemos que uma probabilidade P no espaço produto \\Omega=\\times_{n\\geq 1}E (com a \\sigma -álgebra canônica) é fortemente misturadora se, para todo k\\geq 1 , temos \\lim_{n\\to\\infty}\\sup\\big{|}P(A\\cap B)-P(A)P(B)\\big{|}=0, (3.65) onde o supremo acima é tomado sobre A\\in\\sigma(X_{1},\\dots,X_{k}) e B\\in\\sigma(X_{n},X_{n+1},\\dots) . Mostre que nesse caso, a \\sigma -álgebra dos eventos caudais é trivial. {exercise} [Depende de Tópico: Percolação] Considere o grafo G=(\\mathbb{Z}^{2},E) , onde E=\\big{\\{}\\{x,y\\};|x-y|_{2}=1\\big{\\}} . Dotamos agora o espaço \\{0,1\\}^{E} com a \\sigma -álgebra \\mathcal{A} gerada pelas projeções canônicas Y_{e}(\\omega)=\\omega(e) , onde \\omega\\in\\{0,1\\}^{E} e e\\in E . Definimos o conjunto A\\subseteq\\{0,1\\}^{E} por A=\\Big{[}\\begin{array}[]{c}\\text{existe uma sequ\\^{e}ncia de distintos $x_{0},% x_{1},\\dots\\in\\mathbb{Z}^{2}$,}\\\\ \\text{tais que $e_{i}=\\{x_{i},x_{i+1}\\}\\in E$ e $Y_{e_{i}}=1$ para cada $i\\geq 0% $}\\end{array}\\Big{]}. (3.66)  a)​Mostre que A é mensurável com respeito a \\mathcal{A} .  b)​Mostre que A é um evento caudal, ou seja A\\in\\bigcap_{K\\subseteq E;\\text{ finito}}\\sigma\\big{(}Y_{e};e\\not\\in K\\big{)}. (3.67)  c)​Conclua que P(A)\\in\\{0,1\\} . {exercise} Seja \\Omega=E^{\\mathbb{Z}} um espaço produto infinito, dotado da \\sigma -álgebra \\mathcal{A} gerada pelas projeções canônicas (X_{i})_{i\\in\\mathbb{Z}} . Consideramos agora em (\\Omega,\\mathcal{A}) a medida produto \\mathbb{P}=P^{\\otimes\\mathbb{Z}} , onde P é uma probabilidade fixada no espaço polonêns (E,\\mathcal{B}(E)) .  a)​Mostre que para qualquer evento A\\in\\mathcal{A} e qualquer \\varepsilon>0 , existe um k\\in\\mathbb{Z}_{+} e um evento A_{k}\\in\\sigma(X_{i},|i|\\leq k) tais que \\mathbb{P}[(A\\setminus A_{k})\\cup(A_{k}\\setminus A)]<\\varepsilon .  b)​Considere o shift \\theta:\\Omega\\to\\Omega dado por \\theta(\\omega)(i)=\\omega(i-1) e mostre que se A=\\theta(A) , então P(A)\\in\\{0,1\\} . Previous page Next page"],[["index.html","Ch3.html","Ch3.S6.html"],"3.6 Momentos exponenciais ‣ Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. Momentos exponenciais 3.6 Momentos exponenciais Nessa seção desenvolveremos uma outra técnica para estimar a probabilidade de uma variável aleatória se desviar de sua esperança. Já vimos o método do primeiro, segundo e quarto momento para controlar uma soma de variáveis independentes. Um exemplo disso foi visto na estimativa P\\Big{[}\\sum_{i=1}^{n}(X_{i}-E(X_{i}))\\geq a\\Big{]}\\leq\\frac{\\sum_{i}\\Var(X_{i% })}{a^{2}}. (3.68) Em geral, quanto maior o momento, melhor a estimativa do decaimento para a probabilidade de que uma variável se desvie de sua esperança. Nessa seção iremos para momentos exponenciais, que em um certo sentido produzem estimativas ótimas para o comportamento assintótico da probabilidade de desvio. Note que se quisermos uma pequena probabilidade de erro (como por exemplo \\sim 0.01 ), o método do segundo momento é muito bom, como veremos posteriormente. Mas se quisermos uma probabilidade de erro minúscula (em situações concretas, algo como 10^{-12} por exemplo), certamente teremos que aumentar bastante o valor de n , mas quanto? As cotas de segundo momento são muito ruins para esse tipo de estimativa, nos levando a escolher um n maior que o necessário. Abaixo, desenvolveremos um método mais eficiente para responder a essa pergunta, obviamente sob certas hipóteses na distribuição das variáveis aleatórias. {definition} Dada uma variável aleatória X , definimos sua transformada de Laplace como \\phi_{X}(s)=E(\\ex{sX})\\in(0,\\infty], (3.69) para todos s\\in\\mathbb{R} . Essa transformada também é chamada função geradora de momentos de X . {exercise} Calcule a função geradora de momentos das distribuições \\Ber(p) , \\Exp(\\lambda) e U_{[0,1]} . {proposition} Se E(\\ex{\\delta|X|})<\\infty , então  a)​ X\\in\\mathcal{L}^{p} para todo 1\\leq p<\\infty ,  b)​ \\phi_{X}(s)<\\infty para todo s\\in(-\\delta,\\delta) ,  c)​ \\phi_{X}(s) é C^{\\infty} em (-\\delta,\\delta) e  d)​ \\phi_{X}^{(n)}(s)=E(X^{n}\\ex{sX}) . A última conclusão da proposição acima justifica a nomenclatura função geradora de momentos pois \\phi_{X}^{(n)}(0)=E(X^{n}) . Demonstração. Obviamente, para todo p\\geq 1 existe c>0 tal que \\ex{\\delta|x|}\\geq c|x|^{p} , donde X\\in\\mathcal{L}^{p} . Além disso, para todo s\\in(-\\delta,\\delta) , temos \\phi_{X}(s)=E(\\ex{sX})\\leq E(\\ex{\\delta|X|})<\\infty , donde 2. segue imediatamente. Fixando s\\in\\mathbb{R} , vamos agora calcular \\frac{\\phi_{X}(s+h)-\\phi_{X}(s)}{h}=\\frac{E\\big{(}\\ex{(s+h)X}-\\ex{sX}\\big{)}}{% h}=E\\Big{(}\\ex{sX}\\frac{\\ex{hX}-1}{h}\\Big{)}. (3.70) Lembrando que |\\tfrac{1}{y}(e^{y}-1)|\\leq e^{|y|} , para todo y\\in\\mathbb{R} , temos que para todos os h<(\\delta-|s|)/2 , o integrando acima é dominado por |X|\\ex{(|s|+h)|X|}\\leq|X|\\ex{\\smash{\\tfrac{\\delta+|s|}{2}|X|}} que pertence a \\mathcal{L}^{1} . Logo podemos usar o Teorema da Convergência Dominada para trocar o limite h\\to 0 com a esperança, obtendo \\phi_{X}^{\\prime}(s)=E(X\\ex{sX}). (3.71) Note que para todo \\varepsilon>0 e k\\geq 1 , |x|^{k}\\leq c(k)\\ex{\\varepsilon|x|} , isso nos permite repetir o argumento acima indutivamente para obter c) e d). ∎ Lembramos que ao usar o método do segundo momento, nos foi bastante útil o fato que a variância se comporta bem com relação a somas independentes. Mais precisamente, \\Var(X_{1}+\\dots+X_{k})=\\Var(X_{1})+\\dots+\\Var(X_{k}) . Uma outra propriedade importante da função geradora de momentos é que ela também se comporta bem com respeito à somas independentes. {proposition} Se X_{1},\\dots,X_{n} são variáveis independentes com \\phi_{X_{i}}(s)<\\infty para todo i\\leq k e |s|<\\delta , então \\phi_{X_{1}+\\dots+X_{k}}(s)=\\phi_{X_{1}}(s)\\dotsm\\phi_{X_{k}}(s),\\text{ para % todos $|s|<\\delta$.} (3.72) Demonstração. Basta observar que \\begin{split}E(\\exp&\\{s(X_{1}+\\dots+X_{k})\\})=E(\\ex{sX_{1}}\\dotsm\\ex{sX_{k}}))% \\\\ &=E\\big{(}\\ex{sX_{1}})\\dotsm E(\\ex{sX_{k}}\\big{)}=\\phi_{X_{1}}(s)\\dotsm\\phi_{X% _{k}}(s),\\end{split} (3.73) usando Fubini. ∎ Consideraremos agora uma sequência X_{1},X_{2},\\dots de variáveis \\iidcom \\phi_{X_{1}}(s)<\\infty para |s|<\\delta . Então podemos tentar estimar, para a>0 e |s|<\\delta , \\begin{split}P\\Big{[}&\\frac{X_{1}+\\dots+X_{n}}{n}-E(X_{1})\\geq a\\Big{]}=P\\Big{% [}X_{1}+\\dots+X_{n}\\geq(a+E(X_{1}))n\\Big{]}\\\\ &\\quad=P\\Big{[}\\ex{s(X_{1}+\\dots+X_{n})}\\geq\\ex{s(a+E(X_{1}))n}\\Big{]}\\\\ &\\quad\\leq\\phi_{X_{1}+\\dots+X_{n}}(s)\\ex{-s(a+E(X_{1}))n}=\\phi_{X_{1}}^{n}(s)% \\ex{-s(a+E(X_{1}))n}.\\end{split} O primeiro fator na estimativa acima pode crescer exponencialmente com n , enquanto o segundo decresce. Gostaríamos que o comportamento do segundo predominasse, o que podemos concluir do seguinte argumento. Sabemos que \\phi_{X_{1}}(s) é diferenciável em zero e que \\phi^{\\prime}_{X_{1}}(0)=E(X_{1}) . Logo, existe s>0 tal que \\phi_{X_{1}}(s)<1+(E(X_{1})+\\tfrac{a}{2})s , donde \\begin{split}P\\Big{[}&\\frac{X_{1}+\\dots+X_{n}}{n}-E(X_{1})\\geq a\\Big{]}\\leq% \\phi_{X_{1}}^{n}(s)\\ex{-s(a+E(X_{1}))n}\\\\ &\\quad\\leq\\big{(}1+(E(X_{1})+\\frac{a}{2})s\\big{)}^{n}\\ex{-s(E(X_{1})+a)n}\\\\ &\\quad\\leq\\exp\\Big{\\{}s\\Big{(}E(X_{1}+\\frac{a}{2}-E(X_{1})-a)n\\Big{)}\\Big{\\}}=% \\ex{-san/2}.\\end{split} Isso nos garante um decaimento exponencial da probabilidade da média dos X_{i} se desviar da esperança. {exercise} Aplique o método acima para variáveis X_{i} \\iidcom distribuição \\Ber(1/2) e encontre s(a) que otimize o decaimento da probabilidade P\\big{[}\\sum_{i=1}^{n}X_{i}>(1/2+a)n\\big{]} . Poderíamos nos perguntar se a cota acima é suficientemente boa. Talvez pudéssemos esperar um decaimento ainda melhor que exponencial. Para responder a essa pergunta, vamos considerar o seguinte exemplo. Sejam (X_{i})_{i\\geq 1} variáveis \\iidcom X_{1}\\distr\\Ber(1/2) . Nesse caso temos por exemplo P\\Big{[}\\big{|}\\frac{X_{1}+\\dots+X_{n}}{n}-\\frac{1}{2}\\big{|}\\geq\\frac{1}{4}% \\Big{]}\\geq P[X_{i}=1,\\forall i\\leq n]=2^{-n}. (3.74) Dessa forma, sabemos que não podemos esperar um decaimento melhor que exponencial, mesmo para variáveis bem simples (como Bernoulli) que satisfazem \\phi_{X}(s)<\\infty para todo s\\in\\mathbb{R} . Note que para variáveis com distribuição \\Ber(1/2) , obtivemos acima cotas exponenciais em n (superior e inferior), mas elas possuem expoentes diferentes. Resta agora tentar entender qual é o expoente correto para o decaimento da probabilidade P[X_{1}+\\dots+X_{n}\\geq n(E(X_{1})+a)] , o que será feito na próxima seção. \\todosec Tópico: Processos de ramificaçãofazer… Previous page Next page"],[["index.html","Ch3.html","Ch3.S7.html"],"3.7 Princípio de Grandes Desvios ‣ Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. Princípio de Grandes Desvios 3.7 Princípio de Grandes Desvios A primeira tarefa nossa será otimizar a estimativa grosseira feita na seção anterior. Essas estimativas são chamadas de estimativas de grandes desvios, pois se referem a probabilidades que a média empírica de X_{i} se desvie de sua esperança por um valor constante a . Futuramente no curso estudaremos as probabilidades de que esse desvio seja de ordem a_{n}\\to 0 que são chamados de desvios moderados ou flutuações, dependendo se a probabilidade de desvio converge a zero ou não. {theorem} [Princípio de Grandes Desvios - cota superior] Consideramos variáveis aleatórias \\iid X_{1},X_{2},\\dots tais que \\phi_{X_{1}}(s)<\\infty , para todo s\\in(-\\delta,\\delta) . Então, para a>0 , P\\big{[}X_{1}+\\dots+X_{n}\\geq\\big{(}m+a\\big{)}n\\big{]}\\leq\\ex{-\\psi_{X_{1}}(m+% a)n}, (3.75) onde m=E(X_{1}) e \\psi_{X_{1}}(x)=\\sup_{s\\geq 0}\\big{\\{}xs-\\log\\big{(}\\phi_{X_{1}}(s)\\big{)}\\big% {\\}} (3.76) é chamada função taxa. É importante observar que para estimar P\\big{[}X_{1}+\\dots+X_{n}\\leq(m-a)n\\big{]} , basta considerarmos X^{\\prime}_{i}=-X_{i} ao utilizar o teorema acima. Demonstração. Já sabemos que, para todo s\\geq 0 , \\begin{split}P\\big{[}X_{1}&+\\dots+X_{n}\\geq\\big{(}m+a\\big{)}n\\big{]}\\leq\\phi_{% X_{1}}^{n}(s)\\ex{-s(m+a)n}\\\\[2.84526pt] &=\\ex{\\log\\big{(}\\phi_{X_{1}}(s)\\big{)}n-s(m+a)n}\\\\ &=\\ex{-\\big{(}(m+a)s-\\log\\big{(}\\phi_{X_{1}}(s)\\big{)}\\big{)}n}\\\\ \\end{split} (3.77) O que termina a prova do teorema se tomamos o ínfimo em s\\geq 0 . ∎ {exercise} Calcule \\psi_{X}(a) quando X é distribuída como \\Ber(p) , U_{[0,1]} e \\Exp(\\lambda) . {exercise} Na Nova Caledônia, temos k habitantes. Seja f:\\{1,\\dots,k\\}\\to\\{0,1\\} uma função que indica a intenção de voto de cada cidadão. Mais precisamente, para cada habitante i\\in\\{1,\\dots,k\\} , se f(i)=0 , então i vota no candidato 0 , enquanto se f(i)=1 , o cidadão i vota no candidato 1 . Para estimar o número k_{1}=\\#f^{-1}(\\{1\\}) de pessoas que votam em 1 , nós escolhemos variáveis aleatórias Y_{i} i.i.d. com distribuição uniforme em \\{1,\\dots,k\\} e queremos estimar \\text{Err}_{n}(\\epsilon)=P\\Big{[}\\Big{|}\\frac{1}{n}\\sum_{i=1}^{n}f(Y_{i})-% \\frac{k_{1}}{k}\\Big{|}>\\epsilon\\Big{]}. (3.78) Sabendo que k é par e k_{1}=k/2 , então  a)​use o método do segundo momento para obter um n tal que \\text{Err}_{n}(0.01)<0.02 e um n tal que \\text{Err}_{n}(0.01)<10^{-12} ,  b)​use o método do momento exponencial para obter resolver o ítem acima. Compare os quatro resultados obtidos acima. Vamos agora tomar um exemplo concreto para análise. Sejam X_{1},X_{2},\\dots variáveis aleatórias \\iidcom distribuição \\Ber(1/2) , donde \\phi_{X_{1}}(s)=\\frac{1}{2}(1+e^{s})\\quad\\text{e}\\quad\\psi_{X_{1}}(x)=\\sup_{s% \\geq 0}\\{xs-\\log(1+e^{s})+\\log(2)\\}. (3.79) Um cálculo simples nos mostra que, se x<1 , o mínimo acima é atingido no único ponto s_{\\text{max}}=\\log(\\tfrac{x}{1-x}) . Portanto, podemos concluir do Teorema 3.7 que \\begin{split}P[X_{1}+\\dots&+X_{n}>1/2+a]\\leq\\ex{-\\psi_{X_{1}}(s_{\\text{max}})n% }\\\\ &=\\exp\\Big{\\{}-n\\Big{(}b\\log(b)+(1-b)\\log(1-b)+\\log(2)\\Big{)}\\Big{\\}}\\end{split} (3.80) Note que P[X_{1}+\\dots+X_{n}=n]=2^{-n}=\\ex{-\\log(2)n}=\\ex{-\\psi_{X_{1}}(1-)n} . Isso nos dá um forte indício de que talvez nossas cotas superiores não estejam tão longe de ser precisas. Para confirmar essa hipótese, precisamos obter cotas inferiores parecidas. b 1 \\log(2) 0 \\psi_{X}(b) b 1 0 \\psi_{X^{\\prime}}(b) \\log(4/3) \\log(4) Figura 3.1: Funções taxa \\psi_{X}(b) de uma variável X com distribuição \\Ber(1/2) , e \\psi_{X^{\\prime}}(b) de uma variável com distribuição \\Ber(3/4) , para b\\in(0,1) . Antes de buscar cotas inferiores para as probabilidades de desvio, vamos estabelecer algumas propriedades da função \\psi_{X}(b) . Primeiramente, quando podemos dizer que o supremo na definição de \\psi_{X} é atingido em algum s_{\\text{max}} ? Certamente, esse nem sempre é o caso, por exemplo se X=m quase certamente, então \\phi_{X}(s)=e^{sm} e o supremo definindo \\psi_{X}(b) não é atingido se b\\neq m . {lemma} Seja X uma variável aleatória tal que \\phi_{X}(s)<\\infty para todo s\\in(-\\delta,\\delta) . Supondo a\\geq 0 é tal que P[X>m+a]>0 , então existe s_{\\text{max}}\\geq 0 tal que \\psi_{X}(m+a)=(m+a)s_{\\text{max}}-\\log\\big{(}\\phi_{X}(s_{\\text{max}})\\big{)}. (3.81) Demonstração. Por hipótese, existe x>m+a tal que p=P[X\\geq x]>0 , donde \\phi_{X}(s)\\geq pe^{s(m+a)} . Dessa forma, (m+a)s-\\log\\big{(}\\phi_{X}(s)\\big{)}\\leq(m+a-x)s-\\log(p) , que converge a menos infinito quando s diverge. Isso, junto com a continuidade de \\phi_{X} implica a existência do s_{\\text{max}} desejado. ∎ {lemma} Seja X uma variável aleatória tal que \\phi_{X}(s)<\\infty para todo s\\in(-\\delta,\\delta) . Então o conjunto onde a função \\psi_{X}(s) é finita é um intervalo, na qual \\psi_{X} é convexa e portanto contínua. Demonstração. Primeiramente, supomos que a<b são tais que \\psi_{X}(a) e \\psi_{X}(b) são finitas. Logo, para todo c\\in(a,b) , temos que a função linear cs é menor ou igual a as\\vee bs , daí \\begin{split}\\psi_{X}(c)&=\\sup_{s\\geq 0}\\{cs-\\log(\\phi_{X}(s))\\}\\leq\\sup_{s% \\geq 0}\\{(as\\vee bs)-\\log(\\phi_{X}(s))\\}\\\\ &\\leq\\sup_{s\\geq 0}\\{as-\\log(\\phi_{X}(s))\\}\\vee\\sup_{s\\geq 0}\\{bs-\\log(\\phi_{X% }(s))\\}<\\infty.\\end{split} (3.82) Para mostrar que \\psi_{X} é convexa, observe que \\psi_{X}(x) é dada pelo supremo (para s\\geq 0 ) das funções afins x\\mapsto xs-\\psi_{X}(s) . Como o supremo de funções convexas é também convexo, obtemos o enunciado do lemma. ∎ {exercise} Suponha que se \\phi_{X}(s) é finita para todo s\\in(-\\delta,\\delta) e mostre que  a)​na definição de \\psi_{X}(a) , poderíamos tomar o ínfimo em todos s\\in\\mathbb{R} (ao invéz de s\\geq 0 ) sem mudar o valor de \\psi_{X}(a) ,  b)​a função \\psi_{X}(s) é não negativa, semi-contínua inferior e convexa em seu domínio  c)​ \\psi_{X}(a) se anula somente em a=0 e \\psi_{X} é crescente no seu domínio. Buscaremos agora cotas inferiores para a probabilidade de obter um grande desvio. Gostaríamos que essas estimativas fossem o mais próximas possíveis das estimativas superiores obtidas acima. Certamente não podemos obter algo como ``P\\big{[}X_{1}+\\dots+X_{n}\\geq\\big{(}m+a\\big{)}n\\big{]}\\geq\\exp\\{-\\psi_{X_{1}% }(a)n\\}\", (3.83) pois senão isso nos daria uma igualdade o que é impossível, pois perdemos um pouco de precisão ao utilizar a desigualdade de Markov na cota superior. Contudo, gostaríamos de entender se ao menos o expoente \\psi_{X_{1}}(a) na cota superior também possui algum papel na cota inferior. Isso é confirmado no seguinte resultado. {theorem} [Princípio de Grandes Desvios - cota inferior] Sejam X_{1},X_{2},\\dots variáveis aleatórias \\iidcom \\phi_{X_{1}}(s)<\\infty , para todo s\\in\\mathbb{R} . Então, para todo a>0 , \\liminf_{n\\to\\infty}\\frac{1}{n}\\log P\\big{[}X_{1}+\\dots+X_{n}\\geq\\big{(}m+a% \\big{)}n\\big{]}\\geq-\\psi_{X_{1}}(m+a), (3.84) onde novamente m=E(X_{1}) e \\psi_{X_{1}}(x) é definida como no Teorema 3.7. Note que o resultado do teorema acima é mais fraco que o que vemos na equação (3.83), mas mostra que \\psi_{X_{1}}(a) é realmente o expoente correto no decaimento da probabilidade de grandes desvios. Um corolário dos Teoremas 3.7 e 3.1 é o seguinte {corollary} Se X_{1},X_{2},\\dots variáveis aleatórias \\iidcom \\phi_{X_{1}}(s)<\\infty , para todo s\\in\\mathbb{R} , então \\lim_{n\\to\\infty}\\frac{1}{n}\\log P\\big{[}X_{1}+\\dots+X_{n}\\geq\\big{(}m+a\\big{)% }n\\big{]}=-\\psi_{X_{1}}(m+a). (3.85) A idéia da prova é transformar a distribuição de X_{i} , usando uma exponencial como derivada de Radon-Nikodim. Essa nova distribuição possuirá esperança maior que m+a , de forma que se tomamos a média de variáveis \\iid X^{\\prime}_{1},\\dots,X^{\\prime}_{n} distribuídas dessa forma, obteremos algo que se concentra acima de m+a . Finalmente, o preço pago para que as variáveis X_{i} se comportem como as X^{\\prime}_{i} será aproximadamente \\exp\\{-\\psi_{X_{1}}(m+a)\\} , como desejado para nossa cota inferior. Demonstração. Primeiramente, consideraremos o caso P[X_{1}\\leq m+a]=1 , que se assemelha ao caso que analizamos acima (\\Ber(1/2)\\leq 1) . Nesse caso, temos \\begin{split}P\\big{[}X_{1}+\\dots+X_{n}\\geq\\big{(}m+a\\big{)}n\\big{]}&=P[X_{i}=m% +a,\\text{ para todo $i\\leq n$}]\\\\ &=P[X_{1}=m+a]^{n}.\\end{split} Donde o limite acima é igual a \\log(P[X_{1}=m+a]) . Mas por outro lado, \\begin{split}-\\psi_{X_{1}}(m+a)&=\\inf_{s\\geq 0}\\big{\\{}\\log\\big{(}E(\\ex{s(X_{1% })})\\big{)}-(m+a)s\\big{\\}}=\\inf_{s\\geq 0}\\big{\\{}\\log\\big{(}E(\\ex{s(X_{1}-m-a)% })\\big{)}\\big{\\}}\\\\ &\\leq\\liminf_{s\\to\\infty}\\;\\log\\big{(}E(\\ex{s(X_{1}-m-a)})\\big{)}=\\log\\big{(}P% [X_{1}=m+a]\\big{)},\\end{split} pelo Teorema da Convergência Dominada, demonstrando o teorema nesse caso especial. Suponhamos agora que P[X_{1}>m+a]>0 , o que implica que para b>m+a suficientemente próximo de m+a , temos P[X_{1}>b]>0 . Observe que basta mostrar que para todo b>a satisfazendo P[X_{1}>b]>0 e para todo \\delta>0 , temos \\liminf_{n}\\frac{1}{n}\\log\\Big{(}P\\Big{[}\\frac{X_{1}+\\dots+X_{n}}{n}\\in(b-% \\delta,b+\\delta)\\Big{]}\\Big{)}\\geq-\\psi_{X_{1}}(b), (3.86) pois a função \\psi_{X_{1}}(x) é convexa, portanto contínua. Vamos definir uma nova distribuição \\nu com derivada de Radon-Nikodim \\frac{\\d{\\nu}}{\\d{P}_{X_{1}}}=\\frac{1}{Z_{\\sigma}}\\ex{\\sigma x}. (3.87) Observamos primeiramente que o valor de \\sigma ainda não foi escolhido. Além disso após escolhido \\sigma , teremos que calcular a constante de normalização Z_{\\sigma} de forma que \\nu seja uma probabilidade. Escolheremos \\sigma\\geq 0 como no Lema 3.7, isto é, tal que \\psi_{X_{1}}(b)=b\\sigma-\\log\\big{(}\\phi_{X_{1}}(\\sigma)\\big{)} . Isso nos dá imediatamente que Z_{\\sigma}=E[\\ex{\\sigma X_{1}}]=\\phi_{X_{1}}(\\sigma) por definição. Por diferenciabilidade de \\phi_{X_{1}} , o máximo deve ser assumido em um ponto de derivada zero para a função \\psi_{X_{1}} , ou seja b=\\frac{\\phi_{X_{1}}^{\\prime}(\\sigma)}{\\phi_{X_{1}}(\\sigma)}\\overset{\\text{% Prop.\\leavevmode\\nobreak\\ \\ref{p:propried_phi}}}{=}\\frac{E(X\\ex{\\sigma X})}{E(% \\ex{\\sigma X})}=\\frac{E(X\\ex{\\sigma X})}{Z_{\\sigma}}=\\int x\\nu(\\d{x}). (3.88) Isso implica que se uma variável aleatória tem distribuição \\nu , sua esperança é b . É possível verificar que uma tal variável aleatória X^{\\prime} satisfaz obrigatoriamente \\phi_{X^{\\prime}}(s)<\\infty para todo s\\geq 0 , donde X^{\\prime}\\in\\mathcal{L}^{p} para todo p>1 . Como prometido, consideramos variáveis X_{1}^{\\prime},X_{2}^{\\prime},\\dots \\iidcom distribuição \\nu . Pela lei fraca dos grandes números, para qualquer \\delta>0 , \\lim_{n}P\\Big{[}\\frac{X_{1}^{\\prime}+\\dots+X_{n}^{\\prime}}{n}\\in(b-\\delta,b+% \\delta)\\Big{]}=1. (3.89) Finalmente vamos relacionar essa probabilidade à probabilidade definida em termos de X_{i} , na qual estamos interessados. \\begin{split}P\\Big{[}&\\frac{X_{1}+\\dots+X_{n}}{n}\\in(b-\\delta,b+\\delta)\\Big{]}% =\\int_{x_{i};\\big{|}\\tfrac{1}{n}\\sum_{i\\leq n}x_{i}-b\\big{|}<\\delta}\\;\\;% \\bigotimes_{i=1}^{n}(X_{1}\\circ P)(\\d{x}_{i})\\\\ &=Z_{\\sigma}^{n}\\int_{x_{i};\\big{|}\\tfrac{1}{n}\\sum_{i\\leq n}x_{i}-b\\big{|}<% \\delta}\\;\\;\\ex{-\\sigma\\textstyle{\\sum_{i=1}^{n}x_{i}}}\\bigotimes_{i=1}^{n}(X_{% 1}^{\\prime}\\circ P)(\\d{x}_{i})\\\\[5.69054pt] &\\geq Z_{\\sigma}^{n}\\exp\\{-(b+\\delta)\\sigma n\\}P\\Big{[}\\frac{X_{1}^{\\prime}+% \\dots+X_{n}^{\\prime}}{n}\\in(b-\\delta,b+\\delta)\\Big{]}.\\end{split} Tomando o logarítmo, dividindo por n e tomando o liminf quando n vai a infinito, recuperamos \\begin{split}\\lim_{n}\\frac{1}{n}\\log\\Big{(}P\\Big{[}&\\frac{X_{1}+\\dots+X_{n}}{n% }\\in(b-\\delta,b+\\delta)\\Big{]}\\Big{)}\\geq\\log(Z_{\\sigma})-(b+\\delta)\\sigma\\\\ &=\\log(\\phi_{X_{1}}(\\sigma))-(b+\\delta)\\sigma=-\\psi_{X_{1}}(\\sigma)-\\delta% \\sigma.\\end{split} (3.90) Como isso vale para todo \\delta>0 , provamos (3.86) o que conclui a prova do teorema. ∎ {exercise} Mostre o Teorema 3.1 no caso em que \\phi_{X_{1}}(s)<\\infty , para todo s\\in(-\\delta,\\delta) . Previous page Next page"],[["index.html","Ch3.html","Ch3.S8.html"],"3.8 O Teorema Central do Limite ‣ Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. O Teorema Central do Limite 3.8 O Teorema Central do Limite Até o presente momento, já sabemos por exemplo que médias de variáveis aleatórias \\iid, suficientemente regulares convergem para sua esperança quase certamente. Vamos fazer contudo um experimento para visualizar esse fenômeno. Nesse experimento, jogamos 100 moedas e contamos quantas caras obtivemos. Pelo que discutimos anteriormente, esperamos que esse número se encontre por volta de 50 , que é a esperança desta soma de variáveis \\iid. Vamos portanto repetir esse experimento mil vezes e observar quantas vezes obtemos algo próximo de 50 , veja Figura 3.2. 10 20 30 40 50 60 70 50 100 150 200 250 300 Figura 3.2: Vários ensaios de uma variável \\Bin(100,0.5) , pra ser mais preciso 1000 ensaios. Cada barra representa o número de ensaios que caíram no intervalo determinado pela base da barra. Note que apesar dos experimentos se concentrarem em torno da média, alguns se afastam um pouco (obviamente pois o experimento é aleatório). Nessa seção estudaremos esses desvios espontâneos, que são chamados de flutuaçãoes. Nosso objetivo nessa seção será obter qual é o tamanho típico das flutuações em torno da média dessa soma de variáveis aleatórias. Ao contrário do que fizemos ao estudar Grandes Desvios, nós agora estamos buscando flutuações menores, que acontecem espontaneamente e não com baixa probabilidade. Note também que apesar de observarmos uma aleatoriedade na Figura 3.2, também notamos uma certa regularidade que muitas vezes é chamada de ’forma de sino’ no histograma apresentado. 3.8.1 A distribuição normal Começaremos estudando qual poderia ser uma possível forma limite para o histograma da Figura 3.2. Como uma primeira tentativa, suponha que \\sum_{i=1}^{\\infty}Z_{i} possui uma certa distribuição \\mu (veremos posteriormente que isso somente pode acontecer em casos triviais). Mas se esse fosse o caso, poderíamos dividir a soma nos termos pares e ímpares X=\\sum_{i\\text{ par}}Z_{i} e Y=\\sum_{i\\text{ \\'{\\i}mpar}}Z_{i} . Nesse caso teríamos X e Y independentes e também distribuídos como \\mu (pois são dados por uma soma que tem a mesma distribuição daquela que define \\mu ). O seguinte lema mostra que isso somente pode acontecer na situação trivial em que \\mu=\\delta_{0} . {lemma} Sejam X e Y variáveis aleatórias em \\mathcal{L}^{2} , \\iidcom distribuição \\mu . Nesse caso, se X+Y também tem distribuição \\mu , então \\mu=\\delta_{0} . Demonstração. Sabemos que \\begin{split}E(X+Y)&=E(X)+E(Y)=2E(X)\\text{ e}\\\\ \\Var(X+Y)&=\\Var(X)+\\Var(Y)=2\\Var(X).\\end{split} (3.95) Mas como X+Y tem a mesma distribuição de X , então E(X)=2E(X) e \\Var(X)=2\\Var(X) , donde ambas são zero. Usando o método dos segundo momento, para todo a>0 , P[|X|\\geq a]\\leq\\frac{\\Var(X)}{a^{2}}=0, (3.96) terminando a prova de que X=0 quase certamente. ∎ A intuição dessa prova é que quando somamos duas variáveis não determinísticas, a incerteza da soma (medida através da variância) tende a aumentar. Dessa forma não podemos obter a mesma distribuição após a soma. Mas existe uma maneira simples de tornar esse problema interessante novamente. Digamos que X e Y pertencem a \\mathcal{L}^{2} e são i.i.d. Então \\Var\\Big{(}\\frac{X+Y}{\\sqrt{2}}\\Big{)}=2\\Var\\Big{(}\\frac{X}{\\sqrt{2}}\\Big{)}=% \\Var(X). (3.97) Então podemos nos perguntar se {question} Existe alguma distribuição não trivial \\mu em \\mathcal{L}^{2} tal que, se X e Y são independentes e distribuídas de acordo com \\mu , temos \\frac{X+Y}{\\sqrt{2}}\\distr\\mu\\;? (3.98) Pelo menos sabemos agora que a variância não se altera através dessa operação. Ou em outras palavras, queremos saber se existe algum ponto fixo para o operador \\Gamma que toma uma distribuição \\mu em \\mathbb{R} e retorna \\Gamma(\\mu)=\\Big{(}\\frac{X_{1}+X_{2}}{\\sqrt{2}}\\Big{)}\\circ\\mu\\otimes\\mu. (3.99) Para tentar responder a essa questão, vamos estudar mais a fundo qual é a distribuição da soma de duas variáveis aleatórias independentes. Para isso, considere a distribuição (X,Y)\\circ P do par, que coincide com \\mu\\otimes\\mu , nos dando P\\Big{[}\\frac{X+Y}{\\sqrt{2}}\\leq z\\Big{]}=\\mu\\otimes\\mu\\big{(}\\big{\\{}(x,y);% \\tfrac{x+y}{\\sqrt{2}}\\leq z\\big{\\}}\\big{)}. (3.100) Note também que a transformação linear (x,y)\\mapsto\\tfrac{1}{\\sqrt{2}}\\big{(}x+y,x-y\\big{)} é uma rotação rígida em \\mathbb{R}^{2} , o que nos motiva a propor a pergunta mais simples. {question} Existe alguma distribuição não trivial \\mu em \\mathcal{L}^{2} tal que, se X e Y são independentes e distribuídas de acordo com \\mu , a distribuição do par (X,Y) é invariante por rotações? Ainda estamos numa busca não rigorosa de tal distribuição, então vamos supor algumas outras propriedades, como por exemplo que \\mu seja absolutamente contínua com respeito a Lebesgue, isto é \\d{\\mu}=f(x)\\d{x} . Nesse caso, já vimos que (X,Y)\\distr f(x)f(y)\\d{x}\\d{y} e no fundo estamos procurando uma função f tal que f(x)f(y)=h(x^{2}+y^{2}),\\text{ para todo $x,y\\in\\mathbb{R}$ e alguma $h:% \\mathbb{R}_{+}\\to\\mathbb{R}_{+}$.} (3.101) Para trasformar o produto f(x)f(y) em uma soma, definimos g=\\log f e k=\\log h e o que gostaríamos que acontecesse é g(x)+g(y)=k(x^{2}+y^{2}) . Como ainda não estamos preocupados com unicidade de \\mu e apenas com a existência, já podemos encontrar nossa resposta para nossa pergunta, escolhendo uma função quadrática, tal como g(x)=\\alpha x^{2}-\\beta . Mas temos ainda que cuidar para que f(x)=\\ex{\\alpha x^{2}-\\beta} seja uma densidade, ou seja \\int f\\d{x}=1 . Para isso, precisamos que \\alpha seja negativo e, fixado \\alpha , o valor de \\beta já estará determinado por normalização. Tudo isso motiva finalmente a seguinte definição. {definition} Dizemos que X tem distibuição normal canônica, se X\\distr\\frac{1}{\\sqrt{2\\pi}}\\exp\\big{\\{}-x^{2}/2\\big{\\}}\\d{x}. (3.102) Além disso, para m\\in\\mathbb{R} e \\sigma\\geq 0 , dizemos que Y\\distr\\mathcal{N}(m,\\sigma^{2}) se Y tem a mesma distribuição de \\sigma X+m , onde X tem distribuição normal canônica \\mathcal{N}(0,1) . Note que \\mathcal{N}(m,0)=\\delta_{m} . Muitas vezes chamamos essa distribuição de gaussiana, obviamente em homenagem a Gauss. Vamos rapidamente observar que a definição acima realmente descreve uma distribuição de probabilidade, ou seja que a integral dessa densidade é um. Para tanto, vamos usar um truque conhecido, que consiste em retornar ao plano. Obviamente, \\begin{split}\\Big{(}\\int\\exp\\big{\\{}-x^{2}/2\\big{\\}}\\d{x}\\Big{)}^{2}&=\\int\\int% \\exp\\big{\\{}-(x^{2}+y^{2})/2\\big{\\}}\\d{x}\\d{y}\\\\ &=\\int_{0}^{2\\pi}\\int_{0}^{\\infty}\\exp\\{-r^{2}/2\\}r\\d{r}\\d{\\theta}\\overset{2s% \\;=\\;r^{2}}{=}2\\pi.\\end{split} (3.103) Donde a constante em (3.102) está de fato correta. {exercise} Mostre que a distribuição \\mathcal{N}(m,\\sigma^{2}) , tem densidade \\frac{1}{\\sigma\\sqrt{2\\pi}}\\ex{-(x-m)^{2}/(2\\sigma^{2})}. (3.104) {exercise} Mostre que Y\\distr\\mathcal{N}(m,\\sigma^{2}) tem esperança m e variância \\sigma^{2} . Para confirmar que de fato as distribuições normais se comportam bem com respeito a somas independentes, apresentamos o seguinte resultado. {proposition} Se X\\distr\\mathcal{N}(m,\\sigma^{2}) e Y\\distr\\mathcal{N}(\\bar{m},\\bar{\\sigma}^{2}) são independentes, então X+Y tem distribuição \\mathcal{N}(m+\\bar{m},\\sigma^{2}+\\bar{\\sigma}^{2}) . Em particular, \\mu é um ponto fixo do operador \\Gamma definido em (3.99). Demonstração. O caso em que \\sigma ou \\bar{\\sigma} se anulam é trivial, portanto vamos considerar que ambas são positivas. Não é difícil ver que podemos também supor que m=\\bar{m}=0 . Podemos então calcular P[X+Y\\leq a]=P[\\sigma W+\\bar{\\sigma}Z\\leq a], (3.105) onde W e Z são independentes com distribuição \\mathcal{N}(0,1) . Assim, a probabilidade acima pode ser escrita como \\mathcal{N}(0,1)\\otimes\\mathcal{N}(0,1)\\Big{(}\\big{\\{}(w,z)\\in\\mathbb{R}^{2};% \\sigma w+\\bar{\\sigma}z\\leq a\\big{\\}}\\Big{)}. (3.106) Agora aplicaremos a rotação rígida A:\\mathbb{R}^{2}\\to\\mathbb{R}^{2} dada por A(w,z)=\\frac{1}{\\sqrt{\\sigma^{2}+\\bar{\\sigma}^{2}}}\\big{(}\\sigma w+\\bar{\\sigma% }z,\\bar{\\sigma}w-\\sigma z\\big{)}. (3.107) Como sabemos que a densidade f de (W,Z) é invariante por A , ou seja f\\circ A=f , então podemos escrever (3.106) como \\begin{split}\\mathcal{N}(0,1)&\\otimes\\mathcal{N}(0,1)\\Big{(}A\\big{(}\\big{\\{}(w% ,z)\\in\\mathbb{R}^{2};\\sigma w+\\bar{\\sigma}z\\leq a\\big{\\}}\\big{)}\\Big{)}\\\\ &=\\mathcal{N}(0,1)\\otimes\\mathcal{N}(0,1)\\Big{(}\\Big{\\{}(w,z);\\frac{1}{\\sqrt{% \\sigma^{2}+\\bar{\\sigma}^{2}}}w\\leq a\\Big{\\}}\\Big{)}\\\\ &=\\mathcal{N}(0,1)\\big{(}(-\\infty,a\\sqrt{\\sigma^{2}+\\bar{\\sigma}^{2}}\\big{]}% \\big{)}=\\mathcal{N}(0,\\sigma^{2}+\\bar{\\sigma}^{2})\\big{(}(-\\infty,a\\big{]}\\big% {)},\\end{split} terminando a prova da proposição. ∎ Podemos obter um corolário interessante sobre a soma de normais i.i.d. {corollary} Sejam X_{1},X_{2},\\dots variáveis \\iidcom distribuição \\mathcal{N}(m,\\sigma^{2}) , então X_{1}+\\dots+X_{n}\\distr\\mathcal{N}(nm,n\\sigma^{2}). (3.108) Como consequência \\frac{\\sum_{i=1}^{n}X_{i}-nE(X_{1})}{\\sigma\\sqrt{n}}\\distr\\mathcal{N}(0,1). (3.109) Lembrando da Lei dos Grandes Números, se dividimos a soma dos X_{i}-E(X_{i}) por n , essa fração vai a zero quase certamente. O que concluímos acima é que ao dividir por \\sqrt{n} obtemos um limite não trivial (nem zero, nem infinito) e aleatório (não determinístico). Mais uma observação curiosa: nossa motivação para a definição da distribuição normal passou por invariância por rotações e podemos extender essa invariância para n normais independentes. Note que somar as coordenadas canônicas é equivalente a tomar o produdo escalar com o vetor (1,1,\\dots,1) , que tem norma euclideana \\sqrt{n} . Uma outra maneira de entender o corolário acima é que a normal é um ponto fixo da operação seguinte  a)​tome uma distribuição \\mu\\in\\mathcal{L}^{2} ,  b)​considere X_{1},\\dots,X_{n} \\iidcom distribuição \\mu e  c)​retorne a distribuição de \\frac{X_{1}+\\dots+X_{n}-nE(X_{1})}{\\sqrt{n}}. (3.110) Na Questão 3.8.1, nos perguntamos quais seriam os outros possíveis pontos fixos de \\Gamma e isso será considerado depois. Mas uma outra questão bastante importante é se o ponto fixo \\mathcal{N}(0,1) é atrator, ou seja se começando com outras distribuições poderíamos nos aproximar de \\mathcal{N}(0,1) à medida que iteramos \\Gamma . Isso é estudado no Teorema Central do Limite (TCL) que provaremos posteriormente. Mas antes, precisamos desenvolver uma boa definição de convergência para distribuições, ou em outras palavras definir uma topologia. Esse será o nosso próximo tópico. 3.8.2 Convergência fraca Em muitos casos é importante termos bem definida uma noção de convergência de medidas de probabilidade. Supondo por exemplo no espaço mensurável (E,\\mathcal{A}) , tenhamos uma sequência de probabilidades \\mu_{n} e gostaríamos de saber se ela converge a uma determinada \\mu . Um candidato natural para dara sentido a essa convergência poderia se a distância de variação total entre duas medidas d_{\\VT}(\\mu,\\nu)=\\sup_{A\\in\\mathcal{A}}|\\mu(A)-\\nu(A)|. (3.111) Não é difícil mostrar que a definição acima induz uma métrica, mas ela possui alguns problemas que descreveremos a seguir. {exercise} Mostre que d_{\\VT} define uma métrica. {exercise} Sejam \\mu e \\nu absolutamente contínuas com respeito a uma medida fixa \\eta , tendo densidades \\rho e \\pi respectivamente. Encontre uma fórmula para d_{\\VT}(\\mu,\\nu) em termos das densidades. Essa fórmula nos remete a qual distância entre funções? Digamos que o espaço amostral E já seja provido de uma métrica d e \\mathcal{A} seja a \\sigma -álgebra dos borelianos em E . Qualquer que seja a noção de convergência que iremos considerar, gostaríamos de dizer que \\delta_{x_{n}} converge a \\delta_{x} sempre que x_{n}\\to x em E . Esse porém não é o caso para d_{\\VT} , pois se x_{n}\\neq x para todo n e \\{x\\}\\in\\mathcal{A} , teríamos d_{\\VT}(\\delta_{x_{n}},\\delta_{x})\\geq|\\delta_{x_{n}}(\\{x\\})-\\delta_{x}(\\{x\\})% |=|0-1|=1. (3.112) Aqueles que já viram o conceito de convergência fraca acharão natural que a convergência de \\mu_{n} para \\mu seja definida em termos da convergência das integrais \\int f\\d{\\mu}_{n} para \\int f\\d{\\mu} . Porém, como mencionamos no exemplo das medidas \\delta_{x_{n}} acima, gostaríamos também de a convergência respeitasse a topologia original do espaço E , o que torna natural o seguinte conceito. {definition} Dizemos que uma sequência de medidas de probabilidade \\mu_{n} converge fracamente (ou converge em distribuição) para uma probabilidade \\mu se \\lim_{n\\to\\infty}\\int f\\d{\\mu}_{n}=\\int f\\d{\\mu},\\text{ para toda $f:E\\to% \\mathbb{R}$ cont\\'{\\i}nua e limitada.} (3.113) Essa convergência muitas vezes é denotada por \\mu_{n}\\Rightarrow\\mu . Essa definição fica ainda mais natural para aqueles que conhecem o Teorema da Representação de Riesz. Com isso em mente, podemos relacionar a convergência em distribuição com a convergência fraca- \\star no espaço de medidas finitas. {exercise} Mostre que em (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) , temos que \\tfrac{1}{n}\\sum_{i=1}^{n}\\delta_{i/n}\\Rightarrow U_{[0,1]} . {exercise} Considere a função \\phi do espaço de medidas em ([0,1],\\mathcal{B}([0,1])) nele mesmo, dada por: \\phi(\\mu)(A)=\\tfrac{1}{2}\\big{(}\\mu(3A)+\\mu(3A-2)\\big{)}. (3.114) Identifique o limite em distribuição de \\phi^{(n)}(\\delta_{0}) . Mostre que  a)​a função de distribuição acumulada associada ao limite é contínua,  b)​o limite não é absolutamente contínuo com respeito à medida de Lebesgue. {exercise} Sejam X_{1},X_{2},\\dots i.i.d. distribuidas como \\text{Exp}(1) e defina M_{n}=\\max_{i=1,\\dots,n}X_{i}. (3.115) Mostre que M_{n}-\\log(n) converge fracamente e identifique o limite. Observe que não precisamos dividir M_{n}-\\log(n) por nada para obter a convergência. Nós algumas vezes denotamos X_{n}\\Rightarrow X quando X_{n} e X são elementos aleatórios de (\\Omega,\\mathcal{F},P) para descrever a convergência fraca de suas respectivas distribuições. Mais precisamente, X_{n}\\circ P\\Rightarrow X\\circ P . 3.8.3 Convergência fraca em \\mathbb{R} No caso especial em que E=\\mathbb{R} , temos vários outras maneiras de caracterizar convergência em distribuição. A primeira é dada pela seguinte {proposition} Se \\int g\\d{\\mu}_{n} converge para \\int g\\d{\\mu} para toda g\\in C^{3} limitada e com as três primeiras derivadas limitadas, então \\mu_{n}\\Rightarrow\\mu . Demonstração. Primeiramente, vamos ver que podemos nos concentrar em um conjunto compacto da reta. Para isso fixe um \\varepsilon>0 e tome M^{\\prime} tal que \\mu\\big{(}[-M^{\\prime},M^{\\prime}]\\big{)}>1-\\varepsilon/3 . Tomando uma função g satisfazendo as hipóteses do teorema e tal que \\1{[-M^{\\prime},M^{\\prime}]}\\leq g\\leq\\1{[-M^{\\prime}-1,M^{\\prime}+1]}, (3.116) concluimos que \\mu_{n}\\big{(}[-M^{\\prime}-1,M^{\\prime}+1]\\big{)}\\geq 1-\\varepsilon/2, (3.117) para todo n suficientemente grande. Se tomamos M\\geq M^{\\prime} suficientemente grande, podemos obter a cota acima para todo n (com M no lugar de M^{\\prime}+1 e \\varepsilon no lugar de \\varepsilon/2 ). Fixamos agora uma f:\\mathbb{R}\\to\\mathbb{R} contínua e limitada. Sabemos que é possível aproximar f por uma função g\\in C^{3} de suporte compacto, com \\lVert g\\rVert_{\\infty}\\leq 2\\lVert f\\rVert_{\\infty} e |g-f|\\leq\\varepsilon/M uniformemente no intervalo [-M,M] . Essa g certamente satisfaz as hipóteses do teorema. Portanto, \\begin{split}\\Big{|}\\int f\\d{\\mu}_{n}-\\int f\\d{\\mu}\\Big{|}&\\leq 2\\varepsilon% \\lVert f\\rVert_{\\infty}+\\Big{|}\\int_{-M}^{M}f\\d{\\mu}_{n}-\\int_{-M}^{M}f\\d{\\mu}% \\Big{|}\\\\ &\\leq 2\\varepsilon\\lVert f\\rVert_{\\infty}+\\frac{\\varepsilon}{M}2M+\\Big{|}\\int_% {-M}^{M}g\\d{\\mu}_{n}-\\int_{-M}^{M}g\\d{\\mu}\\Big{|}\\\\ &\\leq 2\\varepsilon\\lVert f\\rVert_{\\infty}+2\\varepsilon+\\Big{|}\\int g\\d{\\mu}_{n% }-\\int\\d{\\mu}\\Big{|}.\\end{split} Como o último termo converge a zero e \\varepsilon foi escolhido arbitrariamente, isso conclui a prova da proposição. ∎ 3.8.4 O TCL para uma sequência i.i.d. {theorem} [Teorema Central do Limite] Considere em (\\Omega,\\mathcal{F},P) , uma sequência X_{1},X_{2},\\dots de variáveis aleatórias \\iidem \\mathcal{L}^{3} . Nesse caso, se definimos m=E(X_{1}) e \\sigma^{2}=\\Var(X_{1}) , temos \\frac{\\sum_{i=1}^{n}(X_{i}-m)}{\\sigma\\sqrt{n}}\\Rightarrow\\mathcal{N}(0,1). (3.118) Demonstração. Primeiramente, observe que podemos supor que m=0 , pois de qualquer forma iremos subtrair a média da distribuição na qual nos interessamos. Uma outra observação importante é que podemos supor \\sigma=1 , pois no caso geral de qualquer forma estamos somando X_{i}/\\sigma no enunciado. Como vimos na Proposição 3.8.3, basta mostrar a convergência das integrais de funções g\\in C^{3} , que possuam todas as três primeiras derivadas limitadas. Considerando a função \\phi^{n}(x_{1},\\dots,x_{n}):=g\\Big{(}\\frac{x_{1}+\\dots+x_{n}}{\\sqrt{n}}\\Big{)}, (3.119) nos basta provar a convergência das sequências de números reais \\lim_{n}\\int\\phi^{n}(X_{1},\\dots,X_{n})\\d{P}=\\int g(s)\\mathcal{N}(0,1)(\\d{s}). (3.120) Vale lembrar que no Corolário 3.8.1 já estabelecemos algo mais forte para variáveis normais. Mais precisamente, suponha que extendemos nosso espaço de probabilidade para (\\Omega^{\\prime},\\mathcal{F}^{\\prime},P^{\\prime}) , onde exista uma sequência Y_{1},Y_{2},\\dots de variáveis aleatórias \\iidcom distribuição \\mathcal{N}(0,1) independente de X_{1},X_{2},\\dots Então, para todo n\\geq 1 , \\int\\phi^{n}(Y_{1},\\dots,Y_{n})\\d{P}^{\\prime}=\\int g(s)\\mathcal{N}(0,1)(\\d{s}), (3.121) o que tornaria o limite em (3.120) trivial para tais variáveis. A nossa estratégia será aproximar \\phi^{n}(X_{1},\\dots,X_{n}) por \\phi(Y_{1},\\dots,Y_{n}) , e faremos isso trocando uma variável de cada vez. Para entender o que acontece quando trocamos uma das variáveis X_{i} por Y_{i} , temos que expandir g em série de potências, isto é, escrever g(s)=g(s_{0})+g^{\\prime}(s_{0})(s-s_{0})+g^{\\prime\\prime}(s_{o})(s-s_{0})^{2}/% 2+r_{s_{0}}(s-s_{0}), (3.122) onde r_{s_{0}}(h)/h^{3} é limitada por M , uniformemente em h e s_{0} em consequência das nossas suposições sobre g . Denotando z_{i}=(y_{1},\\dots,y_{i-1},x_{i},\\dots x_{n}) , z_{i}^{o}:=(y_{1},\\dots,y_{n-1},0,x_{n+1},\\dots,x_{n}) e s_{i}^{o}=y_{1}+\\dots+y_{n-1}+x_{n+1}+\\dots x_{n} , temos \\phi^{n}(z_{i})=\\phi^{n}(z_{i}^{o})+g^{\\prime}\\Big{(}\\frac{s_{i}^{o}}{\\sqrt{n}% }\\Big{)}\\frac{x_{i}}{\\sqrt{n}}+g^{\\prime\\prime}\\Big{(}\\frac{s_{i}^{o}}{\\sqrt{n% }}\\Big{)}\\frac{x_{i}^{2}}{2n}+r_{\\frac{s_{i}^{o}}{\\sqrt{n}}}\\Big{(}\\frac{x_{i}% }{\\sqrt{n}}\\Big{)}, (3.123) Nós propositalmente expandimos \\phi^{n} até ordem dois, pois X_{i} e Y_{i} possuem os mesmos momentos de ordem um ( m=0 ) e dois ( \\sigma^{2}=1 ). Integrando os dois lados da igualdade acima com respeito a Z_{i}\\circ P (denotamos como antes, Z_{i}=(Y_{1},\\dots,Y_{i-1},X_{i},\\dots,X_{n}) e Z_{i}^{o} , S_{i}^{o} analogamente), teremos \\int\\phi^{n}(Z_{i})\\d{P}^{\\prime}=\\int\\phi^{n}(Z_{i}^{o})\\d{P}^{\\prime}+\\frac{% 1}{2n}v_{i}+k_{i}, (3.124) onde as quantidades v e k , se escrevem como v_{i}=\\int g^{\\prime\\prime}\\Big{(}\\frac{S_{i}^{o}}{\\sqrt{n}}\\Big{)}\\d{P}^{% \\prime}\\quad\\text{ e }\\quad k_{i}=\\int r_{S_{i}^{o}/\\sqrt{n}}\\Big{(}\\frac{X_{i% }}{\\sqrt{n}}\\Big{)}\\d{P}^{\\prime}. (3.125) Note que v_{i} não depende de X_{i} e que |k_{i}|\\leq\\Big{|}\\int\\Big{(}\\frac{X_{i}^{3}}{n^{3/2}}\\Big{)}\\Big{(}\\frac{n^{3% /2}}{X_{i}^{3}}\\Big{)}r_{S_{i}^{o}/\\sqrt{n}}\\Big{(}\\frac{X_{i}}{\\sqrt{n}}\\Big{% )}\\d{P}^{\\prime}\\Big{|}\\leq\\frac{M}{n^{3/2}}E(|X_{i}^{3}|). (3.126) As observações acima são o ponto mais importante da prova de que essa aproximação funciona e uma outra maneira de colocá-las é a seguinte. Como X_{i} e Y_{i} possuem os dois primeiros momentos iguais, os dois primeiros termos de Taylor coincidem após a integração (o primeiro se anula e o segundo é v_{i} tanto para X_{i} quanto para Y_{i} ). O resto é de ordem muito pequena para influir no limite. De fato, se retiramos o termo Y_{i} de Z_{i+1} , fazendo a mesma expansão que para X_{i} , obtemos \\int\\phi^{n}(Z_{i+1})\\d{P}^{\\prime}=\\int\\phi^{n}(Z_{i}^{o})\\d{P}^{\\prime}+% \\frac{1}{2n}v_{i}+k^{\\prime}_{i}, (3.127) com o termo de ordem superior k^{\\prime}_{i} sendo definido exatamente como k_{i} , mas com Y_{i} no lugar de X_{i} . Estamos prontos agora para a computação final \\begin{split}\\Big{|}\\int\\phi^{n}&(X_{1},\\dots,X_{n})\\d{P}-\\int g(s)\\mathcal{N}% (0,1)(\\d{s})\\Big{|}\\\\ &=\\Big{|}\\int\\phi^{n}(Z_{0})\\d{P}^{\\prime}-\\int\\phi^{n}(Z_{n})\\d{P}^{\\prime}% \\Big{|}\\\\ &\\leq\\sum_{i=0}^{n-1}\\Big{|}\\int\\phi^{n}(Z_{i})\\d{P}^{\\prime}-\\int\\phi^{n}(Z_{% i+1})\\d{P}^{\\prime}\\Big{|}=\\sum_{i=0}^{n-1}|k_{i}-k^{\\prime}_{i}|\\\\ &\\leq n\\frac{M}{n^{3/2}}\\big{(}E(|X_{1}|^{3})+E(|Y_{1}|^{3})\\big{)},\\end{split} que claramente converge a zero, provando o teorema. ∎ {corollary} A \\mathcal{N}(0,1) é a única distribuição \\mu que possui esperança zero, variância 1 e é tal que se X,Y são \\iidcom distribuição \\mu , então (X+Y)/\\sqrt{2} também possuem distribuição \\mu . Em outras palavras, \\mathcal{N}(0,\\sigma^{2}) , para \\sigma\\geq 0 , são os únicos pontos fixos de \\Gamma em \\mathcal{L}^{3} . Demonstração. Usando a invariância enunciada acima, temos que \\frac{X_{1}+\\dots+X_{2^{k}}}{\\sqrt{2^{k}}}\\distr\\mu. (3.128) Mas pelo Teorema central do limite, a distribuição dessa combinação de X_{i} deve convergir a \\mathcal{N}(0,1) , logo temos \\mu=\\mathcal{N}(0,1) . ∎ Vamos terminar essa seção com uma aplicação do teorema acima. {exercise} Digamos que jogamos 100 moedas honestas e independentes, como foi proposto no início da seção, obtendo finalmente uma variável aleatória Y\\distr\\Bin(100,1/2) . Usando o O TCL para uma sequência i.i.d., estime P[Y\\geq 55] usando uma aproximação por uma \\mathcal{N}(0,1) . Calcule numericamente o valor real desta probabilidade e compare ambas as estimativas. 55todo: 5 falar de Tao Vu, se os momentos batem a distrib de auto-val é proxima + funcao zeta. \\todosec Tópico: Mecânica estatística do gás idealMostrar a equivalência de ensembles. \\todosec Tópico: Funções características???funcoes caracteristicas e tomografia… Previous page Next page"],[["index.html","Ch3.html","Ch3.Sx1.html"],"Tópico: Contando triângulos ‣ Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. Tópico: Contando triângulos Tópico: Contando triângulos Vimos como a Lei Fraca dos Grandes Números seguiu de uma estimativa de segundo momento (mais precisamente usando a variância). Nessa seção iremos mostrar como esse método é mais geral, se aplicando mesmo em situações onde as variáveis não são necessariamente independentes duas a duas. Seja V_{n}=\\{1,\\dots,n\\} com n\\geq 3 e \\mathcal{E}_{n}=\\big{\\{}\\{x,y\\}\\subseteq V_{n};x\\neq y\\big{\\}} . Chamamos o par (V_{n},\\mathcal{E}_{n}) de grafo completo em n vértices. Definimos em um certo espaço de probabilidade P_{n} , as variáveis aleatórias (X_{e})_{e\\in\\mathcal{E}_{n}} de maneira \\iidcom distribuição \\Ber(p) , onde p\\in[0,1] . Essas variáveis induzem um subgrafo aleatório (V_{n},\\mathcal{E}_{n}^{\\prime}) , onde \\mathcal{E}_{n}^{\\prime}=\\big{\\{}e\\in\\mathcal{E}_{n};X_{e}=1\\big{\\}}. (3.39) Dizemos que os elos e , tais que X_{e}=1 são abertos. Definimos nesse espaço a variável aleatória T_{n}=\\#\\big{\\{}\\text{tri\\^{a}ngulos em $(V_{n},\\mathcal{E}_{n}^{\\prime})$}% \\big{\\}}. (3.40) Essa variável claramente pode ser escrita como T_{n}=\\sum_{x,y,z\\in V_{n}\\text{ distintos}}\\1_{A_{\\{x,y,z\\}}}, (3.41) onde A_{\\{x,y,z\\}}=\\big{[}\\text{\\{x,y,z\\} formam um tri\\^{a}ngulo em $(V_{n},% \\mathcal{E}_{n}^{\\prime})$}\\big{]} . Gostaríamos de entender algo sobre a distribuição de T_{n} e começamos calculando \\begin{split}E^{n}(T_{n})&=\\sum_{\\{x,y,z\\}\\text{ distintos}}P^{n}(A_{\\{x,y,z\\}% })\\\\ &=\\binom{n}{3}p^{3}=\\frac{n(n-1)(n-2)}{6}p^{3}.\\end{split} (3.42) Logo, P[T_{n}>a]\\leq n(n-1)(n-2)p^{3}/6a . Mais ainda, \\begin{split}E^{n}(T_{n}^{2})&=\\sum_{\\{x,y,z\\}\\text{ distintos}}\\quad\\sum_{\\{x% ^{\\prime},y^{\\prime},z^{\\prime}\\}\\text{ distintos}}P^{n}(A_{\\{x,y,z\\}}\\cap A_{% \\{x^{\\prime},y^{\\prime},z^{\\prime}\\}})\\\\ &=\\underbrace{\\binom{n}{6}\\binom{6}{3}p^{6}}_{\\text{todos distintos}}+% \\underbrace{\\binom{n}{5}\\binom{5}{3}\\binom{3}{1}p^{6}}_{\\text{$1$-comum}}+% \\underbrace{\\binom{n}{4}\\binom{3}{2}\\binom{4}{3}p^{5}}_{\\text{$2$ em comum}}+% \\underbrace{\\binom{n}{3}p^{3}}_{\\text{iguais}}\\end{split} (3.43) Donde \\Var^{n}(T_{n})=\\frac{1}{36}n^{6}p^{6}-\\frac{1}{36}n^{6}p^{6}+cn^{5}p^{5}+...% \\leq c(n^{5}p^{5}+n^{3}p^{3}), (3.44) para todos p\\in[0,1] e n\\geq 1 se escolhemos bem a constante c>0 . Isso nos permite por exemplo estimar o que acontece em alguns regimes, como por exemplo, se p=1/2 , então E^{n}(T_{n})=\\frac{n(n-1)(n-2)}{48}, (3.45) que cresce como n^{3} , e \\Var^{n}(T_{n})\\leq cn^{5} , logo P^{n}\\Big{[}\\Big{|}T_{n}-E^{n}(T_{n})\\Big{|}>\\varepsilon n^{3}\\Big{]}\\leq\\frac% {\\Var^{n}(T_{n})}{\\varepsilon^{2}n^{6}}\\leq\\frac{c}{\\varepsilon^{2}n}. (3.46) \\todosec Tópico: Análise de DNAfazer \"computational molecular biology- Pevzner seção 5.5… \\todosec Tópico: Método Probabilístico Revisitadousando segundo momento agora Previous page Next page"],[["index.html","Ch3.html","Ch3.Sx2.html"],"Tópico: Funções características 1 footnote 1 1 footnote 1 Somos gratos a Rangel Baldasso por escrever essa seção. ‣ Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. Tópico: Funções características Tópico: Funções características 11 1 Somos gratos a Rangel Baldasso por escrever essa seção. Esta seção trata da função característica de uma variável aleatória, que pode ser vista como um análogo complexo da trasformada de Laplace, ou também como a transformada de Fourier de uma distribuição em \\mathbb{R} . Vamos estudar suas principais propriedades e demonstrar que a função características determinam unicamente a distribuição da variável aleatória. {definition} Dada uma variável aleatória X , a função característica de X , \\widebar{\\phi}_{X}:\\mathbb{R}\\rightarrow\\mathbb{C} , é definida por \\widebar{\\phi}_{X}(t)=\\mathbb{E}(e^{itX}),\\qquad t\\in\\mathbb{R}. (3.91) Vamos começar estudando as propriedades básicas de \\widebar{\\phi}_{X} . {exercise} Prove que a função \\widebar{\\phi}_{X} é absolutamente contínua. {exercise} Suponha que \\mathbb{E}(|X|^{n})<+\\infty . Prove que a função \\widebar{\\phi}_{X} é n vezes diferenciável em t=0 e que \\widebar{\\phi}_{X}^{(n)}(0)=i^{n}\\mathbb{E}(X^{n}) . {exercise} Se X_{1},X_{2},\\ldots,X_{n} são independentes e a_{1},a_{2},\\ldots,a_{n}\\in\\mathbb{R} , então \\widebar{\\phi}_{a_{1}X_{1}+a_{2}X_{2}+\\cdots+a_{n}X_{n}}(t)=\\widebar{\\phi}_{X_% {1}}(a_{1}t)\\widebar{\\phi}_{X_{2}}(a_{2}t)\\cdots\\widebar{\\phi}_{X_{n}}(a_{n}t). (3.92) Como vamos ver agora, a função característica nos permite recuperar a distribuição de X : {exercise} Use a seguinte igualdade \\lim_{T\\rightarrow+\\infty}\\int_{0}^{T}\\frac{\\sin(tz)}{t}\\,dz=\\begin{cases}1&% \\text{se }z>0\\\\ 0&\\text{se }z=0\\\\ -1&\\text{se }x<0\\\\ \\end{cases} (3.93) para provar que se a<b são pontos de continuidade da função de distribuição de X , F_{X} , então F_{X}(b)-F_{X}(a)=\\lim_{T\\rightarrow+\\infty}\\frac{1}{2\\pi}\\int_{-T}^{T}\\frac{e% ^{-itb}-e^{-ita}}{-it}\\widebar{\\phi}_{X}(t)\\,dt. (3.94) Conclua que a distribuição de X é determinada por \\widebar{\\phi}_{X} . O próximo exercício consiste em calcular algumas funções características. {exercise} Calcule as funções características das seguintes distribuições: i.​ X\\sim Ber(p) ; ii.​ X\\sim Poisson(\\lambda) ; iii.​ X\\sim N(0,1) . Dica: fixe z\\in\\mathbb{R} , calcule \\mathbb{E}(e^{zX}) e use o Princípio da continuação analítica. Previous page Next page"],[["index.html","Ch3.html","Ch3.Sx3.html"],"Tópico: O Teorema de Portmanteau ‣ Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. Tópico: O Teorema de Portmanteau Tópico: O Teorema de Portmanteau O próximo resultado é bastante útil para provar convergência fraca, pois nos fornece uma coleção de equivalências muitas vezes mais fáceis de verificar. {theorem} [Teorema de Portmanteau] Sejam (\\mu_{n})_{n\\geq 1} e \\mu medidas de probabilidade em (E,\\mathcal{A}) . São equivalentes: a)​ \\mu_{n}\\Rightarrow\\mu , a’)​ \\int f\\d{\\mu}_{n}\\to\\int f\\d{\\mu} , para toda f unifmormemente contínua e limitada, b)​ \\limsup_{n}\\mu_{n}(F)\\leq\\mu(F), para todo F\\subseteq E fechado, b’)​ \\liminf_{n}\\mu_{n}(G)\\geq\\mu(G), para todo F\\subseteq E aberto, c)​ \\lim_{n}\\mu_{n}(A)=\\mu(A), para todo A\\in\\mathcal{A} com \\mu(\\partial A)=0 . Para memorizar o teorema acima, é conveniente lembrar dos dois exemplos:  i)​se x_{n}\\to x com x_{n}\\neq x , F=\\{x\\} e G=B(x,\\delta)\\setminus\\{x\\} temos, para n grande, \\mu_{n}(F)=\\mu(G)=0<1=\\mu(F)=\\mu_{n}(G), (3.129)  ii)​em (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) , seja \\mu_{2n}=\\delta_{n} e \\mu_{2n+1}=\\mu=\\delta_{0} . Obviamente \\mu_{n} não converge fracamente a \\mu . Contudo, para todo A\\in\\mathcal{B}(\\mathbb{R}) , \\begin{split}\\liminf_{n}\\mu_{n}(A)&\\leq\\liminf_{n}\\mu_{2n}(A)=\\mu(A)\\text{ e}% \\\\ \\limsup_{n}\\mu_{n}(A)&\\geq\\limsup_{n}\\mu_{2n}(A)=\\mu(A).\\end{split} (3.130) Prova do Teorema 3. Obviamente, (a\\Rightarrow a^{\\prime}) , pois a^{\\prime}) somente supõe a convergência das integrais para funções f que sejam uniformemente contínuas, portanto é um requisito mais fraco que a) . Observamos também que (b\\Leftrightarrow b^{\\prime}) . De fato, basta tomarmos complementos e observar a mudança nos sinais das desigualdades. Então, para a prova do teorema, basta mostrar que (a^{\\prime}\\Rightarrow b) , (b+b^{\\prime}\\Rightarrow c) e (c\\Rightarrow a) . Começamos com (a^{\\prime}\\Rightarrow b) e para tanto, consideramos F\\subseteq E fechado. Seja \\delta>0 e defina a função f_{\\delta}:E\\to\\mathbb{R} dada por f_{\\delta}(x)=\\max\\Big{\\{}1-\\frac{d(x,F)}{\\delta},0\\Big{\\}}. (3.131) Claramente, f é uniformemente contínua e vale \\1{F}\\leq f_{\\delta}\\leq\\1{B(F,\\delta)} . Dessa desigualdade, temos \\limsup_{n}\\mu_{n}(F)\\leq\\limsup_{n}\\int f_{\\delta}\\d{\\mu}_{n}=\\int f_{\\delta}% \\d{\\mu}\\leq\\mu(B(F,\\delta)) . Tomando agora o limite com \\delta\\to 0 , obtemos b) por continuidade da probabilidade \\mu . Para mostrar (b+b^{\\prime}\\Rightarrow c) , seja A\\in\\mathcal{A} tal que \\mu(\\partial A)=0 . Nesse caso, sabemos que \\begin{split}\\limsup_{n}\\mu_{n}(A)&\\leq\\limsup_{n}\\mu_{n}(\\bar{A})\\leq\\mu(\\bar% {A})=\\mu(\\mathring{A})\\\\ &\\leq\\liminf\\mu_{n}(\\mathring{A})\\leq\\liminf_{n}\\mu_{n}(A),\\end{split} o que mostra o limite em c) . Finalmente, resta mostrar (c\\Rightarrow a) e, para tanto, consideramos uma função f:E\\to\\mathbb{R} contínua e limitada. Digamos, com \\lVert f\\rVert_{\\infty}=M . Sabemos que os conjuntos \\{f^{-1}(\\{a\\})\\}_{a\\in\\mathbb{R}} são disjuntos, logo os conjuntos f^{-1}(\\{a\\}) podem ter medida \\mu positiva apenas para uma coleção enumerável de valores a\\in\\mathbb{R} . Obtemos assim uma coleção finita b_{0}<b_{1}<\\dots<b_{k} , tal que \\begin{array}[]{c}b_{0}<-M\\text{ e }b_{k}>M,\\quad b_{i+1}-b_{i}\\leq\\delta\\text% { e}\\\\ \\mu\\big{(}f^{-1}(\\{b_{i}\\})\\big{)}=0\\text{ para todo $i\\leq k$}.\\end{array} (3.132) x f(x) Figura 3.3: Uma função contínua e limitada f , os pontos b_{i} e um conjunto A_{i} . Iremos aproximar f por uma função da forma f_{\\delta}=\\sum_{i}b_{i}\\1_{A_{i}} , onde os conjuntos A_{i}=f^{-1}\\big{(}[b_{i},b_{i+1})\\big{)} são disjuntos. Obviamente f_{\\delta}\\leq f\\leq f_{\\delta}+\\delta , donde \\liminf\\int f_{\\delta}\\d{\\mu}_{n}\\leq\\liminf\\int f\\d{\\mu}_{n}\\leq\\limsup\\int f% \\d{\\mu}_{n}\\leq\\liminf\\int f_{\\delta}\\d{\\mu}_{n}+\\delta. Mas como \\int f_{\\delta}\\d{\\mu}_{n}=\\sum_{i}b_{i}\\mu_{n}(A_{i}) , a prova estará concluida se mostrarmos que \\mu_{n}(A_{i})\\to\\mu(A_{i}) para todo i\\leq k . Isso segue de d) , pois \\partial A_{i}\\subseteq f^{-1}(\\{b_{i},b_{i+1}\\}) , que tem medida zero. ∎ {exercise} Lembrando que em (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) , temos \\tfrac{1}{n}\\sum_{i=1}^{n}\\delta_{i/n}\\Rightarrow U_{[0,1]} , use o ítem d) do Teorema 3 para dar uma caracterização dos conjuntos Riemann-mensuráveis. Mais precisamente, encontre os A\\subseteq\\mathbb{R} tais que \\tfrac{1}{n}\\sum_{i=1}^{n}\\delta_{i/n}(A) converge para a medida de Lebesgue de A . \\todosec Tópico: Análise de componentes principaisvariáveis gaussianas e principal component analysis… Previous page Next page"],[["index.html","Ch3.html"],"Capítulo 3 Somas de variáveis independentes ‣ Notas de aula: Probabilidade I","Skip to content. Somas de variáveis independentes Capítulo 3 Somas de variáveis independentes Nesse capítulo introduziremos várias técnicas e resultados que serão úteis em geral, mas que aparecem naturalmente no estudo de somas de variáveis aleatórias independentes, que por sua vez é um assunto de extrema importância em teoria e aplicações de probabilidade. Previous page Next page"],[["index.html","Ch4.html","Ch4.S1.html"],"4.1 Esperança condicional ‣ Capítulo 4 Esperança condicional ‣ Notas de aula: Probabilidade I","Skip to content. Esperança condicional 4.1 Esperança condicional Como já foi dito anteriormente, a estrutura de \\sigma -álgebra tem um papel muito importante em probabilidade. Durante o curso de Teoria da Medida, muitas vezes o conceito de \\sigma -álgebra parece uma tecnicalidade que simplesmente dificulta nosso acesso ao conteúdo realmente interessante do curso. Em alguns momentos, chegamos a desejar que tudo fosse mensurável e não tivéssemos que nos preocupar com tais formalidades. Contudo, no estudo que iniciaremos agora, nos restringiremos a \\sigma -álgebras menores de maneira proposital. Ficará claro em particular, que o estudo de mensurabilidade não é uma mera tecnicalidade, mas sim uma ferramenta importante. Esse interesse, vem da necessidade de representar situações de “informação incompleta”, onde podemos apenas observar uma parte da realidade. Isso certamente é de suma importância em diversas aplicações, desde a estatística, física e computação até a teoria de jogos. Vamos começar com um exemplo simples. Suponha que \\Omega=\\mathbb{R}^{2} é dotado da \\sigma -álgebra de Borel e denotamos por X_{1},X_{2} as coordenadas canônicas. Como podemos representar matematicamente a afirmação “uma pessoa somente conhece o valor de X_{1} e não de X_{2} ”? Digamos por exemplo que essa pessoa deverá tomar uma decisão (por exemplo escolher um elemento de E ) baseando-se apenas nessa informação incompleta. A maneira que modelamos isso matemáticamente é dizendo que a decisão da pessoa deve ser uma função f:\\Omega\\to E mensurável com respeito a \\sigma(X_{1}) . Nossa primeira utilização desse conceito será feita agora ao introduzirmos a noção de esperaça condicional, que generaliza o conceito de esperança. Relembrando o cálculo (3.22), nós podemos pensar em E(X) como uma boa maneira de aproximar X por um número real. Isso por exemplo poderia ser útil se não temos nenhuma informação sobre o que ocorreu, mas ainda sim temos que tentar adivinhar o valor de X . Mas vamos agora imaginar uma outra situação, onde temos um pouco de informação sobre o que ocorreu. Voltando ao exemplo em que \\Omega=\\mathbb{R}^{2} , digamos que nós podemos observar o valor de X_{1} , mas gostaríamos de estimar o valor de X_{2} . De acordo com o que discutimos acima, nossa estimativa agora não precisa mais ser apenas um número real, podendo ser qualquer função mensurável com respeito a \\sigma(X_{1}) . Vamos no que segue tornar esse discussão rigorosa, mas antes lembramos um lema básico de Teoria da Medida. {lemma} Se f,f^{\\prime} são funções mensuráveis tais que \\int_{A}f\\d{\\mu}=\\int_{A}f^{\\prime}\\d{\\mu},\\text{ para todo $A\\in\\mathcal{F}^{% \\prime}$,} (4.1) então f=f^{\\prime} \\mu -quase certamente. Demonstração. Aplicando a hipótese para A=[f>f^{\\prime}] , vemos que \\int_{A}f-f^{\\prime}\\d{\\mu}=0, (4.2) mas no conjunto A acima, o integrando é positivo. Portanto, f=f^{\\prime} , \\mu -quase certamente em A . Aplicando o mesmo raciocínio para [f<f^{\\prime}] obtemos que f=f^{\\prime} quase certamente. ∎ O lema acima nos diz que se soubermos integrar f em todos os eventos A , então podemos recuperar a função f propriamente dita. O que aconteceria se soubéssemos integrar f apenas para eventos A em uma sub- \\sigma -álgebra? É isso que estudaremos à partir de agora. {definition} Seja uma variável aleatória X\\in\\mathcal{L}^{1}(P) e uma sub- \\sigma -álgebra \\mathcal{F}^{\\prime}\\subseteq\\mathcal{F} . Dizemos que uma variável aleatória Y é a esperança condicional de X com respeito a \\mathcal{F}^{\\prime} (ou a esperança condicional de X dada \\mathcal{F}^{\\prime} ) se  a)​ Y é \\mathcal{F}^{\\prime} -mensurável e  b)​ E(X\\1_{A})=E(Y\\1_{A}) para todo A\\in\\mathcal{F}^{\\prime} . Nesse caso, escrevemos Y=E(X|\\mathcal{F}^{\\prime}). (4.3) Observe que faz sentido escrever E\\big{(}Y|\\mathcal{F}^{\\prime}\\big{)}(\\omega) , pois E(X|\\mathcal{F}^{\\prime}) é uma variável aleatória. Interpretamos informalmente a definição acima como “ Y é a melhor aproximação \\mathcal{F}^{\\prime} -mensurável de X ”. Ou Y é a melhor aproximação que podermos fazer de X se “conhecemos apenas \\mathcal{F}^{\\prime} ”. {example} Se \\mathcal{F}^{\\prime}=\\{\\varnothing,\\Omega\\} , então Y=E(X) (uma variável aleatória constante) é esperança condicional de X dado \\mathcal{F}^{\\prime} , pois  a)​ Y é \\mathcal{F}^{\\prime} -mensurável (por ser constante). Além disso  b)​ E(X\\1_{\\varnothing})=0=E(Y\\1_{\\varnothing}) e E(X\\1_{\\Omega})=E(X)=E(Y\\1_{\\Omega}) . Uma propriedade muito importante que segue da Definição 4.1 é dada pela seguinte {proposition} Se Y satisfaz as a) e b) em Definição 4.1, então Y\\in\\mathcal{L}^{1}(P) . Demonstração. Tomamos A=[Y\\geq 0] e A^{\\prime}=[Y<0] que estão em \\mathcal{F}^{\\prime} e estimamos \\int|Y|\\d{P}=\\int_{A}Y\\d{P}+\\int_{A^{\\prime}}Y\\d{P}=\\int_{A}X\\d{P}+\\int_{A^{% \\prime}}X\\d{P}\\leq\\int|X|\\d{P}<\\infty (4.4) O que mostra a proposição. ∎ Além caso trivial dado acima pelo Exemplo 4.1, quando podemos esperar que existam esperanças condicionais? {theorem} Dada X\\in\\mathcal{L}^{1}(P) e \\mathcal{F}^{\\prime}\\subseteq\\mathcal{F} uma \\sigma -álgebra, então existe a esperança condicional E(X|\\mathcal{F}^{\\prime}) . Além disso ela é única P -quase certamente. Demonstração. Vamos primeiro mostrar a unicidade quase certa. Para isso, supomos que existam Y e Y^{\\prime} satisfazendo as condições da Definição 4.1 (logo em \\mathcal{L}^{1} ). Iremos proceder como no Lema 4.1 acima, definindo A=[Y>Y^{\\prime}] , donde concluímos que E\\big{(}(Y-Y^{\\prime})\\1_{A}\\big{)}=E(Y\\1_{A})-E(Y^{\\prime}\\1_{A})=0. (4.5) Mas como Y>Y^{\\prime} em A , vemos que Y\\leq Y^{\\prime} quase certamtente. A prova da unicidade pode ser completa trocando os papéis de Y e Y^{\\prime} acima. Vamos agora para a prova da existência. Como X\\in\\mathcal{L}^{1}(P) , podemos introduzir \\mu(A)=E(X\\1_{A}), (4.6) que define uma medida com sinal em (\\Omega,\\mathcal{F}) , com variação total finita. Caso o leitor não se sinta familiarizado com o conceito de medida com sinal, poderá decompor X em partes positiva e negativa e proceguir sem problemas. Um passo importante da prova é observar que \\mu também define uma medida no espaço (\\Omega,\\mathcal{F}^{\\prime}) . Estamos portanto propositalmente restringindo nossa \\sigma -álgebra. Como P(A)=0 implica que \\mu(A)=0 , temos que \\mu\\ll P e podemos aplicar o Teorema de Radon-Nikodim para obter uma derivada Y:\\Omega\\to\\mathbb{R} tal que  a)​ Y é \\mathcal{F}^{\\prime} -mensurável e  b)​ \\mu(A)=\\int_{A}Y\\d{P} . Agora é só observar que as afirmações acima correspondem às condições da Definição 4.1. ∎ Observe que a condição de \\mathcal{F}^{\\prime} -mensurabilidade é essencial para a unicidade. De fato, X obviamente satisfaz a segunda condição da Definição 4.1, mas não necessariamente a primeira. {exercise} Mostre que se X\\in\\mathcal{F}^{\\prime} , então E(X|\\mathcal{F}^{\\prime})=X quase certamente. {exercise} Seja P a probabilidade uniforme em \\{(x_{1},x_{2})\\in[0,1]^{2};x_{1}\\geq x_{2}\\} . Calcule E(X_{2}|X_{1}) . Previous page Next page"],[["index.html","Ch4.html","Ch4.S2.html"],"4.2 Propriedades básicas da esperança condicional ‣ Capítulo 4 Esperança condicional ‣ Notas de aula: Probabilidade I","Skip to content. Propriedades básicas da esperança condicional 4.2 Propriedades básicas da esperança condicional Nessa seção justificaremos, em certa medida, a nomenclatura “esperança condicional”. Faremos isso mostrando que ela satisfaz várias propriedades que já conhecemos para a esperança tradicional. Mas como podemos mostrar propriedades simples tais como a linearidade da esperança condicional? Vamos começar com um exemplo {proposition} Se X,X^{\\prime}\\in\\mathcal{L}^{1}(P) , então E(X+X^{\\prime}|\\mathcal{F}^{\\prime})=E(X|\\mathcal{F}^{\\prime})+E(X^{\\prime}|% \\mathcal{F}^{\\prime}),\\text{ $P$-quase certamente.} (4.7) Note que a igualdade acima é uma igualdade entre variáveis aleatórias. Demonstração. Sabemos que Y=E(X|\\mathcal{F}^{\\prime})+E(X^{\\prime}|\\mathcal{F}^{\\prime}) é uma variável aleatória bem definida. Mais do que isso, sabemos que ela é uma candidata muito boa a E(X+X^{\\prime}|\\mathcal{F}^{\\prime}) . Logo, por unicidade da esperança condicional, basta verificar que Y satisfaz as condições da Definição 4.1 com respeito a X+X^{\\prime} . De fato  a)​ Y é \\mathcal{F}^{\\prime} -mensurável, por ser uma soma de duas variáveis \\mathcal{F}^{\\prime} -mensuráveis e  b)​por linearidade da esperança (não da esperança condicional), temos \\begin{split}E(Y\\1_{A})&=E\\big{(}E(X|\\mathcal{F}^{\\prime})\\1_{A}+E(X^{\\prime}|% \\mathcal{F}^{\\prime})\\1_{A}\\big{)}\\\\ &=E\\big{(}E(X|\\mathcal{F}^{\\prime})\\1_{A}\\big{)}+E\\big{(}E(X^{\\prime}|\\mathcal% {F}^{\\prime})\\1_{A}\\big{)}\\\\ &=E(X\\1_{A})+E(X^{\\prime}\\1_{A})=E\\big{(}(X+X^{\\prime})\\1_{A}\\big{)}.\\end{split} (4.8) Isso termina a prova do proposição. ∎ {exercise} Dados X\\in\\mathcal{L}^{1} e \\alpha\\in\\mathbb{R} , mostre que E(\\alpha X|\\mathcal{F}^{\\prime})=\\alpha E(X|\\mathcal{F}^{\\prime}) . Uma outra propriedade bem simples da esperança condicional é a monotonicidade. {lemma} Se X\\geq X^{\\prime} em \\mathcal{L}^{1}(P) , então E(X|\\mathcal{F}^{\\prime})\\geq E(X^{\\prime}|\\mathcal{F}^{\\prime}),\\text{$P$-% quase certamente.} (4.9) Em particular, se X\\geq 0 , então E(X|\\mathcal{F}^{\\prime})\\geq 0 quase certamente. Demonstração. Seja A=[E(X^{\\prime}|\\mathcal{F}^{\\prime})-E(X|\\mathcal{F}^{\\prime})>0] , que pertence a \\mathcal{F}^{\\prime} . Então 0\\leq E\\big{(}(E(X^{\\prime}|\\mathcal{F}^{\\prime})-E(X|\\mathcal{F}^{\\prime}))\\1% _{A}\\big{)}=E\\big{(}(X^{\\prime}-X)\\1_{A}\\big{)}\\leq 0, (4.10) o que implica que P(A)=0 . ∎ {proposition} Se X,ZX\\in\\mathcal{L}^{1}(P) , com Z\\in\\mathcal{F}^{\\prime} , temos E(XZ|\\mathcal{F}^{\\prime})=ZE(X|\\mathcal{F}^{\\prime})\\text{ $P$-quase % certamente}. (4.11) Em particular, E(\\alpha X|\\mathcal{F}^{\\prime})=\\alpha E(X|\\mathcal{F}^{\\prime}) , para todo \\alpha\\in\\mathbb{R} . Uma outra consequência interessante é que ZE(X|\\mathcal{F}^{\\prime}) estará automaticamente em \\mathcal{L}^{1} . De maneira bastante informal, vamos dar uma intuição para o resultado acima. Ao considerarmos a esperança condicional dada \\mathcal{F}^{\\prime} , nós já conhecemos as variáveis aleatórias \\mathcal{F}^{\\prime} -mensuráveis, portanto elas se comportam como constantes. Demonstração. Mais uma vez, basta verificar que ZE(X|\\mathcal{F}^{\\prime}) satisfaz as condições que definem a esperança condicional. A primeira é trivial, pois ZE(X|\\mathcal{F}^{\\prime}) é \\mathcal{F}^{\\prime} -mensurável por ser um produto de funções \\mathcal{F}^{\\prime} -mensuráveis. Para provar a segunda condição, começamos com o caso Z=\\1_{B} , implicando que B\\in\\mathcal{F}^{\\prime} , donde E\\big{(}ZE(X|\\mathcal{F}^{\\prime})\\1_{A}\\big{)}=E\\big{(}E(X|\\mathcal{F}^{% \\prime})\\1_{A\\cap B}\\big{)}=E(X\\1_{A\\cap B})=E(ZX\\1_{A}). Por linearidade, já sabemos que o resultado vale para funções Z simples e gostaríamos de extender para quaisquer Z positivas via Teorema da Convergência Monótona. Um problema aqui é que mesmo que Z seja positiva, não sabemos se E(X|\\mathcal{F}^{\\prime}) também será positiva. Portanto, trataremos primeiramente do caso X\\geq 0 . Para tais X , sabemos pelo Lema 4.2 que E(X|\\mathcal{F}^{\\prime})\\geq 0 quase certamente. Daí, podemos concluir que ZE(X|\\mathcal{F}^{\\prime})=E(ZX|\\mathcal{F}^{\\prime}) para toda Z\\geq 0 , podemos aproximá-la por baixo por Z_{n} simples e, pelo Teorema da Convergência Monótona, \\begin{array}[]{e}E\\big{(}ZE(X|\\mathcal{F}^{\\prime})\\big{)}&\\overset{\\text{TCM% }}{=}&\\lim_{n}E\\big{(}Z_{n}E(X|\\mathcal{F}^{\\prime})\\big{)}\\\\ &=&\\lim_{n}E\\big{(}E(Z_{n}X|\\mathcal{F}^{\\prime})\\big{)}\\overset{\\text{TCM}}{=% }E\\big{(}E(ZX|\\mathcal{F}^{\\prime})\\big{)}.\\end{array} (4.12) O que mostra o resultado sempre que X\\geq 0 . Além disso, pela Proposição 4.1, sabemos que ZE(X|\\mathcal{F}^{\\prime})\\in\\mathcal{L}^{1} . Podemos finalmente concluir a prova por linearidade decompondo X=X_{+}-X_{-} . ∎ O próximo resultado tenta corroborar nossa afirmação que a esperança condicional é uma boa maneira de aproximar uma variável aleatória. {lemma} Se X\\in\\mathcal{L}^{2}(P) e \\mathcal{F}^{\\prime}\\subseteq\\mathcal{F} , então E(X|\\mathcal{F}^{\\prime}) é a projeção ortogonal de X no espaço vetorial H_{\\mathcal{F}^{\\prime}} . Onde H_{\\mathcal{F}^{\\prime}}=\\{Y\\in\\mathcal{L}^{2};Y\\text{ \\'{e} $\\mathcal{F}^{% \\prime}$-mensur\\'{a}vel}\\} . Demonstração. Temos que verificar que X-E(X|\\mathcal{F}^{\\prime}) é ortogonal a H_{\\mathcal{F}^{\\prime}} . Ou seja, mostrar que para todo Z\\in H_{\\mathcal{F}^{\\prime}} , temos E\\big{(}XZ-E(X|\\mathcal{F}^{\\prime})Z\\big{)}=0. (4.13) Note que não é claro que essa esperança faz sentido, pois não sabemos que ZE(X|\\mathcal{F}^{\\prime})\\in\\mathcal{L}^{1} . Mas isso segue facilmente da Proposição 4.2. Mas E\\big{(}E(X|\\mathcal{F}^{\\prime})Z\\big{)}=ZE\\big{(}E(X|\\mathcal{F}^{\\prime})\\1% _{\\Omega}\\big{)}=ZE\\big{(}X\\1_{\\Omega}\\big{)} , provando o resultado. 66todo: 6 Adicionar footnote. ∎ Vimos acima uma metodologia que se repete frequentemente. Digamos que queremos provar que uma determinada expressão nos dá a esperança condicional de algo. Podemos começar provando esse resultado para funções indicadoras, depois para funções simples usando a linearidade provada acima. Porém ainda falta um ingrediente bastante importante para construir ou verificar que determinadas variáveis são esperanças condicionais. {theorem} [Convergência Monótona para Esperanças Condicionais] Se as variáveis X_{n} satisfazem X_{n}\\uparrow X e estão todas em \\mathcal{L}^{1}(P) , então \\lim_{n}E(X_{n}|\\mathcal{F}^{\\prime})=E(X|\\mathcal{F}^{\\prime}). (4.14) Demonstração do Teorema 4.2. Sabemos que E(X_{n+1}|\\mathcal{F}^{\\prime})\\geq E(X_{n}|\\mathcal{F}^{\\prime}) , donde concluímos que E(X_{n}|\\mathcal{F}^{\\prime})\\uparrow Y . Vamos demosntrar que Y=E(X|\\mathcal{F}^{\\prime}) .  a)​Por ser um limite de funções \\mathcal{F}^{\\prime} mensuráveis, Y é \\mathcal{F}^{\\prime} -mensurável.  b)​Dado A\\in\\mathcal{F}^{\\prime} , temos \\begin{split}E(Y\\1_{A})&=E(\\lim_{n}E(X_{n}|\\mathcal{F}^{\\prime})\\1_{A})% \\overset{\\text{TCM}}{=}\\lim_{n}E\\big{(}E(X_{n}|\\mathcal{F}^{\\prime})\\1_{A}\\big% {)}\\\\ &=\\lim_{n}E(X_{n}\\1_{A})\\overset{\\text{TCM}}{=}E(X\\1_{A}).\\end{split} (4.15) O que termina a prova do teorema. ∎ No que segue, muitas vezes escreveremos E(X|Z) para representar a esperança condicional E(X|\\sigma(Z)) . {exercise} Sejam X_{1} e X_{2} as coordenadas canônicas em \\mathbb{R}\\times E e definimos a probabilidade \\d{P}=\\rho(x,y)\\d{\\mu}_{1}\\d{\\mu}_{2} , onde \\rho:\\mathbb{R}\\times E\\to\\mathbb{R}_{+} é uma densidade. Dê sentido à expressão abaixo e mostre que elá é E(X_{1}|X_{2}) : \\frac{\\int x\\rho(x,X_{2})\\mu_{1}(\\d{x})}{\\int\\rho(x,X_{2})\\mu_{1}(\\d{x})}. (4.16) {exercise} Seja E enumerável com uma \\sigma -álgebra \\mathcal{F}^{\\prime} . Mostre que \\mathcal{F}^{\\prime}=\\sigma(A_{i},i\\geq 1),\\text{ com $A_{i}\\subseteq E$ % disjuntos}. (4.17) Suponha que todos conjuntos A_{i} tem probabilidade positiva e mostre que E(X|\\mathcal{F}^{\\prime})=\\sum_{i}E^{i}(X)\\1_{A_{i}}, (4.18) onde E^{i} é a esperança com respeito à probabilidade P(\\cdot|A_{i}) . Em breve extenderemos esse tipo de resultado a espaços quaisquer. Uma outra propriedade que a esperança condicional herda da integral é a {proposition} [Desigualdade de Jensen] Se \\phi:\\mathbb{R}\\to\\mathbb{R} é convexa, X,\\phi(X)\\in\\mathcal{L}^{1}(P) , então \\phi\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{)}\\leq E\\big{(}\\phi(X)|\\mathcal{F}^{% \\prime}\\big{)}. (4.19) Demonstração. Se \\phi for uma função linear, o resultado segue da linearidade que já provamos para a esperança condicional. Além disso, se temos uma função \\psi:\\mathbb{R}\\to\\mathbb{R} linear e tal que \\psi(x)\\leq\\phi(x) para todo x\\in\\mathbb{R} , então E\\big{(}\\phi(X)|\\mathcal{F}^{\\prime}\\big{)}\\geq E\\big{(}\\psi(X)|\\mathcal{F}^{% \\prime}\\big{)}=\\psi\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{)}. (4.20) Tomamos finalmente o supremo em todas as \\psi lineares com \\psi\\leq\\phi dos dois lados da desigualdade acima, obtendo E\\big{(}\\phi(X)|\\mathcal{F}^{\\prime}\\big{)}\\geq\\sup_{\\begin{subarray}{c}\\psi% \\leq\\phi\\\\ \\psi\\text{ linear}\\end{subarray}}\\psi\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{)}=% \\phi\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{)}, (4.21) terminando a prova da proposição. ∎ {corollary} Se X\\in\\mathcal{L}^{1}(P) , então \\big{|}E(X|\\mathcal{F}^{\\prime})\\big{|}\\leq E\\big{(}|X|\\big{|}\\mathcal{F}^{% \\prime}\\big{)} . Uma outra propriedade interessante da esperança condicional diz respeito a sua relação com independência. {proposition} Se X\\in\\mathcal{L}^{1}(P) é independente de \\mathcal{F}^{\\prime} , então E(X|\\mathcal{F}^{\\prime})=E(X)\\text{ $P$-quase certamente.} (4.22) Demonstração. Funções constantes são sempre mensuráveis. Além disso, se A\\in\\mathcal{F}^{\\prime} , então E(X\\1_{A})=E(X)P(A)=E\\big{(}E(X)\\1_{A}\\big{)}, (4.23) concluindo a prova. ∎ Terminamos essa seção com o que chamamos da propriedade de torre da esperança condicional. {proposition} Se \\mathcal{F}^{\\prime}\\subseteq\\mathcal{F}^{\\prime\\prime} são ambas sub- \\sigma -álgebras de \\mathcal{F} , então para X\\in\\mathcal{L}^{1}(P) , temos E\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{|}\\mathcal{F}^{\\prime\\prime}\\big{)}=E(X|% \\mathcal{F}^{\\prime})=E\\big{(}E(X|\\mathcal{F}^{\\prime\\prime})\\big{|}\\mathcal{F% }^{\\prime}\\big{)}, (4.24) ou em outras palavras, independentemente da ordem, prevalece a condição na menor \\sigma -álgebra. Consequentemente, E\\big{(}E(X|\\mathcal{F}^{\\prime})\\big{)}=E(X) . Demonstração. Como E(X|\\mathcal{F}^{\\prime}) é \\mathcal{F}^{\\prime\\prime} -mensurável, a Proposição 4.2, aplicada com X=1 , mostra a primeira igualdade em (4.24). Falta mostrar que E\\big{(}E(X|\\mathcal{F}^{\\prime\\prime})\\big{|}\\mathcal{F}^{\\prime}\\big{)} é a esperança condicional de X dada \\mathcal{F}^{\\prime} . Obviamente ela é \\mathcal{F}^{\\prime} -mensurável, e nos resta verificar a segunda condição. Mas para todo A\\in\\mathcal{F}^{\\prime} , lembrando que A também pertence a \\mathcal{F}^{\\prime\\prime} e usando a definição de esperança condicional duas vezes, E\\Big{(}E\\big{(}E(X|\\mathcal{F}^{\\prime\\prime})\\big{|}\\mathcal{F}^{\\prime}\\big% {)}\\1_{A}\\Big{)}=E\\big{(}E(X|\\mathcal{F}^{\\prime\\prime})\\1_{A}\\big{)}=E(X\\1_{A% }). (4.25) O que termina a prova da proposição. ∎ {lemma} Se X:\\Omega\\to E é um elemento aleatório e f:\\Omega\\to\\mathbb{R} é \\sigma(X) -mensurável, então existe uma g:E\\to\\mathbb{R} mensurável tal que f=g\\circ X . Demonstração. Como de costume, consideramos primeiramente o caso f=\\1_{A} Claramente A tem que pertencer a \\sigma(X) , ou seja A=X^{-1}(B) para algum B\\in\\mathcal{A} . Neste caso colocamos g=\\1_{B} , donde obtemos f(\\omega)=1\\Leftrightarrow\\omega\\in A\\Leftrightarrow X(\\omega)\\in B% \\Leftrightarrow g\\circ X=1 . No caso em que f é simples, temos f=\\sum_{i}a_{i}(g_{i}\\circ X)=(\\sum_{i}a_{i}g_{i})\\circ X . Se f é positiva, então ela é um limite crescente de funções do tipo g_{n}\\circ X , além disso podemos tomar g_{n} crescentes, pois f_{n+1}=f_{n+1}\\vee f_{n}=(g_{n+1}\\circ X)\\vee(g_{n}\\circ X)=(g_{n}\\vee g_{n+1% })\\circ X. (4.26) Finalmente usamos a linearidade da composição novamente para resolver o caso geral f=f_{+}-f_{-} . ∎ Se X:\\Omega\\to E é elemento aleatório, então E(Y|\\sigma(X)) é obviamente \\sigma(X) -mensurável. Pelo lema anterior, E(Y|\\sigma(X))=g\\circ X para alguma g:E\\to\\mathbb{R} . Nesse caso denotamos E(Y|X=x)=g(x). (4.27) {exercise} Mostre que g é única X\\circ P -quase certamente. Gostaríamos de dizer que E(Y|X=x) satisfaz alguma propriedade que justifique essa notação. Apesar de que apenas na próxima seção poderemos justificar completamente essa nomenclatura, nesse momento já podemos mostrar a seguinte relação E(Y)=E\\big{(}E(Y|X)\\big{)}=E\\big{(}E(Y|X=x)\\circ X\\big{)}=\\int E(Y|X=x)(X\\circ P% )(\\d{x}). Em outras palavras, para integrar Y , basta conhecermos a distribuição de X e a esperança condicional de Y , dado que X=x . {exercise} Sejam X e Y as coordenadas canônicas em E_{1}\\times E_{2} , com a probabilidade P=\\mu_{1}\\otimes\\mu_{2} e seja f:E_{1}\\times E_{2}\\to\\mathbb{R} em \\mathcal{L}^{1}(P) . Mostre que E(f|X=x)=\\int f(x,y)\\mu_{2}(\\d{y}). (4.28) {exercise} Se K é um núcleo de transição entre E_{1} e \\mathbb{R} e P_{1} é uma probabilidade em E_{1} , mostre que em P_{1}\\star K temos E(X_{2}|X_{1}=x_{1})=\\int x_{2}K(x_{1},\\d{x}_{2}). (4.29) Um outro resultado bastante importante é o seguinte {theorem} [Teorema da Convergência Dominada para Esperanças Condicionais] Se X_{n}\\to X e existe Y\\in\\mathcal{L}^{1}(P) tal que |X_{n}|\\leq Y para todo n , então E(X_{n}|\\mathcal{F})\\to E(X|\\mathcal{F})\\text{ $P$-quase certamente.} (4.30) Demonstração. Seja Z_{n}=\\sup_{k\\geq n}|X_{k}-X| o erro máximo à partir de n . Claramente, Z_{n}\\downarrow 0 quase certamente e além disso |Z_{n}|\\leq\\sup_{k\\geq 1}|X_{k}|+|X|\\leq 2Y, (4.31) donde E(Z_{n})\\to E(0)=0 , quase certamente pelo Teorema da Convergência Dominada. Obviamente E(Z_{n}|\\mathcal{F}) é uma sequência positiva e não-crescente, logo decresce quase certamtente para algum Z . Daí, \\big{|}E(X_{n}|\\mathcal{F})-E(X|\\mathcal{F})\\big{|}\\leq E(Z_{n}|\\mathcal{F})% \\downarrow Z\\geq 0. (4.32) Mas E(Z)\\leq E\\big{(}E(Z_{n}|\\mathcal{F})\\big{)}=E(Z_{n}) . Como E(Z_{n}) vai a zero pelo Teorema da Convergência Dominada, temos que Z=0 quase certamente como gostaríamos. ∎ {exercise} Sejam Z_{1},Z_{2},\\dots variáveis aleatórias \\iidem \\mathcal{L}^{1}(P) com E(Z_{1})=0 .  a)​Defina X_{0}=0 e X_{n}=\\sum_{i=1}^{n}Z_{i},\\text{ para $n\\geq 1$.} (4.33) Mostre que E(X_{n+1}|Z_{1},\\dots,Z_{n})=X_{n} .  b)​Supondo agora que Z_{1}\\in\\mathcal{L}^{2}(P) e E(Z)=0 , defina Y_{0}=0 e Y_{n}=\\Big{(}\\sum_{i=1}^{n}Z_{i}\\Big{)}^{2}-nE(Z_{1}^{2}) (4.34) Mostre que E(Y_{n+1}|Z_{1},\\dots,Z_{n})=Y_{n} . \\todosec Tópico: Martingais a tempo discretofazer… \\todosec Tópico: Propriedade fraca de Markovmostrar que cadeias = processos… \\todosec Tópico: Recorrência e transiênciamarkov recorrência/transiência + periodicidade… Previous page Next page"],[["index.html","Ch4.html","Ch4.S3.html"],"4.3 Probabilidade Condicional Regular ‣ Capítulo 4 Esperança condicional ‣ Notas de aula: Probabilidade I","Skip to content. Probabilidade Condicional Regular 4.3 Probabilidade Condicional Regular Já sabemos definir por exemplo E(\\1_{A}|X=x) . Gostaríamos porém de garantir que essa expressão definisse uma probabilidade em A , e chamaríamos essa probabilidade de P(A|X=x) . Mas certamente gostaríamos que P(\\cdot|X=x) fosse uma função \\sigma -aditiva. Essa especulação parece promissora, por exemplo se A e B são disjuntos, P(A\\cup B|\\mathcal{F}^{\\prime})=E(\\1_{A\\cup B}|\\mathcal{F}^{\\prime})=E(\\1_{A}|% \\mathcal{F}^{\\prime})+E(\\1_{B}|\\mathcal{F}^{\\prime})=P(A|\\mathcal{F}^{\\prime})% +P(B|\\mathcal{F}^{\\prime}). Ótimo, mas ainda temos o seguinte problema. Lembramos que a equação acima está bem definida apenas quase certamente. Poderíamos portanto garantir que para uma classe enumerável de conjuntos A\\in\\mathcal{F} , essa aditividade fosse satisfeita. Porém, a \\sigma -álgebra \\mathcal{F} é frequentemente não enumerável, portanto não conseguimos a \\sigma -aditividade plena. Isso pode ser contornado se o espaço for canônico, como afirma o nosso próximo resultado. Ele nos ajudará bastante ao fazermos cálculos usando condicionais, de maneira semelhante à Lei da Probabilidade Total. Esse é o conteúdo do seguinte resultado. {theorem} [Teorema da Desintegração] Sejam espaços mensuráveis (\\Omega,\\mathcal{F}) e (E,\\mathcal{A}) , com E canônico. Se P é uma probabilidade no espaço produto (\\Omega\\times E,\\mathcal{F}\\otimes\\mathcal{A}) e denotamos por P_{\\Omega}=P\\circ X_{1} a primeira distribuição marginal de P , então existe um núcleo de transição K:\\Omega\\times\\mathcal{A}\\to[0,1] satisfazendo P=P_{\\Omega}\\star K, (4.35) Em particular, P(A\\times B)=\\int_{A}K(\\omega,B)P_{\\Omega}(\\d{\\omega})\\text{ para todo $A\\in% \\mathcal{F}$, $B\\in\\mathcal{A}$}. (4.36) Nesse caso denotamos K(\\omega,B) por P[X_{2}\\in B|X_{1}=\\omega] (como de costume X_{i} denota a i -ésima coordenada canônica). Demonstração. Como de costume, basta resolver o caso (E,\\mathcal{A})=(\\mathbb{R},\\mathcal{B}(\\mathbb{R})) . De fato, se assumimos a validade do teorema para a reta, podemos usar a função bi-mensurável \\phi:E\\to B\\in\\mathcal{B}(\\mathbb{R}) para concluir o caso geral. Nos restringiremos agora ao espaço (\\Omega\\times\\mathbb{R},\\mathcal{F}\\otimes\\mathcal{B}(\\mathbb{R}),P) . Para cada q\\in\\mathbb{Q} , definimos P^{q}_{\\Omega}:\\mathcal{F}\\to[0,1] por P^{q}_{\\Omega}(A)=P\\big{(}(-\\infty,q]\\times A\\big{)}. (4.37) Observando que P^{q}_{\\Omega} é absolutamente contínua com respeito a P_{\\Omega} , podemos definir F(\\omega,q)=\\frac{\\d{P}^{q}_{\\Omega}}{\\d{P}_{\\Omega}}(\\omega). (4.38) Observamos as seguintes propriedades de F :  a)​para cada q\\in\\mathbb{Q} , F(\\cdot,q)\\in[0,1] , P_{\\Omega} -quase certamente, pois P^{q}_{\\Omega}(A)\\leq P_{\\Omega}(A) para todo A\\in\\mathcal{F} ,  b)​para q<q^{\\prime}\\in\\mathbb{Q} , F(\\cdot,q)\\leq F(\\cdot,q^{\\prime}) , P_{\\Omega} -quase certamente, pois P^{q}_{\\Omega}(A)\\leq P^{q^{\\prime}}_{\\Omega}(A) para todo A\\in\\mathcal{F} e  c)​ F(\\cdot,n)\\to 1 (analogamente F(\\cdot,-n)\\to 0 ) quando n tende a infinito, P_{\\Omega} -quase certamente. Para ver isso, note que a sequência de variáveis aleatórias F(\\cdot,n) é quase certamente monótona não decrescente, logo converge P_{\\Omega} -quase certamente. Sendo limitada, converge em \\mathcal{L}^{1} e como sua integral em P_{\\Omega} converge para um, F(\\cdot,n)\\to 1 , quase certamente (analogamente para F(\\cdot,-n) ). Existe pois um conjunto \\Omega^{\\prime}\\in\\mathcal{F} com P_{\\Omega}(\\Omega^{\\prime})=1 no qual as três hipóteses acima são satisfeitas. Definimos \\hat{F}(\\omega,q) como sendo igual a F(\\omega,q) em \\Omega^{\\prime} e igual a F_{0}(q) (uma função de distribuição fixa) caso contrário (que claramente será mensurável). Finalmente podemos definir \\tilde{F}(\\omega,x)=\\inf_{q\\in\\mathbb{Q};q\\downarrow x}\\hat{F}(\\omega,q) , que satisfaz para todo \\omega as hipóteses do Teorema 2.3. Logo, existe para cada \\omega\\in\\Omega uma medida K(\\omega,\\cdot) em (\\mathbb{R},\\mathcal{B}(\\mathbb{R})) satisfazendo K(\\omega,(-\\infty,q])=F(\\omega,q) P_{\\Omega} -quase certamente. Precisamos mostrar que K é um núcleo, e para isso basta observar que F(\\omega,q) são mensuráveis e a família \\{(-\\infty,q];q\\in\\mathbb{Q}\\} forma um \\pi -sistema que gera \\mathcal{B}(\\mathbb{R}) . Finalmente, vamos verificar (4.36), notando que se A\\in\\mathcal{F} e B=(-\\infty,q] , \\int_{A}K(\\omega,B)P_{\\Omega}(\\d{\\omega})=\\int_{A}F(\\omega,q)P_{\\Omega}(\\d{% \\omega})=P^{q}_{\\Omega}(A)=P(A\\times B). (4.39) Como a classe B é um \\pi -sistema gerando \\mathcal{B}(\\mathbb{R}) terminamos a prova. ∎ Interpretamos P[X_{2}\\in B|X_{1}=\\omega] da seguinte forma. Se alguém tiver acesso à \\sigma -álgebra \\sigma(X_{1}) , ou seja, essa pessoa é capaz de observar o valor de \\omega , ela pode não saber o valor de X_{2} , mas já pode atualizar sua distribuição para P(X_{2}\\in\\cdot|X_{1}=\\omega) . Uma das grandes vantagens de ter um núcleo de transição a determinar uma distribuição conjunta, como foi feito acima, é que podemos usar a versão generalizada de Fubini. Antes, nós somente podiamos usar Fubini para espaços construídos através de um núcleo. {exercise} Se \\Omega=E_{1}\\times E_{2} com E_{2} canônico é dotado da probabilidade \\d{P}=\\rho(x_{1},x_{2})\\mu_{1}\\otimes\\mu_{2}(\\d{x}_{1}\\d{x}_{2}) , mostre que P(X_{2}\\in A|X_{1}=x_{1})=\\frac{\\int_{A}\\rho(x_{1},x_{2})\\mu_{2}(\\d{x}_{2})}{% \\int\\rho(x_{1},x_{2})\\mu_{2}(\\d{x}_{2})}, (4.40) (X_{1}\\circ P) -quase certamtente. {exercise} Sejam X_{1} e X_{2} as projeções canônicas em um espaço produto \\Omega\\times E , com E canônico. Então, se X_{1} e X_{2} são independentes com respeito a P , vale P[X_{2}\\in B|X_{1}=\\omega]=P[X_{2}\\in B]\\text{ para $(X_{1}\\circ P)$-quase % todo $\\omega$}. (4.41) {exercise} Considere em (\\mathbb{R}^{2},\\mathcal{B}(\\mathbb{R}^{2})) as projeções canônicas X_{1} e X_{2} . Calcule, em cada um dos exemplos abaixo, a probabilidade condicional regular P[X_{1}\\in\\cdot|X_{2}=x_{2}] , justificando sua resposta,  a)​Quando P é a medida uniforme em T=\\{(x,y)\\in[0,1]^{2};x\\leq y\\} (ou seja, a medida de Lebesgue em \\mathbb{R}^{2} restrita a T e normalizada para ser uma probabilidade).  b)​Quando P é a medida U_{S^{1}} (uniforme em S^{1} ). Previous page Next page"],[["index.html","Ch4.html","Ch4.S4.html"],"4.4 Princípio da substituição ‣ Capítulo 4 Esperança condicional ‣ Notas de aula: Probabilidade I","Skip to content. Princípio da substituição 4.4 Princípio da substituição O Teorema 4.3 é bastante poderoso e nos permite definir e calcular diversas probabilidades, como faremos à seguir. Nessa seção construiremos nossa última versão de probabilidade condicional regular que não se restringe a espaços produtos e nos fornecerá o que chamamos de Princípio da Substituição. {theorem} Sejam (\\Omega,\\mathcal{F},P) e (E,\\mathcal{A}) espaços mensuráveis canônicos. Considere também X:\\Omega\\to E um elemento aleatório, então existe um núcleo de transição K de E a \\Omega tal que K(X(\\omega),F)=E[\\1_{F}|X],\\text{ para todo $F\\in\\mathcal{F}$}. (4.42) Também denotamos esse núcleo como K(x,F)=P[F|X=x] , que é único no sentido que se K^{\\prime} também satisfaz (4.42), então K(x,F)=K^{\\prime}(x,F) para (X\\circ P) -quase todo x\\in E . Além disso vale o que chamamos de Princípio da Substituição: K(x,[X=x])=1,\\quad\\text{$X\\circ P$-quase certamente}. (4.43) Que pode ser dito de maneira estranha: P[X=x|X=x]=1 , quase certamente. \\Omega E x [X=x] Figura 4.1: O gráfico do elemento aleatório X representado horizontalmente. Os pontos marcados no eixo vertical representam o conjunto [X=x] que possui medida um segundo P[\\;\\cdot\\;|X=x] de acordo com o Teorema 4.4 Demonstração. Defina o elemento aleatório W:\\Omega\\to E\\times\\Omega , dado por W(\\omega)=(X(\\omega),\\omega) , que percorre o gráfico de X (representado horizontalmente). Observe que a medida P_{W}:=W\\circ P possui marginais (X_{1}\\circ P_{W})=(X\\circ P) e (X_{2}\\circ P_{W})=P . Como P_{W} satisfaz as condições do Teorema 4.3, existe um núcleo K:E\\times\\mathcal{F}\\to[0,1] tal que para todo A\\in\\mathcal{A} , F\\in\\mathcal{F} , P_{W}(A\\times F)=\\int_{A}K(x,F)P_{X}(\\d{x}). (4.44) Fixado F\\in\\mathcal{F} , K(X(\\omega),F) é obviamente \\sigma(X) mensurável, por ser uma composição de uma função mensurável em E com X . Logo, para provar (4.42), basta mostrar a segunda propriedade de esperanças condicionais. Se B\\in\\sigma(X) , podemos escrever B=[X\\in A] para algum A\\in\\mathcal{A} , donde \\begin{split}E\\big{[}K(X,F)\\1_{B}\\big{]}&=E\\big{[}K(X,F)\\1_{[X\\in A]}\\big{]}=% \\int_{A}K(x,F)P_{X}(\\d{x})\\\\ &=P_{W}(A\\times F)=E[\\1_{X\\in A}\\1_{F}]=E[\\1_{B}\\1_{F}],\\end{split} (4.45) concluindo a prova de (4.42). Para mostrarmos o Princípio da Substituição, vamos usar o seguinte lema. {lemma} Se X:\\Omega\\to E é um elemento aleatódio tomando valores em um espaço E canônico, então seu gráfico G=\\{(\\omega,X(\\omega));\\omega\\in\\Omega\\} é mensurável na \\sigma -álgebra produto \\mathcal{F}\\otimes\\mathcal{A} . Demonstração. Primeiramente, consideramos o caso (E,\\mathcal{A})=(\\mathbb{R},\\mathcal{B}(\\mathbb{R})) . Neste caso, vemos que G=\\bigcap_{n\\geq 1}\\bigcup_{j\\in\\mathbb{Z}}[X\\in\\big{(}j/2^{n},(j+1)/2^{n}\\big% {]}]\\times\\big{(}j/2^{n},(j+1l)/2^{n}\\big{]}, (4.46) que é mensurável. Caso E seja outro espaço canônico qualquer, existe \\phi:E\\to B\\in\\mathcal{B}(\\mathbb{R}) bi-mensurável e G=\\Phi^{-1}(G_{\\phi\\circ X}) , onde G_{\\phi\\circ X} é o gráfico de \\phi\\circ X e \\Phi(\\omega,x)=(\\omega,\\phi(x)) . Logo G também é mensurável nesse caso. ∎ Retornando à prova de (4.43), já sabemos que G^{\\prime}=\\{(X(\\omega),\\omega);\\omega\\in\\Omega\\} é mensurável. Além disso, por definição P_{W}(G^{\\prime})=P[(X(\\omega),\\omega)\\in G^{\\prime}]=P(\\Omega)=1 , ou seja a medida P_{W} tem suporte em G^{\\prime} . Logo podemos escrever \\begin{split}1=P_{W}(G^{\\prime})&=\\int\\int\\1_{G^{\\prime}}(x,\\omega)K(x,\\d{% \\omega})(X\\circ P)(\\d{x})\\\\ &=\\int K(x,[X=x])(X\\circ P)(\\d{x}).\\end{split} (4.47) Mas como o integrado acima pertence a [0,1] , essa integral só pode ser um se K(x,[X=x])=1 , (X\\circ P) -quase certamente, como desejado. ∎ {exercise} Sejam X:\\Omega\\to E e Y:\\Omega\\to E^{\\prime} elementos aleatórios com E canônico. Então existe um núcleo de transição K entre E e E^{\\prime} tal que K(X(\\omega),B)=E[\\1_{Y\\in B}|X],\\text{ para todo $B\\in\\mathcal{A}^{\\prime}$}. (4.48) Poderíamos chamar esse núcleo de K(x,B)=P[Y\\in B|X=x] . {exercise} Mostre que se K(x,F)=P[F|X=x] , então \\int f(\\omega^{\\prime})K(X(\\omega),\\d{\\omega}^{\\prime})=E(f|X)(\\omega),\\text{ % para toda $f\\in\\mathcal{F}$}. (4.49) {exercise} Se Y é variável aleatória e X:\\Omega\\to E é um elemento aleatório canônico, mostre que E(Y|X)=\\int yP(Y\\in\\d{y}|X=\\cdot)\\circ X,\\text{ $P$-q.c.} (4.50) Vamos agora mostrar uma aplicação do que foi feito acima, tentando justificar o nome Princípio da Substituição. {lemma} Se X,Y são variáveis aleatórias independentes, então a função de distribuição acumulada F de X+Y é dada por F(z)=P[X+Y\\leq z]=\\int_{-\\infty}^{\\infty}F_{Y}(z-x)(X\\circ P)(\\d{x}), (4.51) onde F_{Y}(y)=P[Y\\leq y] . Esse lema pode ser visto como uma generalização do Exercício 2.5.2 para o caso não absolutamente contínuo. Vale a pena tentar diferenciar (não rigorosamente) a equação acima em z . Demonstração. Vamos calcular \\begin{split}P[X+Y\\leq z]&=E\\big{(}E(\\1_{[X+Y\\leq z]}|X)\\big{)}\\\\ &=E\\big{(}E(\\1_{[X+Y\\leq z]}|X)\\big{)}\\\\ &=E\\Big{(}P[X+Y\\leq z|X=\\cdot)\\circ X\\Big{)}\\\\ &=E\\Big{(}P[X+Y\\leq z,X=x|X=\\cdot)\\circ X\\Big{)}\\\\ &=E\\Big{(}P[Y\\leq z-x|X=\\cdot]\\circ X\\Big{)},\\end{split} (4.52) onde P[Y+X\\leq z|X=\\cdot] representa a função x\\mapsto P[Y+X\\leq z|X=x] . Agora vamos usar a hipótese que X e Y são independentes. Isso equivale a dizer que a distribuição conjunta desse par é igual a P_{X}\\otimes P_{Y} e pela unicidade da probabilidade condicional regular temos que P[Y\\in F|X=x]=P[Y\\in F] , (X\\circ P) -quase certamente, veja Exercício 4.3. Portanto, P[X+Y\\leq z]=E\\big{(}P[Y\\leq z-\\cdot]\\circ X\\big{)}=\\int_{-\\infty}^{\\infty}F_{% Y}(z-x)(X\\circ P)(\\d{x}), (4.53) terminando a prova do lema. ∎ {exercise} Considere as medidas \\mu_{a}=\\frac{\\delta_{-1}+\\delta_{1}}{2},\\qquad\\text{e}\\qquad\\mu_{b}=\\mathcal{% N}(0,1). (4.54) e K:\\mathbb{R}\\times\\mathcal{B}(\\mathbb{R})\\to[0,1] dada por K(x,A)=\\begin{cases}\\mu_{a}(A-x),&\\text{ se $x<0$,}\\\\ \\mu_{b}(A-x),&\\text{ se $x\\geq 0$,}\\end{cases} (4.55) Mostre que  a)​ K define um núcleo de transição entre \\mathbb{R} em \\mathbb{R} .  b)​Se X_{1},X_{2},\\dots for uma cadeia de Markov em \\mathbb{R} com núcleo de transição K , então calcule   i)​ E(X_{i}) , para todo i\\geq 1 e   ii)​ \\text{Var}(X_{i}) , para todo i\\geq 1 .   iii)​Mostre que \\frac{\\sum_{i=1}^{n}X_{i}}{\\sqrt{n}}\\Rightarrow\\mathcal{N}(0,1). (4.56) Previous page Next page"],[["index.html","Ch4.html","Ch4.Sx1.html"],"Tópico: Processos de Poisson em ℝ ‣ Capítulo 4 Esperança condicional ‣ Notas de aula: Probabilidade I","Skip to content. Tópico: Processos de Poisson em Tópico: Processos de Poisson em \\mathbb{R} Nessa seção aplicaremos o conceito de Probabilidade Condicional Regular e do Princípio da Substituição para estudarmos um importante processo de chegadas chamado Processo de Poisson. O Tenente Boavista está encarregado de vigiar o Sargento Pimenta, que frequentemente dorme durante sua vigília. Para isso, Boavista tem que decidir os momentos t_{1},t_{2},\\dots\\in\\mathbb{R} que ele irá verificar se Pimenta está cochilando. Uma primeira estratégia poderia ser tomar intervalos igualmente espaçados, t_{1}=1,\\dots,t_{k}=k , mas o Sargento certamente iria dormir nos intevalos (k+\\varepsilon,k+1-\\varepsilon) sem se preocupar. Dado esse problema, o Tenente decide escolher tempos aleatórios T_{1},T_{2},\\dots Mas é importante lembrar que não são todas as distribuições que funcionarão bem, por exemplo se T_{k}-T_{k-1}\\geq a quase certamente o Sargento irá se aproveitar desse intervalinho. A primeira simplificação que o Tenente imagina para esse problema é a seguinte: dado que houve uma vistoria no instante t_{k} , então o que acontecerá à partir daí será o mesmo processo com o qual ele começou. Isso pode ser traduzido de maneira rigorosa como P\\big{[}(T_{k+1}-t_{k},T_{k+2}-t_{k},\\dots)\\in A|T_{k}=t_{k}\\big{]}=P\\big{[}(T% _{1},T_{2},\\dots)\\in A\\big{]}, (4.57) T_{k}\\circ P -quase certamente. Não iremos entrar muito em detalhes sobre qual é essa esperança condicional, pois no momento ainda estamos trabalhando heuristicamente, mas já podemos dizer que: \\begin{split}P\\big{[}T_{1}\\in A_{1},T_{2}-T_{1}\\in A_{2}\\big{]}&=E\\big{[}\\1_{T% _{1}\\in A_{1}}P[T_{2}-T_{1}\\in A_{2}|T_{1}=t_{1}]\\circ T_{1}\\big{]}\\\\ &\\overset{\\eqref{e:Poisson_incr_ind}}{=}E\\big{[}\\1_{T_{1}\\in A_{1}}P[T_{1}\\in A% _{2}]\\big{]}=P[T_{1}\\in A_{1}]P[T_{1}\\in A_{2}].\\end{split} (4.58) Procedendo de maneira análoga, podemos concluir que (T_{1},T_{2}-T_{1},T_{3}-T_{2},\\dots) são uma coleção \\iid. Agora o Tenente Boavista somente precisa escolher a distribuição de T_{1} . Para essa escolha, ele sabe que se ele não chegar em tempo t , então o Sargento Pimenta sabe que sua próxima chegada terá distribuição P[T_{1}-t\\in A|T_{1}>t] . Como o Tenente Boavista gostaria que essa essa informação fosse inútil para o Sargento Pimenta, ele escolherá P[T_{1}-t\\in A|T_{1}>t]=P[T_{1}\\in A]. (4.59) E sabemos que as distribuições \\Exp(\\lambda) , para \\lambda>0 satisfazem isso, portanto já temos um candidato ao nosso processo de vistorias, mas antes vamos introduzir algumas notações. Já podemos perceber por (4.58) que mais importante que os tempos T_{k} , serão os intervalos entre visitas X_{k}=T_{k}-T_{k-1} . Seja \\mathcal{D}\\big{(}[0,\\infty)\\big{)} o espaço de todas as funções càdlàg em \\mathbb{N} , ou seja \\mathcal{D}\\big{(}[0,\\infty)\\big{)}=\\big{\\{}f:\\mathbb{R}_{+}\\to\\mathbb{N}:f% \\text{ \\'{e} cont\\'{\\i}nua \\`{a} direita e com limite \\`{a} esquerda}\\big{\\}}. Definiremos \\Gamma:\\mathbb{R}^{\\mathbb{N}}\\to\\mathcal{D}\\big{(}[0,\\infty)\\big{)} da seguinte forma: dados (x_{1},x_{2},\\dots)\\in\\mathbb{R}^{\\mathbb{N}} , seja \\Gamma(x_{1},\\dots)=N , tal que N_{t}=\\max\\{n;\\sum_{i=1}^{n}x_{i}\\leq t\\}, (4.60) que conta quantas visitas ocorreram antes de t , veja Figura 4.2. t_{1} t_{2} t_{3} t_{4} t_{5} t_{6} t_{7} Figura 4.2: A função N_{t} definindo o número de chegadas do Processo de pontos de Poisson. Note que N é càdlàg. Poderíamos nos perguntar qual é a \\sigma -álgebra que estamos considerando no espaço \\mathcal{D}\\big{(}[0,\\infty)\\big{)} , essa é uma interessante questão que deve ser abordada em estudos mais profundos desse espaço. Mas por enquanto será suficiente considerarmos a \\sigma -álgebra induzida pelo mapa \\Gamma (a maior que ainda o deixa mensurável). Estamos prontos agora pra definir o nosso processo. {definition} Fixado \\lambda>0 , definimos um Processo de Poisson em \\mathbb{R} com parâmetro \\lambda como a lei \\mathbb{P}_{\\lambda} em \\mathcal{D}\\big{(}[0,\\infty)\\big{)} , dada por \\Gamma\\circ\\Exp(\\lambda)^{\\otimes\\mathbb{N}} . Ou em outras palavras, o processo de contagem de chegadas N_{t} , no qual os intervalos entre chegadas são independentes e distribuídos como \\Exp(\\lambda) . Lembramos que como de costume definimos X_{1},X_{2},\\dots como sendo as projeções canônicas em \\mathbb{R}^{\\mathbb{N}} onde definimos \\Exp(\\lambda)^{\\otimes\\mathbb{N}} . Como esses representam os intervalos entre chegadas, definimos também T_{k}=\\sum_{i=1}^{k}X_{i},\\text{ para $k\\geq 1$}. (4.61) Podemos agora enunciar o primeiro lema, que nos fornece a distribuição do número de chegadas em um dado tempo t\\geq 0 . {lemma} Se \\lambda>0 e t\\geq 0 , então N_{t}\\distr\\Poisson(\\lambda t) sob \\mathbb{P}_{\\lambda} . Demonstração. Vamos primeiramente ver que \\mathbb{P}_{\\lambda}[N_{t}=0]=\\mathbb{P}_{\\lambda}[X_{1}>t]=e^{-\\lambda t}, (4.62) que coincide com o caso poissoniano. Para verificar o caso arbitrário [N_{t}=k] , utilizaremos indução e os resultados de esperança condicional regular que vimos anteriormente. Primeiro, observe que se x_{1}>s , então \\Gamma(x_{1},x_{2},\\dots)(r-s)=\\Gamma(x_{1}-s,x_{2},\\dots)(r). (4.63) Logo, \\begin{array}[]{e}\\mathbb{P}_{\\lambda}[N_{t}=k]&=&\\mathbb{P}_{\\lambda}[X_{1}% \\leq t,\\Gamma(X_{2},X_{3},\\dots)(t-X_{1})=k-1]\\\\ &=&\\mathbb{E}_{\\lambda}\\Big{[}\\1_{X_{1}\\leq t}\\mathbb{P}_{\\lambda}[\\Gamma(X_{2% },X_{3},\\dots)(t-X_{1})=k-1|X_{1}]\\Big{]}\\\\ &\\overset{\\textnormal{Subst.}}{=}&\\mathbb{E}_{\\lambda}\\Big{[}\\1_{X_{1}\\leq t}% \\mathbb{P}_{\\lambda}[\\Gamma(X_{2},X_{3},\\dots)(t-x_{1})=k-1|X_{1}=x_{1}]\\circ X% _{1}\\Big{]}\\\\ &\\overset{\\textnormal{induc.}}{=}&\\mathbb{E}_{\\lambda}\\Big{[}\\1_{X_{1}\\leq t}% \\big{(}\\Poisson(\\lambda(t-x_{1}))(\\{k-1\\})\\big{)}\\circ X_{1}\\Big{]}\\\\ &=&\\mathbb{E}_{\\lambda}\\Big{[}\\1_{X_{1}\\leq t}\\frac{(\\lambda(t-X_{1}))^{k-1}e^% {-\\lambda(t-X_{1})}}{(k-1)!}\\Big{]}\\\\ &=&\\int_{0}^{t}\\frac{(\\lambda(t-x_{1}))^{k-1}e^{-\\lambda(t-x_{1})}}{(k-1)!}% \\lambda e^{-\\lambda x_{1}}\\d{x}_{1}=\\frac{\\lambda^{k}e^{-\\lambda t}}{(k-1)!}% \\frac{t^{k}}{k},\\end{array} como queríamos demonstrar. ∎ Um outro resultado importante sobre esses processos se relaciona ao fato de reiniciar o sistema em tempo t>0 . Isso é feito com o seguinte mapa \\theta_{t}:\\mathcal{D}\\big{(}[0,\\infty)\\big{)}\\to\\mathcal{D}\\big{(}[0,\\infty)% \\big{)} , que leva N em \\theta_{t}(N)(s)=N_{s+t}-N_{t}. (4.64) {exercise} Mostre que o mapa \\theta_{t} é mensurável. {lemma} Fixe \\lambda,t>0 e seja N um processo de Poisson de taxa \\lambda . Então, para k\\in\\mathbb{Z}_{+} e A mensurável, \\mathbb{P}_{\\lambda}[N_{t}=k,\\theta_{t}\\circ N\\in A]=\\mathbb{P}_{\\lambda}[N_{t% }=k]\\mathbb{P}_{\\lambda}[N\\in A]. (4.65) Em particular, isso mostra que a distribuição do processo de Poisson N é invariante pelo mapa \\theta_{t} . Demonstração. Começamos reescrevendo o evento e condicionando em T_{k} como abaixo \\begin{split}\\mathbb{P}_{\\lambda}&[N_{t}=k,\\theta_{t}\\circ N\\in A]\\\\ &=\\mathbb{P}_{\\lambda}[T_{k}\\leq t,T_{k+1}>t,\\theta_{t}\\circ N\\in A]\\\\ &=\\mathbb{E}_{\\lambda}\\big{[}{\\bf 1}_{T_{k}\\leq t}\\mathbb{E}_{\\lambda}[X_{k+1}% >t-t_{k},\\theta_{t}\\circ N\\in A|T_{k}=t_{k}]\\circ T_{k}\\big{]}\\\\ &=\\mathbb{E}_{\\lambda}\\Big{[}{\\bf 1}_{T_{k}\\leq t}\\mathbb{E}_{\\lambda}\\big{[}X% _{k+1}>t-t_{k},\\Gamma(X_{k+1}-(t-t_{k}),X_{k+2},X_{k+3},\\dots)\\in A|T_{k}=t_{k% }\\big{]}\\circ T_{k}\\Big{]},\\\\ \\intertext{que, usando que $X_{i}$ s\\~{a}o independentes e $X_{k+1}$ n\\~{a}o % tem sem mem\\'{o}ria, \\'{e} igual a}&=\\mathbb{E}_{\\lambda}\\Big{[}{\\bf 1}_{T_{k}% \\leq t}\\mathbb{P}_{\\lambda}\\big{[}X_{k+1}>t-t_{k}|T_{k}=t_{k}\\big{]}\\circ T_{k% }\\Big{]}\\mathbb{P}_{\\lambda}[N\\in A]\\\\ &=\\mathbb{P}_{\\lambda}[N_{t}=t]\\mathbb{P}_{\\lambda}[N\\in A],\\end{split} terminando a prova do lema. ∎ Como corolário do lema acima, podemos deduzir que um processo de Poisson possui incrementos independentes. Mais precisamente, {corollary} Seja N um Processo de Poisson N com taxa \\lambda>0 . Considerando também tempos 0=t_{0}<t_{1}<\\dots<t_{j} , e inteiros k_{1},\\dots,k_{j}\\geq 0 temos \\mathbb{P}_{\\lambda}\\big{[}N_{t_{1}}=k_{1},\\dots,N_{t_{j}}-N_{t_{j-1}}=k_{j}% \\big{]}=\\mathbb{P}_{\\lambda}[N_{t_{1}}=k_{1}]\\cdots\\mathbb{P}_{\\lambda}[N_{t_{% j}-t_{j-1}}=k_{j}] Demonstração. Basta observar que [N_{t_{2}}-N_{t_{1}},\\dots,N_{t_{j}}-N_{t_{j-1}}]=[N_{t_{2}-t_{1}},\\dots,N_{t_% {j}-t_{1}}-N_{t_{j-1}-t_{1}}]\\circ\\theta_{t_{1}} (4.66) e aplicar o lema para obter \\begin{split}\\mathbb{P}_{\\lambda}\\big{[}&N_{t_{1}}=k_{1},\\dots,N_{t_{j}}-N_{t_% {j-1}}=k_{j}\\big{]}\\\\ &=\\mathbb{P}_{\\lambda}[N_{t_{1}}=k_{1}]\\mathbb{P}_{\\lambda}[N_{t_{2}-t_{1}}=k_% {2},\\dots N_{t_{j}-t_{1}}-N{t_{j-1}-t_{1}}=k_{j}].\\end{split} Repetindo essa operação iterativamente, obtemos o resultado desejado. ∎ T_{1},\\dots,T_{k}\\text{ under }\\mathbb{P}^{t,k}_{\\lambda}\\overset{d}{\\sim} (4.67) x_{1}=t_{1} , x_{2}=t_{2}-t_{1},\\dots,x_{k}=t_{k}-t_{k-1} \\begin{split}\\rho^{t,k}_{\\rho}(t_{1},\\dots,t_{k})&={\\bf 1}_{0\\leq t_{1}\\leq% \\dots\\leq t_{k}\\leq t}\\;\\frac{1}{\\mathbb{P}_{\\lambda}[N_{t}=k]}\\lambda e^{-% \\lambda x_{1}}\\lambda e^{-\\lambda x_{2}}\\cdots e^{-\\lambda x_{k}}e^{-\\lambda(t% -t_{k})}\\\\ &={\\bf 1}_{0\\leq t_{1}\\leq\\dots\\leq t_{k}\\leq t}\\;\\frac{k!}{e^{-\\lambda t}(% \\lambda t)^{k}}\\lambda^{k}e^{-\\lambda t}={\\bf 1}_{0\\leq t_{1}\\leq\\dots\\leq t_{% k}\\leq t}\\;\\frac{k!}{t^{k}}.\\end{split} (4.68) Note que não depende de \\lambda . Considere variáveis uniformes U_{1},\\dots,U_{k} no intervalo [0,t] \\rho^{t,k}(u_{1},\\dots,u_{k})={\\bf 1}_{\\tilde{u}_{1},\\dots,\\tilde{u}_{k}\\in[0,% t]}\\;\\frac{1}{t^{k}} (4.69) Seja \\tilde{U}_{1}<\\dots<\\tilde{U}_{k} a versão ordenada das U_{i} ’s. (\\tilde{U}_{1},\\dots,\\tilde{U}_{k})\\overset{q.c.}{=}\\sum_{\\sigma\\text{ perm. % de $\\{1,\\dots,k\\}$}}(U_{\\sigma_{1}},\\dots,U_{\\sigma_{k}}){\\bf 1}_{0\\leq U_{% \\sigma_{1}}\\leq\\dots\\leq U_{\\sigma_{k}}\\leq t} (4.70) Então, \\begin{split}\\tilde{\\rho}^{t,k}&={\\bf 1}_{0\\leq\\tilde{u}_{1}\\leq\\dots\\leq% \\tilde{u}_{k}\\leq t}\\;\\frac{1}{t^{k}}\\sum_{\\sigma\\text{ perm. de $\\{1,\\dots,k% \\}$}}\\rho^{t,k}(\\tilde{u}_{\\sigma_{1}},\\dots,\\tilde{u}_{\\sigma_{k}})\\\\ &={\\bf 1}_{0\\leq\\tilde{u}_{1}\\leq\\dots\\leq\\tilde{u}_{k}\\leq t}\\;\\frac{k!}{t^{k% }}\\end{split} (4.71) \\todosec Tópico: Processos de Markov em tempo contínuofazer… \\todosec Tópico: Sistemas de partículasfazer… Previous page Next page"],[["index.html","Ch4.html"],"Capítulo 4 Esperança condicional ‣ Notas de aula: Probabilidade I","Skip to content. Esperança condicional Capítulo 4 Esperança condicional Previous page Next page"],[["index.html","Ch5.html"],"Capítulo 5 Soluções de exercícios ‣ Notas de aula: Probabilidade I","Skip to content. Soluções de exercícios Capítulo 5 Soluções de exercícios Solução de 3.3 Primeiramente, vamos ver qual é a distribuição de R_{0} . Vamos escrever R_{0}=E_{0}+D_{0} , onde E_{0} é o número de casas acessíveis à esquerda e D_{0} à direita. Note que E_{0} e D_{0} são independentes e identicamente distribuídas, com P[D_{0}=l]=P[X_{l}=1,X_{i}=0\\text{ para $i=0,\\dots,l-1$}]=p(1-p)^{l}. (5.1) Podemos agora calcular P[R_{0}=k]=\\sum_{l=0}^{k}P[D_{0}=l,E_{0}=k-l]=\\sum_{l=0}^{k}p^{2}(1-p)^{k}=p^{% 2}k(1-p)^{k}. (5.2) Além disso, E(R_{0})=2E(D_{0})=\\sum_{l=0}^{\\infty}lP[D_{0}=l]=2p\\sum_{l=0}^{\\infty}l(1-p)^% {l}=\\frac{2(1-p)}{p}=:m. (5.3) O que resolve o primeiro item. A grande dificuldade do segundo item é que as variáveis R_{i} não são independentes, veja por exemplo que P[R_{0}=0,R_{1}=2,R_{2}=0]=0 . Nesse caso, o método do segundo momento deve ser feito com atenção. Chamando de S_{n}=\\sum_{i=1}^{n}R_{i} , temos P\\Big{[}\\Big{|}\\frac{1}{n}S_{n}-E(R_{0})\\Big{|}>a\\Big{]}\\leq\\frac{\\text{Var}(S% _{n})}{a^{2}n^{2}}, (5.4) mas a variância da soma não se torna a soma das variâncias. De fato \\begin{split}\\text{Var}(S_{n})&=E\\Big{(}\\big{(}\\sum_{i=1}^{n}(R_{i}-E(R_{i}))% \\big{)}^{2}\\Big{)}=\\sum_{i=1}^{n}\\sum_{j=1}^{n}E\\Big{(}\\big{(}R_{i}-E(R_{i})% \\big{)}\\big{(}R_{j}-E(R_{j})\\big{)}\\Big{)}\\\\ &=\\sum_{i=1}^{n}\\sum_{j=1}^{n}\\text{Cov}(R_{i},R_{j})=n\\text{Var}(R_{0})+2\\sum% _{k=1}^{n-1}(n-k)\\text{Cov}(R_{0},R_{k}).\\end{split} (5.5) Aqui já temos metade da estimativa resolvida, mas ainda falta obter uma estimativa explícita. Então precisamos estimar superiormente \\text{Cov}(R_{i},R_{j})=\\text{Cov}(R_{0},R_{j-1}) . Podemos calcular essa quantidade explicitamente, mas vamos evitar contas chatas fazendo uma estimativa do tipo \\text{Cov}(R_{0},R_{k})\\leq c\\exp\\{-c^{\\prime}k\\},\\text{ para todo $k\\geq 1$}. (5.6) O que nos daria que \\text{Var}(S_{n})\\leq n\\text{Var}(R_{0})+2\\sum_{k=1}^{n-1}(n-k)c\\exp\\{-c^{% \\prime}k\\}\\leq c^{\\prime\\prime}n. (5.7) Donde a probabilidade que queríamos estimar é no máximo {c}/{a^{2}n} , como no caso independente. Para obter a prometida cota para a covariância, observe que podemos truncar D_{0} e E_{k} para obter independência. Definindo \\tilde{R_{0}}=E_{0}+(D_{0}\\wedge\\lfloor k/2\\rfloor)\\text{ e }\\tilde{R}_{k}=D_{% k}+(E_{k}\\wedge\\lfloor k/2\\rfloor), (5.8) temos que \\tilde{R}_{0} e \\tilde{R}_{k} são independentes (pois dependem de elos disjuntos). Daí \\begin{split}\\text{Cov}(R_{0},R_{k})&=E(R_{0}R_{k})-m^{2}\\\\ &=E(\\tilde{R}_{0}\\tilde{R_{k}})+E(R_{0}R_{k}\\1{[R_{0}\\neq\\tilde{R}_{0}]\\cup[R_% {k}\\neq\\tilde{R}_{k}]})-m^{2}\\\\ &\\leq E(\\tilde{R}_{0})^{2}-m^{2}+E\\big{(}(E_{0}+D_{0})(E_{k}+D_{k})\\1{[R_{0}% \\neq\\tilde{R}_{0}]\\cup[R_{k}\\neq\\tilde{R}_{k}]}\\big{)}\\\\ &\\leq E\\big{(}(E_{0}+k+D_{k})^{2}\\1{[R_{0}\\neq\\tilde{R}_{0}]\\cup[R_{k}\\neq% \\tilde{R}_{k}]}\\big{)}\\\\ &=E\\big{(}(E_{0}+k+D_{k})^{2}\\big{)}P\\big{(}[R_{0}\\neq\\tilde{R}_{0}]\\cup[R_{k}% \\neq\\tilde{R}_{k}]\\big{)}\\\\ &\\leq\\big{(}2E(E_{0}^{2})+k^{2}+2kE(E_{0})+E(E_{0})^{2}\\big{)}\\cdot 2\\cdot P[R% _{0}\\neq\\tilde{R}_{0}]\\\\ &\\leq ck^{2}(1-p)^{\\lfloor k/2\\rfloor}\\leq c\\exp\\{-c^{\\prime}k\\}.\\end{split} (5.9) Finalizando a cota para a covariância. Previous page Next page"],[["index.html","Chx1.html"],"Licença ‣ Notas de aula: Probabilidade I","Skip to content. Licença Licença Esse trabalho é licenciado nos termos da licença Creative Commons Atribuição-CompartilhaIgual 3.0 Não Adaptada (CC BY-SA 3.0). Assim, qualquer um pode usar, distribuir e modificar o conteúdo em obras derivadas livremente, incluindo para fins comerciais, desde com a devida citação da fonte. Qualquer violação dos termos da licença citada será considerado uso ilegal. Previous page Next page"],[["index.html","Chx2.html"],"Contribuições ‣ Notas de aula: Probabilidade I","Skip to content. Contribuições Contribuições Somos gratos especialmente a Hubert Lacoin, pela revisão do texto, assim como pelas colaborações autorais. Também gostaríamos de agradecer Roberto Imbuzeiro de Oliveira Milton Jara Cláudio Landim Conrado Costa Rangel Baldasso por diversas discussões, sugestões e correções. Previous page Next page"],[["index.html","bib.html"],"Referências ‣ Notas de aula: Probabilidade I","Skip to content. Referências Referências [1] B. Bollobás and O. Riordan (2006) Percolation. Cambridge University Press. External Links: ISBN 9780521872324, LCCN 2006287798, Link Cited by: Capítulo 2. [2] G. Grimmett (1999) Percolation. Second edition, Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences], Vol. 321, Springer-Verlag, Berlin. External Links: ISBN 3-540-64902-6, MathReview (Neal Madras) Cited by: Capítulo 2. Previous page Next page"],[["index.html","idx.html"],"Índice Remissivo ‣ Notas de aula: Probabilidade I","Skip to content. Índice Remissivo Índice Remissivo ] §1.1 anel de conjuntos §2.6.1 bi-mensurável §2.10 Cadia de Markov Capítulo 2 càdlàg item c condição de compatibilidade §2.6.2 conjunto livre de somas Capítulo 2 continuidade no vazio §2.6.1 convergência fraca §3.8.2 coordenadas canônicas §2.6.2 densidade §2.2 Desigualdade de Markov §3.1.1 distribuição §1.4.1 binomial item b conjunta §2.7 de Bernoulli item a de Poisson Capítulo 2 exponencial item b geométrica item c, §2.8 marginal §2.6.2 normal §3.8.1 uniforme item a \\d{P}=\\rho\\d{\\mu} §2.2 elemento aleatório §1.4 espaço mensurável §1.1 espaço amostral §1.1 canônico §2.10 polonês §2.10.1 esperança §3.1 condicional §4.1 aditividade §4.2 desigualdade de Jensen §4.2 monotonicidade §4.2 T.C.D. §4.2 T.C.M. §4.2 torre §4.2 evento Capítulo 1, §1.1 flutuações Figura 3.2 função geradora de momentos §3.6 taxa §3.7 função de distribuição §2.3 F_{X} §2.3 inclusão e exclusão item c independência de elementos §2.5.2 de eventos §2.5, §2.5.1, §2.5.1 de \\sigma -álgebras §2.5.2 \\lambda -sistema §1.3 Lei \\{0,1\\} de Kolmogorov §3.5 dos Pequenos Números Capítulo 2 Forte dos Grandes Números §3.4 Fraca dos Grandes Números §3.3 Método Probabilístico Capítulo 2 momento primeiro §3.2 segundo Capítulo 3 \\lVert\\mu_{1}-\\mu_{2}\\rVert Capítulo 2 núcleo de transição §2.9 Paradoxo de Bertrand Capítulo 1 passeio aleatório simples Capítulo 2 \\pi -sistema §1.3 Princípio da Substituição §4.4, Capítulo 4 de Grandes Desvios §3.7 Princípio de Grandes Desvios §3.7 probabilidade §1.2 condicional §2.8 Processo de Poisson Capítulo 4 sequências intercambiáveis Capítulo 2 \\sigma -álgebra §1.1 caudal §3.5 de borel §1.1 gerada por \\mathcal{G} §1.1 trivial §3.5 Teorema Central do Limite §3.8.4 da Desintegração §4.3 da Extensão de Caratheodory §2.6.1 da Extensão §2.10, §2.6.2 de Dynkin §1.3 de Fubini para Núcleos §2.9 de Portmanteau Capítulo 3 trasformada de Laplace §3.6 variação total Capítulo 2 variância §3.2 variável aleatória item a integrável §3.1 X\\distr\\mu item b X\\distr Y item a Previous page"],[["index.html"],"Notas de aula: Probabilidade I","Skip to content. Notas de aula: Probabilidade I Notas de aula: Probabilidade I Augusto Teixeira Next page"]]